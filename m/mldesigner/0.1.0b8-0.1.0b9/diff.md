# Comparing `tmp/mldesigner-0.1.0b8-py3-none-any.whl.zip` & `tmp/mldesigner-0.1.0b9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,67 +1,77 @@
-Zip file size: 84443 bytes, number of entries: 65
--rw-rw-rw-  2.0 fat      992 b- defN 22-Oct-26 10:06 mldesigner/__init__.py
--rw-rw-rw-  2.0 fat    10394 b- defN 22-Oct-26 10:06 mldesigner/_component.py
--rw-rw-rw-  2.0 fat    28093 b- defN 22-Oct-26 10:06 mldesigner/_component_executor.py
--rw-rw-rw-  2.0 fat     2726 b- defN 22-Oct-26 10:06 mldesigner/_component_generator.py
--rw-rw-rw-  2.0 fat      469 b- defN 22-Oct-26 10:06 mldesigner/_component_loader.py
--rw-rw-rw-  2.0 fat     4292 b- defN 22-Oct-26 10:06 mldesigner/_constants.py
--rw-rw-rw-  2.0 fat    14617 b- defN 22-Oct-26 10:06 mldesigner/_dependent_component_executor.py
--rw-rw-rw-  2.0 fat     4648 b- defN 22-Oct-26 10:06 mldesigner/_exceptions.py
--rw-rw-rw-  2.0 fat     6117 b- defN 22-Oct-26 10:06 mldesigner/_get_root_pipeline_context.py
--rw-rw-rw-  2.0 fat    20761 b- defN 22-Oct-26 10:06 mldesigner/_input_output.py
--rw-rw-rw-  2.0 fat     1431 b- defN 22-Oct-26 10:06 mldesigner/_logger_factory.py
--rw-rw-rw-  2.0 fat     3855 b- defN 22-Oct-26 10:06 mldesigner/_reference_component.py
--rw-rw-rw-  2.0 fat     9344 b- defN 22-Oct-26 10:06 mldesigner/_utils.py
--rw-rw-rw-  2.0 fat       21 b- defN 22-Oct-26 10:15 mldesigner/_version.py
--rw-rw-rw-  2.0 fat      267 b- defN 22-Oct-26 10:06 mldesigner/_cli/__init__.py
--rw-rw-rw-  2.0 fat    10351 b- defN 22-Oct-26 10:06 mldesigner/_cli/mldesigner_commands.py
--rw-rw-rw-  2.0 fat      267 b- defN 22-Oct-26 10:06 mldesigner/_compile/__init__.py
--rw-rw-rw-  2.0 fat     5161 b- defN 22-Oct-26 10:06 mldesigner/_compile/_base_compiler.py
--rw-rw-rw-  2.0 fat     2534 b- defN 22-Oct-26 10:06 mldesigner/_compile/_compile.py
--rw-rw-rw-  2.0 fat     9964 b- defN 22-Oct-26 10:06 mldesigner/_compile/_compile_collector.py
--rw-rw-rw-  2.0 fat    10247 b- defN 22-Oct-26 10:06 mldesigner/_compile/_compile_impl.py
--rw-rw-rw-  2.0 fat     1940 b- defN 22-Oct-26 10:06 mldesigner/_compile/_component_compiler.py
--rw-rw-rw-  2.0 fat      720 b- defN 22-Oct-26 10:06 mldesigner/_compile/_internal_component_compiler.py
--rw-rw-rw-  2.0 fat     5559 b- defN 22-Oct-26 10:06 mldesigner/_compile/_pipeline_component_compiler.py
--rw-rw-rw-  2.0 fat      267 b- defN 22-Oct-26 10:06 mldesigner/_execute/__init__.py
--rw-rw-rw-  2.0 fat     8272 b- defN 22-Oct-26 10:06 mldesigner/_execute/_execute.py
--rw-rw-rw-  2.0 fat      236 b- defN 22-Oct-26 10:06 mldesigner/_export/__init__.py
--rw-rw-rw-  2.0 fat     1124 b- defN 22-Oct-26 10:06 mldesigner/_export/_export.py
--rw-rw-rw-  2.0 fat     2768 b- defN 22-Oct-26 10:06 mldesigner/_export/_export_impl.py
--rw-rw-rw-  2.0 fat     3163 b- defN 22-Oct-26 10:06 mldesigner/_export/_parse_url.py
--rw-rw-rw-  2.0 fat      729 b- defN 22-Oct-26 10:06 mldesigner/_export/export.py
--rw-rw-rw-  2.0 fat      336 b- defN 22-Oct-26 10:06 mldesigner/_generate/__init__.py
--rw-rw-rw-  2.0 fat     2177 b- defN 22-Oct-26 10:06 mldesigner/_generate/_assets_entity.py
--rw-rw-rw-  2.0 fat     1549 b- defN 22-Oct-26 10:06 mldesigner/_generate/_assets_schema.py
--rw-rw-rw-  2.0 fat     5549 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generate_package.py
--rw-rw-rw-  2.0 fat    12378 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generate_package_impl.py
--rw-rw-rw-  2.0 fat      267 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/__init__.py
--rw-rw-rw-  2.0 fat     3996 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_base_component_generator.py
--rw-rw-rw-  2.0 fat     1428 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_base_generator.py
--rw-rw-rw-  2.0 fat     3383 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_components_generator.py
--rw-rw-rw-  2.0 fat     3672 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_components_impl_generator.py
--rw-rw-rw-  2.0 fat     1545 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_constants.py
--rw-rw-rw-  2.0 fat     1434 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_doc_generator.py
--rw-rw-rw-  2.0 fat      869 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_init_generator.py
--rw-rw-rw-  2.0 fat     4767 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_module_generator.py
--rw-rw-rw-  2.0 fat     3316 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_package_generator.py
--rw-rw-rw-  2.0 fat     4098 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_param_generator.py
--rw-rw-rw-  2.0 fat      577 b- defN 22-Oct-26 10:06 mldesigner/_generate/_generators/_setup_generator.py
--rw-rw-rw-  2.0 fat      489 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/_components.template
--rw-rw-rw-  2.0 fat      407 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/_components_impl.template
--rw-rw-rw-  2.0 fat      322 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/_components_init.template
--rw-rw-rw-  2.0 fat     4137 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/conf.py.template
--rw-rw-rw-  2.0 fat      184 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/index.rst.template
--rw-rw-rw-  2.0 fat      604 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/setup.template
--rw-rw-rw-  2.0 fat     1003 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/single_component_entity.template
--rw-rw-rw-  2.0 fat     1175 b- defN 22-Oct-26 10:06 mldesigner/_generate/templates/single_component_reference.template
--rw-rw-rw-  2.0 fat      362 b- defN 22-Oct-26 10:06 mldesigner/_operations/__init__.py
--rw-rw-rw-  2.0 fat     2280 b- defN 22-Oct-26 10:06 mldesigner/_operations/_component_operations.py
--rw-rw-rw-  2.0 fat      870 b- defN 22-Oct-26 10:06 mldesigner/dsl/__init__.py
--rw-rw-rw-  2.0 fat     2386 b- defN 22-Oct-26 10:06 mldesigner/dsl/_condition_output.py
--rw-rw-rw-  2.0 fat     6806 b- defN 22-Oct-26 10:15 mldesigner-0.1.0b8.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 22-Oct-26 10:15 mldesigner-0.1.0b8.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       72 b- defN 22-Oct-26 10:15 mldesigner-0.1.0b8.dist-info/entry_points.txt
--rw-rw-rw-  2.0 fat       11 b- defN 22-Oct-26 10:15 mldesigner-0.1.0b8.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     6235 b- defN 22-Oct-26 10:15 mldesigner-0.1.0b8.dist-info/RECORD
-65 files, 250105 bytes uncompressed, 74273 bytes compressed:  70.3%
+Zip file size: 109078 bytes, number of entries: 75
+-rw-rw-rw-  2.0 fat      992 b- defN 22-Dec-06 06:55 mldesigner/__init__.py
+-rw-rw-rw-  2.0 fat    13024 b- defN 22-Dec-06 06:55 mldesigner/_component.py
+-rw-rw-rw-  2.0 fat    29503 b- defN 22-Dec-06 06:55 mldesigner/_component_executor.py
+-rw-rw-rw-  2.0 fat     2726 b- defN 22-Dec-06 06:55 mldesigner/_component_generator.py
+-rw-rw-rw-  2.0 fat    16081 b- defN 22-Dec-06 06:55 mldesigner/_component_loader.py
+-rw-rw-rw-  2.0 fat     5116 b- defN 22-Dec-06 06:55 mldesigner/_constants.py
+-rw-rw-rw-  2.0 fat    17086 b- defN 22-Dec-06 06:55 mldesigner/_dependent_component_executor.py
+-rw-rw-rw-  2.0 fat     4648 b- defN 22-Dec-06 06:55 mldesigner/_exceptions.py
+-rw-rw-rw-  2.0 fat     6135 b- defN 22-Dec-06 06:55 mldesigner/_get_root_pipeline_context.py
+-rw-rw-rw-  2.0 fat    26738 b- defN 22-Dec-06 06:55 mldesigner/_input_output.py
+-rw-rw-rw-  2.0 fat     1431 b- defN 22-Dec-06 06:55 mldesigner/_logger_factory.py
+-rw-rw-rw-  2.0 fat     4699 b- defN 22-Dec-06 06:55 mldesigner/_reference_component.py
+-rw-rw-rw-  2.0 fat    15136 b- defN 22-Dec-06 06:55 mldesigner/_utils.py
+-rw-rw-rw-  2.0 fat       21 b- defN 22-Dec-06 07:01 mldesigner/_version.py
+-rw-rw-rw-  2.0 fat      267 b- defN 22-Dec-06 06:55 mldesigner/_cli/__init__.py
+-rw-rw-rw-  2.0 fat    10403 b- defN 22-Dec-06 06:55 mldesigner/_cli/mldesigner_commands.py
+-rw-rw-rw-  2.0 fat      267 b- defN 22-Dec-06 06:55 mldesigner/_compile/__init__.py
+-rw-rw-rw-  2.0 fat     6160 b- defN 22-Dec-06 06:55 mldesigner/_compile/_base_compiler.py
+-rw-rw-rw-  2.0 fat     2534 b- defN 22-Dec-06 06:55 mldesigner/_compile/_compile.py
+-rw-rw-rw-  2.0 fat    10500 b- defN 22-Dec-06 06:55 mldesigner/_compile/_compile_collector.py
+-rw-rw-rw-  2.0 fat    10827 b- defN 22-Dec-06 06:55 mldesigner/_compile/_compile_impl.py
+-rw-rw-rw-  2.0 fat     1940 b- defN 22-Dec-06 06:55 mldesigner/_compile/_component_compiler.py
+-rw-rw-rw-  2.0 fat      720 b- defN 22-Dec-06 06:55 mldesigner/_compile/_internal_component_compiler.py
+-rw-rw-rw-  2.0 fat     6067 b- defN 22-Dec-06 06:55 mldesigner/_compile/_pipeline_component_compiler.py
+-rw-rw-rw-  2.0 fat      267 b- defN 22-Dec-06 06:55 mldesigner/_execute/__init__.py
+-rw-rw-rw-  2.0 fat     8474 b- defN 22-Dec-06 06:55 mldesigner/_execute/_execute.py
+-rw-rw-rw-  2.0 fat      236 b- defN 22-Dec-06 06:55 mldesigner/_export/__init__.py
+-rw-rw-rw-  2.0 fat     5791 b- defN 22-Dec-06 06:55 mldesigner/_export/_cycle_validator.py
+-rw-rw-rw-  2.0 fat     1124 b- defN 22-Dec-06 06:55 mldesigner/_export/_export.py
+-rw-rw-rw-  2.0 fat     4449 b- defN 22-Dec-06 06:55 mldesigner/_export/_export_impl.py
+-rw-rw-rw-  2.0 fat     3031 b- defN 22-Dec-06 06:55 mldesigner/_export/_parse_url.py
+-rw-rw-rw-  2.0 fat      336 b- defN 22-Dec-06 06:55 mldesigner/_generate/__init__.py
+-rw-rw-rw-  2.0 fat     2177 b- defN 22-Dec-06 06:55 mldesigner/_generate/_assets_entity.py
+-rw-rw-rw-  2.0 fat     1549 b- defN 22-Dec-06 06:55 mldesigner/_generate/_assets_schema.py
+-rw-rw-rw-  2.0 fat     5549 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generate_package.py
+-rw-rw-rw-  2.0 fat    12378 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generate_package_impl.py
+-rw-rw-rw-  2.0 fat      267 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/__init__.py
+-rw-rw-rw-  2.0 fat     3996 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_base_component_generator.py
+-rw-rw-rw-  2.0 fat     1428 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_base_generator.py
+-rw-rw-rw-  2.0 fat     3448 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_component_func_generator.py
+-rw-rw-rw-  2.0 fat     3383 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_components_generator.py
+-rw-rw-rw-  2.0 fat     3672 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_components_impl_generator.py
+-rw-rw-rw-  2.0 fat     1545 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_constants.py
+-rw-rw-rw-  2.0 fat     1434 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_doc_generator.py
+-rw-rw-rw-  2.0 fat      869 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_init_generator.py
+-rw-rw-rw-  2.0 fat     5391 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_module_generator.py
+-rw-rw-rw-  2.0 fat     3316 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_package_generator.py
+-rw-rw-rw-  2.0 fat     4098 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_param_generator.py
+-rw-rw-rw-  2.0 fat     4682 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_pipeline_code_generator.py
+-rw-rw-rw-  2.0 fat     6496 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_pipeline_generator.py
+-rw-rw-rw-  2.0 fat     4233 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_pipelines_generator.py
+-rw-rw-rw-  2.0 fat      577 b- defN 22-Dec-06 06:55 mldesigner/_generate/_generators/_setup_generator.py
+-rw-rw-rw-  2.0 fat      136 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_azureml_config.template
+-rw-rw-rw-  2.0 fat      489 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_components.template
+-rw-rw-rw-  2.0 fat      121 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_components_code_def.template
+-rw-rw-rw-  2.0 fat      407 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_components_impl.template
+-rw-rw-rw-  2.0 fat      322 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_components_init.template
+-rw-rw-rw-  2.0 fat     2194 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_pipeline_def.template
+-rw-rw-rw-  2.0 fat     2859 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/_run.template
+-rw-rw-rw-  2.0 fat     4137 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/conf.py.template
+-rw-rw-rw-  2.0 fat      184 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/index.rst.template
+-rw-rw-rw-  2.0 fat      604 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/setup.template
+-rw-rw-rw-  2.0 fat     1003 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/single_component_entity.template
+-rw-rw-rw-  2.0 fat     1175 b- defN 22-Dec-06 06:55 mldesigner/_generate/templates/single_component_reference.template
+-rw-rw-rw-  2.0 fat      362 b- defN 22-Dec-06 06:55 mldesigner/_operations/__init__.py
+-rw-rw-rw-  2.0 fat     2280 b- defN 22-Dec-06 06:55 mldesigner/_operations/_component_operations.py
+-rw-rw-rw-  2.0 fat      882 b- defN 22-Dec-06 06:55 mldesigner/dsl/__init__.py
+-rw-rw-rw-  2.0 fat     2107 b- defN 22-Dec-06 06:55 mldesigner/dsl/_condition_output.py
+-rw-rw-rw-  2.0 fat     5483 b- defN 22-Dec-06 06:55 mldesigner/dsl/_dynamic.py
+-rw-rw-rw-  2.0 fat    10807 b- defN 22-Dec-06 06:55 mldesigner/dsl/_dynamic_executor.py
+-rw-rw-rw-  2.0 fat     7487 b- defN 22-Dec-06 07:01 mldesigner-0.1.0b9.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 22-Dec-06 07:01 mldesigner-0.1.0b9.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       72 b- defN 22-Dec-06 07:01 mldesigner-0.1.0b9.dist-info/entry_points.txt
+-rw-rw-rw-  2.0 fat       11 b- defN 22-Dec-06 07:01 mldesigner-0.1.0b9.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     7324 b- defN 22-Dec-06 07:01 mldesigner-0.1.0b9.dist-info/RECORD
+75 files, 337755 bytes uncompressed, 97118 bytes compressed:  71.2%
```

## zipnote {}

```diff
@@ -75,26 +75,26 @@
 
 Filename: mldesigner/_execute/_execute.py
 Comment: 
 
 Filename: mldesigner/_export/__init__.py
 Comment: 
 
+Filename: mldesigner/_export/_cycle_validator.py
+Comment: 
+
 Filename: mldesigner/_export/_export.py
 Comment: 
 
 Filename: mldesigner/_export/_export_impl.py
 Comment: 
 
 Filename: mldesigner/_export/_parse_url.py
 Comment: 
 
-Filename: mldesigner/_export/export.py
-Comment: 
-
 Filename: mldesigner/_generate/__init__.py
 Comment: 
 
 Filename: mldesigner/_generate/_assets_entity.py
 Comment: 
 
 Filename: mldesigner/_generate/_assets_schema.py
@@ -111,14 +111,17 @@
 
 Filename: mldesigner/_generate/_generators/_base_component_generator.py
 Comment: 
 
 Filename: mldesigner/_generate/_generators/_base_generator.py
 Comment: 
 
+Filename: mldesigner/_generate/_generators/_component_func_generator.py
+Comment: 
+
 Filename: mldesigner/_generate/_generators/_components_generator.py
 Comment: 
 
 Filename: mldesigner/_generate/_generators/_components_impl_generator.py
 Comment: 
 
 Filename: mldesigner/_generate/_generators/_constants.py
@@ -135,26 +138,47 @@
 
 Filename: mldesigner/_generate/_generators/_package_generator.py
 Comment: 
 
 Filename: mldesigner/_generate/_generators/_param_generator.py
 Comment: 
 
+Filename: mldesigner/_generate/_generators/_pipeline_code_generator.py
+Comment: 
+
+Filename: mldesigner/_generate/_generators/_pipeline_generator.py
+Comment: 
+
+Filename: mldesigner/_generate/_generators/_pipelines_generator.py
+Comment: 
+
 Filename: mldesigner/_generate/_generators/_setup_generator.py
 Comment: 
 
+Filename: mldesigner/_generate/templates/_azureml_config.template
+Comment: 
+
 Filename: mldesigner/_generate/templates/_components.template
 Comment: 
 
+Filename: mldesigner/_generate/templates/_components_code_def.template
+Comment: 
+
 Filename: mldesigner/_generate/templates/_components_impl.template
 Comment: 
 
 Filename: mldesigner/_generate/templates/_components_init.template
 Comment: 
 
+Filename: mldesigner/_generate/templates/_pipeline_def.template
+Comment: 
+
+Filename: mldesigner/_generate/templates/_run.template
+Comment: 
+
 Filename: mldesigner/_generate/templates/conf.py.template
 Comment: 
 
 Filename: mldesigner/_generate/templates/index.rst.template
 Comment: 
 
 Filename: mldesigner/_generate/templates/setup.template
@@ -174,23 +198,29 @@
 
 Filename: mldesigner/dsl/__init__.py
 Comment: 
 
 Filename: mldesigner/dsl/_condition_output.py
 Comment: 
 
-Filename: mldesigner-0.1.0b8.dist-info/METADATA
+Filename: mldesigner/dsl/_dynamic.py
+Comment: 
+
+Filename: mldesigner/dsl/_dynamic_executor.py
+Comment: 
+
+Filename: mldesigner-0.1.0b9.dist-info/METADATA
 Comment: 
 
-Filename: mldesigner-0.1.0b8.dist-info/WHEEL
+Filename: mldesigner-0.1.0b9.dist-info/WHEEL
 Comment: 
 
-Filename: mldesigner-0.1.0b8.dist-info/entry_points.txt
+Filename: mldesigner-0.1.0b9.dist-info/entry_points.txt
 Comment: 
 
-Filename: mldesigner-0.1.0b8.dist-info/top_level.txt
+Filename: mldesigner-0.1.0b9.dist-info/top_level.txt
 Comment: 
 
-Filename: mldesigner-0.1.0b8.dist-info/RECORD
+Filename: mldesigner-0.1.0b9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mldesigner/_component.py

```diff
@@ -1,34 +1,102 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access, unused-argument
 
+import copy
 import functools
 import inspect
-import types
+from collections import OrderedDict
 from os import PathLike
 from pathlib import Path
 from typing import Any, Callable, TypeVar, Union
 
 from mldesigner._component_executor import ComponentExecutor, ExecutorBase
 from mldesigner._exceptions import ComponentDefiningError
-from mldesigner._utils import _relative_to, _resolve_source_directory, _resolve_source_file, is_valid_name
+from mldesigner._utils import _copy_func, _relative_to, _resolve_source_directory, _resolve_source_file, is_valid_name
 
 # hint vscode intellisense
 _TFunc = TypeVar("_TFunc", bound=Callable[..., Any])
 SPEC_EXT = ".spec.yaml"
 
 
+def _validate_component_name(name: str):
+    if name and not is_valid_name(name):
+        msg = "Name is not valid, it could only contains a-z, A-Z, 0-9 and '.-_', got '%s'." % name
+        raise ComponentDefiningError(name, msg)
+
+
+def _create_executor(EXECUTOR_CLASS, func, code, entity_args):
+    # pylint: disable=isinstance-second-argument-not-valid-type
+    if not isinstance(func, Callable):
+        raise ComponentDefiningError(
+            name=None,
+            cause=f"Mldesigner component decorator accept only function type, got {type(func)}.",
+        )
+    return_annotation = EXECUTOR_CLASS._get_outputs_from_return_annotation(func=func)
+
+    entity_args = EXECUTOR_CLASS._refine_entity_args(entity_args, return_annotation)
+
+    entity_args["name"] = entity_args.get("name", func.__name__)
+    entity_args["display_name"] = entity_args.get("display_name", entity_args["name"])
+    entity_args["description"] = entity_args.get("description", func.__doc__)
+    # pop description if not set, otherwise it's None value and will raise error when load schema
+    if entity_args["description"] is None:
+        entity_args.pop("description")
+    func_entry_path = _resolve_source_file()
+    if not func_entry_path:
+        func_entry_path = Path(inspect.getfile(func)).resolve().absolute()
+        # if component defined in a .ipynb the path is a pseudo path and it will interfere component entity
+        # generation or component compile
+        if not Path(func_entry_path).exists():
+            msg = (
+                f"Component source path not found: '{func_entry_path}'. If the component is defined inside "
+                f"'.ipynb' please try to define it in a separate '.py' file."
+            )
+            raise ComponentDefiningError(entity_args["name"], msg)
+
+    # Fall back to func entry directory if not specified.
+    entity_args["source_path"] = str(func_entry_path)
+    entity_args["code"] = entity_args.pop("code") if code else Path(func_entry_path).parent.absolute().as_posix()
+
+    # Set entry name as relative path to code
+    entry_relative_path = _relative_to(func_entry_path, entity_args["code"])
+    if not entry_relative_path:
+        raise ComponentDefiningError(
+            name=entity_args["name"],
+            cause=(
+                f"Mldesigner component {entity_args['name']!r} source directory {func_entry_path!r} "
+                f"not under code directory {entity_args['code']!r}"
+            ),
+        )
+    entry_relative_path = entry_relative_path.as_posix()
+    entity_args["command"] = [
+        "mldesigner",
+        "execute",
+        "--source",
+        str(entry_relative_path),
+        "--name",
+        entity_args["name"],
+    ]
+    # Initialize a ComponentExecutor to make sure it works and use it to update the component function.
+    # Save the raw func as we will wrap it
+    raw_func = _copy_func(func)
+
+    executor = EXECUTOR_CLASS(func=raw_func, entity_args=entity_args, _entry_file=func_entry_path)
+    executor._update_func(raw_func)
+    return executor, raw_func, entity_args
+
+
 def command_component(
     func=None,
     *,
     name=None,
-    version="1",
+    version=None,
     display_name=None,
     description=None,
     is_deterministic=None,
     tags=None,
     environment: Union[str, dict, PathLike, "Environment"] = None,
     distribution: Union[dict, "PyTorchDistribution", "MpiDistribution", "TensorFlowDistribution"] = None,
     resources: Union[dict, "ResourceConfiguration"] = None,
@@ -102,17 +170,16 @@
     :param resources: Compute Resource configuration for the component.
     :type resources: Union[dict, ResourceConfiguration]
     :param code: The source directory of component, with default value '.'.
                  i.e. The directory of mldesigner component file.
     :type code: Union[str, PathLike]
     :return: The decorated function which could be used to create component directly.
     """
-    if name and not is_valid_name(name):
-        msg = "Name is not valid, it could only contains a-z, A-Z, 0-9 and '.-_', got '%s'." % name
-        raise ComponentDefiningError(name, msg)
+
+    _validate_component_name(name=name)
 
     # Get the directory of decorator to resolve absolute code path in environment
     # Note: The decorator defined source directory may be different from mldesigner component source directory.
     decorator_defined_source_dir = _resolve_source_directory()
     # If is in mldesigner component execution process, skip resolve file path.
     EXECUTOR_CLASS = ExecutorBase._get_executor_class()
     environment = EXECUTOR_CLASS._refine_environment(environment, decorator_defined_source_dir)
@@ -123,103 +190,96 @@
     entity_args = {
         k: v for k, v in locals().items() if v is not None and k in inspect.signature(command_component).parameters
     }
 
     # func is not necessary for component entity
     entity_args.pop("func", None)
 
-    # pylint: disable=isinstance-second-argument-not-valid-type
     def component_func_decorator(func: _TFunc) -> _TFunc:
-        if not isinstance(func, Callable):
-            raise ComponentDefiningError(
-                name=None,
-                cause=f"Mldesigner component decorator accept only function type, got {type(func)}.",
-            )
-
         nonlocal entity_args
-        return_annotation = EXECUTOR_CLASS._get_outputs_from_return_annotation(func=func)
-
-        entity_args = EXECUTOR_CLASS._refine_entity_args(entity_args, return_annotation)
 
-        entity_args["name"] = entity_args.get("name", func.__name__)
-        entity_args["display_name"] = entity_args.get("display_name", entity_args["name"])
-        entity_args["description"] = entity_args.get("description", func.__doc__)
-        # pop description if not set, otherwise it's None value and will raise error when load schema
-        if entity_args["description"] is None:
-            entity_args.pop("description")
-        func_entry_path = _resolve_source_file()
-        if not func_entry_path:
-            func_entry_path = Path(inspect.getfile(func)).resolve().absolute()
-            # if component defined in a .ipynb the path is a pseudo path and it will interfere component entity
-            # generation or component compile
-            if not Path(func_entry_path).exists():
-                msg = (
-                    f"Component source path not found: '{func_entry_path}'. If the component is defined inside "
-                    f"'.ipynb' please try to define it in a separate '.py' file."
-                )
-                raise ComponentDefiningError(entity_args["name"], msg)
-
-        # Fall back to func entry directory if not specified.
-        entity_args["source_path"] = str(func_entry_path)
-        entity_args["code"] = entity_args.pop("code") if code else Path(func_entry_path).parent.absolute().as_posix()
-
-        # Set entry name as relative path to code
-        entry_relative_path = _relative_to(func_entry_path, entity_args["code"])
-        if not entry_relative_path:
-            raise ComponentDefiningError(
-                name=entity_args["name"],
-                cause=(
-                    f"Mldesigner component {entity_args['name']!r} source directory {func_entry_path!r} "
-                    f"not under code directory {entity_args['code']!r}"
-                ),
-            )
-        entry_relative_path = entry_relative_path.as_posix()
-        entity_args["command"] = [
-            "mldesigner",
-            "execute",
-            "--source",
-            str(entry_relative_path),
-            "--name",
-            entity_args["name"],
-        ]
-        # Initialize a ComponentExecutor to make sure it works and use it to update the component function.
-        # Save the raw func as we will wrap it
-        raw_func = _copy_func(func)
-
-        executor = EXECUTOR_CLASS(func=raw_func, entity_args=entity_args, _entry_file=func_entry_path)
-        executor._update_func(raw_func)
+        executor, raw_func, entity_args = _create_executor(
+            EXECUTOR_CLASS=EXECUTOR_CLASS, func=func, code=code, entity_args=entity_args
+        )
 
         _component_func = None
 
         @functools.wraps(raw_func)
         def wrapper(*args, **kwargs):
             nonlocal _component_func, executor
+            if executor._is_variable_inputs:
+                variable_inputs_executor = copy.copy(executor)
+                variable_inputs_executor, func_kwargs = _update_executor_inputs_by_values(
+                    kwargs, raw_func, variable_inputs_executor
+                )
+                if EXECUTOR_CLASS == ComponentExecutor:
+                    # Convert inputs to key-value dict.
+                    variable_inputs_dict = (
+                        inspect.signature(variable_inputs_executor._func).bind_partial(*args, **kwargs).arguments
+                    )
+                    kwargs_param = next(
+                        filter(
+                            lambda param: param.kind in [param.VAR_KEYWORD],
+                            inspect.signature(variable_inputs_executor._func).parameters.values(),
+                        )
+                    )
+                    inputs_kwargs = variable_inputs_dict.pop(kwargs_param.name, {})
+                    variable_inputs_dict.update(inputs_kwargs)
+                    variable_inputs_executor._execution_args = dict(variable_inputs_dict)
+                    return variable_inputs_executor
+                _variable_inputs_component_func = EXECUTOR_CLASS._get_generate_component_function(
+                    variable_inputs_executor.component
+                )
+                return _variable_inputs_component_func(*args, **func_kwargs)  # pylint: disable=not-callable
             if not _component_func:
                 _component_func = (
                     # If used in standalone mode, return the executor, otherwise return a component function.
                     executor
                     if EXECUTOR_CLASS == ComponentExecutor
                     else EXECUTOR_CLASS._get_generate_component_function(executor.component)
                 )
             return _component_func(*args, **kwargs)
 
         wrapper._is_mldesigner_component = True
         wrapper._executor = executor
         if EXECUTOR_CLASS != ComponentExecutor:
-            try:
-                wrapper.component = executor.component
-            except Exception as e:  # pylint: disable=broad-except
-                raise ComponentDefiningError(name=entity_args["name"], cause=str(e)) from e
+            wrapper.component = executor.component
         return wrapper
 
     # enable using decorator without "()" if all arguments are default values
     if func is not None:
         return component_func_decorator(func)
     return component_func_decorator
 
 
-def _copy_func(f):
-    """Copy func without deep copy as some method may contains fields can not be copied."""
-    g = types.FunctionType(f.__code__, f.__globals__, name=f.__name__, argdefs=f.__defaults__, closure=f.__closure__)
-    g = functools.update_wrapper(g, f)
-    g.__kwdefaults__ = f.__kwdefaults__
-    return g
+def _update_executor_inputs_by_values(kwargs, func, executor):
+    """Update execute inputs by the func kwargs and
+    return the updated executor and the key-value of func inputs."""
+    try:
+        from azure.ai.ml.entities._inputs_outputs.utils import _get_annotation_by_value
+    except ImportError:
+        from mldesigner._input_output import _get_annotation_by_value
+
+    args_mapping, func_kwargs = OrderedDict(executor._arg_mapping), {}
+    parameters = inspect.signature(func).parameters
+
+    # Generate input mapping by kwargs, the input name is the key.
+    var_kwarg = next((param for param in parameters.values() if param.kind == param.VAR_KEYWORD), None)
+    for k, v in kwargs.items():
+        if k in executor._arg_mapping:
+            args_mapping[k] = executor._arg_mapping[k]
+        elif not var_kwarg:
+            raise ComponentDefiningError(executor._entity_args["name"], "Component does not support variable kwargs.")
+        else:
+            data = v
+            if not isinstance(executor, ComponentExecutor):
+                from azure.ai.ml.entities._job.pipeline._io import PipelineInput
+
+                if isinstance(v, PipelineInput):
+                    data = v._data
+
+            annotation = _get_annotation_by_value(data)
+            annotation.name = k
+            args_mapping[k] = annotation
+        func_kwargs[k] = v
+    executor._arg_mapping = args_mapping
+    return executor, func_kwargs
```

## mldesigner/_component_executor.py

```diff
@@ -9,28 +9,40 @@
 import inspect
 import json
 import sys
 import types
 from abc import abstractmethod
 from pathlib import Path
 
-from mldesigner._constants import AssetTypes, ComponentSource, IoConstants, NodeType, SupportedParameterTypes
+from mldesigner._constants import (
+    AssetTypes,
+    ComponentSource,
+    ExecutorTypes,
+    IoConstants,
+    NodeType,
+    SupportedParameterTypes,
+)
 from mldesigner._exceptions import (
     ComponentDefiningError,
     ImportException,
     NoComponentError,
     RequiredComponentNameError,
     RequiredParamParsingError,
     TooManyComponentsError,
     UserErrorException,
     ValidationException,
 )
-from mldesigner._input_output import Input, Output, _standalone_get_param_with_standard_annotation
+from mldesigner._input_output import Input, Output, _Param, _standalone_get_param_with_standard_annotation
 from mldesigner._logger_factory import _LoggerFactory
-from mldesigner._utils import _import_component_with_working_dir, _is_mldesigner_component, inject_sys_path
+from mldesigner._utils import (
+    _import_component_with_working_dir,
+    _is_mldesigner_component,
+    _is_variable_args_function,
+    inject_sys_path,
+)
 
 execute_logger = _LoggerFactory.get_logger("execute", target_stdout=True)
 
 
 class ExecutorBase:
     """An executor base. Only to be inherited for sub executor classes."""
 
@@ -41,15 +53,16 @@
         "Generator": inspect.isgeneratorfunction,
     }
     # This is only available on Py3.6+
     if sys.version_info.major == 3 and sys.version_info.minor > 5:
         SPECIAL_FUNC_CHECKERS["Async generator"] = inspect.isasyncgenfunction
     DEFAULT_OUTPUT_NAME = "output"
     CONTROL_OUTPUTS_KEY = "azureml.pipeline.control"
-    SUPPORTED_RETURN_TYPES = (Output,)
+    SUPPORTED_RETURN_TYPES = (Output, _Param)
+    SUPPORTED_RETURN_PARAM_TYPES = list(SupportedParameterTypes)
 
     def __init__(self, func: types.FunctionType, arg_mapping, entity_args=None, _entry_file=None):
         """Initialize a ComponentExecutor with a function to enable calling the function with command line args.
 
         :param func: A function decorated by mldesigner.command_component.
         :type func: types.FunctionType
         :param arg_mapping: A dict mapping from parameter name to annotation.
@@ -74,14 +87,15 @@
         self._entity_file_path = None
         self._assert_valid_func(func)
         self._arg_mapping = arg_mapping
         self._return_mapping = self._get_output_annotations(func=func, mapping=self._arg_mapping)
         self._execution_args = None
         self._execution_outputs = None
         self._additional_args = None  # used to notify user for additional args that are useless after execution
+        self._is_variable_inputs = _is_variable_args_function(func)
         if _is_mldesigner_component(func):
             # If is mldesigner component func, set the func and entry file as original value
             self._func = func._executor._func
             self._entry_file = func._executor._entry_file
         else:
             # Else, set func directly, if _entry_file is None, resolve it from func.
             # Note: The entry file here might not equal with inspect.getfile(component._func),
@@ -176,32 +190,37 @@
                 Please make sure all requirements inside conda.yaml has been installed."""
                 raise ImportException(message=msg.format(py_module, e)) from e
 
         objects_with_source_line_order = sorted(
             inspect.getmembers(py_module, inspect.isfunction), key=lambda x: inspect.getsourcelines(x[1])[1]
         )
 
-        EXECUTOR_CLASS = cls._get_executor_class()
         for _, obj in objects_with_source_line_order:
             if cls._look_like_component(obj):
-                component = EXECUTOR_CLASS(obj)
+                EXECUTOR_CLASS = cls._get_executor_class(obj)
+                component = EXECUTOR_CLASS(func=obj)
                 component._check_py_module_valid(py_module)
                 yield component
 
     @classmethod
     def _look_like_component(cls, f):
         """Return True if f looks like a component."""
         if not isinstance(f, types.FunctionType):
             return False
         if not hasattr(f, cls.INJECTED_FIELD):
             return False
         return True
 
     @classmethod
-    def _get_executor_class(cls):
+    def _get_executor_class(cls, func=None):
+        # dynamic subgraph
+        if func is not None and func._executor._type == ExecutorTypes.DYNAMIC:
+            from mldesigner.dsl._dynamic_executor import DynamicExecutor
+
+            return DynamicExecutor
         try:
             from mldesigner._dependent_component_executor import DependentComponentExecutor
 
             return DependentComponentExecutor
         except ImportException:
             return ComponentExecutor
 
@@ -335,17 +354,15 @@
         # Convert the string values to real params of the function.
         params = {}
         for name, param in arg_mapping.items():
             type_name = type(param).__name__
             val = args.pop(param.name, None)
             # 1. If current param has no value
             if val is None:
-                # Note: here param value only contains user input except default value on function
-                if type_name == "Output" or not param.optional:
-                    raise RequiredParamParsingError(name=param.name)
+                self._validate_unprovided_params(type_name=type_name, param=param)
                 # If the Input is optional and no value set from args, set it as None for function to execute
                 if type_name == "Input" and param.optional is True:
                     params[name] = None
                 continue
 
             # 2. If current param has value:
             #       If it is a parameter, we help the user to parse the parameter, if it is an input port,
@@ -367,19 +384,28 @@
                         f"{val!r} can not be casted to type {param.type!r}"
                     )
             params[name] = param_value
 
             # 2b. For Output params, create dir for output path
             if type_name == "Output" and param.type == AssetTypes.URI_FOLDER and not Path(val).exists():
                 Path(val).mkdir(parents=True, exist_ok=True)
-
-        # used to notify user for additional args that are useless
-        self._additional_args = args
+        if self._is_variable_inputs:
+            # TODO convert variable inputs to the corresponding type
+            params.update(args)
+        else:
+            # used to notify user for additional args that are useless
+            self._additional_args = args
         return params
 
+    @classmethod
+    def _validate_unprovided_params(cls, type_name, param):
+        # Note: here param value only contains user input except default value on function
+        if type_name == "Output" or not param.optional:
+            raise RequiredParamParsingError(name=param.name)
+
     def _refine_args_with_original_parameter_definition(self, args, arg_mapping):
         """According to param definition, update actual arg or fill with default value.
 
         :param args: The actual args passed to execute component, need to be updated in this function.
         :type args: dict
         :param arg_mapping: Original parameters definition. Values are Input/Output objects.
         :type arg_mapping: dict
@@ -396,24 +422,27 @@
             # have to handle case like "max_epocs=10"
             if (
                 # When used with main package, EnumInput needs to be handled
                 type_name in ("Input", "EnumInput")
                 and param.name not in args
                 and param._is_primitive_type is True
                 and param.default is not None
-            ):
+            ) or isinstance(param, _Param):
                 args[param.name] = param.default
 
             # work 2: Update args outputs to ComponentName_timestamp/output_name
-            # if output is not specified, mldesigner will generate an output path automatically
             if type_name == "Output":
-                if param.name not in args:
-                    # if output path not specified, set as parameter name
-                    args[param.name] = param.name
-                self._execution_outputs[param.name] = str(Path(args[param.name]).resolve().absolute())
+                self._update_outputs_to_execution_args(args, param)
+
+    def _update_outputs_to_execution_args(self, args, param):
+        # if output is not specified, mldesigner will generate an output path automatically
+        if param.name not in args:
+            # if output path not specified, set as parameter name
+            args[param.name] = param.name
+        self._execution_outputs[param.name] = str(Path(args[param.name]).resolve().absolute())
 
     @classmethod
     def _get_output_annotations(cls, func, mapping: dict):
         """Analyze the annotation of the function to get the parameter mapping dict and the output port list.
         :param func:
         :return: (param_mapping, output_list)
             param_mapping: The mapping from function param names to input ports/component parameters;
@@ -428,44 +457,52 @@
                     f"Duplicate output {key!r} found in both parameters "
                     f"and return annotations of function {func.__name__!r}."
                 )
             mapping[key] = definition
         return return_mapping
 
     @classmethod
+    def _get_standard_output_annotation(cls, annotation, func, output_name=None) -> dict:
+        exception_tail = (
+            f"in return annotation of function {func.__name__!r}, "
+            f"expected instance types: {cls.SUPPORTED_RETURN_TYPES}) "
+            f"with output types: {cls.SUPPORTED_RETURN_PARAM_TYPES}."
+            f'e.g. func()-> Output(type="{cls.SUPPORTED_RETURN_PARAM_TYPES[0]}")'
+        )
+        output_name = cls.DEFAULT_OUTPUT_NAME if output_name is None else output_name
+
+        if annotation is inspect.Parameter.empty:
+            return {}
+
+        if isinstance(annotation, _Param):
+            annotation = Output(**annotation._to_io_entity_args_dict())
+
+        if isinstance(annotation, cls.SUPPORTED_RETURN_TYPES):
+            if annotation.type not in cls.SUPPORTED_RETURN_PARAM_TYPES:
+                raise UserErrorException(f"Unsupported output type {annotation.type!r} {exception_tail}")
+            annotation.name = output_name
+            return {output_name: annotation}
+
+        raise UserErrorException(f"Unsupported type {annotation!r} {exception_tail}")
+
+    @classmethod
     def _get_outputs_from_return_annotation(cls, func):
         """Convert return annotation to Outputs.
 
         Supported type:
             1. dsl output type. func() -> Output(type='boolean', is_control=True) will be keep as they are.
+            2. primitive output type, such as Output(type='string', is_control=True) will be converted to Output type.
 
         Note:
             - Single output will be named as 'output'.
         """
 
         return_annotation = inspect.signature(func).return_annotation
-        exception_tail = f"in return annotation of function {func.__name__!r}"
-
-        if return_annotation is inspect.Parameter.empty:
-            return {}
-
-        if isinstance(return_annotation, cls.SUPPORTED_RETURN_TYPES):
-            if return_annotation.type not in list(SupportedParameterTypes):
-                raise UserErrorException(
-                    f"Unsupported output type {return_annotation.type!r} {exception_tail}, "
-                    f"expected types: {cls.SUPPORTED_RETURN_TYPES})."
-                    f'e.g. func()-> Output(type="boolean")'
-                )
-            return_annotation.name = cls.DEFAULT_OUTPUT_NAME
-            return {cls.DEFAULT_OUTPUT_NAME: return_annotation}
 
-        raise UserErrorException(
-            f"Unsupported type {return_annotation!r} {exception_tail}, "
-            f'expected are primitive type dsl.types objects. e.g. func() -> Output(type="boolean")'
-        )
+        return cls._get_standard_output_annotation(annotation=return_annotation, func=func)
 
     @classmethod
     def _update_environment(cls, environment_dict: dict, return_annotation: dict):
         """Add mlflow dependency if control output exists. If failed to update, environment will be kept as it is."""
         if not isinstance(environment_dict, dict):
             return environment_dict
 
@@ -489,17 +526,17 @@
                         if not has_dependency(mlflow_dep, dep["pip"]):
                             dep["pip"].append(mlflow_dep)
         except (AttributeError, KeyError):
             pass
         return environment_dict
 
     @classmethod
-    def _write_control_outputs_to_run_history(cls, control_output_content: str):
-        """Write control output content to run history."""
-        execute_logger.info("Writing control outputs: '%s' to run history", control_output_content)
+    def _write_properties_to_run_history(cls, properties: dict):
+        """Write properties dict to run history."""
+        execute_logger.info("Writing content: '%s' to run history", properties)
 
         try:
             import mlflow
             from mlflow.tracking import MlflowClient
             from mlflow.utils.rest_utils import http_request
 
         except ImportError as e:
@@ -521,18 +558,23 @@
             # step4: call run history
             http_request(
                 host_creds=cred,
                 endpoint="/experimentids/{}/runs/{}".format(run.info.experiment_id, run.info.run_id),
                 method="PATCH",
                 json={
                     "runId": run.info.run_id,
-                    "properties": {cls.CONTROL_OUTPUTS_KEY: control_output_content},
+                    "properties": properties,
                 },
             )
-            execute_logger.info("Finished writing control outputs: '%s'", control_output_content)
+            execute_logger.info("Finished writing properties: '%s' to run history", properties)
+
+    @classmethod
+    def _write_control_outputs_to_run_history(cls, control_output_content: str):
+        """Write control output content to run history."""
+        return cls._write_properties_to_run_history({cls.CONTROL_OUTPUTS_KEY: control_output_content})
 
 
 class ComponentExecutor(ExecutorBase):
     """An executor to analyze the entity args of a function and convert it to a runnable component in AzureML."""
 
     def __init__(self, func: types.FunctionType, entity_args=None, _entry_file=None):
         """Initialize a ComponentExecutor with a function to enable calling the function with command line args.
@@ -567,15 +609,14 @@
         # Indicate the component is generated by mldesigner
         tags[ExecutorBase.CODE_GEN_BY_KEY] = ComponentSource.MLDESIGNER.lower()
         entity_args["tags"] = tags
 
         if "type" in entity_args and entity_args["type"] == "SweepComponent":
             return entity_args
 
-        entity_args["environment"] = cls._update_environment(entity_args.get("environment", None), return_annotation)
         entity_args["distribution"] = entity_args.get("distribution", None)
         return entity_args
 
     @classmethod
     def _refine_environment(cls, environment, mldesigner_component_source_dir):
         return environment
```

## mldesigner/_component_loader.py

```diff
@@ -1,11 +1,357 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
-
 # pylint: disable=unused-argument
+import importlib
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Optional
+
+from omegaconf import OmegaConf
+
+from mldesigner._exceptions import UserErrorException
+
+
+@dataclass
+class StructuredComponentLoaderConfig:
+    default_version: Optional[str] = None  # noqa: E704
+    force_version: Optional[str] = None  # noqa: E701
+    post_load: Optional[str] = None
+    use_local: Optional[str] = "*"
+
+
+class Config:
+    CONFIG_KEY = ""
+    STRUCTURED_CONFIG = None
+
+    def __init__(self, default_config_path=None, config_key=None):
+        structured_config = (
+            OmegaConf.structured(self.STRUCTURED_CONFIG) if self.STRUCTURED_CONFIG else OmegaConf.create({})
+        )
+        # only load from config if exists
+        if default_config_path and Path(default_config_path).exists():
+            default_config = OmegaConf.load(default_config_path)
+            if config_key:
+                default_config = default_config.get(config_key, {})
+            self.default_config = OmegaConf.merge(
+                OmegaConf.to_container(structured_config, resolve=True), default_config
+            )
+        else:
+            self.default_config = structured_config
+
+    @classmethod
+    def convert_to_absolute_path(cls, config, conf_keys, config_path):
+        """
+        Convert relative path to absolute path in the config.
+
+        :param config: The config which need to be updated.
+        :type config: DictConfig
+        :param conf_keys: The config keys which need to be converted to absolute path in the config.
+        :type conf_keys: List[str]
+        :param config_path: Config file path.
+        :type config_path: str or Path
+        """
+        config_parent_path = Path(config_path).parent
+        for key in conf_keys:
+            if OmegaConf.select(config, key):
+                OmegaConf.update(config, key, (config_parent_path / config[key]).absolute().as_posix())
+
+
+class ComponentsConfig(Config):
+    CONFIG_KEY = "components"
+    PATH_KEY = "path"
+    NAME_KEY = "name"
+    VERSION_KEY = "version"
+    REGISTRY_KEY = "registry"
+
+    def __init__(self, default_config_path=None, config_key=None):
+        super(ComponentsConfig, self).__init__(default_config_path, config_key)
+        if default_config_path:
+            # Convert yaml path to absolute path.
+            for _, component_config in self.default_config.items():
+                self.convert_to_absolute_path(component_config, [self.PATH_KEY], default_config_path)
+
+    @classmethod
+    def create_single_component_config(cls, key, name=None, path=None, registry=None, version=None):
+        """Create a component config which only contains one component config with key."""
+        component_config = {
+            # config items can not be object type translate to string.
+            cls.PATH_KEY: Path(path).resolve().absolute().as_posix() if path else None,
+            cls.NAME_KEY: name,
+            cls.VERSION_KEY: version,
+            cls.REGISTRY_KEY: registry,
+        }
+        component_config = {key: val for key, val in component_config.items() if val is not None}
+        components_config = OmegaConf.create({key: component_config})
+        return components_config
+
+
+class ComponentLoaderConfig(Config):
+    CONFIG_KEY = "component_loader"
+    POST_LOAD_KEY = "post_load"
+    STRUCTURED_CONFIG = StructuredComponentLoaderConfig
+
+    def __init__(self, default_config_path, config_key):
+        super(ComponentLoaderConfig, self).__init__(default_config_path, config_key)
+        self._validate_use_local(self.default_config)
+
+    @staticmethod
+    def _validate_use_local(config):
+        error_format = False
+        if "use_local" not in config:
+            use_local = "*"
+        elif not config.use_local:
+            use_local = None
+        elif config.use_local == "*":
+            use_local = "*"
+        else:
+            use_local = config.use_local
+            if isinstance(use_local, str):
+                use_local = [x.strip() for x in config.use_local.split(",")]
+            if not use_local or not isinstance(use_local, list) or not all(use_local):
+                error_format = True
+            else:
+                # Check use_local syntax valid, all items are prefixed by ! or not.
+                is_other_local = use_local[0].startswith("!")
+                error_format = not all([not (item.startswith("!") ^ is_other_local) for item in use_local])
+
+        if error_format:
+            raise UserErrorException(
+                "Invalid value for `use_local`. Please follow one of the four patterns: \n"
+                '1) use_local="", all components are remote\n'
+                '2) use_local="*", all components are local\n'
+                '3) use_local="COMPONENT_KEY_1, COMPONENT_KEY_2", only COMPONENT_KEY_1, COMPONENT_KEY_2 are local, '
+                "everything else is remote\n"
+                '4) use_local="!COMPONENT_KEY_1, !COMPONENT_KEY_2", '
+                "all except for COMPONENT_KEY_1, COMPONENT_KEY_2 are local"
+            )
+        return use_local
+
+
+class ComponentLoader:
+    """
+    Load component in different ways through the config.
+    ComponentLoader exposes two public methods set_override_config and load_component.
+    set_override_config is a class method, it's used to set the override config when loading the component.
+    load_component is used to load the component in different ways(local, workspace, registry).
+
+    The component loader provides the following features:
+        - Determine the component to be loaded remotely or locally through the component config loader
+        - Modify the runsettings of a specific type of component after the component loaded
+        - Execute user-defined function after the component loaded.
+
+    Example of loading component by ComponentLoader:
+    .. code-block:: python
+        # Init component loader
+        component_loader = ComponentLoader(default_component_config_path)
+        # Load the component by name
+        component_func = component_loader.load_component(name=<component name>)
+        # Create component
+        component = component_func()
+
+        # The post function is executed after component loaded.
+        def post_load_func(component: azure.ml.component.Component):
+            # Update component runsettings after loading.
+            component.runsettings.resource_layout.node_count = 1
+
+    Example of component config and component loader config:
+    .. code-block:: yaml
+        components:
+          component1:
+            name: my_component
+            version: component_version
+            registry: test_registry
+            path: ../components/my_component/component_version/component1.spec.yaml
+        component_loader:
+          use_local: '*'
+          post_load: <module_name>:<function_name>
+    """
+
+    _override_components_config = None
+    _override_component_loader_config = None
+
+    def __init__(self, components_config, default_component_loader_config_path):
+        """
+        Init component loader.
+
+        :param components_config: The default component config.
+        :param components_config: ComponentsConfig
+        :param default_component_loader_config_path: Default component loader config path
+        :type default_component_loader_config_path: str or Path
+        """
+        self._components_config = components_config
+
+        self._file_components_config = ComponentsConfig(
+            default_config_path=default_component_loader_config_path, config_key=ComponentsConfig.CONFIG_KEY
+        ).default_config
+
+        self._component_loader_config = ComponentLoaderConfig(
+            default_config_path=default_component_loader_config_path, config_key=ComponentLoaderConfig.CONFIG_KEY
+        ).default_config
+
+    @staticmethod
+    def _get_post_component_load_func(component_loader_config):
+        """
+        Get the user defined post_component_load function from component loader config.
+
+        :param component_loader_config: Component loader config
+        :type component_loader_config: DictConfig
+        :return: post_component_load function
+        :rtype: func
+        """
+        post_load_func_name = component_loader_config.get(ComponentLoaderConfig.POST_LOAD_KEY, None)
+        if post_load_func_name:
+            if ":" not in post_load_func_name:
+                raise UserErrorException(
+                    "Wrong format of post_load in the component loader config, "
+                    "please use <module_name>:<post_load_func_name>"
+                )
+            module_name, func_name = post_load_func_name.rsplit(":", 1)
+            try:
+                module = importlib.import_module(module_name)
+                return getattr(module, func_name)
+            except Exception as e:
+                raise UserErrorException(
+                    f'Cannot import the post component load function "{func_name}"' f' from the module "{module_name}"'
+                ) from e
+        else:
+            return None
+
+    @staticmethod
+    def is_load_component_from_local(component_name, component_loader_config):
+        """
+        Check whether the component is loaded from local.
+
+        use_local="", all components are remote'
+        use_local="*", all components are local
+        use_local="component1, component2", only component1, component2 are local, everything else is remote
+        use_local="!component1, !component2", all except for component1, component2 are local
+        Throw exceptions in other situations
+
+        :param component_name: Component name
+        :param component_loader_config: Component loader config.
+        :return: Whether component load from local.
+        :rtype: bool
+        """
+        # pylint: disable=protected-access
+        use_local = ComponentLoaderConfig._validate_use_local(component_loader_config)
+        if not use_local:
+            # If use_local='', all components will be loaded from remote.
+            return False
+        if isinstance(use_local, str) and use_local == "*":
+            # If use_local='*', all components will be loaded from local.
+            return True
+        if use_local[0].startswith("!"):
+            # If !component_name in use_local, the component will be loaded from remote.
+            return f"!{component_name}" not in use_local
+
+        # If component name in use_local, the component will be loaded from local.
+        return component_name in use_local
+
+    @classmethod
+    def _load_component_by_config(cls, component_name, component_config, component_loader):
+        """
+        Load component by component loader config.
+
+        If the component_name is specified from local, it will use component yaml to load component.
+        If the component_name is specified from remote, it will first use workspace/registry id to load if id exists.
+        Then, if name and version exists, it will use default workspace to load component.
+        If only name exists, it will load default version from default workspace.
+
+        :param component_name: Component name
+        :type component_name: str
+        :param component_config: Component config
+        :type component_config: DictConfig
+        :param component_loader: Config of component loader
+        :type component_loader: DictConfig
+
+        :return: Component entity or component id
+        :rtype: azure.ai.ml.entities.Component or str
+        """
+        from azure.ai.ml import load_component
+
+        if (
+            cls.is_load_component_from_local(component_name, component_loader)
+            and ComponentsConfig.PATH_KEY in component_config
+        ):
+            # Load component by yaml file.
+            component = load_component(source=component_config.path)
+        elif "version" in component_config:
+            # Load component by component name and version.
+            default_version = (
+                component_loader.get("force_version")
+                or component_config.get("version")
+                or component_loader.get("default_version")
+            )
+            # TODO(2072812): handle component in registry
+            component = f"{component_config.name}:{default_version}"
+        elif "name" in component_config:
+            component = component_config.name
+        else:
+            raise UserErrorException("Cannot load component through the component config.")
+        return component
+
+    @classmethod
+    def set_override_config(cls, components_config=None, component_loader_config=None):
+        """
+        Set the override config when loading component.
+
+        It will set component config and component loader config to the override config of ComponentLoader.
+        Override config of ComponentLoader has higher priority than the object config.
+        When loading the component, it will first use override config.
+
+        :param components_config: Override component config
+        :type components_config: DictConfig
+        :param component_loader_config: Override config of component loader
+        :type component_loader_config: DictConfig
+        """
+        cls._override_component_loader_config = component_loader_config
+        cls._override_components_config = components_config
+
+    def load_component(self, name):
+        """
+        Load the component by name.
+
+        It will use the name to get the config of the component and component loader.
+        Then it will use these configs to load the components. Override config of ComponentLoader has higher priority
+        than the default config. If not found override config, it will use the default config to load the component.
+
+
+        :param name: The name of the component to be loaded
+        :type name: str
+        :return: Component definition
+        :rtype: Union[azure.ai.ml.entities.Component, str]
+        """
+        if self._override_components_config:
+            # If override config exists, use override config to load component.
+            component_config = self._override_components_config.get(name) or self._components_config.get(name)
+        elif self._file_components_config.get(name):
+            # If override config does not exist, use default config to load component.
+            component_config = self._file_components_config.get(name)
+        else:
+            # Otherwise, use the component config from the component loader config.
+            component_config = self._components_config.get(name)
+        if not component_config:
+            raise UserErrorException(f"Cannot find {name} in the components config.")
+
+        # Get the component function by config
+        component_loader_config = self._override_component_loader_config or self._component_loader_config
+        return self._load_component_by_config(name, component_config, component_loader_config)
+
+    def apply_post_load_func(self, node):
+        """
+        Apply post load function to the node if specified in config.
 
+        :param node: Node object inside pipeline.
+        :return: node object after post load function applied.
+        """
 
-def _overwrite_component_load_options(name, component):
-    """If config file "components.yaml" exist in current folder, overwrite component load options with the config."""
-    # TODO(1831493): support component loader
-    return component
+        component_loader_config = self._override_component_loader_config or self._component_loader_config
+        post_component_load_func = self._get_post_component_load_func(component_loader_config)
+        if post_component_load_func:
+            try:
+                # Execute user defined function after component load.
+                post_component_load_func(node)
+            except Exception as e:
+                raise UserErrorException(f"Post component load func failed. {e}")
+        return node
```

## mldesigner/_constants.py

```diff
@@ -55,22 +55,44 @@
         "channels": ["defaults"],
         "dependencies": [
             "python=3.8.12",
             "pip=21.2.2",
             {
                 "pip": [
                     "--extra-index-url=https://azuremlsdktestpypi.azureedge.net/sdk-cli-v2",
-                    "mldesigner==0.0.75044055",
+                    "mldesigner==0.0.78358100",
                 ]
             },
         ],
     }
     IMAGE = "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04"
 
 
+class DynamicDefaultEnv(DefaultEnv):
+    CONDA_FILE = {
+        "name": "default_environment",
+        "channels": ["defaults"],
+        "dependencies": [
+            "python=3.8.12",
+            "pip=21.2.2",
+            {
+                "pip": [
+                    "--extra-index-url=https://azuremlsdktestpypi.azureedge.net/test-sdk-cli-v2",
+                    # pylint: disable=line-too-long
+                    "--extra-index-url=https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/",
+                    "mldesigner==0.0.77608301",
+                    "azure-ai-ml==1.1.2a20221124003",
+                    "mlflow",
+                    "azureml-mlflow",
+                ]
+            },
+        ],
+    }
+
+
 class ComponentSource:
     """Indicate where the component is constructed."""
 
     MLDESIGNER = "MLDESIGNER"
     BUILDER = "BUILDER"
     DSL = "DSL"
     CLASS = "CLASS"
@@ -127,7 +149,11 @@
 
 
 class SupportedParameterTypes(str, Enum):  # pylint: disable=enum-must-inherit-case-insensitive-enum-meta
     NUMBER = "number"
     INTEGER = "integer"
     BOOLEAN = "boolean"
     STRING = "string"
+
+
+class ExecutorTypes:
+    DYNAMIC = "dynamic"
```

## mldesigner/_dependent_component_executor.py

```diff
@@ -22,26 +22,28 @@
 from mldesigner._exceptions import (
     ComponentDefiningError,
     ComponentException,
     ComponentExecutorDependencyException,
     ImportException,
     UserErrorException,
 )
+from mldesigner._input_output import _Param
 from mldesigner._utils import _mldesigner_component_execution
 
 try:
     from azure.ai.ml import (
         Input,
         MpiDistribution,
         Output,
         PyTorchDistribution,
         TensorFlowDistribution,
         load_environment,
     )
     from azure.ai.ml.entities import CommandComponent, Environment, ResourceConfiguration
+    from azure.ai.ml.entities._inputs_outputs import EnumInput
 
 except ImportError:
     raise ImportException(IMPORT_AZURE_AI_ML_ERROR_MSG)
 
 
 class DependentComponentExecutor(ExecutorBase):
     """An executor to analyze the entity args of a function and convert it to a runnable component in AzureML."""
@@ -65,14 +67,21 @@
     @property
     def component(self):
         """
         Return the module entity instance of the component.
 
         Initialized by the function annotations and the meta data.
         """
+
+        try:
+            return self._get_component()
+        except Exception as e:  # pylint: disable=broad-except
+            raise ComponentDefiningError(name=self._entity_args["name"], cause=str(e)) from e
+
+    def _get_component(self):
         io_properties = self._generate_entity_io_properties(self._arg_mapping)
         command, args = self._entity_args["command"], io_properties.pop("args")
         # for normal command component
         entity_args = copy.copy(self._entity_args)
         entity_args["command"] = self._get_command_str_by_command_args(command, args)
         # Compatibility handling
         try:
@@ -140,29 +149,38 @@
         return {val.name: val for val in arg_mapping.values() if isinstance(val, Input)}
 
     def _generate_entity_io_properties(self, arg_mapping):
         """Generate the required properties for a component entity according to the annotation of a function."""
         self._validate_type(arg_mapping)
         inputs = self._update_io_descriptions(self._generate_entity_inputs(arg_mapping))
         outputs = self._update_io_descriptions(self._generate_entity_outputs(arg_mapping))
+
         args = []
-        if inputs:
-            args.append("--inputs")
-            args += [MldesignerCommandLineArgument(val).arg_group_str() for val in list(inputs.values())]
-        if outputs:
-            args.append("--outputs")
-            args += [MldesignerCommandLineArgument(val).arg_group_str() for val in list(outputs.values())]
+        self._update_inputs_to_args(args=args, inputs=inputs)
+        self._update_outputs_to_args(args=args, outputs=outputs)
 
         return {
             "inputs": {k: v._to_dict() for k, v in inputs.items()},
             "outputs": {k: v._to_dict() for k, v in outputs.items()},
             "args": args,
         }
 
     @classmethod
+    def _update_inputs_to_args(cls, args, inputs):
+        if inputs:
+            args.append("--inputs")
+            args += [MldesignerCommandLineArgument(val).arg_group_str() for val in list(inputs.values())]
+
+    @classmethod
+    def _update_outputs_to_args(cls, args, outputs):
+        if outputs:
+            args.append("--outputs")
+            args += [MldesignerCommandLineArgument(val).arg_group_str() for val in list(outputs.values())]
+
+    @classmethod
     def _analyze_annotations(cls, func):
         """Analyze the annotation of the function to get the parameter mapping dict and the output port list.
 
         :param func: A function wrapped by mldesigner.command_component.
         :return: (param_mapping, output_list)
             param_mapping: The mapping from function param names to input ports/component parameters;
             output_list: The output port list analyzed from return annotations.
@@ -225,15 +243,15 @@
 
         tags["codegenBy"] = "mldesigner"
         entity_args["tags"] = tags
 
         if "type" in entity_args and entity_args["type"] == "SweepComponent":
             return entity_args
 
-        core_env = entity_args.get("environment", Environment(image=DefaultEnv.IMAGE, conda_file=DefaultEnv.CONDA_FILE))
+        core_env = entity_args.get("environment", cls._get_default_env())
         if isinstance(core_env, Environment):
             core_env = core_env._to_dict()
         core_env = cls._update_environment(core_env, return_annotation)
         entity_args["environment"] = core_env
 
         distribution = entity_args.get("distribution", None)
         if distribution:
@@ -245,28 +263,42 @@
         if resources:
             if isinstance(resources, ResourceConfiguration):
                 entity_args["resources"] = resources._to_rest_object().as_dict()
 
         return entity_args
 
     @classmethod
+    def _get_default_env(cls):
+        """Return default environment."""
+        return Environment(image=DefaultEnv.IMAGE, conda_file=DefaultEnv.CONDA_FILE)
+
+    @classmethod
     def _refine_environment(cls, environment, mldesigner_component_source_dir):
         if cls._is_arm_versioned_str(environment):
             return environment
         environment = (
             Environment(image=DefaultEnv.IMAGE, conda_file=DefaultEnv.CONDA_FILE)
             if _mldesigner_component_execution()
             else cls._refine_environment_to_obj(environment, mldesigner_component_source_dir)
         )
         return environment
 
     @classmethod
     def _refine_environment_to_obj(cls, environment, mldesigner_component_source_dir) -> Environment:
         if isinstance(environment, dict):
             environment = Environment(**environment)
+            # when passing conda_file as Pathlike object or path string instead of actual dict into above Environment()
+            # environment.conda_file will have a nested conda_file dict, need to promote it one level up
+            # this should be the correct behavior since load_environment result env has no nested conda_file
+            if (
+                isinstance(environment.conda_file, dict)
+                and "conda_file" in environment.conda_file
+                and isinstance(environment.conda_file["conda_file"], dict)
+            ):
+                environment.conda_file = environment.conda_file["conda_file"]
         if isinstance(environment, (str, Path)):
             environment = Path(mldesigner_component_source_dir) / environment
             environment = load_environment(environment)
         if environment and not isinstance(environment, Environment):
             raise UserErrorException(
                 f"Unexpected environment type {type(environment).__name__!r}, "
                 f"expected str, path, dict or azure.ai.ml.core.Environment object."
@@ -274,62 +306,84 @@
         return environment
 
     @classmethod
     def _is_arm_versioned_str(cls, env):
         return isinstance(env, str) and env.lower().startswith("azureml:")
 
     @classmethod
-    def _get_outputs_from_return_annotation(cls, func):
-        result = super(DependentComponentExecutor, cls)._get_outputs_from_return_annotation(func)
-        for k, return_annotation in result.items():
+    def _unify_return_annotations(cls, return_annotations):
+        for k, return_annotation in return_annotations.items():
             # normalize to core output
             if isinstance(return_annotation, MldesignerOutput):
                 return_annotation = Output(**return_annotation._to_io_entity_args_dict())
             return_annotation.name = k
-            result[k] = return_annotation
+            return_annotations[k] = return_annotation
+
+    @classmethod
+    def _get_outputs_from_return_annotation(cls, func):
+        result = super(DependentComponentExecutor, cls)._get_outputs_from_return_annotation(func)
+        cls._unify_return_annotations(return_annotations=result)
         return result
 
 
 def _update_to_azure_ai_ml_io(func) -> dict:
     """This function will translate IOBase from mldesigner package to azure.ai.ml.Input/Output.
     This function depend on `mldesigner._input_output._IOBase._to_io_entity_args_dict` to translate Input/Output
     instance annotations to IO entities.
     This function depend on class names of `mldesigner._input_output` to translate Input/Output class annotations
     to IO entities.
 
     Note: You may notice that there are same code in azure-ai-ml package, do not remove this, or mldesigner will
         be break by with some version of azure-ai-ml.
     """
     mldesigner_pkg = "mldesigner"
+    return_annotation_key = "return"
     annotations = getattr(func, "__annotations__", {})
 
     def _is_input_or_output_type(io: type, type_str: str):
         """Return true if type name contains type_str"""
         if isinstance(io, type) and io.__module__.startswith(mldesigner_pkg):
             if type_str == io.__name__:
                 return True
         return False
 
+    def _is_private_primitive_type(io):
+        """Check io is primitive annotation."""
+        if isinstance(io, _Param) or (isinstance(io, type) and issubclass(io, _Param)):
+            return True
+        return False
+
     result = {}
     for key, io in annotations.items():
         if isinstance(io, type):
             if _is_input_or_output_type(io, "Input"):
                 # mldesigner.Input -> entities.Input
                 io = Input
             elif _is_input_or_output_type(io, "Output"):
                 # mldesigner.Output -> entities.Output
                 io = Output
+            elif _is_private_primitive_type(io):
+                io = Output(type=io.TYPE_NAME) if key == return_annotation_key else Input(type=io.TYPE_NAME)
         elif hasattr(io, "_to_io_entity_args_dict"):
             try:
                 if _is_input_or_output_type(type(io), "Input"):
                     # mldesigner.Input() -> entities.Input()
                     io = Input(**io._to_io_entity_args_dict())
                 elif _is_input_or_output_type(type(io), "Output"):
                     # mldesigner.Output() -> entities.Output()
                     io = Output(**io._to_io_entity_args_dict())
+                elif _is_private_primitive_type(type(io)):
+                    if io._is_enum():
+                        io = EnumInput(**io._to_io_entity_args_dict())
+                    else:
+                        io = (
+                            Output(**io._to_io_entity_args_dict())
+                            if key == return_annotation_key
+                            else Input(**io._to_io_entity_args_dict())
+                        )
             except BaseException as e:
                 msg = f"Failed to parse {io} to azure-ai-ml Input/Output: {str(e)}"
                 raise ComponentException(message=msg) from e
         result[key] = io
     # Copy a new func to set the updated annotation.
     f = _copy_func(func)
     setattr(f, "__annotations__", result)
```

## mldesigner/_get_root_pipeline_context.py

```diff
@@ -73,15 +73,15 @@
             STAGE_EXECUTION: execution_stage,
         }
 
     @staticmethod
     def _from_job_properties(properties: typing.Dict) -> "PipelineContext":
         try:
             root_job_name = properties["rootRunId"]
-            stages = json.loads(properties["properties"]["stages"])
+            stages = json.loads(properties["properties"]["azureml.pipelines.stages"])
             init_stage = PipelineStage._from_stage(stages.get(STAGE_INIT))
             execution_stage = PipelineStage._from_stage(stages.get(STAGE_EXECUTION))
             return PipelineContext(root_job_name, init_stage, execution_stage)
         except (KeyError, json.decoder.JSONDecodeError, ValueError) as e:
             raise SystemErrorException("Parse pipeline job properties failed.") from e
```

## mldesigner/_input_output.py

```diff
@@ -24,15 +24,15 @@
             pass
 
 """
 from collections import OrderedDict
 from enum import Enum as PyEnum
 from enum import EnumMeta
 from inspect import Parameter, signature
-from typing import Iterable, Sequence, Union, overload
+from typing import Iterable, Optional, Sequence, Union, overload
 
 from typing_extensions import Literal
 
 from mldesigner._constants import IoConstants
 from mldesigner._exceptions import UserErrorException
 
 
@@ -294,14 +294,15 @@
             "string",
             "boolean",
         ] = "uri_folder",
         path=None,
         mode=None,
         description=None,
         is_control=None,
+        early_available=None,
     ):
         """Define an output of a component.
 
         :param path: The path to which the output is pointing. Needs to point to a cloud path.
         :type path: str
         :param type: The type of the data output. Possible values include:
                             'uri_folder', 'uri_file', 'mltable', 'mlflow_model', 'custom_model', and user-defined types.
@@ -311,37 +312,41 @@
                             'upload': Upload the data from the compute target,
                             'direct': Pass in the URI as a string
         :type mode: str
         :param description: Description of the output
         :type description: str
         :param is_control: Determine the Output is control or not.
         :type is_control: bool
+        :param early_available: Determine the Output is early available or not.
+        :type early_available: bool
         """
 
     def __init__(
         self,
         *,
         type: str = "uri_folder",
         path=None,
         mode=None,
         description=None,
         is_control=None,
+        early_available=None,
         **kwargs,
     ):
         # As an annotation, it is not allowed to initialize the name.
         # The name will be updated by the annotated variable name.
         self.path = path
         self.mode = mode
         self.is_control = is_control
+        self.early_available = early_available
         super().__init__(name=None, type=type, description=description, **kwargs)
         self._is_primitive_type = self.type in IoConstants.PRIMITIVE_STR_2_TYPE
 
     def _to_io_entity_args_dict(self):
         """Convert the Output object to a kwargs dict for azure.ai.ml.entity.Output."""
-        keys = ["name", "path", "type", "mode", "description", "is_control"]
+        keys = ["name", "path", "type", "mode", "description", "is_control", "early_available"]
         result = {key: getattr(self, key) for key in keys}
         result.update(self._kwargs)
         return _remove_empty_values(result)
 
 
 def _remove_empty_values(data, ignore_keys=None):
     if not isinstance(data, dict):
@@ -364,15 +369,15 @@
 def _get_annotation_by_value(val):
     if val is Parameter.empty or val is None:
         # If no default value or default is None, create val as the basic parameter type,
         # it could be replaced using component parameter definition.
         annotation = Input._get_default_unknown_input()
     elif isinstance(val, PyEnum):
         # Handle enum values
-        annotation = EnumInput(enum=val.__class__)
+        annotation = String(enum=val.__class__)
     else:
         # for types generated from default value, regard it as optional input
         annotation = _get_annotation_cls_by_type(type(val), raise_error=False)
         if not annotation:
             # Fall back to default
             annotation = Input._get_default_unknown_input()
     return annotation
@@ -386,15 +391,15 @@
         annotation_fields = OrderedDict()
         for name, annotation in annotations.items():
             # Skip return type
             if name == "return":
                 continue
             # Handle EnumMeta annotation
             if isinstance(annotation, EnumMeta):
-                annotation = EnumInput(enum=annotation)
+                annotation = String(enum=annotation)
             # Try creating annotation by type when got like 'param: int'
             if not _is_mldesigner_type_cls(annotation) and not _is_mldesigner_types(annotation):
                 annotation = _get_annotation_cls_by_type(annotation, raise_error=False)
                 if not annotation:
                     # Fall back to default unknown parameter
                     annotation = Input._get_default_unknown_input()
             annotation_fields[name] = annotation
@@ -418,14 +423,17 @@
         if default is Input._EMPTY:
             return complete_annotation
         if isinstance(complete_annotation, Input) and complete_annotation._is_primitive_type:
             # For mldesigner Input, user cannot set default inside Input class,
             # instead it's set by "=" as parameter default
             # As mldesigner Input is merely an interface, there is no validation for default value yet
             complete_annotation.default = default
+        elif isinstance(complete_annotation, _Param):
+            # Set default value to primitive type in mldesigner
+            complete_annotation._default = default
         return complete_annotation
 
     def _merge_and_update_annotations(annotation_fields, defaults_dict):
         """Use public values in class dict to update annotations."""
         all_fields = OrderedDict()
         all_filed_keys = _merge_field_keys(annotation_fields, defaults_dict)
         for name in all_filed_keys:
@@ -438,58 +446,164 @@
             # Create annotation if is class type and update default
             annotation = _update_annotation_with_default(annotation, name, defaults_dict.get(name, Input._EMPTY))
             all_fields[name] = annotation
         return all_fields
 
     annotations = getattr(func, "__annotations__", {})
     annotation_fields = _get_fields(annotations)
-    defaults_dict = {key: val.default for key, val in signature(func).parameters.items()}
+    defaults_dict = {
+        key: val.default
+        for key, val in signature(func).parameters.items()
+        if val.kind not in [val.VAR_POSITIONAL, val.VAR_KEYWORD]
+    }
     all_fields = _merge_and_update_annotations(annotation_fields, defaults_dict)
     return all_fields
 
 
-class EnumInput(Input):
-    """Enum parameter parse the value according to its enum values."""
+def _is_mldesigner_type_cls(t: type):
+    if not isinstance(t, type):
+        return False
+    return issubclass(t, (Input, Output, _Param))
+
+
+def _is_mldesigner_types(o: object):
+    return _is_mldesigner_type_cls(type(o))
+
+
+class _Param(_IOBase):
+    """This is the base class of component primitive types Inputs/Outputs.
+
+    The properties including type/options/optional/min/max will be dumped in component spec.
+    """
+
+    DATA_TYPE = None  # This field is the corresponding python type of the class, e.g. str/int/float.
+    TYPE_NAME = None  # This field is the type name of the parameter, e.g. string/integer/number.
 
     def __init__(
         self,
-        *,
-        enum: Union[EnumMeta, Sequence[str]] = None,
-        default=None,
         description=None,
+        optional=None,
+        min=None,
+        max=None,
+        enum=None,
+        is_control=None,
         **kwargs,
     ):
-        """Initialize an enum parameter, the options of an enum parameter are
-        the enum values.
+        """Define a parameter of a component."""
+        super().__init__(name=None, type=self.TYPE_NAME, description=description)
+        self._optional = optional
+        self._min = min
+        self._max = max
+        self._enum = enum
+        self._is_control = is_control
+        self._default = kwargs.pop("default", None)
+
+    def _to_io_entity_args_dict(self):
+        """Convert the object to a kwargs dict for azure.ai.ml.entity.Output."""
+        keys = ["type", "optional", "min", "max", "enum", "description", "is_control", "default"]
+        result = {key: getattr(self, key, None) for key in keys}
+        result.update(self._kwargs)
+        return _remove_empty_values(result)
+
+    def _is_enum(self):
+        """returns true if the param is enum."""
+        return self.type == String.TYPE_NAME and self.enum
+
+    @property
+    def optional(self) -> bool:
+        """Return whether the parameter is optional."""
+        return self._optional
+
+    @property
+    def max(self) -> Optional[Union[int, float]]:
+        """Return the maximum value of the parameter for a numeric parameter."""
+        return self._max
+
+    @property
+    def min(self) -> Optional[Union[int, float]]:
+        """Return the minimum value of the parameter for a numeric parameter."""
+        return self._min
+
+    @property
+    def enum(self) -> Optional[Union[EnumMeta, Sequence[str]]]:
+        """Return the enum list of the parameter for a string parameter."""
+        return self._enum
+
+    @property
+    def is_control(self):
+        """Return the parameter is control output or not."""
+        return self._is_control
+
+    @property
+    def default(self):
+        """Return the default value of the parameter."""
+        return self._default
+
+
+class String(_Param):
+    """String parameter passed the parameter string with its raw value."""
+
+    DATA_TYPE = str
+    TYPE_NAME = "string"
+
+    def __init__(
+        self,
+        description=None,
+        optional=None,
+        enum=None,
+        is_control=None,
+        **kwargs,
+    ):
+        """Initialize a string parameter.
 
-        :param enum: Enum values.
-        :type Union[EnumMeta, Sequence[str]]
         :param description: Description of the param.
         :type description: str
         :param optional: If the param is optional.
         :type optional: bool
+        :param is_control: Determine the String is control or not.
+        :type is_control: bool
         """
-        enum_values = self._assert_enum_valid(enum)
-        # This is used to parse enum class instead of enum str value if a enum class is provided.
-        if isinstance(enum, EnumMeta):
-            self._enum_class = enum
-            self._str2enum = dict(zip(enum_values, enum))
+        if enum:
+            enum_values = self._assert_enum_valid(enum)
+            # This is used to parse enum class instead of enum str value if a enum class is provided.
+            if isinstance(enum, EnumMeta):
+                self._enum_class = enum
+                self._str2enum = dict(zip(enum_values, enum))
+            else:
+                self._enum_class = None
+                self._str2enum = {v: v for v in enum_values}
         else:
-            self._enum_class = None
-            self._str2enum = {v: v for v in enum_values}
-        super().__init__(type="string", default=default, enum=enum_values, description=description)
-        self._allowed_types = (
-            (str,)
-            if not self._enum_class
-            else (
-                self._enum_class,
-                str,
-            )
+            enum_values = None
+        _Param.__init__(
+            self,
+            description=description,
+            optional=optional,
+            enum=enum_values,
+            is_control=is_control,
         )
 
+    @property
+    def default(self):
+        return self._parse_enum(self._default)
+
+    def _parse_enum(self, val: str):
+        """Parse the enum value from a string value or the enum value."""
+        if val is None:
+            return val
+
+        if self._enum_class and isinstance(val, self._enum_class):
+            return val.value
+
+        if val not in self._str2enum:
+            msg = "Not a valid enum value: '{}', valid values: {}"
+            raise UserErrorException(
+                message=msg.format(val, ", ".join(self.enum)),
+            )
+        return self._str2enum[val].value
+
     @classmethod
     def _assert_enum_valid(cls, enum):
         """Check whether the enum is valid and return the values of the
         enum."""
         if isinstance(enum, EnumMeta):
             enum_values = [str(option.value) for option in enum]
         elif isinstance(enum, Iterable):
@@ -503,38 +617,125 @@
         if any(not isinstance(v, str) for v in enum_values):
             raise UserErrorException(
                 message="enum values must be str type.",
             )
 
         return enum_values
 
-    def _parse(self, val: str):
-        """Parse the enum value from a string value or the enum value."""
-        if val is None:
-            return val
 
-        if self._enum_class and isinstance(val, self._enum_class):
-            return val  # Directly return the enum value if it is the enum.
+class _Numeric(_Param):
+    """Numeric Parameter is an intermediate type which is used to validate the value according to min/max."""
 
-        if val not in self._str2enum:
-            msg = "Not a valid enum value: '{}', valid values: {}"
-            raise UserErrorException(
-                message=msg.format(val, ", ".join(self.enum)),
-            )
-        return self._str2enum[val]
+    def _validate_or_throw(self, val):
+        if self._min is not None and val < self._min:
+            raise ValueError("Parameter '%s' should not be less than %s." % (self.name, self._min))
+        if self._max is not None and val > self._max:
+            raise ValueError("Parameter '%s' should not be greater than %s." % (self.name, self._max))
 
-    def _update_default(self, default_value):
-        """Enum parameter support updating values with a string value."""
-        enum_val = self._parse(default_value)
-        if self._enum_class and isinstance(enum_val, self._enum_class):
-            enum_val = enum_val.value
-        self.default = enum_val
 
+class Integer(_Numeric):
+    """Int Parameter parse the value to a int value."""
 
-def _is_mldesigner_type_cls(t: type):
-    if not isinstance(t, type):
-        return False
-    return issubclass(t, (Input, Output))
+    DATA_TYPE = int
+    TYPE_NAME = "integer"
 
+    def __init__(
+        self,
+        min=None,
+        max=None,
+        description=None,
+        optional=None,
+        is_control=None,
+        **kwargs,
+    ):
+        """Initialize an integer parameter.
 
-def _is_mldesigner_types(o: object):
-    return _is_mldesigner_type_cls(type(o))
+        :param min: Minimal value of the param.
+        :type min: int
+        :param max: Maximum value of the param.
+        :type max: int
+        :param description: Description of the param.
+        :type description: str
+        :param optional: If the param is optional.
+        :type optional: bool
+        :param is_control: Determine the Integer is control or not.
+        :type is_control: bool
+        """
+        _Numeric.__init__(
+            self,
+            optional=optional,
+            description=description,
+            min=min,
+            max=max,
+            is_control=is_control,
+            **kwargs,
+        )
+
+
+class Number(_Numeric):
+    """Float Parameter parse the value to a float value."""
+
+    DATA_TYPE = float
+    TYPE_NAME = "number"
+
+    def __init__(
+        self,
+        min=None,
+        max=None,
+        description=None,
+        optional=None,
+        is_control=None,
+        **kwargs,
+    ):
+        """Initialize a float parameter.
+
+        :param min: Minimal value of the param.
+        :type min: float
+        :param max: Maximum value of the param.
+        :type max: float
+        :param description: Description of the param.
+        :type description: str
+        :param optional: If the param is optional.
+        :type optional: bool
+        :param is_control: Determine the Float is control or not.
+        :type is_control: bool
+        """
+        _Numeric.__init__(
+            self,
+            optional=optional,
+            description=description,
+            min=min,
+            max=max,
+            is_control=is_control,
+            **kwargs,
+        )
+
+
+class Boolean(_Param):
+    """Bool Parameter parse the value to a bool value."""
+
+    DATA_TYPE = bool
+    TYPE_NAME = "boolean"
+
+    def __init__(
+        self,
+        description=None,
+        optional=None,
+        is_control=None,
+        **kwargs,
+    ):
+        """Initialize a bool parameter.
+
+        :param description: Description of the param.
+        :type description: str
+        :param optional: If the param is optional.
+        :type optional: bool
+        :param is_control: Determine the Boolean is control or not.
+        :type is_control: bool
+        """
+        _Param.__init__(
+            self,
+            optional=optional,
+            description=description,
+            is_control=is_control,
+            **kwargs,
+        )
```

## mldesigner/_reference_component.py

```diff
@@ -2,25 +2,30 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=redefined-builtin, unused-argument
 
 from functools import wraps
 from os import PathLike
+from pathlib import Path
 from typing import Any, Callable, TypeVar, Union, get_type_hints
 
-from mldesigner._component_loader import _overwrite_component_load_options
-
 _TFunc = TypeVar("_TFunc", bound=Callable[..., Any])
 
+DEFAULT_COMPONENT_LOADER_CONFIG_PATH = Path(".").parent / "components.yaml"
+
 
-def reference_component(path: Union[PathLike, str] = None, name=None, version=None, **kwargs) -> _TFunc:
+def reference_component(path: Union[PathLike, str] = None, name=None, version=None, registry=None, **kwargs) -> _TFunc:
     """Reference an existing component with a function and return a component node built with given params.
     The referenced component can be defined with local yaml file or in remote with name and version.
     The returned component node type are hint with function return annotation and default to Command.
+    If the referenced component is local component, it'll be registered as anonymous component in pipeline's workspace.
+    If the referenced component is workspace component, we assume it has been registered in pipeline's workspace.
+    If the referenced component is registry component, it'll still be referenced from registry in pipeline.
+
     Eg: Both
     .. code-block:: python
 
         @reference_component()
         def my_func():
             ...
     and
@@ -39,46 +44,47 @@
 
     :param path: Path to local component file.
     :type path: str
     :param name: Name of component to load.
     :type name: str
     :param version: Version of component to load.
     :type version: str
+    :param registry: Registry of component's source. None means it's not a registry component.
+    :type registry: str
 
     :return: Component node.
     :rtype: Union[Command, Parallel]
     """
 
     def component_decorator(func: _TFunc) -> _TFunc:
         @wraps(func)
         def wrapper(*args, **inner_kwargs):
-            from azure.ai.ml import load_component
             from azure.ai.ml.dsl._dynamic import _assert_arg_valid
             from azure.ai.ml.entities._builders import Command
             from azure.ai.ml.exceptions import UserErrorException
+            from mldesigner._component_loader import ComponentLoader, ComponentsConfig
             from mldesigner._generate._generators._constants import COMPONENT_TO_NODE
 
             if args:
                 raise UserErrorException(
                     message="`reference_component` wrapped function only accept keyword parameters."
                 )
             # handle params case insensitively, raise error when unknown kwargs are passed
             _assert_arg_valid(inner_kwargs, func.__code__.co_varnames, func_name=func.__name__)
 
-            if path:
-                # load from local
-                component = load_component(source=path)
-            else:
-                # load from remote
-                # use function name as component name if not specified
-                component_name = name or func.__name__
+            # currently component loader only support load 1 component in reference_component
+            # create a component loader only contain 1 component config with function name as key
+            component_loader = ComponentLoader(
+                components_config=ComponentsConfig.create_single_component_config(
+                    key=func.__name__, path=path, name=name, version=version, registry=registry
+                ),
+                default_component_loader_config_path=DEFAULT_COMPONENT_LOADER_CONFIG_PATH,
+            )
 
-                component = component_name if version is None else f"{component_name}:{version}"
-
-            component = _overwrite_component_load_options(func.__name__, component)
+            component = component_loader.load_component(name=func.__name__)
 
             result_cls = get_type_hints(func).get("return", Command)
 
             # supported return annotations, traverse in order
             # Note: make sure no base node in supported_cls
             supported_cls = COMPONENT_TO_NODE.values()
             for cls in supported_cls:
@@ -86,14 +92,18 @@
                     result_cls = cls
             if result_cls not in supported_cls:
                 msg = (
                     f"Return annotation of `reference_component` wrapped function can only be {supported_cls} "
                     f"or its subclass, got {result_cls} instead."
                 )
                 raise UserErrorException(message=msg)
-            result = result_cls(component=component, inputs=inner_kwargs, _from_component_func=True)
 
-            return result
+            # This node will be init with inner_kwargs and push to pipeline stack
+            node = result_cls(component=component, inputs=inner_kwargs, _from_component_func=True)
+
+            node = component_loader.apply_post_load_func(node=node)
+
+            return node
 
         return wrapper
 
     return component_decorator
```

## mldesigner/_utils.py

```diff
@@ -1,25 +1,28 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 import contextlib
+import functools
 import importlib
 import inspect
 import logging
 import os
 import re
 import sys
+import types
 from datetime import datetime
 from pathlib import Path
+from typing import Optional, Tuple
 
 import pkg_resources
 
 from mldesigner._constants import MLDESIGNER_COMPONENT_EXECUTION, VALID_NAME_CHARS
-from mldesigner._exceptions import ComponentException
+from mldesigner._exceptions import ComponentException, UserErrorException
 from mldesigner._logger_factory import _LoggerFactory
 
 
 def is_valid_name(name: str):
     """Indicate whether the name is a valid component name."""
     return all(c in VALID_NAME_CHARS for c in name)
 
@@ -221,15 +224,15 @@
         return None
 
 
 def check_main_package(logger=None):
     if logger is None:
         logger = _LoggerFactory.get_logger("mldesigner")
     version = get_package_version("azure-ai-ml")
-    target_version = "0.1.0b7"
+    target_version = "1.2.0"
     version_to_check = pkg_resources.parse_version(target_version)
     msg = (
         f"Mldesigner requires azure-ai-ml >= {target_version} package to be fully functional."
         f"It's highly recommended to install the latest azure-ai-ml package."
     )
     if version:
         if not version.startswith("0.0."):
@@ -244,14 +247,21 @@
     return getattr(func, "_is_mldesigner_component", None) is True
 
 
 def _is_dsl_pipeline_function(func):
     return getattr(func, "_is_dsl_func", None) is True
 
 
+def _is_variable_args_function(func):
+    is_variable_func = any(
+        param.kind in [param.VAR_KEYWORD, param.VAR_POSITIONAL] for param in inspect.signature(func).parameters.values()
+    )
+    return is_variable_func
+
+
 def _remove_empty_key_in_dict(data):
     if not isinstance(data, dict):
         return data
     res = {}
     for k, v in data.items():
         if v == {}:
             continue
@@ -267,7 +277,148 @@
         credential = DefaultAzureCredential()
         # Check if given credential can get token successfully.
         credential.get_token("https://management.azure.com/.default")
     except Exception:  # pylint: disable=broad-except
         # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work
         credential = InteractiveBrowserCredential()
     return credential
+
+
+def _copy_func(f):
+    """Copy func without deep copy as some method may contains fields can not be copied."""
+    g = types.FunctionType(f.__code__, f.__globals__, name=f.__name__, argdefs=f.__defaults__, closure=f.__closure__)
+    g = functools.update_wrapper(g, f)
+    g.__kwdefaults__ = f.__kwdefaults__
+    return g
+
+
+def extract_input_output_name_from_binding(expression):
+    """Use this func to process two format of output string and get valid output name:
+    1: parent.jobs.a_job.output.a_port
+    2: parent.inputs.a_input
+    3: parent.outputs.b_output"""
+    _jobs_regex = r"parent.jobs.([^.]+).([^.]+).([^.]+)\Z"
+    _inputs_regex = r"parent.inputs.([^.]+)\Z"
+    _outputs_regex = r"parent.outputs.([^.]+)\Z"
+
+    if re.match(_jobs_regex, expression):
+        expression_l = re.match(_jobs_regex, expression)
+        return f"{expression_l.group(1)}.{expression_l.group(2)}.{expression_l.group(3)}"
+    if re.match(_inputs_regex, expression):
+        return re.match(_inputs_regex, expression).group(1)
+    if re.match(_outputs_regex, expression):
+        return re.match(_outputs_regex, expression).group(1)
+    raise UserErrorException(f"Invalid input expression: {expression}")
+
+
+class AMLVersionedArmId(object):
+    """Parser for versioned arm id: e.g. /subscription/.../code/my-
+    code/versions/1.
+
+    :param arm_id: The versioned ARM id.
+    :type arm_id: str
+    :raises UserErrorException: Raised if the ARM id is incorrectly formatted.
+    """
+
+    REGEX_PATTERN = (
+        "^/?subscriptions/([^/]+)/resourceGroups/(["
+        "^/]+)/providers/Microsoft.MachineLearningServices/workspaces/([^/]+)/([^/]+)/([^/]+)/versions/(["
+        "^/]+)"
+    )
+
+    def __init__(self, arm_id=None):
+        self.is_registry_id = None
+        if arm_id:
+            match = re.match(AMLVersionedArmId.REGEX_PATTERN, arm_id)
+            if match:
+                self.subscription_id = match.group(1)
+                self.resource_group_name = match.group(2)
+                self.workspace_name = match.group(3)
+                self.asset_type = match.group(4)
+                self.asset_name = match.group(5)
+                self.asset_version = match.group(6)
+            else:
+                REGISTRY_VERSION_PATTERN = "^azureml://registries/([^/]+)/([^/]+)/([^/]+)/versions/([^/]+)"
+                match = re.match(REGISTRY_VERSION_PATTERN, arm_id)
+                if match:
+                    self.asset_name = match.group(3)
+                    self.asset_version = match.group(4)
+                    self.is_registry_id = True
+                else:
+                    raise UserErrorException(f"Invalid AzureML ARM versioned Id {arm_id}")
+
+
+class AMLLabelledArmId(object):
+    """Parser for versioned arm id: e.g. /subscription/.../code/my-
+    code/labels/default.
+
+    :param arm_id: The labelled ARM id.
+    :type arm_id: str
+    :raises UserErrorException: Raised if the ARM id is incorrectly formatted.
+    """
+
+    REGEX_PATTERN = (
+        "^/?subscriptions/([^/]+)/resourceGroups/(["
+        "^/]+)/providers/Microsoft.MachineLearningServices/workspaces/([^/]+)/([^/]+)/([^/]+)/labels/(["
+        "^/]+)"
+    )
+
+    def __init__(self, arm_id=None):
+        self.is_registry_id = None
+        if arm_id:
+            match = re.match(AMLLabelledArmId.REGEX_PATTERN, arm_id)
+            if match:
+                self.subscription_id = match.group(1)
+                self.resource_group_name = match.group(2)
+                self.workspace_name = match.group(3)
+                self.asset_type = match.group(4)
+                self.asset_name = match.group(5)
+                self.asset_label = match.group(6)
+            else:
+                REGISTRY_VERSION_PATTERN = "^azureml://registries/([^/]+)/([^/]+)/([^/]+)/versions/([^/]+)"
+                match = re.match(REGISTRY_VERSION_PATTERN, arm_id)
+                if match:
+                    self.asset_name = match.group(3)
+                    self.asset_label = match.group(4)
+                    self.is_registry_id = True
+                else:
+                    raise UserErrorException(f"Invalid AzureML ARM versioned Id {arm_id}")
+
+
+def parse_name_version(name: str) -> Tuple[str, Optional[str]]:
+    """Parser for Command.component in the format of "component_name:component_version"
+    :param name: The Command.component
+    :type name: str
+    :raises UserErrorException: Raised if the name is incorrectly formatted
+    :return parsed name and version
+    """
+    if name.find("/") != -1 and name[0] != "/":
+        raise UserErrorException(f"Could not parse {name}. If providing an ARM id, it should start with a '/'.")
+    token_list = name.split(":")
+    if len(token_list) == 1:
+        return name, None
+    name, *version = token_list  # type: ignore
+    return name, ":".join(version)
+
+
+def _is_arm_id(component_str):
+    try:
+        AMLVersionedArmId(component_str)
+        return True
+    except Exception:  # pylint: disable=broad-except
+        return False
+
+
+def _is_name_version(component_str):
+    try:
+        parse_name_version(component_str)
+        return True
+    except Exception:  # pylint: disable=broad-except
+        return False
+
+
+def _is_name_label(component_str):
+    try:
+        AMLLabelledArmId(component_str)
+        return True
+    except Exception:  # pylint: disable=broad-except
+        return False
```

## mldesigner/_version.py

```diff
@@ -1 +1 @@
-VERSION = "0.1.0b8"
+VERSION = "0.1.0b9"
```

## mldesigner/_cli/mldesigner_commands.py

```diff
@@ -198,44 +198,44 @@
 def add_parser_export(subparsers):
     # mldesigner export
 
     example_text = """
     Examples:
 
     # export pipeline run to code without component snapshot by URL
-    mldesigner export --source pipeline_run_url
+    mldesigner export --source "<pipeline_run_url>"
 
     # export full snapshot of a pipeline run by URL
-    mldesigner export --source pipeline_run_url --include-components "*"
+    mldesigner export --source "<pipeline_run_url>" --include-components "*"
 
     # export pipeline with selected component snapshot by URL
-    mldesigner export --source pipeline_run_url --include-components train:0.0.1 anonymous_component:guid_version
+    mldesigner export --source "<pipeline_run_url>" --include-components train:0.0.1 anonymous_component:guid_version
     """
-    generate_parser = subparsers.add_parser(
+    export_parser = subparsers.add_parser(
         "export",
-        description="A CLI tool to export UI graph to azure-ai-ml code.",
-        help="mldesigner export",
+        description="A CLI tool to export pipeline job from portal url to @pipeline code.",
+        help="Export pipeline job to @pipeline code [Preview]",
         epilog=example_text,
         formatter_class=argparse.RawDescriptionHelpFormatter,
     )
-    generate_parser.add_argument(
+    export_parser.add_argument(
         "--source",
         type=str,
         help="""Pipeline job source, currently supported format is pipeline run URL.""",
     )
-    generate_parser.add_argument(
+    export_parser.add_argument(
         "--include-components",
         nargs="+",
         type=str,
         help="""Included components to download snapshot. Use * to export all components;
         Or separated string which contains a subset of components used in pipeline.
         Provided components can be name:version to download specific version of component
         or just name to download all versions of that component.""",
     )
-    generate_parser.set_defaults(action="export")
+    export_parser.set_defaults(action="export")
 
 
 def main():
     """Entrance of mldesigner CLI."""
     command_args = sys.argv[1:]
     if len(command_args) == 0:
         command_args.append("-h")
```

## mldesigner/_compile/_base_compiler.py

```diff
@@ -5,15 +5,15 @@
 # pylint: disable=protected-access
 
 import copy
 from pathlib import Path
 
 from azure.ai.ml.entities import Component
 from mldesigner._compile._compile_collector import CompileCollector
-from mldesigner._constants import InternalNodeType, IoConstants
+from mldesigner._constants import InternalNodeType, IoConstants, ComponentSource
 from mldesigner._exceptions import MldesignerCompileError
 
 
 class BaseCompiler:
     """Base compiler to compile SDK-defined components to yaml components"""
 
     SCHEMA_KEY = "$schema"
@@ -30,15 +30,15 @@
 
     def compile(self):
         self._update_compile_content()
 
         if self._component_content is None:
             raise MldesignerCompileError("Component content is empty, nothing to compile.")
         # make sure yaml file keys are ordered
-        self._reorder_content_dict()
+        self._component_content = self._get_reordered_dict(self._component_content)
         self._collector._compile_with_data(
             component=self._component, data=self._component_content, snapshot_list=self._snapshot
         )
 
     @classmethod
     def _validate_component(cls, component):
         result = component._customized_validate()
@@ -60,42 +60,50 @@
                     correct_value = param_parser(input_dict[key])
                     input_dict[key] = correct_value
 
     def _update_compile_content(self):
         """Update component content and snapshot which will be compiled, implemented by sub-compilers"""
         raise NotImplementedError()
 
-    def _reorder_content_dict(self):
+    def _get_reordered_dict(self, original_dict):
         """Make sure dict keys are in order when getting dumped"""
         KEY_ORDER = [
             BaseCompiler.SCHEMA_KEY,
             "name",
             "display_name",
             "description",
             "type",
             "version",
             "is_deterministic",
             "tags",
+            "component",
             "inputs",
             "outputs",
             "code",
             "environment",
             "command",
             "jobs",
         ]
 
-        original_dict = copy.deepcopy(self._component_content)
+        original_dict = copy.deepcopy(original_dict)
         new_dict = {}
         for key in KEY_ORDER:
             if key in original_dict:
                 new_dict[key] = original_dict.pop(key)
 
+        # for pipeline component yaml, need to sort job node dict and node's component dict
+        if "jobs" in new_dict and isinstance(new_dict["jobs"], dict):
+            for node_name, node_dict in new_dict["jobs"].items():
+                if "component" in node_dict and isinstance(node_dict["component"], dict):
+                    node_dict["component"] = self._get_reordered_dict(node_dict["component"])
+                new_dict["jobs"][node_name] = self._get_reordered_dict(new_dict["jobs"][node_name])
+
         # in case there are missed keys in original dict
         new_dict.update(original_dict)
-        self._component_content = new_dict
+        return new_dict
 
     def _get_component_snapshot(self, code):
         """Generate a list that contains all dependencies of a component"""
         # when compiling yaml component, code could be None and use its source file directory as code
         source_path = Path(self._component._source_path)
         code = code or "."
         code = source_path.parent / code
@@ -108,14 +116,21 @@
                 or (file.is_file() and file.suffix in (".pyc", ".additional_includes"))
             )
         )
 
         # add additional includes into snapshot list
         snapshot_list += self._get_additional_includes()
 
+        # remove original yaml file if the input is yaml as we need to update code to "."
+        # and output new yaml with original file name
+        if self._component._source == ComponentSource.YAML_COMPONENT:
+            original_yaml = Path(self._component._source_path).resolve().as_posix()
+            if original_yaml in snapshot_list:
+                snapshot_list.remove(original_yaml)
+
         return snapshot_list
 
     def _get_additional_includes(self):
         """Get a list of additional includes for the component"""
         res = []
         # currently only support v1.5 component since additional includes is not supported yet in v2
         if self._component.type in InternalNodeType.all_values():
```

## mldesigner/_compile/_compile_collector.py

```diff
@@ -9,19 +9,21 @@
 import shutil
 import tempfile
 from pathlib import Path
 
 import yaml
 
 from azure.ai.ml.entities import Component
+from mldesigner._constants import ComponentSource
 from mldesigner._exceptions import ImportException, MldesignerCompileError
 from mldesigner._utils import (
     _import_component_with_working_dir,
     _is_dsl_pipeline_function,
     _is_mldesigner_component_function,
+    _is_variable_args_function,
     _remove_empty_key_in_dict,
 )
 
 
 class CompileCollector:
     """Work as an overall context manager to manage compile targets during the compile process"""
 
@@ -91,18 +93,22 @@
                 raise ImportException(message=msg.format(py_module, e)) from e
 
         objects_with_source_line_order = sorted(
             inspect.getmembers(py_module, inspect.isfunction), key=lambda x: inspect.getsourcelines(x[1])[1]
         )
 
         for _, obj in objects_with_source_line_order:
-            if _is_mldesigner_component_function(obj):
-                yield obj.component
-            elif _is_dsl_pipeline_function(obj):
-                yield obj._pipeline_builder.build()
+            # Skip compile variable args function
+            if not _is_variable_args_function(obj):
+                if _is_mldesigner_component_function(obj):
+                    yield obj.component
+                elif _is_dsl_pipeline_function(obj):
+                    # Skip the pipeline with non-pipeline-inputs
+                    if not obj._pipeline_builder.non_pipeline_parameter_names:
+                        yield obj._pipeline_builder.build()
 
     def _update_compile_candidate(self, component: Component):
         candidate = CompileTask(component)
         self._compile_candidates[component.name] = candidate
 
     def _update_failed_source_file(self, file, msg):
         self._clean_up_collector()
@@ -190,15 +196,18 @@
         # give an extra layer named by component name
         dest_folder = Path(self._temp_dir.name) / component.name
 
         # if this component folder already exists, then it must be an identical component so we can reuse
         # _validate_compile_target() has guaranteed this, if same component with different source, error will be raised
         if not dest_folder.exists():
             dest_folder.mkdir(parents=True, exist_ok=True)
-            dest_yaml = dest_folder / f"{component.name}.yaml"
+            dest_yaml_name = f"{component.name}.yaml"
+            if component._source == ComponentSource.YAML_COMPONENT:
+                dest_yaml_name = Path(component._source_path).name
+            dest_yaml = dest_folder / dest_yaml_name
             self._update_compile_candidate(component)
             # remove empty dict in data
             data = _remove_empty_key_in_dict(data)
             with open(dest_yaml, "w", encoding="utf-8") as fout:
                 yaml.dump(data, fout, sort_keys=False)
 
             # copy snapshot if output is specified
```

## mldesigner/_compile/_compile_impl.py

```diff
@@ -3,29 +3,30 @@
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
 
 import glob
 import logging
 import os
+import sys
 import types
 from pathlib import Path
 from types import FunctionType
 from typing import Union
 
 from azure.ai.ml import load_component
 from azure.ai.ml.entities import Component
 from mldesigner._compile._compile import compile_logger
 from mldesigner._compile._compile_collector import CompileCollector
 from mldesigner._compile._component_compiler import CommandComponentCompiler
 from mldesigner._compile._internal_component_compiler import InternalComponentCompiler
 from mldesigner._compile._pipeline_component_compiler import PipelineComponentCompiler
 from mldesigner._constants import InternalNodeType, NodeType
 from mldesigner._exceptions import MldesignerCompileError, ValidationException
-from mldesigner._utils import _is_dsl_pipeline_function, _is_mldesigner_component_function
+from mldesigner._utils import _is_dsl_pipeline_function, _is_mldesigner_component_function, _is_variable_args_function
 
 
 def _compile(
     source: Union[str, FunctionType],
     *,
     name=None,
     output=None,
@@ -143,15 +144,19 @@
     else:
         error_msg = f"Unsupported file suffix '{file_suffix}', should be one of ['.py', '.yaml', '.yml']."
         collector._update_failed_source_file(file, error_msg)
 
 
 def _compile_from_single_function(func: types.FunctionType, collector: CompileCollector):
     """Compile component from a specified function source"""
+    if _is_variable_args_function(func):
+        raise ValidationException("Not support compile variable args function.")
     if _is_dsl_pipeline_function(func):
+        if func._pipeline_builder.non_pipeline_parameter_names:
+            raise ValidationException("Not support compile pipeline func with non-pipeline-input.")
         component = func._pipeline_builder.build()
     elif _is_mldesigner_component_function(func):
         component = func.component
     else:
         raise ValidationException("Function is not a valid dsl pipeline function.")
 
     _compile_from_single_component_or_pipeline(component, collector)
@@ -228,7 +233,13 @@
     additional_info_2 = (
         f" Skipped {failed_file_cnt} files and {failed_component_cnt} components."
         if failed_file_cnt + failed_component_cnt > 0
         else ""
     )
     summary_info = f"Mldesigner has compiled {succeeded_component_cnt} components{additional_info}.{additional_info_2}"
     compile_logger.info(summary_info)
+
+    # exit code to be 1 if there is failed case
+    exit_code = 1 if failed_file_cnt or failed_component_cnt else 0
+    if exit_code:
+        print(f"Mldesigner compile command finished with exit code {exit_code}")
+        sys.exit(exit_code)
```

## mldesigner/_compile/_pipeline_component_compiler.py

```diff
@@ -13,34 +13,34 @@
 from ._base_compiler import BaseCompiler
 from ._component_compiler import CommandComponentCompiler
 
 
 class PipelineComponentCompiler(BaseCompiler):
     """Pipeline component compiler to compile pipelines to yaml pipeline components"""
 
-    PIPELINE_SCHEMA = "https://azuremlschemas.azureedge.net/development/pipelineComponent.schema.json"
+    PIPELINE_SCHEMA = "https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json"
 
     def _update_compile_content(self):
         """Gernerate pipeline component dict and refine"""
         self._component_content = self._component._to_dict()
         self._component_content[BaseCompiler.SCHEMA_KEY] = self.PIPELINE_SCHEMA
         self._component_content["jobs"] = self._resolve_pipeline_jobs_dict()
 
-    def _resolve_pipeline_jobs_dict(self):
+    def _resolve_pipeline_jobs_dict(self) -> dict:
         jobs_dict = {}
         for node_name, node in self._component.jobs.items():
             jobs_dict[node_name] = self._resolve_pipeline_node_dict(
                 node.component, self._component_content["jobs"][node_name]
             )
             # node level code is not needed for mldesigner compile result
             jobs_dict[node_name].pop("code", None)
             self._update_node_inputs(jobs_dict[node_name])
         return jobs_dict
 
-    def _resolve_pipeline_node_dict(self, component, node_dict):
+    def _resolve_pipeline_node_dict(self, component, node_dict) -> dict:
         node_source = component._source
 
         # builder function as inline component in pipeline
         if node_source == ComponentSource.BUILDER:
             return self._resolve_builder_component_node(node_dict)
         if node_source == ComponentSource.MLDESIGNER:
             return self._resolve_mldesigner_component_node(component, node_dict)
@@ -48,19 +48,19 @@
             return self._resolve_yaml_component_node(component, node_dict)
         if node_source == ComponentSource.DSL:
             return self._resolve_pipeline_component_node(component, node_dict)
 
         msg = f"Component '{component.name}' failed: Unsupported node type '{node_source}'"
         raise MldesignerCompileError(message=msg)
 
-    def _resolve_builder_component_node(self, node_dict):
+    def _resolve_builder_component_node(self, node_dict) -> dict:
         self._update_component_inputs(node_dict["component"])
         return node_dict
 
-    def _resolve_mldesigner_component_node(self, component, node_dict):
+    def _resolve_mldesigner_component_node(self, component, node_dict) -> dict:
         CommandComponentCompiler(component, self._collector).compile()
         if self._output:
             node_dict["component"] = f"../{component.name}/{component.name}.yaml"
             return node_dict
 
         start = Path(self._component._source_path)
         dest = Path(component._source_path)
@@ -69,35 +69,44 @@
             relative_path = Path(f"./{component.name}.yaml")
         else:
             relative_path = Path(os.path.relpath(dest, start.parent)).parent / f"{component.name}.yaml"
         relative_path = relative_path.as_posix()
         node_dict["component"] = relative_path
         return node_dict
 
-    def _resolve_yaml_component_node(self, component, node_dict):
+    def _resolve_yaml_component_node(self, component, node_dict) -> dict:
         if self._output:
-            node_type = component.type
-            if node_type == NodeType.COMMAND:
-                CommandComponentCompiler(component, self._collector).compile()
-            elif node_type == NodeType.PIPELINE:
-                PipelineComponentCompiler(component, self._collector).compile()
-            else:
-                raise MldesignerCompileError(
-                    f"Unsupported node type '{node_type}' when compiling pipeline component '{self._component.name}'."
-                )
-            node_dict["component"] = f"../{component.name}/{component.name}.yaml"
-            return node_dict
+            return self._resolve_yaml_component_node_with_output(component, node_dict)
 
         start = Path(self._component._source_path)
         dest = Path(component._source_path)
         relative_path = Path(os.path.relpath(dest, start.parent)).as_posix()
         node_dict["component"] = relative_path
         return node_dict
 
-    def _resolve_pipeline_component_node(self, component, node_dict):
+    def _resolve_yaml_component_node_with_output(self, component, node_dict) -> dict:
+        """Resolve yaml component node dict when output folder is specified"""
+        node_type = component.type
+        if node_type == NodeType.COMMAND:
+            CommandComponentCompiler(component, self._collector).compile()
+        elif node_type == NodeType.PIPELINE:
+            PipelineComponentCompiler(component, self._collector).compile()
+        else:
+            raise MldesignerCompileError(
+                f"Unsupported node type '{node_type}' when compiling pipeline component '{self._component.name}'."
+            )
+
+        yaml_file_name = f"{component.name}.yaml"
+        # if the component has original yaml, use original yaml file name
+        if component._source == ComponentSource.YAML_COMPONENT:
+            yaml_file_name = Path(component._source_path).name
+        node_dict["component"] = f"../{component.name}/{yaml_file_name}"
+        return node_dict
+
+    def _resolve_pipeline_component_node(self, component, node_dict) -> dict:
         PipelineComponentCompiler(component, self._collector).compile()
         if self._output:
             node_dict["component"] = f"../{component.name}/{component.name}.yaml"
             return node_dict
 
         relative_path = Path(os.path.relpath(component._source_path, self._component._source_path))
         if relative_path == Path("."):
```

## mldesigner/_execute/_execute.py

```diff
@@ -5,15 +5,15 @@
 # pylint: disable=protected-access, redefined-builtin
 
 from os import PathLike
 from pathlib import Path
 from typing import Union
 
 from mldesigner._component_executor import ComponentExecutor, ExecutorBase
-from mldesigner._constants import ComponentSource
+from mldesigner._constants import ComponentSource, ExecutorTypes
 from mldesigner._exceptions import MldesignerExecutionError
 from mldesigner._logger_factory import _LoggerFactory
 
 execute_logger = _LoggerFactory.get_logger("execute", target_stdout=True)
 
 
 def execute(source: Union[ExecutorBase, "Command", "Parallel"]):
@@ -146,25 +146,30 @@
     abs_file_path = file.resolve().absolute()
     execute_logger.info("Looking for target component file: '%s'", abs_file_path)
     if not file.exists():
         raise MldesignerExecutionError(f"Source file does not exist: {abs_file_path}")
     execute_logger.info("Fetching target component: '%s'", name)
     if name is None:
         execute_logger.info("Component name is not specified, the first component in source file will be executed.")
+
     executor = ComponentExecutor._collect_component_from_file(
         py_file=file, component_name=name, from_executor=True, force_reload=True
     )
     return executor
 
 
 def _execute_component_from_executor(executor, inputs, outputs):
     """Execute target component"""
     execute_logger.info("Mldesigner starts executing target component: '%s'...", executor._name)
-    # TODO: handle case when there are overlap parameters
-    args = {**inputs, **outputs}
+    if executor._type == ExecutorTypes.DYNAMIC:
+        # TODO: outputs will be dropped since it won't get processed in dynamic executor
+        args = {**inputs}
+    else:
+        # TODO: handle case when there are overlap parameters
+        args = {**inputs, **outputs}
     res = executor.execute(args)
     if len(res) != 0:
         execute_logger.info("Component outputs:")
         for k, v in res.items():
             execute_logger.info("\t'%s': '%s'", k, v)
 
     # warning about the user input args that did not get used.
```

## mldesigner/_export/_export_impl.py

```diff
@@ -1,17 +1,58 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
+from pathlib import Path
 from typing import List
 
 from azure.ai.ml import MLClient
 from azure.ai.ml.entities._builders import Command, Pipeline
+
 from mldesigner._exceptions import UserErrorException
 from mldesigner._export._parse_url import _parse_designer_url
-from mldesigner._utils import get_credential_auth
+from mldesigner._generate._generators._pipeline_code_generator import (
+    PipelineCodeGenerator,
+)
+from mldesigner._utils import (
+    _is_arm_id,
+    _is_name_version,
+    _is_name_label,
+    get_credential_auth,
+    AMLVersionedArmId,
+    parse_name_version,
+)
+
+
+def _load_component_from_pipeline(client, job_entity):
+    name2component_dict = {}
+    for node in job_entity.jobs.values():  # pylint: disable=no-member
+        # pylint: disable=unidiomatic-typecheck
+        if isinstance(node, Command):
+            component_str = node.component
+            if _is_arm_id(component_str):
+                arm_id = AMLVersionedArmId(component_str)
+                component = client.components.get(name=arm_id.asset_name, version=arm_id.asset_version)
+            elif _is_name_version(component_str):
+                asset_name, asset_version = parse_name_version(component_str)
+                component = client.components.get(name=asset_name, version=asset_version)
+            elif _is_name_label(component_str):
+                arm_id = AMLVersionedArmId(component_str)
+                component = client.components.get(name=arm_id.asset_name, label=arm_id.asset_version)
+            else:
+                raise UserErrorException(
+                    f"The component:{node.component} of node {node.name} is invalid."
+                )
+            name2component_dict[component_str] = component
+        elif isinstance(node, Pipeline):
+            # TODO: generate code for pipeline with subgraphs
+            raise UserErrorException("Generating code for pipeline with subgraphs is not supported currently")
+        else:
+            node_type = type(node)
+            raise UserErrorException(f"Generating code for pipeline with {node_type} node is not supported currently")
+    return name2component_dict
 
 
 def _export(source: str, include_components: List[str] = None):  # pylint: disable=unused-argument
     """Export pipeline source to code.
 
     :param source: Pipeline job source, currently supported format is pipeline run URL
     :param include_components: Included components to download snapshot.
@@ -25,42 +66,40 @@
         subscription_id,
         resource_group,
         workspace_name,
         draft_id,
         run_id,
         endpoint_id,
         published_pipeline_id,
-        graph_id,  # pylint: disable=unused-variable
     ) = _parse_designer_url(source)
 
     # validate: raise error when the job type is not pipeline job
     if draft_id:
         raise UserErrorException("Invalid url. Export pipeline draft is not supported.")
     if endpoint_id:
         raise UserErrorException("Invalid url. Export pipeline endpoint is not supported.")
     if published_pipeline_id:
         raise UserErrorException("Invalid url. Export published pipeline is not supported.")
 
     credential = get_credential_auth()
-
     # get pipeline entity
     client = MLClient(
         credential=credential,
         resource_group_name=resource_group,
         subscription_id=subscription_id,
         workspace_name=workspace_name,
     )
     job_entity = client.jobs.get(run_id)
 
-    # validate: raise error when the pipeline job contain subgraph
+    # validate: raise error when the PipelineJob.jobs contain no nodes
     if len(job_entity.jobs) == 0:
-        raise UserErrorException("Failed to fetch pipeline nodes")
-    for node in job_entity.jobs.values():  # pylint: disable=no-member
-        # check whether this component has subgraph
-        # pylint: disable=unidiomatic-typecheck
-        if type(node) == Command:
-            # generate a new yml to write down the component (further work)
-            pass
-            # generate
-        if type(node) == Pipeline:
-            # TODO: generate code for pipeline with subgraphs
-            raise UserErrorException("Generating code for pipeline with subgraphs is not supported currently")
+        raise UserErrorException("Unsupported Pipeline Job: failed to retrieve child jobs.")
+
+    pattern_to_components = _load_component_from_pipeline(client, job_entity)
+    pipeline_code_generator = PipelineCodeGenerator(
+        asset=source,
+        pipeline_entity=job_entity,
+        target_dir=Path("."),
+        force_regenerate=False,
+        pattern_to_components=pattern_to_components,
+    )
+    pipeline_code_generator.generate(target_dir=Path(f"./{str(job_entity.display_name)}"))
```

## mldesigner/_export/_parse_url.py

```diff
@@ -56,20 +56,16 @@
 
     if draft_id is None and run_id is None and endpoint_id is None and published_pipeline_id is None:
         raise UserErrorException("Invalid url. No draft_id, run_id, endpoint_id, published_pipeline_id found.")
 
     if subscription_id is None or resource_group is None or workspace_name is None:
         raise UserErrorException("Invalid url. No subscription_id, resource_group or workspace_name found")
 
-    graph_id = re.findall("graphid=([^/&?]+)", url.lower())
-    graph_id = graph_id[0] if graph_id else None
-
     return (
         subscription_id,
         resource_group,
         workspace_name,
         draft_id,
         run_id,
         endpoint_id,
         published_pipeline_id,
-        graph_id,
     )
```

## mldesigner/_generate/_generators/_module_generator.py

```diff
@@ -1,34 +1,40 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 # pylint: disable=protected-access
-
 import hashlib
 from pathlib import Path
 from typing import Dict, List
 from uuid import UUID
 
 from azure.ai.ml.dsl._utils import _sanitize_python_variable_name
 from azure.ai.ml.entities import Component
 from mldesigner._generate._generate_package import generate_pkg_logger
 from mldesigner._generate._generators._components_generator import ComponentReferenceGenerator
 from mldesigner._generate._generators._components_impl_generator import ComponentImplGenerator
 from mldesigner._generate._generators._init_generator import InitGenerator
 
 
+def _get_selected_component_name(component):
+    """try to use display_name when component name is not clear"""
+    if component.display_name and component.name == "azureml_anonymous":
+        return component.display_name
+    return component.name
+
 def get_unique_component_func_names(components: List[Component]):
     """Try to return unique component func names, raise exception when duplicate component are found."""
     name_to_component = {}
     name_version_to_component = {}
     errors = []
 
     for component in components:
-        name_version = f"{component.name}:{component.version}"
+        selected_name = _get_selected_component_name(component)
+        name_version = f"{selected_name}:{component.version}"
         if name_version in name_version_to_component:
             existing_component = name_version_to_component[name_version]
             load_source = [
                 existing_component._source_path or existing_component.id,
                 component._source_path or existing_component.id,
             ]
             errors.append(f"Duplicate component {name_version} found. Loaded from: {load_source}")
@@ -37,24 +43,26 @@
 
         name_candidate = get_unique_component_func_name(name_to_component, component)
         name_to_component[name_candidate] = component
     return name_to_component, errors
 
 
 def get_unique_component_func_name(existing_names, component):
-    name_version = f"{component.name}:{component.version}"
-
-    name_candidate = _sanitize_python_variable_name(component.name)
+    component_func_name = _get_selected_component_name(component)
+    name_version = f"{component_func_name}:{component.version}"
+    name_candidate = _sanitize_python_variable_name(component_func_name)
     if name_candidate not in existing_names:
         return name_candidate
 
     name_candidate = _sanitize_python_variable_name(name_version)
     if name_candidate not in existing_names:
         return name_candidate
 
+    # if _sanitize_python_variable_name(component_func_name) and _sanitize_python_variable_name(name_version) both exist
+    # add hash result behind name_version because current name_version must differ from other name_versions
     suffix = str(UUID(hashlib.md5(name_version.encode("utf-8")).hexdigest()))
     name_candidate = _sanitize_python_variable_name(f"{name_version}_{suffix}")
     return name_candidate
 
 
 class ModuleGenerator:
     COMPONENTS_FILE_NAME = "_components.py"
```

## mldesigner/dsl/__init__.py

```diff
@@ -6,13 +6,14 @@
 from mldesigner._exceptions import UserErrorException
 
 from ._condition_output import _condition_output as condition_output
 
 try:
     from azure.ai.ml.dsl._condition import condition
     from azure.ai.ml.dsl._do_while import do_while
-    from azure.ai.ml.dsl._parameter_group_decorator import parameter_group
+    from azure.ai.ml.dsl._group_decorator import group
 except ImportError as e:
     err_msg = f"Please install extra dependencies by running `pip install azure-ai-ml`, currently got {e}"
     raise UserErrorException(err_msg)
+from ._dynamic import dynamic
 
-__all__ = ["do_while", "condition", "condition_output", "parameter_group"]  # pylint: disable=naming-mismatch
+__all__ = ["do_while", "condition", "condition_output", "dynamic", "group"]  # pylint: disable=naming-mismatch
```

## mldesigner/dsl/_condition_output.py

```diff
@@ -1,34 +1,28 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 from pathlib import Path
 from typing import Union
 
-from azure.ai.ml import load_component
-from azure.ai.ml.entities import Command
-from azure.ai.ml.entities._job.pipeline._io import InputOutputBase, NodeOutput
-
 _DATA_PATH = Path(__file__).resolve().parent.parent / "data"
 _COMPONENT_PATH = _DATA_PATH / "condition_output" / "component_spec.yaml"
 
 
-def _condition_output(
-    condition: Union[str, bool, InputOutputBase], *, input_a: NodeOutput = None, input_b: NodeOutput = None
-) -> Command:
+def _condition_output(condition: Union[str, bool], *, input_a=None, input_b=None):
     """
     Create a dsl.condition_output node to link output to input_a or input_b depends on condition.
 
     Below is an example of using expression result to control which step is executed.
     If pipeline parameter 'int_param1' > 'int_param2', then 'input_a' will be linked as output,
     else, the 'input_b' will be linked.
 
     .. code-block:: python
 
-    @dsl.pipeline(default_compute_target='aml-compute')
+    @pipeline
     def pipeline_func(int_param1: int, int_param2: int):
         step1 = component_func()
         step2 = another_component_func()
         condition_output_step = dsl.condition_output(
             condition=int_param1 > int_param2,
             input_a=true_step.outputs.output,
             input_b=false_step.outputs.output
@@ -42,13 +36,14 @@
         The value could be a boolean type control output or a pipeline expression.
     :type condition: Union[str, bool, InputOututBase]
     :param input_a: Output linked if condition resolved result is true.
     :type input_a: NodeOutput
     :param input_b: Output linked if condition resolved result is false.
     :type input_b: NodeOutput
     :return: The dsl.condition component.
-    :rtype: azure.ml.component.Component
+    :rtype: azure.ai.ml.entities.Component
     """
-    # _validate_parameters(condition, input_a, input_b)
+    from azure.ai.ml import load_component
+
     condition_output_component_func = load_component(_COMPONENT_PATH)
     condition_node = condition_output_component_func(condition=condition, input_a=input_a, input_b=input_b)
     return condition_node
```

## Comparing `mldesigner-0.1.0b8.dist-info/METADATA` & `mldesigner-0.1.0b9.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mldesigner
-Version: 0.1.0b8
+Version: 0.1.0b9
 Summary: Azure Machine Learning Designer SDK
 Home-page: https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/jobs/pipelines
 Author: Microsoft Corporation
 License: MIT License
 Keywords: AzureMachineLearning
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
@@ -19,14 +19,15 @@
 Description-Content-Type: text/markdown
 Requires-Dist: typing-extensions (<5.0.0)
 Provides-Extra: pipeline
 Requires-Dist: azure-ai-ml ; extra == 'pipeline'
 Requires-Dist: azure-identity ; extra == 'pipeline'
 Requires-Dist: jinja2 (==3.0.0) ; extra == 'pipeline'
 Requires-Dist: tqdm ; extra == 'pipeline'
+Requires-Dist: omegaconf (<2.2,>=2.0.5) ; extra == 'pipeline'
 
 # Azure Machine Learning Designer Python SDK
 
 The `mldesigner` package provide the SDK interface which work along with Azure ML Designer (drag-n-drop ML) UI experience.
 
 - [Azure ML Designer (drag-n-drop ML)](https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer): designer is a UI tool in the Azure ML workspace for visually connecting datasets and components on an interactive canvas to create machine learning pipelines. To learn how to get started with the designer, see [Tutorial: Predict automobile price with the designer](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-score).
 
@@ -35,18 +36,33 @@
 
 - [Components](https://docs.microsoft.com/en-us/azure/machine-learning/concept-component): self-contained piece of code that does one step in a machine learning pipeline: data preprocessing, model training, model scoring, a hyperparameter tuning run, etc. Such that it can be parameterized and then used in different contexts.
 - [Pipelines](https://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines): independently executable workflow of machine learning tasks composed by Components.
 
 
 # Change Log
 
+## [v0.1.0b9](https://pypi.org/project/mldesigner/0.1.0b9/) (2022.12.06)
+
+Recommended to work with azure-ai-ml==1.2.0
+
+**Improvements**
+- Enable creating component with auto-incremented version if no version specified.
+- Update mldesigner default environment image to be `mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04`
+- Mldesigner compile improvements:
+  - Exits with code 1 when there is failed compilation.
+  - Output yaml file with original file name if the input is a yaml.
+  - Generated pipeline node keys is ordered.
+
+**Fixed Bugs**
+- Fixed mldesigner executor does not pass `**kwargs` to component func
+
 ## [v0.1.0b8](https://pypi.org/project/mldesigner/0.1.0b8/) (2022.10.26)
 
 **Fixed Bugs**
-- Fix dependency issue when importing `typing_extensions`
+- Fixed dependency issue when importing `typing_extensions`
 
 ## [v0.1.0b7](https://pypi.org/project/mldesigner/0.1.0b7/) (2022.10.25)
 
 **New Features**
 - Support mldesigner compile: `mldesigner compile`
 - Support list type component input for generate_package.
```

## Comparing `mldesigner-0.1.0b8.dist-info/RECORD` & `mldesigner-0.1.0b9.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,65 +1,75 @@
 mldesigner/__init__.py,sha256=2o2PmrPFp-mvxEtzao-hJShkH3OJSFSbQPGpfHk7-OI,992
-mldesigner/_component.py,sha256=22BFSir2J70LNFwclKrsoob5fqGaOsMOQcjqafWTwMU,10394
-mldesigner/_component_executor.py,sha256=mnh-5Hcpjsh5GNLQw7fe_R_fNo5WlY4gLzeXfiH_9MM,28093
+mldesigner/_component.py,sha256=f1oxv-wNnF8yP7rHFo7cxMpwtdUxRFz5tiWazBTf60Q,13024
+mldesigner/_component_executor.py,sha256=62ALrh7lts58C-u88VNwBPx7Njny1e1nW77Ffzyps7A,29503
 mldesigner/_component_generator.py,sha256=1houZkJg5rJozFb2OGAgm745FnZDKlwNtfUxsaEsvCE,2726
-mldesigner/_component_loader.py,sha256=0MufaoyYf9VqY3jTP_zWpqANZ7eI9FklD7E09fcshNc,469
-mldesigner/_constants.py,sha256=I34Zw62NHQQNCrEQB8vgTQNUBiF_jnYLJ4AQn4k39e0,4292
-mldesigner/_dependent_component_executor.py,sha256=Oel9ExowuJw9JNCNSinoWHLhjOBUcj8O-xQzZok-nPM,14617
+mldesigner/_component_loader.py,sha256=9sT8X4IPtjc1dOncgKhEmsw3hZbtHKjIEIbEgWa9nvg,16081
+mldesigner/_constants.py,sha256=ZsWZnbCFqn4fUlAry0ozf-ozXtD3U8U5VcNpEWi0VeE,5116
+mldesigner/_dependent_component_executor.py,sha256=2eLtOJoklE6PrHj6juqBxu0iN-9OFz1NK2CHqma40I4,17086
 mldesigner/_exceptions.py,sha256=MJ6RAM8rKPSnc79_VybGKIbNZ50i8_W1z5V430DLGxQ,4648
-mldesigner/_get_root_pipeline_context.py,sha256=yK6J8yH6WrpoSyaNXL-6CHAaKFoQfkO_GDLW9eLKOA8,6117
-mldesigner/_input_output.py,sha256=KU1JEhrUtsgxEYDpec8XBuSNztpr9bHc7em5pkwCPs8,20761
+mldesigner/_get_root_pipeline_context.py,sha256=TCV4UIhUORGe18vWT6REdYjvSvdBUkO1HnYmxHtLUx0,6135
+mldesigner/_input_output.py,sha256=iUJAxwrNQGfBM5SqYnnEG0uGkXOYcp2bn76pyHj_cto,26738
 mldesigner/_logger_factory.py,sha256=jdCi5eZMyOKitPaQpuwg8n4Y9Ug6lSwxpYkUzRhLN9Q,1431
-mldesigner/_reference_component.py,sha256=01yiUWkGcTntoYMUILHSrZL20thV31bVNF5dq4kD9LQ,3855
-mldesigner/_utils.py,sha256=pnwMGa5MXLJTIRnj0mZPrp1EDxnmosRyi_FppkFSsDU,9344
-mldesigner/_version.py,sha256=zT9VazClnrrHkH5xP1Ceuoz6QN9i1TV7vdzcRzJ9ifY,21
+mldesigner/_reference_component.py,sha256=YOGSZ3ZKkJkO8l9f34I2tPXec1Nn7Ayfi1tQnz8HDOg,4699
+mldesigner/_utils.py,sha256=-qZC6C-bAjMGiXvihlHnRZtWm598Hibr-sJhnyEskjM,15136
+mldesigner/_version.py,sha256=MnqlqujrgKhyGXwtatbExaNzKDIc8yyDGAHuw7woon0,21
 mldesigner/_cli/__init__.py,sha256=d5b08hPILQxNDQ9p22-0d5Fl-90qmLEP7axZw6c0Ryw,267
-mldesigner/_cli/mldesigner_commands.py,sha256=bEKoOZ2GP1WbXjp3rX62GJ3QU67t6RGVixeFGoFyaM4,10351
+mldesigner/_cli/mldesigner_commands.py,sha256=svIty72qQhprPB-NprEkYQI6U30WKFdRqLiURm7bEwc,10403
 mldesigner/_compile/__init__.py,sha256=d5b08hPILQxNDQ9p22-0d5Fl-90qmLEP7axZw6c0Ryw,267
-mldesigner/_compile/_base_compiler.py,sha256=eeONoLz_8PcxXNYi_1QZsSdvseTHf6xB6kNKs3eiwm4,5161
+mldesigner/_compile/_base_compiler.py,sha256=MPDmsvPJpY1GK8yA1hbfHhG2756OKTybPKZiddhdaVY,6160
 mldesigner/_compile/_compile.py,sha256=RccGvu34XLZUHb9nUbanrPa_Ic5xGzHMW6l1fx5p7jI,2534
-mldesigner/_compile/_compile_collector.py,sha256=20skhcyKPxFbkozcJXaKMPeMqKytJJYGXdDnv-7HjII,9964
-mldesigner/_compile/_compile_impl.py,sha256=lTOGZRzheusyir6N0k2-UqoctRUGFAF9Go11OtWzMIE,10247
+mldesigner/_compile/_compile_collector.py,sha256=GtmTB4k2IiCJJ6WsK51z2V_AWzwA9p0yNEVN2BrOap8,10500
+mldesigner/_compile/_compile_impl.py,sha256=CRy9byyMMJ5yfZWkSPI9m3e37knC1WITw-ZIpvjONcQ,10827
 mldesigner/_compile/_component_compiler.py,sha256=7fst29GkIUdmMfuJjcxFdiG9xOtUm_dkh5ur0gaSrkA,1940
 mldesigner/_compile/_internal_component_compiler.py,sha256=c0NK7JVFHLAmXM7Ji1eyXG-SxzWWP9fZaXj13YJ-9oI,720
-mldesigner/_compile/_pipeline_component_compiler.py,sha256=qhP0TM8OnTN4-yir2kc9qrG2a8Xtk6WaUmllJuecQHg,5559
+mldesigner/_compile/_pipeline_component_compiler.py,sha256=IuJ5zPX4XtBgmTXisHt6IJm45Luu3sUJy6jZbM3uZhc,6067
 mldesigner/_execute/__init__.py,sha256=d5b08hPILQxNDQ9p22-0d5Fl-90qmLEP7axZw6c0Ryw,267
-mldesigner/_execute/_execute.py,sha256=F95bDzvkU0HJP8tX1ZkGpbGUZnLsa6qG0H7acOKv6tI,8272
+mldesigner/_execute/_execute.py,sha256=aGy9KbOxx-LpC02wjq2dyfkQCrAQx_9TjoYCAc98hK4,8474
 mldesigner/_export/__init__.py,sha256=9MRJMi2cZFHutWhneUnJrDaCy_MYPq5hUx_ERsKB3ZE,236
+mldesigner/_export/_cycle_validator.py,sha256=bQwsvJkIC0YI2apWxF0F5YRfLnz1Ac3hgUzJw71o89s,5791
 mldesigner/_export/_export.py,sha256=6FGjnei7Rq6IJ6dTk6IEP9lfFdVffIGGCkjOVE2gDOs,1124
-mldesigner/_export/_export_impl.py,sha256=kim4A8a0_zC5FLthaKYnF57P7C7gBPlNO6fvV_8mLkc,2768
-mldesigner/_export/_parse_url.py,sha256=gtjzB7yerQHHTLWQYOYKwLTlO6ApBzpUeqgY4ZTqAlY,3163
-mldesigner/_export/export.py,sha256=2G0JdPJm6C3e_rZ8-xRTYhOiLiC5N9hmeuigA6YWFZw,729
+mldesigner/_export/_export_impl.py,sha256=kTTDcyxZWm5uR-GBIrCT31aqRcaTsNk2WpV926Q616s,4449
+mldesigner/_export/_parse_url.py,sha256=He62CJ9shru1PZs4ZDNHJvKxTbKeTSwKi20JeB-kB-A,3031
 mldesigner/_generate/__init__.py,sha256=3RCr0cIITU5cK5_1ls5BOpOcoptNbhPGbvqWeiHlDnA,336
 mldesigner/_generate/_assets_entity.py,sha256=JZnfI1Pbp5n1ME58hQVG8gOU068YZpgD80XxhAz2yrU,2177
 mldesigner/_generate/_assets_schema.py,sha256=dprYLGOnjLaHseskX_9px02uCGE0G5FJU1ZJ2o2vfIs,1549
 mldesigner/_generate/_generate_package.py,sha256=VYV_NeusgY4UF_CkhVkp_nvHL-mScWTjV3pK043A2xs,5549
 mldesigner/_generate/_generate_package_impl.py,sha256=HUNRXCXfCU-6Rdrb6JPdj4lUmqPCHsOB9xjsULN26oY,12378
 mldesigner/_generate/_generators/__init__.py,sha256=d5b08hPILQxNDQ9p22-0d5Fl-90qmLEP7axZw6c0Ryw,267
 mldesigner/_generate/_generators/_base_component_generator.py,sha256=0gZD67yuCxy3OkbXrTbwTji18TFCvLLHS3VhkcMcpIQ,3996
 mldesigner/_generate/_generators/_base_generator.py,sha256=jh-Y-SBt0v1uv6nvn4eTjktRnQ07ieaUwPYhhmQO04U,1428
+mldesigner/_generate/_generators/_component_func_generator.py,sha256=ASuUhzUzOiv9_91FaITS1PtzpQcvjT2CJCyqNG7qqcQ,3448
 mldesigner/_generate/_generators/_components_generator.py,sha256=1-Oskg4vhdeMjoaZseUeQm3cotcUHg9_9zaLVYm9NmI,3383
 mldesigner/_generate/_generators/_components_impl_generator.py,sha256=wp71ehfb8_EMyn-QIqKdsSR98oyKDW7ynOxfDj9Fhzk,3672
 mldesigner/_generate/_generators/_constants.py,sha256=U7joC3yloMyFqk0obwI0aslDmhPNR8BVW8MLydOqH94,1545
 mldesigner/_generate/_generators/_doc_generator.py,sha256=rzhpH19BlVAyOYqgAi_Muh_NcAeb-qB9ENWloRryjpI,1434
 mldesigner/_generate/_generators/_init_generator.py,sha256=eTnXWJid7IOkliAWjT0kEfijcfTz7OK8y3V4S9ElCiA,869
-mldesigner/_generate/_generators/_module_generator.py,sha256=oivNTOFm55QYsD8cN1sU_4zuAb2JxbJ0fVcgIb2Chv0,4767
+mldesigner/_generate/_generators/_module_generator.py,sha256=Er6nPkkuoZbEg7gt8vxa4zNm07_gOOHpRPHKfvnRkHE,5391
 mldesigner/_generate/_generators/_package_generator.py,sha256=lLaCjc0e68fi_4mY0r8jLbt430ctR-Dzs1j6lAiR-CY,3316
 mldesigner/_generate/_generators/_param_generator.py,sha256=FcT0r0tRadYHYelj-Ine7_CTZMbe8npiSu1e0I_XSpA,4098
+mldesigner/_generate/_generators/_pipeline_code_generator.py,sha256=aqH00yWvlqJqFoXCnEB-8UTcBaSs4uwevNU87nVfbC8,4682
+mldesigner/_generate/_generators/_pipeline_generator.py,sha256=XscNRnOlu-hzUt9F5VASv8ybteB5zeOKHJ8rBsuYwFs,6496
+mldesigner/_generate/_generators/_pipelines_generator.py,sha256=BMfT_8h6e2eLYoBkNMeVnAD4-kE9m1-qxWZnGIKVLpY,4233
 mldesigner/_generate/_generators/_setup_generator.py,sha256=jZ_YHlYTI3kjT6Hrt24K-1FF_4fNvkKXYxDpe-MKslM,577
+mldesigner/_generate/templates/_azureml_config.template,sha256=he8HwdtW0wzBqXfeo_o3PSpbRBBIVE1jP289wGHwdtQ,136
 mldesigner/_generate/templates/_components.template,sha256=XqE8uBah8xWHnjaP3tMP6gN5_0PfVXZtYNA1-jOwRIc,489
+mldesigner/_generate/templates/_components_code_def.template,sha256=bl48g-KGzySnon5qQMxn1E2rHraqHS8aFWs-RcSiE4I,121
 mldesigner/_generate/templates/_components_impl.template,sha256=rmOsmu4184TXfaHwyQTLfI2FMvEXo_dvJm6hNTlVMIM,407
 mldesigner/_generate/templates/_components_init.template,sha256=J1R4IlwSA6tUNqlsBr9Ihlg4LMpBbMUV1TQZzCAv0GU,322
+mldesigner/_generate/templates/_pipeline_def.template,sha256=gTJR7JKdmncc34htmHDx6RQFRJfapIHR0MvK8HwmaUs,2194
+mldesigner/_generate/templates/_run.template,sha256=6iRZoLy-q5v6HAtL44geugi6avhXiKAcki9VMlbso0I,2859
 mldesigner/_generate/templates/conf.py.template,sha256=kXBAKfe5666-sN1nDayQcSeddui85yEIOhUAzfsa96Q,4137
 mldesigner/_generate/templates/index.rst.template,sha256=XUw2d7CPbBqPekX734yao5k5d3Et7fzoMjc16kVTq0c,184
 mldesigner/_generate/templates/setup.template,sha256=EE02DCELpvqdOzaaM0JtxvIr8TIpDSrzhegWpnd4-nw,604
 mldesigner/_generate/templates/single_component_entity.template,sha256=JbWhmY8iBcf03uZMjuPr6Uqwie_LAHtjk425XyezL-I,1003
 mldesigner/_generate/templates/single_component_reference.template,sha256=q-_CErH33i6ql_J7CP1x0AAPvRqafJr15ZOBveovOt4,1175
 mldesigner/_operations/__init__.py,sha256=HezdU28FZnwGK8nkF0jqEcAAgdz8jPqlanXXnNnBqDI,362
 mldesigner/_operations/_component_operations.py,sha256=1toVafIr-nOdHpnw0V_12dNIuu_MPrEdGBUpuic-yoI,2280
-mldesigner/dsl/__init__.py,sha256=fZo5uhr8aRhad8NmLtnsU3AWTUo5Ecz6fR6bisrPBDw,870
-mldesigner/dsl/_condition_output.py,sha256=_WHjpxACL7L2tTYqVNyWIf2BXyOAOsUdlL_InNd9YwY,2386
-mldesigner-0.1.0b8.dist-info/METADATA,sha256=keZ1EBFk7qZZINrGUPVrsxfI4u6WgBF_W_6bgJhO8DA,6806
-mldesigner-0.1.0b8.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-mldesigner-0.1.0b8.dist-info/entry_points.txt,sha256=lgjgpxZupY9dovcu4gv8z05ezTH8Cc3ZoPCfhjp9Iws,72
-mldesigner-0.1.0b8.dist-info/top_level.txt,sha256=N5oY-_q1ZW6Lpl3fyxcpDyS4abE7oNfWXCk64AC52X4,11
-mldesigner-0.1.0b8.dist-info/RECORD,,
+mldesigner/dsl/__init__.py,sha256=w5YkBfbfDT1yA1OvFD3bWEreLMH0OleG4Vb1nVA2SjE,882
+mldesigner/dsl/_condition_output.py,sha256=tM-R0vnC7bENUckN1RXAbH0iyShm-I0yS9Tky8rOf0w,2107
+mldesigner/dsl/_dynamic.py,sha256=F4Wk-xiCJCz1h7SvxQkDI_gytx78_sK35mYRY5_CvlQ,5483
+mldesigner/dsl/_dynamic_executor.py,sha256=sLZuONByvJXfLNFSCRcJ5VxyJUhd4gLzeud-IPhlVJQ,10807
+mldesigner-0.1.0b9.dist-info/METADATA,sha256=u0KPLGOvuMfBI0BacMxDb7pnJrO1MLYTFsisB6shG7Y,7487
+mldesigner-0.1.0b9.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+mldesigner-0.1.0b9.dist-info/entry_points.txt,sha256=lgjgpxZupY9dovcu4gv8z05ezTH8Cc3ZoPCfhjp9Iws,72
+mldesigner-0.1.0b9.dist-info/top_level.txt,sha256=N5oY-_q1ZW6Lpl3fyxcpDyS4abE7oNfWXCk64AC52X4,11
+mldesigner-0.1.0b9.dist-info/RECORD,,
```

