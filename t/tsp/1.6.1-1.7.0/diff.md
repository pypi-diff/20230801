# Comparing `tmp/tsp-1.6.1-py3-none-any.whl.zip` & `tmp/tsp-1.7.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,88 +1,90 @@
-Zip file size: 3035587 bytes, number of entries: 86
--rw-r--r--  2.0 unx      380 b- defN 23-Jun-16 16:01 tsp/__init__.py
--rw-r--r--  2.0 unx       93 b- defN 23-Jun-16 16:01 tsp/__meta__.py
--rw-r--r--  2.0 unx    30796 b- defN 23-Jun-16 16:01 tsp/core.py
--rw-r--r--  2.0 unx     3991 b- defN 23-Jun-16 16:01 tsp/gtnp.py
--rw-r--r--  2.0 unx      107 b- defN 23-Jun-16 16:01 tsp/misc.py
--rw-r--r--  2.0 unx     2699 b- defN 23-Jun-16 16:01 tsp/physics.py
--rw-r--r--  2.0 unx    18520 b- defN 23-Jun-16 16:01 tsp/readers.py
--rw-r--r--  2.0 unx     1379 b- defN 23-Jun-16 16:01 tsp/time.py
--rw-r--r--  2.0 unx     2932 b- defN 23-Jun-16 16:01 tsp/utils.py
--rw-rw-rw-  2.0 unx      171 b- defN 23-Jun-16 16:01 tsp/data/2023-01-06_755-test-Dataset_2031-Constant_Over_Interval-Hourly-Ground_Temperature-Thermistor_Automated.timeserie.csv
--rw-rw-rw-  2.0 unx     5686 b- defN 23-Jun-16 16:01 tsp/data/2023-01-06_755-test.metadata.txt
--rw-rw-rw-  2.0 unx   262289 b- defN 23-Jun-16 16:01 tsp/data/example_geotop.csv
--rw-rw-rw-  2.0 unx   191812 b- defN 23-Jun-16 16:01 tsp/data/example_gtnp.csv
--rw-r--r--  2.0 unx     1777 b- defN 23-Jun-16 16:01 tsp/dataloggers/AbstractReader.py
--rw-r--r--  2.0 unx     3281 b- defN 23-Jun-16 16:01 tsp/dataloggers/FG2.py
--rw-r--r--  2.0 unx     3312 b- defN 23-Jun-16 16:01 tsp/dataloggers/GP5W.py
--rw-r--r--  2.0 unx      916 b- defN 23-Jun-16 16:01 tsp/dataloggers/Geoprecision.py
--rw-r--r--  2.0 unx    33472 b- defN 23-Jun-16 16:01 tsp/dataloggers/HOBO.py
--rw-r--r--  2.0 unx     8538 b- defN 23-Jun-16 16:01 tsp/dataloggers/RBRXL800.py
--rw-r--r--  2.0 unx    13908 b- defN 23-Jun-16 16:01 tsp/dataloggers/RBRXR420.py
--rw-r--r--  2.0 unx      410 b- defN 23-Jun-16 16:01 tsp/dataloggers/__init__.py
--rw-r--r--  2.0 unx     2665 b- defN 23-Jun-16 16:01 tsp/dataloggers/logr.py
--rw-rw-rw-  2.0 unx   201018 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/004448.DAT
--rw-rw-rw-  2.0 unx   331292 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/004531.DAT
--rw-rw-rw-  2.0 unx   118535 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/004531.HEX
--rw-rw-rw-  2.0 unx   118531 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/004534.HEX
--rw-rw-rw-  2.0 unx   171935 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/010252.dat
--rw-rw-rw-  2.0 unx    84712 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/010252.hex
--rw-rw-rw-  2.0 unx    62720 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/010274.hex
--rw-rw-rw-  2.0 unx   173117 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/010278.hex
--rw-rw-rw-  2.0 unx   127062 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/012064.dat
--rw-rw-rw-  2.0 unx    62921 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/012064.hex
--rw-rw-rw-  2.0 unx   172576 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/012081.hex
--rw-rw-rw-  2.0 unx  1007616 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/062834_20220904_2351.rsk
--rw-rw-rw-  2.0 unx   308908 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/062834_20220904_2351.xlsx
--rw-rw-rw-  2.0 unx   107655 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/07B1592.DAT
--rw-rw-rw-  2.0 unx    59683 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/07B1592.HEX
--rw-rw-rw-  2.0 unx   162502 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/07B4450.DAT
--rw-rw-rw-  2.0 unx    84576 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/07B4450.HEX
--rw-rw-rw-  2.0 unx   648322 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/FG2_399.csv
--rw-rw-rw-  2.0 unx    36948 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/GP5W.csv
--rw-rw-rw-  2.0 unx    68696 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/GP5W_260.csv
--rw-rw-rw-  2.0 unx   147550 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/GP5W_270.csv
--rw-rw-rw-  2.0 unx    37920 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/H08-030-08_HOBOware.csv
--rw-rw-rw-  2.0 unx    82735 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/RBR_01.dat
--rw-rw-rw-  2.0 unx   242142 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/RBR_02.dat
--rw-rw-rw-  2.0 unx   470085 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/RSTDT2055.csv
--rw-rw-rw-  2.0 unx    55854 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/U23-001_HOBOware.csv
--rw-rw-rw-  2.0 unx   247057 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo-negative-2.txt
--rw-rw-rw-  2.0 unx   221034 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo-negative-3.txt
--rw-rw-rw-  2.0 unx    36089 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo-positive-number-1.txt
--rw-rw-rw-  2.0 unx    38331 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo-positive-number-2.csv
--rw-rw-rw-  2.0 unx    47776 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo-positive-number-3.csv
--rw-rw-rw-  2.0 unx    53444 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo-positive-number-4.csv
--rw-rw-rw-  2.0 unx   531384 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo2.csv
--rw-rw-rw-  2.0 unx      408 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB.config.json
--rw-rw-rw-  2.0 unx   958834 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB.csv
--rw-rw-rw-  2.0 unx     4333 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_Details.txt
--rw-rw-rw-  2.0 unx   168846 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_classic.csv
--rw-rw-rw-  2.0 unx   987910 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_defaults.csv
--rw-rw-rw-  2.0 unx    48977 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_minimal.txt
--rw-rw-rw-  2.0 unx    65536 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_raw.hobo
--rw-rw-rw-  2.0 unx   142070 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_var2.csv
--rw-rw-rw-  2.0 unx    92381 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/hobo_1_AB_var3.csv
--rw-rw-rw-  2.0 unx    21966 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/logR_ULogC16-32_1.csv
--rw-rw-rw-  2.0 unx    19066 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/logR_ULogC16-32_2.csv
--rw-rw-rw-  2.0 unx   734009 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/mon_3_Ta_2010-08-18_2013-02-08.txt
--rw-rw-rw-  2.0 unx   111570 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_001.dat
--rw-rw-rw-  2.0 unx    55293 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_001.hex
--rw-rw-rw-  2.0 unx   111547 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_001_no_comment.dat
--rw-rw-rw-  2.0 unx    55270 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_001_no_comment.hex
--rw-rw-rw-  2.0 unx    93525 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_002.dat
--rw-rw-rw-  2.0 unx    57536 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_002.hex
--rw-rw-rw-  2.0 unx    62703 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_003.hex
--rw-rw-rw-  2.0 unx   263680 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_003.xls
--rw-rw-rw-  2.0 unx    80057 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_xl_001.DAT
--rw-rw-rw-  2.0 unx    81601 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_xl_002.DAT
--rw-rw-rw-  2.0 unx   221656 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_xl_003.DAT
--rw-rw-rw-  2.0 unx   118459 b- defN 23-Jun-16 16:01 tsp/dataloggers/test_files/rbr_xl_003.HEX
--rw-r--r--  2.0 unx       71 b- defN 23-Jun-16 16:01 tsp/plots/__init__.py
--rw-r--r--  2.0 unx     9449 b- defN 23-Jun-16 16:01 tsp/plots/static.py
--rw-rw-rw-  2.0 unx    35149 b- defN 23-Jun-16 16:01 tsp-1.6.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     3048 b- defN 23-Jun-16 16:01 tsp-1.6.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-16 16:01 tsp-1.6.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       30 b- defN 23-Jun-16 16:01 tsp-1.6.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     8102 b- defN 23-Jun-16 16:01 tsp-1.6.1.dist-info/RECORD
-86 files, 11523034 bytes uncompressed, 3022681 bytes compressed:  73.8%
+Zip file size: 3038046 bytes, number of entries: 88
+-rw-r--r--  2.0 unx      427 b- defN 23-Aug-01 16:29 tsp/__init__.py
+-rw-r--r--  2.0 unx       93 b- defN 23-Aug-01 16:29 tsp/__meta__.py
+-rw-r--r--  2.0 unx    34356 b- defN 23-Aug-01 16:29 tsp/core.py
+-rw-r--r--  2.0 unx     3991 b- defN 23-Aug-01 16:29 tsp/gtnp.py
+-rw-r--r--  2.0 unx       78 b- defN 23-Aug-01 16:29 tsp/labels.py
+-rw-r--r--  2.0 unx     2614 b- defN 23-Aug-01 16:29 tsp/misc.py
+-rw-r--r--  2.0 unx     2699 b- defN 23-Aug-01 16:29 tsp/physics.py
+-rw-r--r--  2.0 unx    18520 b- defN 23-Aug-01 16:29 tsp/readers.py
+-rw-r--r--  2.0 unx     1379 b- defN 23-Aug-01 16:29 tsp/time.py
+-rw-r--r--  2.0 unx     2932 b- defN 23-Aug-01 16:29 tsp/utils.py
+-rw-r--r--  2.0 unx       15 b- defN 23-Aug-01 16:29 tsp/version.py
+-rw-rw-rw-  2.0 unx      171 b- defN 23-Aug-01 16:29 tsp/data/2023-01-06_755-test-Dataset_2031-Constant_Over_Interval-Hourly-Ground_Temperature-Thermistor_Automated.timeserie.csv
+-rw-rw-rw-  2.0 unx     5686 b- defN 23-Aug-01 16:29 tsp/data/2023-01-06_755-test.metadata.txt
+-rw-rw-rw-  2.0 unx   262289 b- defN 23-Aug-01 16:29 tsp/data/example_geotop.csv
+-rw-rw-rw-  2.0 unx   191812 b- defN 23-Aug-01 16:29 tsp/data/example_gtnp.csv
+-rw-r--r--  2.0 unx     1777 b- defN 23-Aug-01 16:29 tsp/dataloggers/AbstractReader.py
+-rw-r--r--  2.0 unx     3281 b- defN 23-Aug-01 16:29 tsp/dataloggers/FG2.py
+-rw-r--r--  2.0 unx     3312 b- defN 23-Aug-01 16:29 tsp/dataloggers/GP5W.py
+-rw-r--r--  2.0 unx      916 b- defN 23-Aug-01 16:29 tsp/dataloggers/Geoprecision.py
+-rw-r--r--  2.0 unx    33472 b- defN 23-Aug-01 16:29 tsp/dataloggers/HOBO.py
+-rw-r--r--  2.0 unx     8538 b- defN 23-Aug-01 16:29 tsp/dataloggers/RBRXL800.py
+-rw-r--r--  2.0 unx    13908 b- defN 23-Aug-01 16:29 tsp/dataloggers/RBRXR420.py
+-rw-r--r--  2.0 unx      410 b- defN 23-Aug-01 16:29 tsp/dataloggers/__init__.py
+-rw-r--r--  2.0 unx     2665 b- defN 23-Aug-01 16:29 tsp/dataloggers/logr.py
+-rw-rw-rw-  2.0 unx   201018 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/004448.DAT
+-rw-rw-rw-  2.0 unx   331292 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/004531.DAT
+-rw-rw-rw-  2.0 unx   118535 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/004531.HEX
+-rw-rw-rw-  2.0 unx   118531 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/004534.HEX
+-rw-rw-rw-  2.0 unx   171935 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/010252.dat
+-rw-rw-rw-  2.0 unx    84712 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/010252.hex
+-rw-rw-rw-  2.0 unx    62720 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/010274.hex
+-rw-rw-rw-  2.0 unx   173117 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/010278.hex
+-rw-rw-rw-  2.0 unx   127062 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/012064.dat
+-rw-rw-rw-  2.0 unx    62921 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/012064.hex
+-rw-rw-rw-  2.0 unx   172576 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/012081.hex
+-rw-rw-rw-  2.0 unx  1007616 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/062834_20220904_2351.rsk
+-rw-rw-rw-  2.0 unx   308908 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/062834_20220904_2351.xlsx
+-rw-rw-rw-  2.0 unx   107655 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/07B1592.DAT
+-rw-rw-rw-  2.0 unx    59683 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/07B1592.HEX
+-rw-rw-rw-  2.0 unx   162502 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/07B4450.DAT
+-rw-rw-rw-  2.0 unx    84576 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/07B4450.HEX
+-rw-rw-rw-  2.0 unx   648322 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/FG2_399.csv
+-rw-rw-rw-  2.0 unx    36948 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/GP5W.csv
+-rw-rw-rw-  2.0 unx    68696 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/GP5W_260.csv
+-rw-rw-rw-  2.0 unx   147550 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/GP5W_270.csv
+-rw-rw-rw-  2.0 unx    37920 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/H08-030-08_HOBOware.csv
+-rw-rw-rw-  2.0 unx    82735 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/RBR_01.dat
+-rw-rw-rw-  2.0 unx   242142 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/RBR_02.dat
+-rw-rw-rw-  2.0 unx   470085 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/RSTDT2055.csv
+-rw-rw-rw-  2.0 unx    55854 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/U23-001_HOBOware.csv
+-rw-rw-rw-  2.0 unx   247057 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo-negative-2.txt
+-rw-rw-rw-  2.0 unx   221034 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo-negative-3.txt
+-rw-rw-rw-  2.0 unx    36089 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo-positive-number-1.txt
+-rw-rw-rw-  2.0 unx    38331 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo-positive-number-2.csv
+-rw-rw-rw-  2.0 unx    47776 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo-positive-number-3.csv
+-rw-rw-rw-  2.0 unx    53444 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo-positive-number-4.csv
+-rw-rw-rw-  2.0 unx   531384 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo2.csv
+-rw-rw-rw-  2.0 unx      408 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB.config.json
+-rw-rw-rw-  2.0 unx   958834 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB.csv
+-rw-rw-rw-  2.0 unx     4333 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_Details.txt
+-rw-rw-rw-  2.0 unx   168846 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_classic.csv
+-rw-rw-rw-  2.0 unx   987910 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_defaults.csv
+-rw-rw-rw-  2.0 unx    48977 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_minimal.txt
+-rw-rw-rw-  2.0 unx    65536 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_raw.hobo
+-rw-rw-rw-  2.0 unx   142070 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_var2.csv
+-rw-rw-rw-  2.0 unx    92381 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/hobo_1_AB_var3.csv
+-rw-rw-rw-  2.0 unx    21966 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/logR_ULogC16-32_1.csv
+-rw-rw-rw-  2.0 unx    19066 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/logR_ULogC16-32_2.csv
+-rw-rw-rw-  2.0 unx   734009 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/mon_3_Ta_2010-08-18_2013-02-08.txt
+-rw-rw-rw-  2.0 unx   111570 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_001.dat
+-rw-rw-rw-  2.0 unx    55293 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_001.hex
+-rw-rw-rw-  2.0 unx   111547 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_001_no_comment.dat
+-rw-rw-rw-  2.0 unx    55270 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_001_no_comment.hex
+-rw-rw-rw-  2.0 unx    93525 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_002.dat
+-rw-rw-rw-  2.0 unx    57536 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_002.hex
+-rw-rw-rw-  2.0 unx    62703 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_003.hex
+-rw-rw-rw-  2.0 unx   263680 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_003.xls
+-rw-rw-rw-  2.0 unx    80057 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_xl_001.DAT
+-rw-rw-rw-  2.0 unx    81601 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_xl_002.DAT
+-rw-rw-rw-  2.0 unx   221656 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_xl_003.DAT
+-rw-rw-rw-  2.0 unx   118459 b- defN 23-Aug-01 16:29 tsp/dataloggers/test_files/rbr_xl_003.HEX
+-rw-r--r--  2.0 unx       71 b- defN 23-Aug-01 16:29 tsp/plots/__init__.py
+-rw-r--r--  2.0 unx    10971 b- defN 23-Aug-01 16:29 tsp/plots/static.py
+-rw-rw-rw-  2.0 unx    35149 b- defN 23-Aug-01 16:29 tsp-1.7.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3048 b- defN 23-Aug-01 16:29 tsp-1.7.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Aug-01 16:29 tsp-1.7.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       30 b- defN 23-Aug-01 16:29 tsp-1.7.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     8241 b- defN 23-Aug-01 16:29 tsp-1.7.0.dist-info/RECORD
+88 files, 11530902 bytes uncompressed, 3024934 bytes compressed:  73.8%
```

## zipnote {}

```diff
@@ -6,14 +6,17 @@
 
 Filename: tsp/core.py
 Comment: 
 
 Filename: tsp/gtnp.py
 Comment: 
 
+Filename: tsp/labels.py
+Comment: 
+
 Filename: tsp/misc.py
 Comment: 
 
 Filename: tsp/physics.py
 Comment: 
 
 Filename: tsp/readers.py
@@ -21,14 +24,17 @@
 
 Filename: tsp/time.py
 Comment: 
 
 Filename: tsp/utils.py
 Comment: 
 
+Filename: tsp/version.py
+Comment: 
+
 Filename: tsp/data/2023-01-06_755-test-Dataset_2031-Constant_Over_Interval-Hourly-Ground_Temperature-Thermistor_Automated.timeserie.csv
 Comment: 
 
 Filename: tsp/data/2023-01-06_755-test.metadata.txt
 Comment: 
 
 Filename: tsp/data/example_geotop.csv
@@ -237,23 +243,23 @@
 
 Filename: tsp/plots/__init__.py
 Comment: 
 
 Filename: tsp/plots/static.py
 Comment: 
 
-Filename: tsp-1.6.1.dist-info/LICENSE
+Filename: tsp-1.7.0.dist-info/LICENSE
 Comment: 
 
-Filename: tsp-1.6.1.dist-info/METADATA
+Filename: tsp-1.7.0.dist-info/METADATA
 Comment: 
 
-Filename: tsp-1.6.1.dist-info/WHEEL
+Filename: tsp-1.7.0.dist-info/WHEEL
 Comment: 
 
-Filename: tsp-1.6.1.dist-info/top_level.txt
+Filename: tsp-1.7.0.dist-info/top_level.txt
 Comment: 
 
-Filename: tsp-1.6.1.dist-info/RECORD
+Filename: tsp-1.7.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tsp/__init__.py

```diff
@@ -1,10 +1,11 @@
 from tsp.core import TSP, IndexedTSP
 from tsp.misc import _is_depth_column
 
 from tsp.plots.static import trumpet_curve, time_series, colour_contour
 from tsp.readers import read_gtnp, read_geotop, read_geoprecision, read_hoboware, read_ntgs, read_logr, read_csv, read_rbr
 from tsp.utils import resolve_duplicate_times
+from tsp.version import version as __version__
 
 #TSP.__module__ = "teaspoon"
 
 __all__ = ["TSP", "IndexedTSP"]
```

## tsp/__meta__.py

```diff
@@ -1,3 +1,3 @@
 # Automatically created. Please do not edit.
-__version__ = '1.6.1'
+__version__ = '1.7.0'
 __author__ = 'Nick Brown'
```

## tsp/core.py

```diff
@@ -1,11 +1,12 @@
 from __future__ import annotations
 
 import pandas as pd
 import re
+import inspect
 import numpy as np
 import functools
 import warnings
 
 try:
     import netCDF4 as nc
 
@@ -17,18 +18,20 @@
 except ModuleNotFoundError:
     warnings.warn("Missing netCDF4 library. Some functionality will be limited.", stacklevel=2)
 
 from typing import Union, Optional
 from datetime import datetime, tzinfo, timezone, timedelta
 
 import tsp
+import tsp.labels as lbl
 from tsp.physics import analytical_fourier
 from tsp.plots.static import trumpet_curve, colour_contour, time_series
 from tsp.time import format_utc_offset
 from tsp.time import get_utc_offset
+from tsp.misc import completeness
 
 from matplotlib.figure import Figure
 
 
 class TSP:
     """ A Time Series Profile (a collection of time series data at different depths)
     
@@ -85,19 +88,42 @@
         if self.utc_offset:
             self._output_utc_offset = self.utc_offset
         else:
             self._output_utc_offset = None
         
         self._depths = np.atleast_1d(depths)
         self._values = np.atleast_2d(values)
-        self.__number_of_observations = np.ones_like(values) * ~np.isnan(values)
+        self.__number_of_observations = np.ones_like(values, dtype=int)
+        self.__number_of_observations[np.isnan(values)] = 0
         self.metadata = metadata
         self.latitude = latitude
         self.longitude = longitude
         self.site_id = site_id
+        self._freq = None
+        self._completeness = None
+
+    @property
+    def freq(self) -> Optional[int]:
+        """ Measurement frequency [s] """
+        return self._freq
+    
+    @freq.setter
+    def freq(self, value: int):
+        if not isinstance(value, int):
+            raise TypeError("Must be string, e.g. '1D', '3600s'")
+        self._freq = value
+
+    @property
+    def completeness(self) -> Optional[pd.DataFrame]:
+        """ Data completeness """
+        return self._completeness
+    
+    @completeness.setter
+    def completeness(self, value):
+        raise ValueError("You can't assign this variable.")
 
     @classmethod
     def from_tidy_format(cls, times, depths, values,
                         number_of_observations=None,
                         latitude: Optional[float]=None, 
                         longitude: Optional[float]=None,
                         site_id: Optional[str]=None,
@@ -125,40 +151,55 @@
             Additional metadata
         """
         times = np.atleast_1d(times)
         depths = np.atleast_1d(depths)
         values = np.atleast_1d(values)
         
         number_of_observations = number_of_observations if number_of_observations else np.ones_like(values)
-        
         df = pd.DataFrame({"times": times, "depths": depths, "temperature_in_ground": values, "number_of_observations": number_of_observations})
         df.set_index(["times", "depths"], inplace=True)
 
         try:
             unstacked = df.unstack()
         except ValueError as e:
             if np.any(df.index.duplicated()):
                 print(f"Duplicate data found at {df.iloc[np.where(df.index.duplicated())[0], :].index.get_level_values(0).unique()}")
             raise e
 
-        number_of_observations = unstacked.get('number_of_observations')
         temps = unstacked.get('temperature_in_ground') 
         
         this = cls(times=temps.index.values,
                    depths=temps.columns.values,
                    values=temps.values,
                    latitude=latitude, 
                    longitude=longitude,
                    site_id=site_id,
                    metadata=metadata)
+        
+        number_of_observations = unstacked.get('number_of_observations').values
 
-        this.__number_of_observations = number_of_observations.values
+        number_of_observations[np.isnan(number_of_observations)] = 0
+        this.__number_of_observations = number_of_observations
         return this
 
     @classmethod
+    def __from_tsp(cls, t:TSP, **kwargs) -> "TSP":
+        """ Use an existing TSP object as a template, """
+        kw = {}
+        for arg in inspect.getfullargspec(TSP).args[1:]:
+            if kwargs.get(arg) is not None:
+                kw[arg] = kwargs.get(arg)
+            else:
+                kw[arg] = getattr(t, arg)
+        
+        t = TSP(**kw)
+
+        return t
+
+    @classmethod
     def from_json(cls, json_file) -> "TSP":
         """ Read data from a json file 
 
         Parameters
         ----------
         json_file : str
             Path to a json file from which to read
@@ -280,49 +321,17 @@
 
         return tabular
 
     @number_of_observations.setter
     def number_of_observations(self, value):
         raise ValueError(f"You can't assign {value} to this variable (no assignment allowed).")
 
-    def __nly(self, 
-              freq_fmt:str,
-              min_count:int,
-              max_gap:int,
-              min_span:int) -> "TSP":
-        """
-        Temporal aggregation by grouping according to a string-ified time
-
-        Parameters
-        ----------
-        freq_fmt : str
-            Python date format string  used to aggregate and recover time 
-        
-        """
-        data = self.long
-        index = data['time'].dt.strftime(freq_fmt)
-        grouped = data.groupby([index, "depth"])
-
-        # calculate data
-        agg_avg = grouped['temperature_in_ground'].mean().unstack()
-        agg_counts = grouped['number_of_observations'].sum().unstack() 
-        times = pd.to_datetime(agg_avg.index, format=freq_fmt)
-
-        # apply masks
-        count_mask = _observation_count_mask(number_of_observations=agg_counts,
-                                             min_count=min_count)
-        interval_mask = _temporal_gap_mask(grouped, max_gap, min_span)
-        mask = np.logical_or(count_mask, interval_mask)
-        values = np.ma.masked_array(agg_avg, mask=mask)
-
-        # make TSP
-        t = TSP(times=times, depths=self.depths, values=values)
-        t.__number_of_observations = agg_counts
-        
-        return t
+    def reset_counts(self):
+        """ Set observation count to 1 if data exists, 0 otherwise """
+        self.__number_of_observations = (~self.wide.isna()).astype('boolean')
 
     def set_utc_offset(self, offset:"Union[int,str]") -> None:
         """ Set the time zone of the data by providing a UTC offset 
 
         Parameters
         ----------
         offset : int, str
@@ -395,18 +404,70 @@
         
         """
         if self.utc_offset is None:
             raise ValueError("You can't reset the output time zone if the time zone of the data hasn't yet been set with set_utc_offset.")
         else:
             self._output_utc_offset = self.utc_offset
 
+    def __nly(self, 
+              freq_fmt:str,
+              new_freq,
+              min_count:Optional[int],
+              max_gap:Optional[int],
+              min_span:Optional[int]) -> TSP:
+        """
+        Temporal aggregation by grouping according to a string-ified time
+
+        Parameters
+        ----------
+        freq_fmt : str
+            Python date format string  used to aggregate and recover time 
+        
+        Returns
+        -------
+        tuple[pd.DataFrame, pd.DataFrame]
+            A tuple of dataframes, the first containing the aggregated data, the second containing the number of observations
+        """
+        R = self.wide.drop("time", axis=1).resample(freq_fmt)
+        cumulative_obs = self.number_of_observations.drop("time", axis=1).resample(freq_fmt).sum()
+        total_obs = R.count()
+        values = R.mean()
+
+        # Calculate masks
+        mc_mask = Mg_mask = ms_mask = pd.DataFrame(index=values.index, columns=values.columns, data=False)
+
+        if min_count is not None:
+            mc_mask = (cumulative_obs < min_count)
+        if max_gap is not None:
+            Mg_mask = max_gap_mask(R, max_gap)
+        if min_span is not None:
+            ms_mask = min_span_mask(R, min_span)
+        
+        mask = (mc_mask | Mg_mask | ms_mask)
+        values[mask] = np.nan
+        
+        # Construct TSP
+        t = TSP.__from_tsp(self, times=values.index, 
+                           depths=values.columns, 
+                           values=values.values)
+        t.__number_of_observations = cumulative_obs
+        t.freq = new_freq
+
+        # Calculate data completeness
+        if self.freq is not None:
+            f1 = self.freq
+            f2 = new_freq
+            t._completeness = completeness(total_obs, f1, f2)
+
+        return t
+    
     def monthly(self,
-                min_count:int=24,
-                max_gap:int=3600*24*8,
-                min_span:int=3600*24*21) -> "TSP":
+                min_count:Optional[int]=24,
+                max_gap:Optional[int]=3600*24*8,
+                min_span:Optional[int]=3600*24*21) -> "TSP":
         """ Monthly averages, possibly with some months unavailable (NaN) if there is insufficient data
 
         Parameters
         ----------
         min_count : int
             Minimum number of observations in a month to be considered a valid average, defaults to 24
         max_gap : int
@@ -415,25 +476,26 @@
             Minimum total data range (in seconds) to be consiered a valid average, defaults to 1814400 (21 days)
             
         Returns
         -------
         TSP
             A TSP object with data aggregated to monthly averages
         """
-        t = self.__nly(freq_fmt="%Y%m", 
-                         min_count=min_count,
-                         max_gap=max_gap,
-                         min_span=min_span)
-        
+        t = self.__nly(freq_fmt="M", 
+                       new_freq=lbl.MONTHLY, 
+                       min_count=min_count, 
+                       max_gap=max_gap, 
+                       min_span=min_span)
+
         return t
 
     def daily(self, 
-              min_count:int=8,
-              max_gap:int=3600*3,
-              min_span:int=3600*18) -> "TSP":
+              min_count:Optional[int]=8,
+              max_gap:Optional[int]=3600*3,
+              min_span:Optional[int]=3600*18) -> "TSP":
         """ Daily averages, possibly with some days unavailable (NaN) if there is insufficient data
 
         Parameters
         ----------
         min_count : int
             Minimum number of observations in a day to be considered a valid average, defaults to 8
         max_gap : int
@@ -443,31 +505,26 @@
         
         Returns
         -------
         TSP
             A TSP object with data aggregated to daily averages
         """
         # if the data is already daily +/- 1min , just return it
-        if np.all(np.isclose(np.diff(self.times).astype('float64'), 
-                            8.64e13,
-                            atol=8.64e13 / (24 * 60 ))):
-            
-            return self
-        
-        t = self.__nly(freq_fmt="%Y%m%d", 
-                         min_count=min_count,
-                         max_gap=max_gap,
-                         min_span=min_span)
-        
+        t = self.__nly(freq_fmt="D", 
+                new_freq=lbl.DAILY, 
+                min_count=min_count, 
+                max_gap=max_gap, 
+                min_span=min_span)
+
         return t
 
     def yearly(self,
-               min_count:int=270,
-               max_gap:int=3600*24*35,
-               min_span:int=3600*24*330) -> "TSP":
+               min_count:Optional[int]=270,
+               max_gap:Optional[int]=3600*24*35,
+               min_span:Optional[int]=3600*24*330) -> "TSP":
         """ Yearly averages, possibly with some years unavailable (NaN) if there is insufficient data
 
         Parameters
         ----------
         min_count : int
             Minimum number of observations in a month to be considered a valid average, defaults to 270
         max_gap : int
@@ -476,19 +533,20 @@
             Minimum total data range (in seconds) to be consiered a valid average, defaults to 28512000 (330 days)
         
         Returns
         -------
         TSP
             A TSP object with data aggregated to yearly averages
         """
-        t = self.__nly(freq_fmt="%Y", 
-                         min_count=min_count,
-                         max_gap=max_gap,
-                         min_span=min_span)
-        
+        t = self.__nly(freq_fmt="Y", 
+                new_freq=lbl.YEARLY, 
+                min_count=min_count, 
+                max_gap=max_gap, 
+                min_span=min_span)
+
         return t
 
     @property
     def depths(self) -> "np.ndarray":
         """ Return the depth values in the profile 
 
         Returns
@@ -626,15 +684,20 @@
         """ Write the data to a serialized json file """
         with open(file, 'w') as f:
             f.write(self._to_json())
 
     def _to_json(self) -> str:
         return self.wide.to_json()
 
-    def plot_trumpet(self, year: Optional[int]=None, begin: Optional[datetime]=None, end: Optional[datetime]=None, **kwargs) -> Figure:
+    def plot_trumpet(self, 
+                     year: Optional[int]=None,
+                     begin: Optional[datetime]=None,
+                     end: Optional[datetime]=None,
+                     min_completeness: Optional[float]=None,
+                     **kwargs) -> Figure:
         """ Create a trumpet plot from the data
         
         Parameters
         ----------
         year : int, optional
             Which year to plot
         begin : datetime, optional
@@ -650,29 +713,45 @@
         Figure
             a matplotlib `Figure` object
         """
         df = self.long.dropna()
  
         if year is not None:
             df = df[df['time'].dt.year == year]
-        
+
         elif begin is not None or end is not None:
             raise NotImplementedError
-            
+
         else:
             raise ValueError("One of 'year', 'begin', 'end' must be provided.")
 
         grouped = df.groupby('depth')
-        
+
         max_t = grouped.max().get('temperature_in_ground').values
         min_t = grouped.min().get('temperature_in_ground').values
         mean_t = grouped.mean().get('temperature_in_ground').values
         depth = np.array([d for d in grouped.groups.keys()])
 
-        fig = trumpet_curve(depth=depth, t_max=max_t, t_min=min_t, t_mean=mean_t, **kwargs)
+        # Calculate completeness
+        c = self.yearly(None, None, None).completeness
+        
+        if min_completeness is not None and c is not None:
+            C = c[c.index.year == year]
+            C = C[depth].iloc[0,:].values
+        
+        else:
+            C = None
+
+        fig = trumpet_curve(depth=depth, 
+                            t_max=max_t, 
+                            t_min=min_t, 
+                            t_mean=mean_t, 
+                            min_completeness=min_completeness,
+                            data_completeness=C,
+                            **kwargs)
         fig.show()
 
         return fig
     
     def plot_contour(self, **kwargs) -> Figure:
         """ Create a contour plot
         
@@ -796,15 +875,51 @@
         ----------
         depths : np.ndarray
             An array or list of depth values equal in lenth to the depth indices
         """
         self.depths = depths
         self.__class__ = TSP
 
-def _temporal_gap_mask(grouped: "pd.core.groupby.DataFrameGroupBy", max_gap: int, min_span: int) -> np.ndarray:
+
+
+def span(S: pd.Series) -> float:
+    first = S.first_valid_index()  # type: pd.Timestamp
+    last = S.last_valid_index()  # type: pd.Timestamp
+    if first is None or last is None:
+        return 0
+    
+    return (last - first).total_seconds()
+
+def min_span_mask(R: "pd.core.resample.DatetimeIndexResampler",
+             threshold: float) -> "pd.DataFrame":
+    s = R.apply(lambda x: span(x))
+    return s < threshold
+
+
+def gap(S: pd.Series) -> float:
+
+    d = np.diff(S.dropna().index)
+    if len(d) == 0:
+        return 0
+    elif len(d) == 1:
+        return 0
+    elif len(d) > 1:
+        gap = max(d).astype('timedelta64[s]').astype(float)
+    return gap
+
+
+def max_gap_mask(R: "pd.core.resample.DatetimeIndexResampler",
+            threshold: float) -> "pd.DataFrame":
+    g = R.apply(lambda x: gap(x))
+    return (g > threshold) | (g == 0)
+
+
+
+
+def _temporal_gap_mask(grouped: "pd.core.groupby.DataFrameGroupBy", max_gap: Optional[int], min_span: Optional[int]) -> np.ndarray:
     """ Mask out observational groups in which there is more than a certain size temporal gap
 
     Controls for gaps in the data within an aggregation group (using max_gap) and missing data at the beginning
     or end of the aggregation group (using min_span).
     
     Parameters
     ----------
@@ -815,21 +930,27 @@
     min_span : int
         minimum data range (beginning to end) in seconds. 
 
     Returns
     -------
     numpy.ndarray
         boolean array with ``True`` where measurement spacing or range in group does not satisfy tolerances
-    """    
-    max_diff = grouped.time.apply(np.diff).apply(lambda x: np.max(x, initial=np.timedelta64(0))).apply(lambda x: x.total_seconds())
-    max_diff = max_diff.unstack().to_numpy()
-    diff_mask = np.where((max_diff == 0) | (max_diff >= max_gap), True, False)
-    
-    total_span = grouped.time.apply(np.ptp).apply(lambda x: x.total_seconds()).unstack().to_numpy()
-    span_mask = np.where(total_span < min_span, True, False)
+    """
+    if max_gap is not None:
+        max_diff = grouped.time.apply(np.diff).apply(lambda x: np.max(x, initial=np.timedelta64(0))).apply(lambda x: x.total_seconds())
+        max_diff = max_diff.unstack().to_numpy()
+        diff_mask = np.where((max_diff == 0) | (max_diff >= max_gap), True, False)
+    else:
+        diff_mask = np.zeros_like(grouped, dtype=bool)
+    
+    if min_span is not None:
+        total_span = grouped.time.apply(np.ptp).apply(lambda x: x.total_seconds()).unstack().to_numpy()
+        span_mask = np.where(total_span < min_span, True, False)
+    else:
+        span_mask = np.zeros_like(grouped, dtype=bool)
 
     mask = diff_mask * span_mask
 
     return mask
 
 
 def _observation_count_mask(number_of_observations: np.ndarray, min_count:int) -> np.ndarray:
```

## tsp/misc.py

```diff
@@ -1,5 +1,90 @@
+import numpy as np
+import pandas as pd
 import re
 
+import tsp.labels as lbl
+
 
 def _is_depth_column(col_name, pattern) -> bool:
     return bool(re.search(pattern, col_name))
+
+
+def completeness(df: pd.DataFrame, f1, f2) -> pd.DataFrame:
+    """ Calculate completeness of an aggregated dataframe 
+    Parameters
+    ----------
+    df : pd.DataFrame
+        Dataframe with temporal index and values equal to the number of observations
+        in aggregation period
+    f1 : str
+        Aggregation period of data from which df is aggregated
+    f2 : str
+        Aggregation period of df
+
+    Returns
+    -------
+    pd.DataFrame : Dataframe with completeness values as a decimal fraction [0,1]
+    """
+    # df must have temporal index
+    C = None
+    if f1 == lbl.HOURLY:
+        if f2 == lbl.DAILY:
+            C = df / 24
+    
+    elif f1 == lbl.DAILY:
+        if f2 == lbl.MONTHLY:
+            C = df / E_day_in_month(df)
+        elif f2 == lbl.YEARLY:
+            C = df / E_day_in_year(df)
+    
+    elif f1 == lbl.MONTHLY:
+        if f2 == lbl.YEARLY:
+            cnt = 12
+    
+    elif isinstance(f1, float) and isinstance(f1, float):
+        R = f2 / f1
+        C = df / R
+    
+    if C is None:
+        raise ValueError(f"Unknown aggregation period {f1} or {f2}")
+    
+    return C
+
+
+def df_has_period(f, *args, **kwargs):
+    df = args[0] if args[0] else kwargs.get('df')
+    if not isinstance(df.index, pd.PeriodIndex):
+        raise ValueError("Index must be a PeriodIndex")
+    return f(*args, **kwargs)
+
+
+#@df_has_period
+def E_day_in_year(df: "pd.DataFrame") -> "pd.DataFrame":
+    """ Expected number of daily observations per year """
+    leap = df.index.to_period().is_leap_year
+    days = np.atleast_2d(np.where(leap, 366, 365)).transpose()
+    result = pd.DataFrame(index=df.index,
+                          columns=df.columns,
+                          data=np.repeat(np.atleast_2d(days), df.shape[1], axis=1))
+    return result
+
+
+#@df_has_period
+def E_month_in_year(df: "pd.DataFrame") -> "pd.DataFrame":
+    """ Expected number of monthly observations per year """
+    result = pd.DataFrame(index=df.index, 
+                          columns=df.columns, 
+                          data=12)
+    return result
+
+
+#@df_has_period
+def E_day_in_month(df: "pd.DataFrame") -> "pd.DataFrame":
+    """ Expected number of daily observations per month """
+    nday = df.index.to_period().days_in_month
+    result = pd.DataFrame(index=df.index, 
+                          columns=df.columns, 
+                          data=np.repeat(np.atleast_2d(nday).transpose(), df.shape[1], axis=1))
+    return result
+
+
```

## tsp/plots/static.py

```diff
@@ -1,25 +1,30 @@
 import numpy as np
 import warnings
 
 import matplotlib.dates as mdates
 from matplotlib import pyplot as plt
 from matplotlib.figure import Figure
+from typing import Optional
 
 try:
     from scipy.interpolate import griddata
 except ModuleNotFoundError:
     warnings.warn("Missing scipy module. Some functionality will be limited.")
 
 from typing import Union
 
 import tsp
 
 
-def trumpet_curve(depth, t_max, t_min, t_mean, title="", max_depth=None, t_units=u'\N{DEGREE SIGN} C', d_units="m") -> Figure:
+def trumpet_curve(depth, t_max, t_min, t_mean, 
+                  title:str="", max_depth:Optional[float]=None, 
+                  t_units:str=u'\N{DEGREE SIGN} C', d_units:str="m",
+                  data_completeness=None,
+                  min_completeness:Optional[float]=0.9) -> Figure:
     """Plot a trumpet curve
 
     The function returns a matplotlib Figure object. To show the figure, you must call the `show()` method.
 
     Parameters
     ----------
     depth : numpy.ndarray
@@ -34,39 +39,53 @@
         A title for the figure, by default ""
     max_depth : float, optional
         If provided, limits the maximum y-axis extent of the plot, by default None
     t_units : unicode, optional
         Units for the x-axis (assumed to be temperature), by default u'\N{DEGREE SIGN} C'
     d_units : str, optional
         Units for the y axis (depth), by default "m"
+    data_completeness : numpy.ndarray
+        A d-length array of representing data completeness as a fraction (e.g. 0 to 1) for each of the averaging periods ()
+    min_completeness : float
+        Minimum data completeness to be included in the temperature envelope
 
     Returns
     -------
     Figure
         A matplotlib Figure. Note that to show the figure you must call the `show()` method or `matplotlib.pyplot.show()`.
 
     Raises
     ------
     ValueError
         _description_
     """
     ## Sanity checks and data 
-    if not len(depth) == len(t_max) == len(t_min) == len(t_mean):
+    if data_completeness is None:
+        data_completeness = np.ones_like(depth)
+    if not len(depth) == len(t_max) == len(t_min) == len(t_mean) == len(data_completeness):
         raise ValueError("Length of input arrays must be equal")
-
+    
     depth = - np.abs(depth)
     
     ## Create figure
     fig, ax1 = plt.subplots()
 
     ## Create artists
     # TODO:  https://stackoverflow.com/questions/45176584/dotted-lines-instead-of-a-missing-value-in-matplotlib
-    line_max = ax1.plot(t_max, depth, marker='.', color='red', gid="max-temperature")
-    line_min = ax1.plot(t_min, depth, marker='.', color='blue', gid="min-temperature")
-    line_mean = ax1.plot(t_mean, depth, marker='.', color='black', gid="mean-temperature")
+    m = np.where(data_completeness >= min_completeness, True, False)
+    if m.any():
+        line_max = ax1.plot(t_max[m], depth[m], color='red', gid="ln-max-temperature")
+        line_min = ax1.plot(t_min[m], depth[m], color='blue', gid="ln-min-temperature")
+        line_mean = ax1.plot(t_mean[m], depth[m], color='black', gid="ln-mean-temperature")
+
+    alphas = np.where((data_completeness / min_completeness) < 1, 0.1 + (0.7 * data_completeness / min_completeness), 1)
+
+    marker_max = ax1.scatter(t_max, depth, marker='.', c=alpha([1,0,0], alphas), gid="pt-max-temperature")
+    marker_min = ax1.scatter(t_min, depth, marker='.', c=alpha([0,0,1], alphas), gid="pt-min-temperature")
+    marker_mean = ax1.scatter(t_mean, depth, marker='.', c=alpha([0,0,0], alphas), gid="pt-mean-temperature")
 
     surface = ax1.hlines(y=0.0, xmin=-100, xmax=100, linewidth=0.5, linestyles='dotted', color='grey')
     zero = ax1.vlines(x=0.0, ymin=-100, ymax=100, linewidth=0.5, linestyles='dotted', color='grey')
 
      ## Set axis properties
     ax1.set_ybound(upper=1, lower=min(depth) - 3)
     
@@ -171,15 +190,15 @@
     ax1.set_ylabel(f"Depth [{d_units}]")
     ax1.set_title(title)
     
 
     return fig
 
 
-def time_series(depths, times, values, title='', d_units='m', t_units=u'\N{DEGREE SIGN} C') -> Figure:
+def time_series(depths, times, values, title='', d_units='m', t_units=u'\N{DEGREE SIGN} C', legend=True) -> Figure:
     """Create a time-series plot
 
     Using time as the X axis and data values as the y axis. Depths are plotted as their own lines.
 
     Parameters
     ----------
     depths : numpy.ndarray
@@ -206,40 +225,49 @@
 
     # Add data elements
     lines = []
     for i, d in enumerate(depths):
         line_i, = ax.plot(times, values[:,i], lw=1, label=f'{d} {d_units}')
         lines.append(line_i)
 
-    # Add legend
-    leg = ax.legend(fancybox=True, shadow=True)
-
-    lined = {}  # Will map legend lines to original lines.
-    for legline, origline in zip(leg.get_lines(), lines):
-        legline.set_picker(True)  # Enable picking on the legend line.
-        lined[legline] = origline
-    
-    on_pick = create_legend_picker(fig, lined)
-    fig.canvas.mpl_connect('pick_event', on_pick)
+    if legend:
+        box = ax.get_position()
+        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
+        fig.subplots_adjust(right=0.8) # shrink plot to make space
+
+        leg = ax.legend(loc='center left', bbox_to_anchor=(1.04, 0.5), fancybox=True, shadow=True)
+
+        lined = {}  # Will map legend lines to original lines.
+        for legline, origline in zip(leg.get_lines(), lines):
+            legline.set_picker(True)  # Enable picking on the legend line.
+            lined[legline] = origline
+        
+        on_pick = create_legend_picker(fig, lined)
+        fig.canvas.mpl_connect('pick_event', on_pick)
 
+    zero = ax.vlines(x=0.0, ymin=min(times), ymax=max(times), linewidth=0.5, linestyles='dotted', color='grey')
     # Set axis properties
 
     # Set axis labels
     ax.set_xlabel('Time')
     ax.set_ylabel(f"Temperature [{t_units}]")
     ax.set_title(title)
 
     return fig
 
 
 
 
-def alpha(rgba: "tuple[float]", alpha: float) -> tuple:
-    alpha = max(0., min(alpha, 1.))
-    return rgba * np.array([1., 1., 1., alpha])
+def alpha(rgb, alpha):
+    rgb = np.atleast_1d(rgb)
+    alpha = np.atleast_1d(alpha)
+    rgba = np.zeros((len(alpha), 4))
+    rgba[:,3] = alpha
+    rgba[:,0:3] = rgb
+    return rgba
     
 
 def contour_levels(data, levels: "Union[str,list]", step=1) -> "np.ndarray":
     if levels == "dynamic":
         return np.arange(np.nanmin(data), np.nanmax(data), step)
     
     elif levels == "symmetric":
```

## Comparing `tsp-1.6.1.dist-info/LICENSE` & `tsp-1.7.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `tsp-1.6.1.dist-info/METADATA` & `tsp-1.7.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tsp
-Version: 1.6.1
+Version: 1.7.0
 Summary: Making permafrost data effortless
 Home-page: https://gitlab.com/permafrostnet/teaspoon
 Author: Nick Brown
 Author-email: nick.brown@carleton.ca
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: GNU General Public License (GPL)
@@ -20,18 +20,18 @@
 Provides-Extra: dev
 Requires-Dist: manuel ; extra == 'dev'
 Requires-Dist: pytest ; extra == 'dev'
 Requires-Dist: pytest-cov ; extra == 'dev'
 Requires-Dist: coverage ; extra == 'dev'
 Requires-Dist: mock ; extra == 'dev'
 Provides-Extra: full
-Requires-Dist: openpyxl ; extra == 'full'
-Requires-Dist: netCDF4 ; extra == 'full'
 Requires-Dist: pfit (==0.2.1) ; extra == 'full'
+Requires-Dist: netCDF4 ; extra == 'full'
 Requires-Dist: pyrsktools ; extra == 'full'
+Requires-Dist: openpyxl ; extra == 'full'
 Requires-Dist: scipy ; extra == 'full'
 Provides-Extra: nc
 Requires-Dist: netCDF4 ; extra == 'nc'
 Requires-Dist: pfit (==0.2.1) ; extra == 'nc'
 Provides-Extra: plotting
 Requires-Dist: scipy ; extra == 'plotting'
 Provides-Extra: rbr
```

## Comparing `tsp-1.6.1.dist-info/RECORD` & `tsp-1.7.0.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,18 @@
-tsp/__init__.py,sha256=Ye8YN7QIbwkk6qMB_D0gB_F39JHY7WHsKKpNmE41g-U,380
-tsp/__meta__.py,sha256=BwjGGORwWYFs0PN8RmpMGLmfBAXByluZuhHe8XxYXiA,93
-tsp/core.py,sha256=aLC84vM5JTu2Njexckxdp9a0Gj_TcKh4wPNuH8z3s_o,30796
+tsp/__init__.py,sha256=V_rDl4XxSRtbFWK7KFZJkKqwjqwLREvlnVc7BCGjHaw,427
+tsp/__meta__.py,sha256=XK-Bt0SejsCFzhBKa0AkjQv38Q7VzWmLPaWlOb2trQU,93
+tsp/core.py,sha256=k55KCS0hDgzx5c9Aitlj-grB7Ii0YDXHNN2sataiwRI,34356
 tsp/gtnp.py,sha256=kIxhLq_ve_cxU9v4_nDebc8jy6l7KQ87MOg8vK8lih4,3991
-tsp/misc.py,sha256=18w41G-umRi69lswXhpvJwrx4hqQ6r3bsvnmeKtpMU4,107
+tsp/labels.py,sha256=URV4zxfur6aYojdra7KGTipFdiN9pAOCEVvkcc2pj-Q,78
+tsp/misc.py,sha256=y0NvW5jOlli5s220QnaLYTOadSlj3Lyu-EE-RsoSbok,2614
 tsp/physics.py,sha256=hgVOGU0Bj1g-gxBNhLEl7Gm3VXJKIHHu35uPvgVMOxE,2699
 tsp/readers.py,sha256=AR2__iJIDW4MGUd11B9RF3kPCEZAQ0xzNOHSrpgd-yM,18520
 tsp/time.py,sha256=82h7nxM-iXs2XwetF-alLtNvUm0qRtAA111gTMp5SY4,1379
 tsp/utils.py,sha256=sOJSZLmfv7sh4X971_gNgtZvXtS8ZwGmUdqnUybcVE4,2932
+tsp/version.py,sha256=AjRt0rKfCuGCu5GdMH7ihRsB1OB2HRnEMPmosTEeDsY,15
 tsp/data/2023-01-06_755-test-Dataset_2031-Constant_Over_Interval-Hourly-Ground_Temperature-Thermistor_Automated.timeserie.csv,sha256=Q3Ssnoo_kiSn9_orZHjtMxQ02YbrjCAEQKs5sHPFJCg,171
 tsp/data/2023-01-06_755-test.metadata.txt,sha256=Ux1YGqmAmRQmMIqqK8-OloQXflg4Y45FRwdT-WgCg8c,5686
 tsp/data/example_geotop.csv,sha256=rgVP7_tGEvUtn1K_KI98VVgm275D7qt8YegKMe3Vjw4,262289
 tsp/data/example_gtnp.csv,sha256=E5km06-cWlWMwzF-Qo7v0ZrlAvCTpyWIKY6hpzln4sc,191812
 tsp/dataloggers/AbstractReader.py,sha256=YsmESWrmH2jdL-Oli9pwjaFmPCEfJxjm4wx16FoRxpY,1777
 tsp/dataloggers/FG2.py,sha256=kvfjMQtoSs5ZzV7hc1lJ_SaDuSOOTONfI_nw2VaihO8,3281
 tsp/dataloggers/GP5W.py,sha256=dJ7I-P4_bIDDGb9zIdOf9vbxbxlcT3ZJ09HKLfRA6a0,3312
@@ -74,13 +76,13 @@
 tsp/dataloggers/test_files/rbr_003.hex,sha256=cjUaYWGm39WthiPvdzQKaOQ5FEKj3U9rCIe_0my7v2M,62703
 tsp/dataloggers/test_files/rbr_003.xls,sha256=PRxsKD88dTQEYOqz5z1FrkPox1jCkYyiBBZK0Kg-7tQ,263680
 tsp/dataloggers/test_files/rbr_xl_001.DAT,sha256=yZXKaClXMtYWDCs1cD2xTVdGj6LBMLKSjKnTgB4qPio,80057
 tsp/dataloggers/test_files/rbr_xl_002.DAT,sha256=JQNHL6X9z4Rp6IDqDBYx8vWsUU6oigl8nC23rMa3Enk,81601
 tsp/dataloggers/test_files/rbr_xl_003.DAT,sha256=ZEKheCvB1CiubY2kMngigY0NNhWTYAiC_hmQhzODPYw,221656
 tsp/dataloggers/test_files/rbr_xl_003.HEX,sha256=sunCD5C1t8l5y4p1b9iiHNsZUznYIuBLz4uwoGkZh3E,118459
 tsp/plots/__init__.py,sha256=i5AhpNwyuT6il7uk2Vtc4YBjVnZ0ifvHNXw19rvDtsM,71
-tsp/plots/static.py,sha256=tg5dBymuW_IbtMo8aSANPkGh9LogI39BmKN-LY_lJNU,9449
-tsp-1.6.1.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-tsp-1.6.1.dist-info/METADATA,sha256=yoki6YMd0KssQj_7ppj8l1q3GNf7qO3iWAPPodjcdMQ,3048
-tsp-1.6.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-tsp-1.6.1.dist-info/top_level.txt,sha256=7tOR6y7BarphfWD2D7QFi_3F1jxagUZpHG8zwJIw4ck,30
-tsp-1.6.1.dist-info/RECORD,,
+tsp/plots/static.py,sha256=IEmFtGdzyVDbdyB9HCJ4kMVFIshjVP9i9YqyFY7LG7A,10971
+tsp-1.7.0.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+tsp-1.7.0.dist-info/METADATA,sha256=xCn2oVC8lvWFS-MHKtsF_ccvWnanbfrYO5vHzW0Q2vg,3048
+tsp-1.7.0.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
+tsp-1.7.0.dist-info/top_level.txt,sha256=7tOR6y7BarphfWD2D7QFi_3F1jxagUZpHG8zwJIw4ck,30
+tsp-1.7.0.dist-info/RECORD,,
```

