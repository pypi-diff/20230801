# Comparing `tmp/bikeshare_model-0.1.0-py3-none-any.whl.zip` & `tmp/bikeshare_model-1.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,21 @@
-Zip file size: 577816 bytes, number of entries: 22
--rw-r--r--  2.0 unx     6148 b- defN 23-Jun-16 16:18 .DS_Store
--rw-rw-r--  2.0 unx        5 b- defN 23-Jun-17 05:07 bikeshare_model/VERSION
--rw-r--r--  2.0 unx      253 b- defN 23-Jun-08 23:54 bikeshare_model/__init__.py
--rw-rw-r--  2.0 unx     2061 b- defN 23-Jun-09 22:47 bikeshare_model/config.yml
--rw-r--r--  2.0 unx     2134 b- defN 23-Jun-09 21:41 bikeshare_model/pipeline.py
--rw-r--r--  2.0 unx     1878 b- defN 23-Jun-10 01:55 bikeshare_model/predict.py
--rw-r--r--  2.0 unx     1679 b- defN 23-Jun-09 22:58 bikeshare_model/train_pipeline.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-02 13:16 bikeshare_model/config/__init__.py
--rw-r--r--  2.0 unx     2928 b- defN 23-Jun-10 04:30 bikeshare_model/config/core.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-02 13:16 bikeshare_model/datasets/__init__.py
--rw-rw-r--  2.0 unx  1598454 b- defN 23-Jun-02 20:20 bikeshare_model/datasets/bike-sharing-dataset.csv
--rw-rw-r--  2.0 unx   318833 b- defN 23-Jun-10 04:13 bikeshare_model/datasets/test.csv
--rw-r--r--  2.0 unx        2 b- defN 23-Jun-02 13:16 bikeshare_model/processing/__init__.py
--rw-r--r--  2.0 unx     3057 b- defN 23-Jun-17 04:45 bikeshare_model/processing/data_manager.py
--rw-r--r--  2.0 unx     3241 b- defN 23-Jun-09 23:14 bikeshare_model/processing/features.py
--rw-r--r--  2.0 unx     1540 b- defN 23-Jun-17 05:07 bikeshare_model/processing/validation.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-02 13:16 bikeshare_model/trained_models/__init__.py
--rw-rw-r--  2.0 unx   659402 b- defN 23-Jun-10 04:30 bikeshare_model/trained_models/bikeshare__model_output_v0.0.1.pkl
--rw-r--r--  2.0 unx     1127 b- defN 23-Jun-17 05:08 bikeshare_model-0.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-17 05:08 bikeshare_model-0.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       16 b- defN 23-Jun-17 05:08 bikeshare_model-0.1.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1965 b- defN 23-Jun-17 05:08 bikeshare_model-0.1.0.dist-info/RECORD
-22 files, 2604815 bytes uncompressed, 574566 bytes compressed:  78.0%
+Zip file size: 306201 bytes, number of entries: 19
+-rw-rw-r--  2.0 unx        5 b- defN 23-Jul-31 23:47 bikeshare_model/VERSION
+-rw-r--r--  2.0 unx      307 b- defN 23-Jun-21 08:52 bikeshare_model/__init__.py
+-rw-rw-r--  2.0 unx     1948 b- defN 23-May-25 02:27 bikeshare_model/config.yml
+-rw-r--r--  2.0 unx     2715 b- defN 23-Jun-21 08:52 bikeshare_model/pipeline.py
+-rw-r--r--  2.0 unx     1851 b- defN 23-Jul-05 18:41 bikeshare_model/predict.py
+-rw-r--r--  2.0 unx     1450 b- defN 23-Jun-21 08:52 bikeshare_model/train_pipeline.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-21 13:27 bikeshare_model/config/__init__.py
+-rw-r--r--  2.0 unx     2820 b- defN 23-Jun-21 08:53 bikeshare_model/config/core.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-21 13:27 bikeshare_model/datasets/__init__.py
+-rw-rw-r--  2.0 unx  1598454 b- defN 23-May-22 10:38 bikeshare_model/datasets/bike-rental-dataset.csv
+-rw-r--r--  2.0 unx        2 b- defN 23-May-21 13:27 bikeshare_model/processing/__init__.py
+-rw-r--r--  2.0 unx     2972 b- defN 23-Jun-21 08:53 bikeshare_model/processing/data_manager.py
+-rw-r--r--  2.0 unx     5280 b- defN 23-Jun-04 01:13 bikeshare_model/processing/features.py
+-rw-r--r--  2.0 unx     1403 b- defN 23-Jun-04 01:43 bikeshare_model/processing/validation.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-21 13:27 bikeshare_model/trained_models/__init__.py
+-rw-r--r--  2.0 unx     1078 b- defN 23-Jul-31 23:53 bikeshare_model-1.0.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-31 23:53 bikeshare_model-1.0.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       16 b- defN 23-Jul-31 23:53 bikeshare_model-1.0.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1682 b- defN 23-Jul-31 23:53 bikeshare_model-1.0.0.dist-info/RECORD
+19 files, 1622075 bytes uncompressed, 303395 bytes compressed:  81.3%
```

## zipnote {}

```diff
@@ -1,10 +1,7 @@
-Filename: .DS_Store
-Comment: 
-
 Filename: bikeshare_model/VERSION
 Comment: 
 
 Filename: bikeshare_model/__init__.py
 Comment: 
 
 Filename: bikeshare_model/config.yml
@@ -24,18 +21,15 @@
 
 Filename: bikeshare_model/config/core.py
 Comment: 
 
 Filename: bikeshare_model/datasets/__init__.py
 Comment: 
 
-Filename: bikeshare_model/datasets/bike-sharing-dataset.csv
-Comment: 
-
-Filename: bikeshare_model/datasets/test.csv
+Filename: bikeshare_model/datasets/bike-rental-dataset.csv
 Comment: 
 
 Filename: bikeshare_model/processing/__init__.py
 Comment: 
 
 Filename: bikeshare_model/processing/data_manager.py
 Comment: 
@@ -45,23 +39,20 @@
 
 Filename: bikeshare_model/processing/validation.py
 Comment: 
 
 Filename: bikeshare_model/trained_models/__init__.py
 Comment: 
 
-Filename: bikeshare_model/trained_models/bikeshare__model_output_v0.0.1.pkl
-Comment: 
-
-Filename: bikeshare_model-0.1.0.dist-info/METADATA
+Filename: bikeshare_model-1.0.0.dist-info/METADATA
 Comment: 
 
-Filename: bikeshare_model-0.1.0.dist-info/WHEEL
+Filename: bikeshare_model-1.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: bikeshare_model-0.1.0.dist-info/top_level.txt
+Filename: bikeshare_model-1.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: bikeshare_model-0.1.0.dist-info/RECORD
+Filename: bikeshare_model-1.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## bikeshare_model/VERSION

```diff
@@ -1 +1 @@
-0.1.0
+1.0.0
```

## bikeshare_model/__init__.py

```diff
@@ -1,7 +1,9 @@
 import sys
 from pathlib import Path
-sys.path.append(str(Path(__file__).parent.parent))
+file = Path(__file__).resolve()
+parent, root = file.parent, file.parents[1]
+sys.path.append(str(root))
 
 from bikeshare_model.config.core import PACKAGE_ROOT, config
 with open(PACKAGE_ROOT / "VERSION") as version_file:
     __version__ = version_file.read().strip()
```

## bikeshare_model/config.yml

```diff
@@ -1,138 +1,128 @@
 # Package Overview
 package_name: bikeshare_model
 
 # Data Files
-training_data_file: bike-sharing-dataset.csv
-test_data_file: test.csv
+training_data_file: bike-rental-dataset.csv
 
 # Variables
 # The variable we are attempting to predict (cnt)
 target: cnt
 
 pipeline_name: bikeshare_model
 pipeline_save_file: bikeshare__model_output_v
 
-features:      # final features to be use
+# Features that will go inside processing pipeline
+features:
+  - dteday
   - season
-  - hr 
-  - holiday 
+  - hr
+  - holiday
   - weekday
-  - workingday  # generated  by  Sibsp + Parch <--Before pipeline alongwith loading the data
-  - weathersit   # generated cabin              <--Before pipeline alongwith loading the data
-  - temp       # generated from name          <--Before pipeline alongwith loading the data
+  - workingday
+  - weathersit
+  - temp
   - atemp
   - hum
   - windspeed
-  - yr
-  - mnth
+  - yr            # generated from dteday colum <--Before pipeline alongwith loading the data
+  - mnth          # generated from dteday colum <--Before pipeline alongwith loading the data
 
 
 unused_fields:  # Features to drop before pipeline
-  - dteday
   - casual
-  - registered  
+  - registered
 
 
-# Features inside processing pipeline
+# Features names
 
-hr_var: hr  # first imputatation , then --> Mappeing
+date_var: dteday
 yr_var: yr
 mnth_var: mnth
 season_var: season
-weekday_var: weekday
+hr_var: hr
 holiday_var: holiday
-weathersit_var: weathersit
 workingday_var: workingday
+weekday_var: weekday
+weathersit_var: weathersit
+temp_var: temp
+atemp_var: atemp
+hum_var: hum
+windspeed_var: windspeed
 
 
+# Mappings for Ordinal categorical features
+
+yr_mappings: 
+  2011: 0
+  2012: 1
+
+mnth_mappings:
+  January: 0
+  February: 1
+  December: 2
+  March: 3
+  November: 4
+  April: 5
+  October: 6
+  May: 7
+  September: 8
+  June: 9
+  July: 10
+  August: 11
 
 season_mappings:
   spring: 0
   winter: 1
   summer: 2
   fall: 3
 
-weekday_mappings:
-  Mon: 0
-  Tue: 1
-  Wed: 2
-  Thu: 3
-  Fri: 4
-  Sat: 5
-  Sun: 6
-
 weathersit_mappings:
-  Clear: 0
-  Mist: 1
-  Light Rain: 2
-  Heavy Rain: 3
-
+  Heavy Rain: 0
+  Light Rain: 1
+  Mist: 2
+  Clear: 3
 
 holiday_mappings:
-  No: 0
-  Yes: 1
+  Yes: 0
+  No: 1
 
 workingday_mappings:
   No: 0
   Yes: 1
 
 hr_mappings:
-  12am: 0
-  1am: 1
-  2am: 2
-  3am: 3
-  4am: 4
-  5am: 5
+  4am: 0
+  3am: 1
+  5am: 2
+  2am: 3
+  1am: 4
+  12am: 5
   6am: 6
-  7am: 7
-  8am: 8
-  9am: 9
-  10am: 10
+  11pm: 7
+  10pm: 8
+  10am: 9
+  9pm: 10
   11am: 11
-  12pm: 12
-  1pm: 13
-  2pm: 14
-  3pm: 15
-  4pm: 16
-  5pm: 17
-  6pm: 18
-  7pm: 19
-  8pm: 20
-  9pm: 21
-  10pm: 22
-  11pm: 23
- 
-yr_mappings:
-  2011: 0
-  2012: 1
-
-mnth_mappings:
-  January: 1
-  February: 2
-  March: 3
-  April: 4
-  May: 5 
-  June: 6
-  July: 7
-  August: 8
-  September: 9
-  October: 10
-  November: 11
-  December: 12
+  7am: 12
+  9am: 13
+  8pm: 14
+  2pm: 15
+  1pm: 16
+  12pm: 17
+  3pm: 18
+  4pm: 19
+  7pm: 20
+  8am: 21
+  6pm: 22
+  5pm: 23
 
-# set train/test split
+  
+# Set train/test split
 test_size: 0.20
 
-# to set the random seed
+# Set the random seed
 random_state: 42
-# alogrithm parameters
+
+# Alogrithm parameters
 n_estimators: 100
 max_depth: 10
-
-
-
-
-
-
-
-
```

## bikeshare_model/pipeline.py

```diff
@@ -1,40 +1,55 @@
 import sys
 from pathlib import Path
-sys.path.append(str(Path(__file__).parent.parent))
+file = Path(__file__).resolve()
+parent, root = file.parent, file.parents[1]
+sys.path.append(str(root))
 
 from sklearn.pipeline import Pipeline
 from sklearn.preprocessing import StandardScaler
-from sklearn.ensemble import RandomForestClassifier
-from sklearn.impute import SimpleImputer
 from sklearn.ensemble import RandomForestRegressor
 
 from bikeshare_model.config.core import config
-#from bikeshare_model.processing.features import WeathersitImputer
+from bikeshare_model.processing.features import WeekdayImputer, WeathersitImputer
 from bikeshare_model.processing.features import Mapper
-from bikeshare_model.processing.features import OutlierHandler
-from bikeshare_model.processing.features import WeekdayOneHotEncoder
-#from bikeshare_model.processing.features import WeekdayImputer
-from bikeshare_model.processing.features import bikeshareImputer
+from bikeshare_model.processing.features import OutlierHandler, WeekdayOneHotEncoder
 
 bikeshare_pipe = Pipeline([
-    ##Imputation##
-    ('weekD', bikeshareImputer(variables='weekday')),
-    ('weathS', bikeshareImputer(variables='weathersit')),
-    ##Mapper##
-    #('map_yr',Mapper('yr',{'2011': 0, '2012': 1})),
-    ('map_mnth',Mapper('mnth',{'January':1,'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8,'September':9, 'October':10, 'November':11, 'December':12})),
-    ('map_season',Mapper('season',{'spring':1, 'summer':2, 'fall':3, 'winter':4})),
-    ('map_weathersit',Mapper('weathersit',{'Clear':1,'Mist':2, 'Light Rain':3, 'Heavy Rain':4})),
-    ('map_holiday',Mapper('holiday',{'No':0, 'Yes':1})),
-    ('map_workingday',Mapper('workingday',{'No':0, 'Yes':1})),
-    ('map_hr', Mapper('hr',{'12am':0, '1am':1, '2am':2, '3am':3, '4am':4, '5am':5, '6am':6, '7am':7, '8am':8, '9am':9, '10am':10, '11am':11, '12pm':12, '1pm':13, '2pm':14, '3pm':15, '4pm':16, '5pm':17, '6pm':18, '7pm':19, '8pm':20, '9pm':21, '10pm':22, '11pm':23 })),
-    
-    #RemoveOutlier#
-    ('temp_outl',OutlierHandler('temp')),
-    ('atemp_outl',OutlierHandler('atemp')),
-    ('hum_outl',OutlierHandler('hum')),
-    ('windspeed_outl', OutlierHandler('windspeed')),
-    #OneHotEncoder#
-    ('weekday_enc',WeekdayOneHotEncoder('weekday')),
-    ('model_rf', RandomForestRegressor(n_estimators=150, max_depth=5,random_state=42))
-])
+
+    ######### Imputation ###########
+    ('weekday_imputation', WeekdayImputer(variable = config.model_config.weekday_var, 
+                                          date_var= config.model_config.date_var)),
+    ('weathersit_imputation', WeathersitImputer(variable = config.model_config.weathersit_var)),
+    
+    ######### Mapper ###########
+    ('map_yr', Mapper(variable = config.model_config.yr_var, mappings = config.model_config.yr_mappings)),
+    
+    ('map_mnth', Mapper(variable = config.model_config.mnth_var, mappings = config.model_config.mnth_mappings)),
+    
+    ('map_season', Mapper(variable = config.model_config.season_var, mappings = config.model_config.season_mappings)),
+    
+    ('map_weathersit', Mapper(variable = config.model_config.weathersit_var, mappings = config.model_config.weathersit_mappings)),
+    
+    ('map_holiday', Mapper(variable = config.model_config.holiday_var, mappings = config.model_config.holiday_mappings)),
+    
+    ('map_workingday', Mapper(variable = config.model_config.workingday_var, mappings = config.model_config.workingday_mappings)),
+    
+    ('map_hr', Mapper(variable = config.model_config.hr_var, mappings = config.model_config.hr_mappings)),
+    
+    ######## Handle outliers ########
+    ('handle_outliers_temp', OutlierHandler(variable = config.model_config.temp_var)),
+    ('handle_outliers_atemp', OutlierHandler(variable = config.model_config.atemp_var)),
+    ('handle_outliers_hum', OutlierHandler(variable = config.model_config.hum_var)),
+    ('handle_outliers_windspeed', OutlierHandler(variable = config.model_config.windspeed_var)),
+
+    ######## One-hot encoding ########
+    ('encode_weekday', WeekdayOneHotEncoder(variable = config.model_config.weekday_var)),
+
+    # Scale features
+    ('scaler', StandardScaler()),
+    
+    # Regressor
+    ('model_rf', RandomForestRegressor(n_estimators = config.model_config.n_estimators, 
+                                       max_depth = config.model_config.max_depth,
+                                      random_state = config.model_config.random_state))
+    
+    ])
```

## bikeshare_model/predict.py

```diff
@@ -1,44 +1,47 @@
 import sys
 from pathlib import Path
-sys.path.append(str(Path(__file__).parent.parent))
+file = Path(__file__).resolve()
+parent, root = file.parent, file.parents[1]
+sys.path.append(str(root))
 
+from typing import Union
 import pandas as pd
 import numpy as np
 
-from bikeshare_model.processing.validation import validate_input_data
 from bikeshare_model import __version__ as _version
 from bikeshare_model.config.core import config
-from bikeshare_model.pipeline import bikeshare_pipe
 from bikeshare_model.processing.data_manager import load_pipeline
 from bikeshare_model.processing.data_manager import pre_pipeline_preparation
+from bikeshare_model.processing.validation import validate_inputs
 
 
 pipeline_file_name = f"{config.app_config.pipeline_save_file}{_version}.pkl"
-bikeshare_pipe= load_pipeline(file_name=pipeline_file_name)
+bikeshare_pipe = load_pipeline(file_name = pipeline_file_name)
 
 
-def make_prediction(*,input_data: dict) -> dict:
+def make_prediction(*, input_data: Union[pd.DataFrame, dict]) -> dict:
     """Make a prediction using a saved model """
-
-    data = pre_pipeline_preparation(data_frame=pd.DataFrame(input_data))
-    #data=data.reindex(columns=['season','hr','holiday','workingday', 'weathersit','temp','atemp','hum','windspeed','yr','mnth','weekday_Fri','weekday_Mon','weekday_Sat','weekday_Sun','weekday_Thu','weekday_Tue','weekday_Wed'])
-    data=data.reindex(columns=['season','hr','holiday','workingday', 'weathersit','temp','atemp','hum','windspeed','yr','mnth','weekday'])
-    results = {"predictions": None, "version": _version, }
     
-    predictions = bikeshare_pipe.predict(data)
-
-    results = {"predictions": predictions,"version": _version}
-    print(results)
+    validated_data, errors = validate_inputs(input_df = pd.DataFrame(input_data))
+    
+    #validated_data = validated_data.reindex(columns = ['dteday', 'season', 'hr', 'holiday', 'weekday', 'workingday', 
+    #                                                   'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'yr', 'mnth'])
+    validated_data = validated_data.reindex(columns = config.model_config.features)
+    
+    results = {"predictions": None, "version": _version, "errors": errors}
+      
+    if not errors:
+        predictions = bikeshare_pipe.predict(validated_data)
+        results = {"predictions": predictions, "version": _version, "errors": errors}
+        print(results)
 
     return results
 
+
+
 if __name__ == "__main__":
 
-    data_in={'dteday':['2012-11-05'],'season':['winter'],'hr':['6am'],'holiday':['No'],'weekday':['Mon'],
-                'workingday':['Yes'],'weathersit':['Mist'],'temp':[6.1],'atemp':[3.0014],'hum':[49],'windspeed':[19.0012],'casual':[4],'registered':[135]}
-    
-    is_valid = validate_input_data(data_in)
-    if is_valid:
-        make_prediction(input_data=data_in)
-    else:
-        print("Invalid Input Data")    
+    data_in = {'dteday': ['2012-11-6'], 'season': ['winter'], 'hr': ['6pm'], 'holiday': ['No'], 'weekday': ['Tue'],
+               'workingday': ['Yes'], 'weathersit': ['Clear'], 'temp': [16], 'atemp': [17.5], 'hum': [30], 'windspeed': [10]}
+
+    make_prediction(input_data = data_in)
```

## bikeshare_model/train_pipeline.py

```diff
@@ -1,51 +1,45 @@
 import sys
 from pathlib import Path
-sys.path.append(str(Path(__file__).parent.parent))
+file = Path(__file__).resolve()
+parent, root = file.parent, file.parents[1]
+sys.path.append(str(root))
+
 import pandas as pd
 from sklearn.model_selection import train_test_split
-from sklearn.metrics import accuracy_score
-from sklearn.utils import check_X_y
 from sklearn.metrics import mean_squared_error, r2_score
 
 from bikeshare_model.config.core import config
 from bikeshare_model.pipeline import bikeshare_pipe
 from bikeshare_model.processing.data_manager import load_dataset, save_pipeline
 
 def run_training() -> None:
     
     """
     Train the model.
     """
 
     # read training data
-    data = load_dataset(file_name=config.app_config.training_data_file)
-    #print("loading preprocess dataset",data.head)
-
+    data = load_dataset(file_name = config.app_config.training_data_file)
+    
     # divide train and test
     X_train, X_test, y_train, y_test = train_test_split(
-        data[config.model_config.features],  # predictors
-        data[config.model_config.target],
-        test_size=config.model_config.test_size,
-        # we are setting the random seed here
-        # for reproducibility
-        random_state=config.model_config.random_state,
+        
+        data[config.model_config.features],     # predictors
+        data[config.model_config.target],       # target
+        test_size = config.model_config.test_size,
+        random_state=config.model_config.random_state,   # set the random seed here for reproducibility
     )
-    
-    #print("Train data ",X_train.head)
 
     # Pipeline fitting
-    #X,y =  check_X_y(X_train,y_train)
-    bikeshare_pipe.fit(X_train,y_train)  #
-    y_pred = bikeshare_pipe.predict(X_test)
-    #print("Accuracy(in %):", accuracy_score(y_test, y_pred)*100)
-    mse = mean_squared_error(y_test, y_pred)
-    r2 = r2_score(y_test, y_pred)
-    print("R2 Score :", r2)
-    print("Mean Square Error",mse)
+    bikeshare_pipe.fit(X_train, y_train)
+    #y_pred = bikeshare_pipe.predict(X_test)
+
+    # Calculate the score/error
+    #print("R2 score:", r2_score(y_test, y_pred).round(2))
+    #print("Mean squared error:", mean_squared_error(y_test, y_pred))
 
     # persist trained model
-    save_pipeline(pipeline_to_persist= bikeshare_pipe)
-    # printing the score
+    save_pipeline(pipeline_to_persist = bikeshare_pipe)
     
 if __name__ == "__main__":
     run_training()
```

## bikeshare_model/config/core.py

```diff
@@ -1,32 +1,24 @@
 # Path setup, and access the config.yml file, datasets folder & trained models
 import sys
-import os
-
-# Get the file path of the core.py file
-core_file_path = os.path.abspath(__file__)
-
-# Derive the project folder path by going one level up from the file path
-project_folder_path = os.path.dirname(os.path.dirname(core_file_path))
-
-#sys.path.append('C:/Users/mili/Desktop/IISC_AIMLOPs/Project')
-sys.path.append(project_folder_path)
+from pathlib import Path
+file = Path(__file__).resolve()
+parent, root = file.parent, file.parents[1]
+sys.path.append(str(root))
 
 from pathlib import Path
 from typing import Dict, List
 
 from pydantic import BaseModel
 from strictyaml import YAML, load
 
 import bikeshare_model
 
 # Project Directories
 PACKAGE_ROOT = Path(bikeshare_model.__file__).resolve().parent
-#PACKAGE_ROOT = project_folder_path
-
 ROOT = PACKAGE_ROOT.parent
 CONFIG_FILE_PATH = PACKAGE_ROOT / "config.yml"
 #print(CONFIG_FILE_PATH)
 
 DATASET_DIR = PACKAGE_ROOT / "datasets"
 TRAINED_MODEL_DIR = PACKAGE_ROOT / "trained_models"
 
@@ -34,42 +26,49 @@
 class AppConfig(BaseModel):
     """
     Application-level config.
     """
 
     package_name: str
     training_data_file: str
-    test_data_file: str
+    pipeline_name: str
     pipeline_save_file: str
 
 
 class ModelConfig(BaseModel):
     """
     All configuration relevant to model
     training and feature engineering.
     """
+
     target: str
     features: List[str]
     unused_fields: List[str]
-    season_var:str
-    hr_var:str
-    holiday_var:str
-    weekday_var:str
-    workingday_var:str
-    weathersit_var:str
-    yr_var:str
-    mnth_var:str
     
-    yr_mappings: Dict[str,int]
-    mnth_mappings: Dict[str,int]
-    season_mappings: Dict[str,int]
-    weathersit_mappings: Dict[str,int]
-    holiday_mappings: Dict[str,int]
-    workingday_mappings: Dict[str,int]
-    hr_mappings: Dict[str,int]
+    date_var: str
+    yr_var: str
+    mnth_var: str
+    season_var: str
+    hr_var: str
+    holiday_var: str
+    workingday_var: str
+    weekday_var: str
+    weathersit_var: str
+    temp_var: str
+    atemp_var: str
+    hum_var: str
+    windspeed_var: str
+        
+    yr_mappings: Dict[int, int]
+    mnth_mappings: Dict[str, int]
+    season_mappings: Dict[str, int]
+    weathersit_mappings: Dict[str, int]
+    holiday_mappings: Dict[str, int]
+    workingday_mappings: Dict[str, int]
+    hr_mappings: Dict[str, int]
     
     test_size:float
     random_state: int
     n_estimators: int
     max_depth: int
 
 
@@ -78,40 +77,43 @@
 
     app_config: AppConfig
     model_config: ModelConfig
 
 
 def find_config_file() -> Path:
     """Locate the configuration file."""
+    
     if CONFIG_FILE_PATH.is_file():
         return CONFIG_FILE_PATH
+    
     raise Exception(f"Config not found at {CONFIG_FILE_PATH!r}")
 
 
 def fetch_config_from_yaml(cfg_path: Path = None) -> YAML:
     """Parse YAML containing the package configuration."""
 
     if not cfg_path:
         cfg_path = find_config_file()
 
     if cfg_path:
         with open(cfg_path, "r") as conf_file:
             parsed_config = load(conf_file.read())
             return parsed_config
+        
     raise OSError(f"Did not find config file at path: {cfg_path}")
 
 
 def create_and_validate_config(parsed_config: YAML = None) -> Config:
     """Run validation on config values."""
     if parsed_config is None:
         parsed_config = fetch_config_from_yaml()
 
     # specify the data attribute from the strictyaml YAML type.
     _config = Config(
-        app_config=AppConfig(**parsed_config.data),
-        model_config=ModelConfig(**parsed_config.data),
+        app_config = AppConfig(**parsed_config.data),
+        model_config = ModelConfig(**parsed_config.data),
     )
 
     return _config
 
 
 config = create_and_validate_config()
```

## bikeshare_model/processing/data_manager.py

```diff
@@ -1,71 +1,71 @@
 import sys
-sys.path.append('/Users/ajaysingh/aimlops/Project')
+from pathlib import Path
+file = Path(__file__).resolve()
+parent, root = file.parent, file.parents[1]
+sys.path.append(str(root))
 
 import typing as t
 from pathlib import Path
-import re
 
 import joblib
 import pandas as pd
 from sklearn.pipeline import Pipeline
 
 from bikeshare_model import __version__ as _version
 from bikeshare_model.config.core import DATASET_DIR, TRAINED_MODEL_DIR, config
 
 
 ##  Pre-Pipeline Preparation
 
-def get_year_and_month(dataframe):
+# Extract year and month from the date column and create two another columns
+
+def get_year_and_month(dataframe: pd.DataFrame, date_var: str):
 
     df = dataframe.copy()
-    print("get_year_and_month:",dataframe)
+    
     # convert 'dteday' column to Datetime datatype
-    df['dteday'] = pd.to_datetime(df['dteday'], format='%Y-%m-%d')
+    df[date_var] = pd.to_datetime(df[date_var], format='%Y-%m-%d')
     
-    #df['dteday'] = pd.to_datetime(df['dteday'], format='%d-%m-%Y')
-    df['dteday']=df['dteday']
     # Add new features 'yr' and 'mnth
-    df['yr'] = df['dteday'].dt.year.astype(str)
-    df['mnth'] = df['dteday'].dt.month_name().astype(str)
-    #print("Year and Month")
+    df['yr'] = df[date_var].dt.year
+    df['mnth'] = df[date_var].dt.month_name()
+    
     return df
- 
-# 2. processing cabin
 
-#f1=lambda x: 0 if type(x) == float else 1  ## Ternary Expression
-  
+
 
 def pre_pipeline_preparation(*, data_frame: pd.DataFrame) -> pd.DataFrame:
-    print("pre_pipeline_preparation:", data_frame)
-    data_frame = get_year_and_month(data_frame)
-    #print("yr and month column")
-    # drop unnecessary variables
-    data_frame.drop(labels=config.model_config.unused_fields, axis=1, inplace=True)
-    #print(data_frame.head)
+
+    data_frame = get_year_and_month(dataframe = data_frame, date_var = config.model_config.date_var)
+    
+    # Drop unnecessary fields
+    for field in config.model_config.unused_fields:
+        if field in data_frame.columns:
+            data_frame.drop(labels = field, axis=1, inplace=True)    
+
     return data_frame
 
 
 def _load_raw_dataset(*, file_name: str) -> pd.DataFrame:
     dataframe = pd.read_csv(Path(f"{DATASET_DIR}/{file_name}"))
     return dataframe
 
 def load_dataset(*, file_name: str) -> pd.DataFrame:
     dataframe = pd.read_csv(Path(f"{DATASET_DIR}/{file_name}"))
-    transformed = pre_pipeline_preparation(data_frame=dataframe)
+    transformed = pre_pipeline_preparation(data_frame = dataframe)
 
     return transformed
 
 
 def save_pipeline(*, pipeline_to_persist: Pipeline) -> None:
     """Persist the pipeline.
-    Saves the versioned model, and overwrites any previous
-    saved models. This ensures that when the package is
-    published, there is only one trained model that can be
-    called, and we know exactly how it was built.
+    Saves the versioned model, and overwrites any previous saved models. 
+    This ensures that when the package is published, there is only one trained model that 
+    can be called, and we know exactly how it was built.
     """
 
     # Prepare versioned save file name
     save_file_name = f"{config.app_config.pipeline_save_file}{_version}.pkl"
     save_path = TRAINED_MODEL_DIR / save_file_name
 
     remove_old_pipelines(files_to_keep=[save_file_name])
@@ -79,15 +79,14 @@
     trained_model = joblib.load(filename=file_path)
     return trained_model
 
 
 def remove_old_pipelines(*, files_to_keep: t.List[str]) -> None:
     """
     Remove old model pipelines.
-    This is to ensure there is a simple one-to-one
-    mapping between the package version and the model
-    version to be imported and used by other applications.
+    This is to ensure there is a simple one-to-one mapping between the package version and 
+    the model version to be imported and used by other applications.
     """
     do_not_delete = files_to_keep + ["__init__.py"]
     for model_file in TRAINED_MODEL_DIR.iterdir():
         if model_file.name not in do_not_delete:
             model_file.unlink()
```

## bikeshare_model/processing/features.py

```diff
@@ -1,90 +1,158 @@
 from typing import List
 import sys
 import pandas as pd
 import numpy as np
 
 from sklearn.base import BaseEstimator, TransformerMixin
-from sklearn.impute import SimpleImputer
 from sklearn.preprocessing import OneHotEncoder
 
 
-class bikeshareImputer(BaseEstimator, TransformerMixin):
-    """bikeshare column Imputer"""
+class WeekdayImputer(BaseEstimator, TransformerMixin):
+    """ Impute missing values in 'weekday' column by extracting dayname from 'dteday' column """
 
-    def __init__(self, variables: str):
+    def __init__(self, variable: str, date_var:str):
 
-        if not isinstance(variables, str):
-            raise ValueError("variables should be a str")
+        if not isinstance(variable, str):
+            raise ValueError("variable name should be a string")
+        if not isinstance(date_var, str):
+            raise ValueError("date variable name should be a string")
 
-        self.variables = variables
+        self.variable = variable
+        self.date_var = date_var
 
     def fit(self, X: pd.DataFrame, y: pd.Series = None):
         # we need the fit statement to accomodate the sklearn pipeline
-        self.fill_value=X[self.variables].mode()[0]
         return self
 
     def transform(self, X: pd.DataFrame) -> pd.DataFrame:
         X = X.copy()
-        X[self.variables]=X[self.variables].fillna(self.fill_value)
-        #print(" Print Feature:", self.variables)
+        # convert 'dteday' column to Datetime datatype
+        X[self.date_var] = pd.to_datetime(X[self.date_var], format='%Y-%m-%d')
+        
+        wkday_null_idx = X[X[self.variable].isnull() == True].index
+        X.loc[wkday_null_idx, self.variable] = X.loc[wkday_null_idx, self.date_var].dt.day_name().apply(lambda x: x[:3])
+
+        # drop 'dteday' column after imputation
+        X.drop(self.date_var, axis=1, inplace=True)
+
         return X
-    
-    
+
+
+class WeathersitImputer(BaseEstimator, TransformerMixin):
+    """ Impute missing values in 'weathersit' column by replacing them with the most frequent category value """
+
+    def __init__(self, variable: str):
+
+        if not isinstance(variable, str):
+            raise ValueError("variable name should be a string")
+
+        self.variable = variable
+
+    def fit(self, X: pd.DataFrame, y: pd.Series = None):
+        # we need the fit statement to accomodate the sklearn pipeline 
+        X = X.copy()
+        self.fill_value = X[self.variable].mode()[0]
+
+        return self
+
+    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
+        X = X.copy()
+        X[self.variable] = X[self.variable].fillna(self.fill_value)
+
+        return X    
+
+
 class Mapper(BaseEstimator, TransformerMixin):
-    """Categorical variable mapper."""
+    """
+    Ordinal categorical variable mapper:
+    Treat column as Ordinal categorical variable, and assign values accordingly
+    """
 
-    def __init__(self, variables: str, mappings: dict):
+    def __init__(self, variable:str, mappings:dict):
 
-        if not isinstance(variables, str):
-            raise ValueError("variables should be a str")
+        if not isinstance(variable, str):
+            raise ValueError("variable name should be a string")
 
-        self.variables = variables
+        self.variable = variable
         self.mappings = mappings
 
     def fit(self, X: pd.DataFrame, y: pd.Series = None):
+        # we need the fit statement to accomodate the sklearn pipeline
         return self
 
     def transform(self, X: pd.DataFrame) -> pd.DataFrame:
         X = X.copy()
-        #print("error",self.variables)
-        #print(X.head)
-        X[self.variables] = X[self.variables].map(self.mappings).astype(int)
+        X[self.variable] = X[self.variable].map(self.mappings).astype(int)
+
         return X
-    
+
+
 class OutlierHandler(BaseEstimator, TransformerMixin):
-    def __init__(self, column, lower_quantile=0.05, upper_quantile=0.95, lower_bound=None, higher_bound=None):
-        self.column = column
-        self.lower_quantile = lower_quantile
-        self.upper_quantile = upper_quantile
-        self.lower_bound = lower_bound
-        self.higher_bound = higher_bound
-
-    def fit(self, X, y=None):
-        if self.lower_bound is None:
-            self.lower_bound = X[self.column].quantile(self.lower_quantile)
-        if self.higher_bound is None:
-            self.higher_bound = X[self.column].quantile(self.upper_quantile)
+    """
+    Change the outlier values: 
+        - to upper-bound, if the value is higher than upper-bound, or
+        - to lower-bound, if the value is lower than lower-bound respectively.
+    """
+
+    def __init__(self, variable:str):
+
+        if not isinstance(variable, str):
+            raise ValueError("variable name should be a string")
+
+        self.variable = variable
+
+    def fit(self, X: pd.DataFrame, y: pd.Series = None):
+        # we need the fit statement to accomodate the sklearn pipeline
+        X = X.copy()
+        q1 = X.describe()[self.variable].loc['25%']
+        q3 = X.describe()[self.variable].loc['75%']
+        iqr = q3 - q1
+        self.lower_bound = q1 - (1.5 * iqr)
+        self.upper_bound = q3 + (1.5 * iqr)
+        
         return self
 
-    def transform(self, X, y=None):
-        X[self.column] = np.where(X[self.column] < self.lower_bound, self.lower_bound,
-                                  np.where(X[self.column] > self.higher_bound, self.higher_bound, X[self.column]))
+    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
+        X = X.copy()
+        
+        for i in X.index:
+            if X.loc[i, self.variable] > self.upper_bound:
+                X.loc[i, self.variable]= self.upper_bound
+            if X.loc[i, self.variable] < self.lower_bound:
+                X.loc[i, self.variable]= self.lower_bound
+
         return X
-    
-    
+
+
 class WeekdayOneHotEncoder(BaseEstimator, TransformerMixin):
     """ One-hot encode weekday column """
-    def __init__(self, column):
-        self.column = column
+
+    def __init__(self, variable:str):
+
+        if not isinstance(variable, str):
+            raise ValueError("variable name should be a string")
+
+        self.variable = variable
         self.encoder = OneHotEncoder(sparse_output=False)
 
-    def fit(self, X, y=None):
-        self.encoder.fit(X[[self.column]])
+    def fit(self, X: pd.DataFrame, y: pd.Series = None):
+        # we need the fit statement to accomodate the sklearn pipeline
+        X = X.copy()
+        self.encoder.fit(X[[self.variable]])
+        # Get encoded feature names
+        self.encoded_features_names = self.encoder.get_feature_names_out([self.variable])
+        
         return self
 
-    def transform(self, X, y=None):
-        encoded = self.encoder.transform(X[[self.column]])
-        column_names = self.encoder.get_feature_names_out([self.column])
-        encoded_df = pd.DataFrame(encoded, columns=column_names, index=X.index)
-        encoded_df = encoded_df.astype(object)
-        return pd.concat([X.drop(self.column, axis=1), encoded_df], axis=1)
+    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
+        X = X.copy()
+        
+        encoded_weekdays = self.encoder.transform(X[[self.variable]])
+        # Append encoded weekday features to X
+        X[self.encoded_features_names] = encoded_weekdays
+
+        # drop 'weekday' column after encoding
+        X.drop(self.variable, axis=1, inplace=True)        
+
+        return X
+
```

## bikeshare_model/processing/validation.py

```diff
@@ -1,58 +1,47 @@
-import pandas as pd
-import numpy as np
 from typing import List, Optional, Tuple, Union
 
+from datetime import datetime
+import numpy as np
+import pandas as pd
 from pydantic import BaseModel, ValidationError
 
 from bikeshare_model.config.core import config
 from bikeshare_model.processing.data_manager import pre_pipeline_preparation
 
 
-
-def validate_input_data(data):
-    # Check for missing values
-    if (data==''):
-        raise ValueError("Input data contains missing values.")
-
-    
-    return True
-
-
-    
-
 def validate_inputs(*, input_df: pd.DataFrame) -> Tuple[pd.DataFrame, Optional[dict]]:
     """Check model inputs for unprocessable values."""
 
-    pre_processed = pre_pipeline_preparation(data_frame=input_df)
+    pre_processed = pre_pipeline_preparation(data_frame = input_df)
     validated_data = pre_processed[config.model_config.features].copy()
     errors = None
 
     try:
         # replace numpy nans so that pydantic can validate
         MultipleDataInputs(
-            inputs=validated_data.replace({np.nan: None}).to_dict(orient="records")
+            inputs = validated_data.replace({np.nan: None}).to_dict(orient="records")
         )
     except ValidationError as error:
         errors = error.json()
 
     return validated_data, errors
 
 
-class DataInputSchema(BaseModel): 
-    dteday: Optional[str]
-    season:Optional[str]
-    hr:Optional[str]
-    holiday:Optional[str]
-    weekday:Optional[str]
-    workingday:Optional[str]
-    weathersit:Optional[str]
-    temp:Optional[float]
-    atemp:Optional[float]
-    hum:Optional[int]
-    windspeed:Optional[float]
-    casual:Optional[int]
-    registered:Optional[int]
-    
+class DataInputSchema(BaseModel):
+    dteday: Optional[Union[str, datetime]]
+    season: Optional[str]
+    hr: Optional[str]
+    holiday: Optional[str]
+    weekday: Optional[str]
+    workingday: Optional[str]
+    weathersit: Optional[str]
+    temp: Optional[float]
+    atemp: Optional[float]
+    hum: Optional[float]
+    windspeed: Optional[float]
+    yr: Optional[int]
+    mnth: Optional[str]
+
 
 class MultipleDataInputs(BaseModel):
     inputs: List[DataInputSchema]
```

## Comparing `bikeshare_model/datasets/bike-sharing-dataset.csv` & `bikeshare_model/datasets/bike-rental-dataset.csv`

 * *Files identical despite different names*

## Comparing `bikeshare_model-0.1.0.dist-info/METADATA` & `bikeshare_model-1.0.0.dist-info/METADATA`

 * *Files 24% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 Metadata-Version: 2.1
 Name: bikeshare-model
-Version: 0.1.0
-Summary: Bikeshare dataset classification model package 
-Author: Ajay Singh
+Version: 1.0.0
+Summary: Bikeshare dataset regression model package 
+Author: Ajay Kumar Singh
 Author-email: ajaytevatia@gmail.com
 License: BSD-3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Requires-Python: >=3.7.0
 Description-Content-Type: text/markdown
-Requires-Dist: numpy (<2.0.0,>=1.21.0)
-Requires-Dist: pandas (<2.0.0,>=1.3.5)
-Requires-Dist: pydantic (<2.0.0,>=1.8.1)
-Requires-Dist: scikit-learn (<2.0.0,>=1.1.3)
-Requires-Dist: strictyaml (<2.0.0,>=1.3.2)
-Requires-Dist: ruamel.yaml (<1.0.0,>=0.16.12)
-Requires-Dist: joblib (<2.0.0,>=1.0.1)
+Requires-Dist: numpy (==1.24.0)
+Requires-Dist: pandas (==1.5.3)
+Requires-Dist: pydantic (==1.10.10)
+Requires-Dist: scikit-learn (==1.3.0)
+Requires-Dist: strictyaml (==1.6.2)
+Requires-Dist: ruamel.yaml (==0.17.32)
+Requires-Dist: joblib (==1.3.1)
 
-Bikeshare dataset classification model package 
+Bikeshare dataset regression model package
```

## Comparing `bikeshare_model-0.1.0.dist-info/RECORD` & `bikeshare_model-1.0.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,19 @@
-.DS_Store,sha256=JYjWrVq6wfd_yH8dN34ccrBeu88OKEKk75boDZo3c9M,6148
-bikeshare_model/VERSION,sha256=atlhOkVXmNbZLl9fOQq0uqcFlryGntaxf1zdKyhjXwY,5
-bikeshare_model/__init__.py,sha256=FBsKr5BGRd1vc2e9OTnoCb4J8Nhb_RWLwuwdDinJYlc,253
-bikeshare_model/config.yml,sha256=ObXJC4ZYuTQXeBwmzNI0eTqhyqajQOo1fxV-ccKWkZg,2061
-bikeshare_model/pipeline.py,sha256=Iv5zp0Eo6aZB5rYo6GG_G5ikheeTdUYkDyb_6VFtWIs,2134
-bikeshare_model/predict.py,sha256=Emdw-4st-Me2WDJ54C4m7MGUv3Gm6xRuDSheFV_UJDs,1878
-bikeshare_model/train_pipeline.py,sha256=FT8b5Zn1i6c6DH_odV2xqeyBazLmZ_PvSEIIswjPlh8,1679
+bikeshare_model/VERSION,sha256=klIfw8vZZL3J9YSpkbif3apXVO0cyW1tQkRTOGacEwU,5
+bikeshare_model/__init__.py,sha256=JgyMhOr15b4vkuO7b3ik4h467eYl4CP_NlLAM88vs_8,307
+bikeshare_model/config.yml,sha256=fd42grpC0KZp5XKfmxyaSV6NkuU9I3F_0uqUsnBLAGw,1948
+bikeshare_model/pipeline.py,sha256=7Mg7hswgR0Z5c3XDoQu_0auZF4gi-NnJ9G19HEqByKI,2715
+bikeshare_model/predict.py,sha256=KuLoOJ9p_iSNjZ8WhGbthOr01lUEV24frCni1gGDNiw,1851
+bikeshare_model/train_pipeline.py,sha256=HGiB1rpKwiC40xkw__STaKGVrUAPP7wdY-OkF3Q9nhI,1450
 bikeshare_model/config/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-bikeshare_model/config/core.py,sha256=SIN1ruGN2QvueaySxmc--5-4OS5TeH4RTzTaQxywkPQ,2928
+bikeshare_model/config/core.py,sha256=1j-SYM_P_5ng4ZoP0EAwgrqCGir1uPCGJiREtml92ag,2820
 bikeshare_model/datasets/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-bikeshare_model/datasets/bike-sharing-dataset.csv,sha256=NyQ2F3BOHwh6JMkESfZL5hIrnecqwNFWQf4_uihALx4,1598454
-bikeshare_model/datasets/test.csv,sha256=qUBW4-MjYr_g-YqdY4wwl8_hNSYfPiAMjAo-TdG1Jhw,318833
+bikeshare_model/datasets/bike-rental-dataset.csv,sha256=NyQ2F3BOHwh6JMkESfZL5hIrnecqwNFWQf4_uihALx4,1598454
 bikeshare_model/processing/__init__.py,sha256=frcCV1k9oG9oKj3dpUqdJg1PxRT2RSN_XKdLCPjaYaY,2
-bikeshare_model/processing/data_manager.py,sha256=NHDHmvkAwYQeUXcOjp6oWvHK13YI_8OPsG-pyiJsU1w,3057
-bikeshare_model/processing/features.py,sha256=RUwJx34n45bcuwHIJuDoiIg-aX71Gf-fr30XGqYgcGc,3241
-bikeshare_model/processing/validation.py,sha256=APfzESuY_1wypVpjEd-X7oVe502jqgIIXape1UmB9D8,1540
+bikeshare_model/processing/data_manager.py,sha256=PzAoNxgYMFnk6D0OHfJGgodpGFzu6PHA4OezEKJXFZM,2972
+bikeshare_model/processing/features.py,sha256=rSTDgQxiwN_ssXjbA0p5o_6yVPq4-wz7NlwgAdEwFuA,5280
+bikeshare_model/processing/validation.py,sha256=ZYSk-v7OAZqMxhsNU6slsA5m412ZatDwSBjDRDio50I,1403
 bikeshare_model/trained_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-bikeshare_model/trained_models/bikeshare__model_output_v0.0.1.pkl,sha256=WCN9pbYeC4IKpjYdl-dX2m1BfQBP7SAagIjXngLg7sQ,659402
-bikeshare_model-0.1.0.dist-info/METADATA,sha256=6n1KUao6nEK1kEgejL8gv40tw1DwzpvdlakKdcOOZ2g,1127
-bikeshare_model-0.1.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-bikeshare_model-0.1.0.dist-info/top_level.txt,sha256=ZKIHSbGTS6ZE2aLhfpCV8HFAqGuZmXzRWQVz-N03wPI,16
-bikeshare_model-0.1.0.dist-info/RECORD,,
+bikeshare_model-1.0.0.dist-info/METADATA,sha256=YrdpFYDmdXclbDbApdn8i-oZriHcK0Pt8XSVkmvasbg,1078
+bikeshare_model-1.0.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+bikeshare_model-1.0.0.dist-info/top_level.txt,sha256=ZKIHSbGTS6ZE2aLhfpCV8HFAqGuZmXzRWQVz-N03wPI,16
+bikeshare_model-1.0.0.dist-info/RECORD,,
```

