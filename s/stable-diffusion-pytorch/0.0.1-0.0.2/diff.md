# Comparing `tmp/stable_diffusion_pytorch-0.0.1-py3-none-any.whl.zip` & `tmp/stable_diffusion_pytorch-0.0.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,20 +1,20 @@
-Zip file size: 14931 bytes, number of entries: 18
--rw-r--r--  2.0 unx      220 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/__init__.py
--rw-r--r--  2.0 unx     2548 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/attention.py
--rw-r--r--  2.0 unx     1798 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/clip.py
--rw-r--r--  2.0 unx     2768 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/decoder.py
--rw-r--r--  2.0 unx     7363 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/diffusion.py
--rw-r--r--  2.0 unx     1553 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/encoder.py
--rw-r--r--  2.0 unx     2397 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/model_loader.py
--rw-r--r--  2.0 unx    10468 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/pipeline.py
--rw-r--r--  2.0 unx     3036 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/tokenizer.py
--rw-r--r--  2.0 unx     1450 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/util.py
--rw-r--r--  2.0 unx      119 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/samplers/__init__.py
--rw-r--r--  2.0 unx     1598 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/samplers/k_euler.py
--rw-r--r--  2.0 unx     1939 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/samplers/k_euler_ancestral.py
--rw-r--r--  2.0 unx     2207 b- defN 23-Aug-01 08:34 stable_diffusion_pytorch/samplers/k_lms.py
--rw-r--r--  2.0 unx      492 b- defN 23-Aug-01 08:35 stable_diffusion_pytorch-0.0.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Aug-01 08:35 stable_diffusion_pytorch-0.0.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       25 b- defN 23-Aug-01 08:35 stable_diffusion_pytorch-0.0.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1704 b- defN 23-Aug-01 08:35 stable_diffusion_pytorch-0.0.1.dist-info/RECORD
-18 files, 41777 bytes uncompressed, 12065 bytes compressed:  71.1%
+Zip file size: 14952 bytes, number of entries: 18
+-rw-r--r--  2.0 unx      220 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/__init__.py
+-rw-r--r--  2.0 unx     2548 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/attention.py
+-rw-r--r--  2.0 unx     1798 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/clip.py
+-rw-r--r--  2.0 unx     2768 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/decoder.py
+-rw-r--r--  2.0 unx     7363 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/diffusion.py
+-rw-r--r--  2.0 unx     1553 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/encoder.py
+-rw-r--r--  2.0 unx     2592 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/model_loader.py
+-rw-r--r--  2.0 unx    10468 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/pipeline.py
+-rw-r--r--  2.0 unx     3036 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/tokenizer.py
+-rw-r--r--  2.0 unx     1450 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/util.py
+-rw-r--r--  2.0 unx      119 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/samplers/__init__.py
+-rw-r--r--  2.0 unx     1598 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/samplers/k_euler.py
+-rw-r--r--  2.0 unx     1939 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/samplers/k_euler_ancestral.py
+-rw-r--r--  2.0 unx     2207 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch/samplers/k_lms.py
+-rw-r--r--  2.0 unx      492 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch-0.0.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch-0.0.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       25 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch-0.0.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1704 b- defN 23-Aug-01 09:08 stable_diffusion_pytorch-0.0.2.dist-info/RECORD
+18 files, 41972 bytes uncompressed, 12086 bytes compressed:  71.2%
```

## zipnote {}

```diff
@@ -36,20 +36,20 @@
 
 Filename: stable_diffusion_pytorch/samplers/k_euler_ancestral.py
 Comment: 
 
 Filename: stable_diffusion_pytorch/samplers/k_lms.py
 Comment: 
 
-Filename: stable_diffusion_pytorch-0.0.1.dist-info/METADATA
+Filename: stable_diffusion_pytorch-0.0.2.dist-info/METADATA
 Comment: 
 
-Filename: stable_diffusion_pytorch-0.0.1.dist-info/WHEEL
+Filename: stable_diffusion_pytorch-0.0.2.dist-info/WHEEL
 Comment: 
 
-Filename: stable_diffusion_pytorch-0.0.1.dist-info/top_level.txt
+Filename: stable_diffusion_pytorch-0.0.2.dist-info/top_level.txt
 Comment: 
 
-Filename: stable_diffusion_pytorch-0.0.1.dist-info/RECORD
+Filename: stable_diffusion_pytorch-0.0.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## stable_diffusion_pytorch/model_loader.py

```diff
@@ -1,7 +1,8 @@
+import os
 import torch
 from . import Tokenizer, CLIP, Encoder, Decoder, Diffusion
 from . import util
 import warnings
 
 
 def make_compatible(state_dict):
@@ -27,46 +28,46 @@
                        " function on model_loader.py. Maybe this happened because you're"
                        " running newer codes with older checkpoint files. This behavior"
                        " (modify old checkpoints and notify rather than throw an error)"
                        " will be removed soon, so please download latest checkpoints file."))
 
     return state_dict
 
-def load_clip(device):
-    state_dict = torch.load(util.get_file_path('ckpt/clip.pt'))
+def load_clip(device, model_path):
+    state_dict = torch.load(util.get_file_path(os.path.join(model_path, 'ckpt/clip.pt')))
     state_dict = make_compatible(state_dict)
 
     clip = CLIP().to(device)
     clip.load_state_dict(state_dict)
     return clip
 
-def load_encoder(device):
-    state_dict = torch.load(util.get_file_path('ckpt/encoder.pt'))
+def load_encoder(device, model_path):
+    state_dict = torch.load(util.get_file_path(os.path.join(model_path, 'ckpt/encoder.pt')))
     state_dict = make_compatible(state_dict)
 
     encoder = Encoder().to(device)
     encoder.load_state_dict(state_dict)
     return encoder
 
-def load_decoder(device):
-    state_dict = torch.load(util.get_file_path('ckpt/decoder.pt'))
+def load_decoder(device, model_path):
+    state_dict = torch.load(util.get_file_path(os.path.join(model_path, 'ckpt/decoder.pt')))
     state_dict = make_compatible(state_dict)
 
     decoder = Decoder().to(device)
     decoder.load_state_dict(state_dict)
     return decoder
 
 def load_diffusion(device, model_path):
-    state_dict = torch.load(util.get_file_path(model_path))
+    state_dict = torch.load(util.get_file_path(os.path.join(model_path, 'ckpt/diffusion.pt')))
     state_dict = make_compatible(state_dict)
 
     diffusion = Diffusion().to(device)
     diffusion.load_state_dict(state_dict)
     return diffusion
 
 def preload_models(device, model_path):
     return {
-        'clip': load_clip(device),
-        'encoder': load_encoder(device),
-        'decoder': load_decoder(device),
+        'clip': load_clip(device, model_path),
+        'encoder': load_encoder(device, model_path),
+        'decoder': load_decoder(device, model_path),
         'diffusion': load_diffusion(device, model_path),
     }
```

## Comparing `stable_diffusion_pytorch-0.0.1.dist-info/RECORD` & `stable_diffusion_pytorch-0.0.2.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 stable_diffusion_pytorch/__init__.py,sha256=hUgRvcyVAqtVH2ptUW0YXIIoz1ckeOzBdHZ27-90YyE,220
 stable_diffusion_pytorch/attention.py,sha256=XXYPGEEjS9HyJVAwKtQLiBjYbYUueHj9GifE8mKYN4s,2548
 stable_diffusion_pytorch/clip.py,sha256=Z6VPCxlz2TjFJrA9WW04duMLpFWJx3xB22ikD_fxCpo,1798
 stable_diffusion_pytorch/decoder.py,sha256=y1sYhgr1UJkUrU8jiyfnDBnz50FlEs2Gj3iJNGUolnE,2768
 stable_diffusion_pytorch/diffusion.py,sha256=8Ed-7sIe9T5cu2uPKGoxOiLQVzV-eTbccASBVUicWbQ,7363
 stable_diffusion_pytorch/encoder.py,sha256=TwBMSLQrffH3E2V1rTjihx6HraY-1Fu6BzdEskJonMQ,1553
-stable_diffusion_pytorch/model_loader.py,sha256=Fgu0gMzd06Mi2TnM1um2ppQL5tv5sqELgtbILulZpCg,2397
+stable_diffusion_pytorch/model_loader.py,sha256=hIASqfgJxxXGiOWfyDfC18gIFHrNp0KfEQYj6rEwZMk,2592
 stable_diffusion_pytorch/pipeline.py,sha256=731CrOSXIGtlK8cMuzjht753feGV-PIFNjPIszKdUSA,10468
 stable_diffusion_pytorch/tokenizer.py,sha256=ToaFF-MeUEiExQAXVVV03hJQL02cwk0wlpm2RnVaMdc,3036
 stable_diffusion_pytorch/util.py,sha256=2Du5RH1ieVO3mZzKpItUilLYBKsa9MBqIXt60tDbbWc,1450
 stable_diffusion_pytorch/samplers/__init__.py,sha256=6HRwIPEhsx84gmQ9NwDow_tSqmTfDIsD68rUWuJ6pnA,119
 stable_diffusion_pytorch/samplers/k_euler.py,sha256=0h2tw9KN50ilb5k9CC1s02HLt0k5cN1dawm9MzpgCO8,1598
 stable_diffusion_pytorch/samplers/k_euler_ancestral.py,sha256=MDrftTo0DA-PFEo8XmRXFo-xedIaMVTMmwowqeaUzi8,1939
 stable_diffusion_pytorch/samplers/k_lms.py,sha256=HW-A2o5ERd9vwexOYdKS-zaWGwELy84xQa4eiPb5kus,2207
-stable_diffusion_pytorch-0.0.1.dist-info/METADATA,sha256=hkyCakCpRPhiDaiGkMS7vBRXaHwLOVzL_1J1_AK5paU,492
-stable_diffusion_pytorch-0.0.1.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
-stable_diffusion_pytorch-0.0.1.dist-info/top_level.txt,sha256=EZhsoh3z5lkw5KoQ4g9zKUj0vQXB_TCewpRa8YbOWdE,25
-stable_diffusion_pytorch-0.0.1.dist-info/RECORD,,
+stable_diffusion_pytorch-0.0.2.dist-info/METADATA,sha256=pHFu-f94De2HwrSjGxrRJmIwRyarUPZbCmcMuGDD0aM,492
+stable_diffusion_pytorch-0.0.2.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
+stable_diffusion_pytorch-0.0.2.dist-info/top_level.txt,sha256=EZhsoh3z5lkw5KoQ4g9zKUj0vQXB_TCewpRa8YbOWdE,25
+stable_diffusion_pytorch-0.0.2.dist-info/RECORD,,
```

