# Comparing `tmp/convokit-2.5.3.tar.gz` & `tmp/convokit-3.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/convokit-2.5.3.tar", last modified: Mon Jan 17 04:44:53 2022, max compression
+gzip compressed data, was "convokit-3.0.0.tar", last modified: Tue Aug  1 14:24:10 2023, max compression
```

## Comparing `convokit-2.5.3.tar` & `convokit-3.0.0.tar`

### file list

```diff
@@ -1,134 +1,136 @@
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     1076 2022-01-17 03:49:35.000000 convokit-2.5.3/LICENSE.md
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      601 2022-01-17 04:44:53.000000 convokit-2.5.3/PKG-INFO
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    28439 2022-01-17 03:56:23.000000 convokit-2.5.3/README.md
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      615 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/__init__.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/bag_of_words/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       44 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/bag_of_words/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5476 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/bag_of_words/bow_transformer.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/classifier/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       93 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/classifier/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    16565 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/classifier/classifier.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6177 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/classifier/util.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    10782 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/classifier/vectorClassifier.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     1587 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/convokitPipeline.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/coordination/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       71 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/coordination/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    25407 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/coordination/coordination.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5484 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/coordination/coordinationScore.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/data/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5257 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/data/coord-liwc-patterns.txt
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    44758 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/data/liu-negative-words.txt
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    19093 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/data/liu-positive-words.txt
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/expected_context_framework/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      325 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/expected_context_framework/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6480 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/expected_context_framework/col_normed_tfidf.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    12541 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/expected_context_framework/dual_context_wrapper.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    37950 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/expected_context_framework/expected_context_model.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    27012 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/expected_context_framework/expected_context_model_pipeline.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/fighting_words/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       29 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/fighting_words/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    20169 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/fighting_words/fightingWords.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/forecaster/
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/forecaster/CRAFT/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     9493 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/CRAFT/CRAFTNN.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     8754 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/CRAFT/CRAFTUtil.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       48 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/CRAFT/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    18875 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/CRAFTModel.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      181 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4549 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/cumulativeBoW.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    10742 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/forecaster.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     1624 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/forecaster/forecasterModel.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/hyperconvo/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       97 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/hyperconvo/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     3091 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/hyperconvo/communityEmbedder.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    10162 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/hyperconvo/hyperconvo.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     7960 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/hyperconvo/hypergraph.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     3193 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/hyperconvo/threadEmbedder.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/model/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      349 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    19984 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/conversation.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4650 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/convoKitIndex.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     8696 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/convoKitMatrix.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     3237 2022-01-17 04:43:17.000000 convokit-2.5.3/convokit/model/convoKitMeta.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    65671 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/corpus.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5830 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/corpusComponent.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    14694 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/corpusHelper.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     3507 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/corpusUtil.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6631 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/speaker.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      231 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/user.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4834 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/utterance.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     1542 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/model/utteranceNode.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/paired_prediction/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      137 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/paired_prediction/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6579 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/paired_prediction/pairedPrediction.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5026 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/paired_prediction/pairedVectorPrediction.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    10159 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/paired_prediction/pairer.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4361 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/paired_prediction/util.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/phrasing_motifs/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       90 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/phrasing_motifs/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     2410 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/phrasing_motifs/censorNouns.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    20882 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/phrasing_motifs/phrasingMotifs.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     2398 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/phrasing_motifs/questionSentences.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politenessStrategies/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       36 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politenessStrategies/__init__.py
--rwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)     8298 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politenessStrategies/politenessStrategies.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       95 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4906 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/marker_utils.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/politeness_api/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_api/__init__.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/politeness_api/features/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_api/features/__init__.py
--rwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)     9077 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_api/features/politeness_strategies.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6122 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_api/features/vectorizer.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/__init__.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/lexicons/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     3893 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/lexicons/ngram_markers.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      114 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/lexicons/non_starter_markers.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      100 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/lexicons/starter_markers.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     3297 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/strategy_extractor.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/__init__.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/lexicons/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      400 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/lexicons/marker_mode.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     1457 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/lexicons/ngram_markers.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       36 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/lexicons/non_starter_markers.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      236 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/lexicons/starter_markers.json
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4612 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/politeness_collections/politeness_local/strategy_extractor.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/prompt_types/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       59 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/prompt_types/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    11106 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/prompt_types/promptTypeWrapper.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    34435 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/prompt_types/promptTypes.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/ranker/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       22 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/ranker/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5688 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/ranker/ranker.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/speakerConvoDiversity/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       36 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/speakerConvoDiversity/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    16985 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/speakerConvoDiversity/speakerConvoDiversity.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    15609 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/speakerConvoDiversity/speakerConvoDiversity2.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/speaker_convo_helpers/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       74 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/speaker_convo_helpers/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     2066 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/speaker_convo_helpers/speaker_convo_attrs.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     1219 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/speaker_convo_helpers/speaker_convo_lifestage.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/surprise/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       23 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/surprise/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    12326 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/surprise/surprise.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit/text_processing/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      117 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/text_processing/__init__.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4570 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/text_processing/textCleaner.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6584 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/text_processing/textParser.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     6150 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/text_processing/textProcessor.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     5976 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/text_processing/textToArcs.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     2401 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/transformer.py
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)    15064 2022-01-17 03:49:35.000000 convokit-2.5.3/convokit/util.py
-drwxrwxr-x   0 ku47     (1573154) pug-ku47 (1582039)        0 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit.egg-info/
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      601 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit.egg-info/PKG-INFO
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     4346 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit.egg-info/SOURCES.txt
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)        1 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit.egg-info/dependency_links.txt
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)      196 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit.egg-info/requires.txt
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)        9 2022-01-17 04:44:53.000000 convokit-2.5.3/convokit.egg-info/top_level.txt
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)       38 2022-01-17 04:44:53.000000 convokit-2.5.3/setup.cfg
--rw-rw-r--   0 ku47     (1573154) pug-ku47 (1582039)     2357 2022-01-17 03:49:35.000000 convokit-2.5.3/setup.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.467328 convokit-3.0.0/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1076 2023-07-16 13:33:04.000000 convokit-3.0.0/LICENSE.md
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      554 2023-08-01 14:24:10.467087 convokit-3.0.0/PKG-INFO
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    29258 2023-07-26 02:58:00.000000 convokit-3.0.0/README.md
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.446438 convokit-3.0.0/convokit/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      646 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/__init__.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.447670 convokit-3.0.0/convokit/bag_of_words/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       44 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/bag_of_words/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     5703 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/bag_of_words/bow_transformer.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.448401 convokit-3.0.0/convokit/classifier/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       93 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/classifier/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    16539 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/classifier/classifier.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6191 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/classifier/util.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    10991 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/classifier/vectorClassifier.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1921 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/convokitConfig.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1870 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/convokitPipeline.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.449070 convokit-3.0.0/convokit/coordination/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       72 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/coordination/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    26030 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/coordination/coordination.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     5157 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/coordination/coordinationScore.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.450648 convokit-3.0.0/convokit/data/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     5257 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/data/coord-liwc-patterns.txt
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    44758 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/data/liu-negative-words.txt
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    19093 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/data/liu-positive-words.txt
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.451864 convokit-3.0.0/convokit/expected_context_framework/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      343 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/expected_context_framework/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6432 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/expected_context_framework/col_normed_tfidf.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    12744 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/expected_context_framework/dual_context_wrapper.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    38578 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/expected_context_framework/expected_context_model.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    27066 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/expected_context_framework/expected_context_model_pipeline.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.452237 convokit-3.0.0/convokit/fighting_words/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       29 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/fighting_words/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    20691 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/fighting_words/fightingWords.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.453307 convokit-3.0.0/convokit/forecaster/
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.453763 convokit-3.0.0/convokit/forecaster/CRAFT/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     9763 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/forecaster/CRAFT/CRAFTNN.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     8899 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/forecaster/CRAFT/CRAFTUtil.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       48 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/forecaster/CRAFT/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    20077 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/forecaster/CRAFTModel.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      180 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/forecaster/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4939 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/forecaster/cumulativeBoW.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    11383 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/forecaster/forecaster.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1012 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/forecaster/forecasterModel.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.454628 convokit-3.0.0/convokit/hyperconvo/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       98 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/hyperconvo/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     3139 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/hyperconvo/communityEmbedder.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    10176 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/hyperconvo/hyperconvo.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     8028 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/hyperconvo/hypergraph.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     3333 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/hyperconvo/threadEmbedder.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.457842 convokit-3.0.0/convokit/model/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      328 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    12342 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/model/backendMapper.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    19945 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/conversation.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4996 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/convoKitIndex.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     8789 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/convoKitMatrix.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6576 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/model/convoKitMeta.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    72009 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/model/corpus.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     8609 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/model/corpusComponent.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     3124 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/corpusUtil.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    37942 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/model/corpus_helpers.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6518 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/speaker.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6105 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/utterance.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1544 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/model/utteranceNode.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.458591 convokit-3.0.0/convokit/paired_prediction/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      138 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/paired_prediction/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6033 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/paired_prediction/pairedPrediction.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4984 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/paired_prediction/pairedVectorPrediction.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     8053 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/paired_prediction/pairer.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4402 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/paired_prediction/util.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.459229 convokit-3.0.0/convokit/phrasing_motifs/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       90 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/phrasing_motifs/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     2714 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/phrasing_motifs/censorNouns.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    21443 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/phrasing_motifs/phrasingMotifs.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     2491 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/phrasing_motifs/questionSentences.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.459539 convokit-3.0.0/convokit/politenessStrategies/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       36 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politenessStrategies/__init__.py
+-rwxr-xr-x   0 seanzhangkx   (501) staff       (20)     8338 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/politenessStrategies/politenessStrategies.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.459815 convokit-3.0.0/convokit/politeness_collections/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       96 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4632 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/politeness_collections/marker_utils.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.459951 convokit-3.0.0/convokit/politeness_collections/politeness_api/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)        0 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_api/__init__.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.460395 convokit-3.0.0/convokit/politeness_collections/politeness_api/features/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)        0 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_api/features/__init__.py
+-rwxr-xr-x   0 seanzhangkx   (501) staff       (20)     9474 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_api/features/politeness_strategies.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6417 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/politeness_collections/politeness_api/features/vectorizer.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.460662 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)        0 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/__init__.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.461559 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/lexicons/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     3893 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/lexicons/ngram_markers.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      114 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/lexicons/non_starter_markers.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      100 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/lexicons/starter_markers.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     3261 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/strategy_extractor.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.462019 convokit-3.0.0/convokit/politeness_collections/politeness_local/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)        0 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_local/__init__.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.463099 convokit-3.0.0/convokit/politeness_collections/politeness_local/lexicons/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      400 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_local/lexicons/marker_mode.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1457 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_local/lexicons/ngram_markers.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       36 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_local/lexicons/non_starter_markers.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      236 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/politeness_collections/politeness_local/lexicons/starter_markers.json
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4373 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/politeness_collections/politeness_local/strategy_extractor.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.463791 convokit-3.0.0/convokit/prompt_types/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       60 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/prompt_types/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    13257 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/prompt_types/promptTypeWrapper.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    35325 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/prompt_types/promptTypes.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.464292 convokit-3.0.0/convokit/ranker/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       22 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/ranker/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     5534 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/ranker/ranker.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.464977 convokit-3.0.0/convokit/speakerConvoDiversity/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       37 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/speakerConvoDiversity/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    18810 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/speakerConvoDiversity/speakerConvoDiversity.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    17077 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/speakerConvoDiversity/speakerConvoDiversity2.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.465609 convokit-3.0.0/convokit/speaker_convo_helpers/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       74 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/speaker_convo_helpers/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     2169 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/speaker_convo_helpers/speaker_convo_attrs.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     1270 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/speaker_convo_helpers/speaker_convo_lifestage.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.465973 convokit-3.0.0/convokit/surprise/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       24 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/surprise/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    13796 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/surprise/surprise.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.466792 convokit-3.0.0/convokit/text_processing/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      118 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/text_processing/__init__.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4054 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/text_processing/textCleaner.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     7794 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/text_processing/textParser.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6206 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/text_processing/textProcessor.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     6911 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/text_processing/textToArcs.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     2393 2023-07-16 13:33:04.000000 convokit-3.0.0/convokit/transformer.py
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)    15391 2023-07-16 13:39:00.000000 convokit-3.0.0/convokit/util.py
+drwxr-xr-x   0 seanzhangkx   (501) staff       (20)        0 2023-08-01 14:24:10.447202 convokit-3.0.0/convokit.egg-info/
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      554 2023-08-01 14:24:10.000000 convokit-3.0.0/convokit.egg-info/PKG-INFO
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     4399 2023-08-01 14:24:10.000000 convokit-3.0.0/convokit.egg-info/SOURCES.txt
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)        1 2023-08-01 14:24:10.000000 convokit-3.0.0/convokit.egg-info/dependency_links.txt
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)      254 2023-08-01 14:24:10.000000 convokit-3.0.0/convokit.egg-info/requires.txt
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)        9 2023-08-01 14:24:10.000000 convokit-3.0.0/convokit.egg-info/top_level.txt
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       64 2023-07-16 13:33:04.000000 convokit-3.0.0/pyproject.toml
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)       38 2023-08-01 14:24:10.467399 convokit-3.0.0/setup.cfg
+-rw-r--r--   0 seanzhangkx   (501) staff       (20)     2212 2023-07-26 02:56:28.000000 convokit-3.0.0/setup.py
```

### filetype from file(1)

```diff
@@ -1 +1 @@
-POSIX tar archive (GNU)
+POSIX tar archive
```

### Comparing `convokit-2.5.3/LICENSE.md` & `convokit-3.0.0/LICENSE.md`

 * *Files identical despite different names*

### Comparing `convokit-2.5.3/PKG-INFO` & `convokit-3.0.0/PKG-INFO`

 * *Files 26% similar despite different names*

```diff
@@ -1,15 +1,18 @@
 Metadata-Version: 2.1
 Name: convokit
-Version: 2.5.3
-Summary: Cornell Conversational Analysis Toolkit
-Home-page: https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit
+Version: 3.0.0
+Summary: ConvoKit
+Home-page: https://github.com/CornellNLP/ConvoKit
 Author: Jonathan P. Chang, Caleb Chiam, Liye Fu, Andrew Wang, Justine Zhang, Cristian Danescu-Niculescu-Mizil
 Author-email: cristian@cs.cornell.edu
 License: UNKNOWN
-Description: UNKNOWN
 Platform: UNKNOWN
 Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
 Provides-Extra: craft
+License-File: LICENSE.md
+
+UNKNOWN
+
```

### Comparing `convokit-2.5.3/README.md` & `convokit-3.0.0/README.md`

 * *Files 14% similar despite different names*

```diff
@@ -1,1778 +1,1829 @@
-00000000: 2320 436f 726e 656c 6c20 436f 6e76 6572  # Cornell Conver
-00000010: 7361 7469 6f6e 616c 2041 6e61 6c79 7369  sational Analysi
-00000020: 7320 546f 6f6c 6b69 7420 285b 436f 6e76  s Toolkit ([Conv
-00000030: 6f4b 6974 5d28 6874 7470 3a2f 2f63 6f6e  oKit](http://con
-00000040: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
-00000050: 752f 2929 0a3c 212d 2d20 414c 4c2d 434f  u/)).<!-- ALL-CO
-00000060: 4e54 5249 4255 544f 5253 2d42 4144 4745  NTRIBUTORS-BADGE
-00000070: 3a53 5441 5254 202d 2044 6f20 6e6f 7420  :START - Do not 
-00000080: 7265 6d6f 7665 206f 7220 6d6f 6469 6679  remove or modify
-00000090: 2074 6869 7320 7365 6374 696f 6e20 2d2d   this section --
-000000a0: 3e0a 5b21 5b41 6c6c 2043 6f6e 7472 6962  >.[![All Contrib
-000000b0: 7574 6f72 735d 2868 7474 7073 3a2f 2f69  utors](https://i
-000000c0: 6d67 2e73 6869 656c 6473 2e69 6f2f 6261  mg.shields.io/ba
-000000d0: 6467 652f 616c 6c5f 636f 6e74 7269 6275  dge/all_contribu
-000000e0: 746f 7273 2d32 382d 6f72 616e 6765 2e73  tors-28-orange.s
-000000f0: 7667 3f73 7479 6c65 3d66 6c61 742d 7371  vg?style=flat-sq
-00000100: 7561 7265 295d 2823 636f 6e74 7269 6275  uare)](#contribu
-00000110: 746f 7273 2d29 0a3c 212d 2d20 414c 4c2d  tors-).<!-- ALL-
-00000120: 434f 4e54 5249 4255 544f 5253 2d42 4144  CONTRIBUTORS-BAD
-00000130: 4745 3a45 4e44 202d 2d3e 0a0a 3c70 3e0a  GE:END -->..<p>.
-00000140: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
-00000150: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
-00000160: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
-00000170: 696f 6e2f 223e 0a20 2020 203c 696d 6720  ion/">.    <img 
-00000180: 7372 633d 2268 7474 7073 3a2f 2f69 6d67  src="https://img
-00000190: 2e73 6869 656c 6473 2e69 6f2f 6261 6467  .shields.io/badg
-000001a0: 652f 646f 6373 2d73 7461 626c 652d 626c  e/docs-stable-bl
-000001b0: 7565 2e73 7667 2220 616c 743d 2244 6f63  ue.svg" alt="Doc
-000001c0: 7322 2f3e 3c2f 613e 0a3c 6120 6872 6566  s"/></a>.<a href
-000001d0: 3d22 6874 7470 733a 2f2f 6769 7468 7562  ="https://github
-000001e0: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
-000001f0: 436f 726e 656c 6c2d 436f 6e76 6572 7361  Cornell-Conversa
-00000200: 7469 6f6e 616c 2d41 6e61 6c79 7369 732d  tional-Analysis-
-00000210: 546f 6f6c 6b69 742f 626c 6f62 2f6d 6173  Toolkit/blob/mas
-00000220: 7465 722f 4c49 4345 4e53 452e 6d64 223e  ter/LICENSE.md">
-00000230: 0a20 2020 203c 696d 6720 7372 633d 2268  .    <img src="h
-00000240: 7474 7073 3a2f 2f69 6d67 2e73 6869 656c  ttps://img.shiel
-00000250: 6473 2e69 6f2f 6769 7468 7562 2f6c 6963  ds.io/github/lic
-00000260: 656e 7365 2f6d 6173 6861 7065 2f61 7069  ense/mashape/api
-00000270: 7374 6174 7573 2e73 7667 2220 616c 743d  status.svg" alt=
-00000280: 224c 6963 656e 7365 2220 2f3e 3c2f 613e  "License" /></a>
-00000290: 200a 3c61 2068 7265 663d 2268 7474 7073   .<a href="https
-000002a0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
-000002b0: 726e 656c 6c4e 4c50 2f43 6f72 6e65 6c6c  rnellNLP/Cornell
-000002c0: 2d43 6f6e 7665 7273 6174 696f 6e61 6c2d  -Conversational-
-000002d0: 416e 616c 7973 6973 2d54 6f6f 6c6b 6974  Analysis-Toolkit
-000002e0: 2f61 6374 696f 6e73 3f71 7565 7279 3d77  /actions?query=w
-000002f0: 6f72 6b66 6c6f 7725 3341 4349 223e 0a20  orkflow%3ACI">. 
-00000300: 2020 203c 696d 6720 7372 633d 2268 7474     <img src="htt
-00000310: 7073 3a2f 2f69 6d67 2e73 6869 656c 6473  ps://img.shields
-00000320: 2e69 6f2f 6769 7468 7562 2f77 6f72 6b66  .io/github/workf
-00000330: 6c6f 772f 7374 6174 7573 2f62 7573 2d73  low/status/bus-s
-00000340: 746f 702f 782d 7465 726d 696e 616c 2f43  top/x-terminal/C
-00000350: 493f 6c6f 676f 3d67 6974 6875 6222 2061  I?logo=github" a
-00000360: 6c74 3d22 6163 7469 6f6e 7320 7374 6174  lt="actions stat
-00000370: 7573 223e 3c2f 613e 0a3c 6120 6872 6566  us"></a>.<a href
-00000380: 3d22 6874 7470 733a 2f2f 7079 7069 2e70  ="https://pypi.p
-00000390: 7974 686f 6e2e 6f72 672f 7079 7069 2f63  ython.org/pypi/c
-000003a0: 6f6e 766f 6b69 742f 223e 0a20 2020 203c  onvokit/">.    <
-000003b0: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
-000003c0: 2f69 6d67 2e73 6869 656c 6473 2e69 6f2f  /img.shields.io/
-000003d0: 7079 7069 2f70 7976 6572 7369 6f6e 732f  pypi/pyversions/
-000003e0: 636f 6e76 6f6b 6974 2220 616c 743d 2276  convokit" alt="v
-000003f0: 6572 7369 6f6e 7322 3e3c 2f61 3e20 2020  ersions"></a>   
-00000400: 200a 3c2f 703e 0a0a 5468 6973 2074 6f6f   .</p>..This too
-00000410: 6c6b 6974 2063 6f6e 7461 696e 7320 746f  lkit contains to
-00000420: 6f6c 7320 746f 2065 7874 7261 6374 2063  ols to extract c
-00000430: 6f6e 7665 7273 6174 696f 6e61 6c20 6665  onversational fe
-00000440: 6174 7572 6573 2061 6e64 2061 6e61 6c79  atures and analy
-00000450: 7a65 2073 6f63 6961 6c20 7068 656e 6f6d  ze social phenom
-00000460: 656e 6120 696e 2063 6f6e 7665 7273 6174  ena in conversat
-00000470: 696f 6e73 2c20 7573 696e 6720 6120 5b73  ions, using a [s
-00000480: 696e 676c 6520 756e 6966 6965 6420 696e  ingle unified in
-00000490: 7465 7266 6163 655d 2868 7474 7073 3a2f  terface](https:/
-000004a0: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
-000004b0: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
-000004c0: 696f 6e2f 6172 6368 6974 6563 7475 7265  ion/architecture
-000004d0: 2e68 746d 6c29 2069 6e73 7069 7265 6420  .html) inspired 
-000004e0: 6279 2028 616e 6420 636f 6d70 6174 6962  by (and compatib
-000004f0: 6c65 2077 6974 6829 2073 6369 6b69 742d  le with) scikit-
-00000500: 6c65 6172 6e2e 2020 5365 7665 7261 6c20  learn.  Several 
-00000510: 6c61 7267 6520 5b63 6f6e 7665 7273 6174  large [conversat
-00000520: 696f 6e61 6c20 6461 7461 7365 7473 5d28  ional datasets](
-00000530: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-00000540: 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f 436f  om/CornellNLP/Co
-00000550: 726e 656c 6c2d 436f 6e76 6572 7361 7469  rnell-Conversati
-00000560: 6f6e 616c 2d41 6e61 6c79 7369 732d 546f  onal-Analysis-To
-00000570: 6f6c 6b69 7423 6461 7461 7365 7473 2920  olkit#datasets) 
-00000580: 6172 6520 696e 636c 7564 6564 2074 6f67  are included tog
-00000590: 6574 6865 7220 7769 7468 2073 6372 6970  ether with scrip
-000005a0: 7473 2065 7865 6d70 6c69 6679 696e 6720  ts exemplifying 
-000005b0: 7468 6520 7573 6520 6f66 2074 6865 2074  the use of the t
-000005c0: 6f6f 6c6b 6974 206f 6e20 7468 6573 6520  oolkit on these 
-000005d0: 6461 7461 7365 7473 2e20 5468 6520 6c61  datasets. The la
-000005e0: 7465 7374 2076 6572 7369 6f6e 2069 7320  test version is 
-000005f0: 5b32 2e35 2e33 5d28 6874 7470 733a 2f2f  [2.5.3](https://
-00000600: 6769 7468 7562 2e63 6f6d 2f43 6f72 6e65  github.com/Corne
-00000610: 6c6c 4e4c 502f 436f 726e 656c 6c2d 436f  llNLP/Cornell-Co
-00000620: 6e76 6572 7361 7469 6f6e 616c 2d41 6e61  nversational-Ana
-00000630: 6c79 7369 732d 546f 6f6c 6b69 742f 7265  lysis-Toolkit/re
-00000640: 6c65 6173 6573 2f74 6167 2f76 322e 352e  leases/tag/v2.5.
-00000650: 3229 2028 7265 6c65 6173 6564 2031 3620  2) (released 16 
-00000660: 4a61 6e20 3230 3232 293b 2066 6f6c 6c6f  Jan 2022); follo
-00000670: 7720 7468 6520 5b70 726f 6a65 6374 206f  w the [project o
-00000680: 6e20 4769 7448 7562 5d28 6874 7470 733a  n GitHub](https:
-00000690: 2f2f 6769 7468 7562 2e63 6f6d 2f43 6f72  //github.com/Cor
-000006a0: 6e65 6c6c 4e4c 502f 436f 726e 656c 6c2d  nellNLP/Cornell-
-000006b0: 436f 6e76 6572 7361 7469 6f6e 616c 2d41  Conversational-A
-000006c0: 6e61 6c79 7369 732d 546f 6f6c 6b69 7429  nalysis-Toolkit)
-000006d0: 2074 6f20 6b65 6570 2074 7261 636b 206f   to keep track o
-000006e0: 6620 7570 6461 7465 732e 0a0a 5265 6164  f updates...Read
-000006f0: 206f 7572 205b 646f 6375 6d65 6e74 6174   our [documentat
-00000700: 696f 6e5d 2868 7474 7073 3a2f 2f63 6f6e  ion](https://con
-00000710: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
-00000720: 752f 646f 6375 6d65 6e74 6174 696f 6e29  u/documentation)
-00000730: 206f 7220 7472 7920 436f 6e76 6f4b 6974   or try ConvoKit
-00000740: 2069 6e20 6f75 7220 5b69 6e74 6572 6163   in our [interac
-00000750: 7469 7665 2074 7574 6f72 6961 6c5d 2868  tive tutorial](h
-00000760: 7474 7073 3a2f 2f63 6f6c 6162 2e72 6573  ttps://colab.res
-00000770: 6561 7263 682e 676f 6f67 6c65 2e63 6f6d  earch.google.com
-00000780: 2f67 6974 6875 622f 436f 726e 656c 6c4e  /github/CornellN
-00000790: 4c50 2f43 6f72 6e65 6c6c 2d43 6f6e 7665  LP/Cornell-Conve
-000007a0: 7273 6174 696f 6e61 6c2d 416e 616c 7973  rsational-Analys
-000007b0: 6973 2d54 6f6f 6c6b 6974 2f62 6c6f 622f  is-Toolkit/blob/
-000007c0: 6d61 7374 6572 2f65 7861 6d70 6c65 732f  master/examples/
-000007d0: 496e 7472 6f64 7563 7469 6f6e 5f74 6f5f  Introduction_to_
-000007e0: 436f 6e76 6f4b 6974 2e69 7079 6e62 292e  ConvoKit.ipynb).
-000007f0: 0a0a 5468 6520 746f 6f6c 6b69 7420 6375  ..The toolkit cu
-00000800: 7272 656e 746c 7920 696d 706c 656d 656e  rrently implemen
-00000810: 7473 2066 6561 7475 7265 7320 666f 723a  ts features for:
-00000820: 0a0a 2323 2320 5b4c 696e 6775 6973 7469  ..### [Linguisti
-00000830: 6320 636f 6f72 6469 6e61 7469 6f6e 5d28  c coordination](
-00000840: 6874 7470 733a 2f2f 7777 772e 6373 2e63  https://www.cs.c
-00000850: 6f72 6e65 6c6c 2e65 6475 2f7e 6372 6973  ornell.edu/~cris
-00000860: 7469 616e 2f45 6368 6f65 735f 6f66 5f70  tian/Echoes_of_p
-00000870: 6f77 6572 2e68 746d 6c29 203c 7375 623e  ower.html) <sub>
-00000880: 3c73 7570 3e5b 2841 5049 295d 2868 7474  <sup>[(API)](htt
-00000890: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
-000008a0: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
-000008b0: 6e74 6174 696f 6e2f 636f 6f72 6469 6e61  ntation/coordina
-000008c0: 7469 6f6e 2e68 746d 6c29 3c2f 7375 703e  tion.html)</sup>
-000008d0: 3c2f 7375 623e 0a0a 4120 6d65 6173 7572  </sub>..A measur
-000008e0: 6520 6f66 206c 696e 6775 6973 7469 6320  e of linguistic 
-000008f0: 696e 666c 7565 6e63 6520 2861 6e64 2072  influence (and r
-00000900: 656c 6174 6976 6520 706f 7765 7229 2062  elative power) b
-00000910: 6574 7765 656e 2069 6e64 6976 6964 7561  etween individua
-00000920: 6c73 206f 7220 6772 6f75 7073 2062 6173  ls or groups bas
-00000930: 6564 206f 6e20 7468 6569 7220 7573 6520  ed on their use 
-00000940: 6f66 2066 756e 6374 696f 6e20 776f 7264  of function word
-00000950: 732e 2020 0a45 7861 6d70 6c65 3a20 5b65  s.  .Example: [e
-00000960: 7870 6c6f 7269 6e67 2074 6865 2062 616c  xploring the bal
-00000970: 616e 6365 206f 6620 706f 7765 7220 696e  ance of power in
-00000980: 2074 6865 2055 2e53 2e20 5375 7072 656d   the U.S. Suprem
-00000990: 6520 436f 7572 745d 2868 7474 7073 3a2f  e Court](https:/
-000009a0: 2f67 6974 6875 622e 636f 6d2f 436f 726e  /github.com/Corn
-000009b0: 656c 6c4e 4c50 2f43 6f72 6e65 6c6c 2d43  ellNLP/Cornell-C
-000009c0: 6f6e 7665 7273 6174 696f 6e61 6c2d 416e  onversational-An
-000009d0: 616c 7973 6973 2d54 6f6f 6c6b 6974 2f62  alysis-Toolkit/b
-000009e0: 6c6f 622f 6d61 7374 6572 2f65 7861 6d70  lob/master/examp
-000009f0: 6c65 732f 636f 6f72 6469 6e61 7469 6f6e  les/coordination
-00000a00: 2f65 7861 6d70 6c65 732e 6970 796e 6229  /examples.ipynb)
-00000a10: 2e0a 0a23 2323 205b 506f 6c69 7465 6e65  ...### [Politene
-00000a20: 7373 2073 7472 6174 6567 6965 735d 2868  ss strategies](h
-00000a30: 7474 7073 3a2f 2f77 7777 2e63 732e 636f  ttps://www.cs.co
-00000a40: 726e 656c 6c2e 6564 752f 7e63 7269 7374  rnell.edu/~crist
-00000a50: 6961 6e2f 506f 6c69 7465 6e65 7373 2e68  ian/Politeness.h
-00000a60: 746d 6c29 203c 7375 623e 3c73 7570 3e5b  tml) <sub><sup>[
-00000a70: 2841 5049 295d 2868 7474 7073 3a2f 2f63  (API)](https://c
-00000a80: 6f6e 766f 6b69 742e 636f 726e 656c 6c2e  onvokit.cornell.
-00000a90: 6564 752f 646f 6375 6d65 6e74 6174 696f  edu/documentatio
-00000aa0: 6e2f 706f 6c69 7465 6e65 7373 5374 7261  n/politenessStra
-00000ab0: 7465 6769 6573 2e68 746d 6c29 3c2f 7375  tegies.html)</su
-00000ac0: 703e 3c2f 7375 623e 0a0a 4120 7365 7420  p></sub>..A set 
-00000ad0: 6f66 206c 6578 6963 616c 2061 6e64 2070  of lexical and p
-00000ae0: 6172 7365 2d62 6173 6564 2066 6561 7475  arse-based featu
-00000af0: 7265 7320 636f 7272 656c 6174 696e 6720  res correlating 
-00000b00: 7769 7468 2070 6f6c 6974 656e 6573 7320  with politeness 
-00000b10: 616e 6420 696d 706f 6c69 7465 6e65 7373  and impoliteness
-00000b20: 2e20 200a 4578 616d 706c 653a 205b 756e  .  .Example: [un
-00000b30: 6465 7273 7461 6e64 696e 6720 7468 6520  derstanding the 
-00000b40: 286d 6973 2975 7365 206f 6620 706f 6c69  (mis)use of poli
-00000b50: 7465 6e65 7373 2073 7472 6174 6567 6965  teness strategie
-00000b60: 7320 696e 2063 6f6e 7665 7273 6174 696f  s in conversatio
-00000b70: 6e73 2067 6f6e 6520 6177 7279 206f 6e20  ns gone awry on 
-00000b80: 5769 6b69 7065 6469 615d 2868 7474 7073  Wikipedia](https
-00000b90: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
-00000ba0: 726e 656c 6c4e 4c50 2f43 6f72 6e65 6c6c  rnellNLP/Cornell
-00000bb0: 2d43 6f6e 7665 7273 6174 696f 6e61 6c2d  -Conversational-
-00000bc0: 416e 616c 7973 6973 2d54 6f6f 6c6b 6974  Analysis-Toolkit
-00000bd0: 2f62 6c6f 622f 6d61 7374 6572 2f65 7861  /blob/master/exa
-00000be0: 6d70 6c65 732f 636f 6e76 6572 7361 7469  mples/conversati
-00000bf0: 6f6e 732d 676f 6e65 2d61 7772 792f 436f  ons-gone-awry/Co
-00000c00: 6e76 6572 7361 7469 6f6e 735f 476f 6e65  nversations_Gone
-00000c10: 5f41 7772 795f 5072 6564 6963 7469 6f6e  _Awry_Prediction
-00000c20: 2e69 7079 6e62 292e 0a0a 2323 2320 5b45  .ipynb)...### [E
-00000c30: 7870 6563 7465 6420 436f 6e76 6572 7361  xpected Conversa
-00000c40: 7469 6f6e 616c 2043 6f6e 7465 7874 2046  tional Context F
-00000c50: 7261 6d65 776f 726b 5d28 6874 7470 733a  ramework](https:
-00000c60: 2f2f 7469 736a 756e 652e 6769 7468 7562  //tisjune.github
-00000c70: 2e69 6f2f 7265 7365 6172 6368 2f64 6973  .io/research/dis
-00000c80: 7365 7274 6174 696f 6e29 203c 7375 623e  sertation) <sub>
-00000c90: 3c73 7570 3e5b 2841 5049 295d 2868 7474  <sup>[(API)](htt
-00000ca0: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
-00000cb0: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
-00000cc0: 6e74 6174 696f 6e2f 6578 7065 6374 6564  ntation/expected
-00000cd0: 5f63 6f6e 7465 7874 5f6d 6f64 656c 2e68  _context_model.h
-00000ce0: 746d 6c29 3c2f 7375 703e 3c2f 7375 623e  tml)</sup></sub>
-00000cf0: 0a0a 4120 6672 616d 6577 6f72 6b20 666f  ..A framework fo
-00000d00: 7220 6368 6172 6163 7465 7269 7a69 6e67  r characterizing
-00000d10: 2075 7474 6572 616e 6365 7320 616e 6420   utterances and 
-00000d20: 7465 726d 7320 6261 7365 6420 6f6e 2074  terms based on t
-00000d30: 6865 6972 2065 7870 6563 7465 6420 636f  heir expected co
-00000d40: 6e76 6572 7361 7469 6f6e 616c 2063 6f6e  nversational con
-00000d50: 7465 7874 2c20 636f 6e73 6973 7469 6e67  text, consisting
-00000d60: 206f 6620 6d6f 6465 6c20 696d 706c 656d   of model implem
-00000d70: 656e 7461 7469 6f6e 7320 616e 6420 7772  entations and wr
-00000d80: 6170 7065 7220 7069 7065 6c69 6e65 732e  apper pipelines.
-00000d90: 0a45 7861 6d70 6c65 733a 205b 6465 7269  .Examples: [deri
-00000da0: 7669 6e67 2071 7565 7374 696f 6e20 7479  ving question ty
-00000db0: 7065 7320 616e 6420 6f74 6865 7220 6368  pes and other ch
-00000dc0: 6172 6163 7465 7269 7a61 7469 6f6e 7320  aracterizations 
-00000dd0: 696e 2042 7269 7469 7368 2070 6172 6c69  in British parli
-00000de0: 616d 656e 7461 7279 2071 7565 7374 696f  amentary questio
-00000df0: 6e20 7065 7269 6f64 735d 2868 7474 7073  n periods](https
-00000e00: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
-00000e10: 726e 656c 6c4e 4c50 2f43 6f72 6e65 6c6c  rnellNLP/Cornell
-00000e20: 2d43 6f6e 7665 7273 6174 696f 6e61 6c2d  -Conversational-
-00000e30: 416e 616c 7973 6973 2d54 6f6f 6c6b 6974  Analysis-Toolkit
-00000e40: 2f62 6c6f 622f 6d61 7374 6572 2f63 6f6e  /blob/master/con
-00000e50: 766f 6b69 742f 6578 7065 6374 6564 5f63  vokit/expected_c
-00000e60: 6f6e 7465 7874 5f66 7261 6d65 776f 726b  ontext_framework
-00000e70: 2f64 656d 6f73 2f70 6172 6c69 616d 656e  /demos/parliamen
-00000e80: 745f 6465 6d6f 2e69 7079 6e62 292c 200a  t_demo.ipynb), .
-00000e90: 5b65 7870 6c6f 7261 7469 6f6e 206f 6620  [exploration of 
-00000ea0: 5377 6974 6368 626f 6172 6420 6469 616c  Switchboard dial
-00000eb0: 6f67 2061 6374 7320 636f 7270 7573 5d28  og acts corpus](
-00000ec0: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-00000ed0: 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f 436f  om/CornellNLP/Co
-00000ee0: 726e 656c 6c2d 436f 6e76 6572 7361 7469  rnell-Conversati
-00000ef0: 6f6e 616c 2d41 6e61 6c79 7369 732d 546f  onal-Analysis-To
-00000f00: 6f6c 6b69 742f 626c 6f62 2f6d 6173 7465  olkit/blob/maste
-00000f10: 722f 636f 6e76 6f6b 6974 2f65 7870 6563  r/convokit/expec
-00000f20: 7465 645f 636f 6e74 6578 745f 6672 616d  ted_context_fram
-00000f30: 6577 6f72 6b2f 6465 6d6f 732f 7377 6974  ework/demos/swit
-00000f40: 6368 626f 6172 645f 6578 706c 6f72 6174  chboard_explorat
-00000f50: 696f 6e5f 6465 6d6f 2e69 7079 6e62 292c  ion_demo.ipynb),
-00000f60: 2020 5b65 7861 6d69 6e69 6e67 2057 696b    [examining Wik
-00000f70: 6970 6564 6961 2074 616c 6b20 7061 6765  ipedia talk page
-00000f80: 2064 6973 6375 7373 696f 6e73 5d28 6874   discussions](ht
-00000f90: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
-00000fa0: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 726e  /CornellNLP/Corn
-00000fb0: 656c 6c2d 436f 6e76 6572 7361 7469 6f6e  ell-Conversation
-00000fc0: 616c 2d41 6e61 6c79 7369 732d 546f 6f6c  al-Analysis-Tool
-00000fd0: 6b69 742f 626c 6f62 2f6d 6173 7465 722f  kit/blob/master/
-00000fe0: 636f 6e76 6f6b 6974 2f65 7870 6563 7465  convokit/expecte
-00000ff0: 645f 636f 6e74 6578 745f 6672 616d 6577  d_context_framew
-00001000: 6f72 6b2f 6465 6d6f 732f 7769 6b69 5f61  ork/demos/wiki_a
-00001010: 7772 795f 6465 6d6f 2e69 7079 6e62 2920  wry_demo.ipynb) 
-00001020: 616e 6420 5b63 6f6d 7075 7469 6e67 2074  and [computing t
-00001030: 6865 206f 7269 656e 7461 7469 6f6e 206f  he orientation o
-00001040: 6620 6a75 7374 6963 6520 7574 7465 7261  f justice uttera
-00001050: 6e63 6573 2069 6e20 7468 6520 5553 2053  nces in the US S
-00001060: 7570 7265 6d65 2043 6f75 7274 5d28 6874  upreme Court](ht
-00001070: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
-00001080: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 726e  /CornellNLP/Corn
-00001090: 656c 6c2d 436f 6e76 6572 7361 7469 6f6e  ell-Conversation
-000010a0: 616c 2d41 6e61 6c79 7369 732d 546f 6f6c  al-Analysis-Tool
-000010b0: 6b69 742f 626c 6f62 2f6d 6173 7465 722f  kit/blob/master/
-000010c0: 636f 6e76 6f6b 6974 2f65 7870 6563 7465  convokit/expecte
-000010d0: 645f 636f 6e74 6578 745f 6672 616d 6577  d_context_framew
-000010e0: 6f72 6b2f 6465 6d6f 732f 7363 6f74 7573  ork/demos/scotus
-000010f0: 5f6f 7269 656e 7461 7469 6f6e 5f64 656d  _orientation_dem
-00001100: 6f2e 6970 796e 6229 0a0a 3c21 2d2d 2023  o.ipynb)..<!-- #
-00001110: 2323 205b 5072 6f6d 7074 2074 7970 6573  ## [Prompt types
-00001120: 5d28 6874 7470 3a2f 2f77 7777 2e63 732e  ](http://www.cs.
-00001130: 636f 726e 656c 6c2e 6564 752f 7e63 7269  cornell.edu/~cri
-00001140: 7374 6961 6e2f 4173 6b69 6e67 5f74 6f6f  stian/Asking_too
-00001150: 5f6d 7563 682e 6874 6d6c 2920 3c73 7562  _much.html) <sub
-00001160: 3e3c 7375 703e 5b28 4150 4929 5d28 6874  ><sup>[(API)](ht
-00001170: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
-00001180: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
-00001190: 656e 7461 7469 6f6e 2f70 726f 6d70 7454  entation/promptT
-000011a0: 7970 6573 2e68 746d 6c29 3c2f 7375 703e  ypes.html)</sup>
-000011b0: 3c2f 7375 623e 0a0a 416e 2075 6e73 7570  </sub>..An unsup
-000011c0: 6572 7669 7365 6420 6d65 7468 6f64 2066  ervised method f
-000011d0: 6f72 2067 726f 7570 696e 6720 7574 7465  or grouping utte
-000011e0: 7261 6e63 6573 2061 6e64 2075 7474 6572  rances and utter
-000011f0: 616e 6365 2066 6561 7475 7265 7320 6279  ance features by
-00001200: 2074 6865 6972 2072 6865 746f 7269 6361   their rhetorica
-00001210: 6c20 726f 6c65 2e0a 4578 616d 706c 6573  l role..Examples
-00001220: 3a20 5b65 7874 7261 6374 696e 6720 7175  : [extracting qu
-00001230: 6573 7469 6f6e 2074 7970 6573 2069 6e20  estion types in 
-00001240: 7468 6520 552e 4b2e 2070 6172 6c69 616d  the U.K. parliam
-00001250: 656e 745d 2868 7474 7073 3a2f 2f67 6974  ent](https://git
-00001260: 6875 622e 636f 6d2f 436f 726e 656c 6c4e  hub.com/CornellN
-00001270: 4c50 2f43 6f72 6e65 6c6c 2d43 6f6e 7665  LP/Cornell-Conve
-00001280: 7273 6174 696f 6e61 6c2d 416e 616c 7973  rsational-Analys
-00001290: 6973 2d54 6f6f 6c6b 6974 2f62 6c6f 622f  is-Toolkit/blob/
-000012a0: 6d61 7374 6572 2f65 7861 6d70 6c65 732f  master/examples/
-000012b0: 7072 6f6d 7074 2d74 7970 6573 2f70 726f  prompt-types/pro
-000012c0: 6d70 742d 7479 7065 2d77 7261 7070 6572  mpt-type-wrapper
-000012d0: 2d64 656d 6f2e 6970 796e 6229 2c20 5b65  -demo.ipynb), [e
-000012e0: 7874 656e 6465 6420 7665 7273 696f 6e20  xtended version 
-000012f0: 6465 6d6f 6e73 7472 6174 696e 6720 6164  demonstrating ad
-00001300: 6469 7469 6f6e 616c 2066 756e 6374 696f  ditional functio
-00001310: 6e61 6c69 7479 5d28 6874 7470 733a 2f2f  nality](https://
-00001320: 6769 7468 7562 2e63 6f6d 2f43 6f72 6e65  github.com/Corne
-00001330: 6c6c 4e4c 502f 436f 726e 656c 6c2d 436f  llNLP/Cornell-Co
-00001340: 6e76 6572 7361 7469 6f6e 616c 2d41 6e61  nversational-Ana
-00001350: 6c79 7369 732d 546f 6f6c 6b69 742f 626c  lysis-Toolkit/bl
-00001360: 6f62 2f6d 6173 7465 722f 6578 616d 706c  ob/master/exampl
-00001370: 6573 2f70 726f 6d70 742d 7479 7065 732f  es/prompt-types/
-00001380: 7072 6f6d 7074 2d74 7970 652d 6465 6d6f  prompt-type-demo
-00001390: 2e69 7079 6e62 292c 205b 756e 6465 7273  .ipynb), [unders
-000013a0: 7461 6e64 696e 6720 7468 6520 7573 6520  tanding the use 
-000013b0: 6f66 2063 6f6e 7665 7273 6174 696f 6e61  of conversationa
-000013c0: 6c20 7072 6f6d 7074 7320 696e 2063 6f6e  l prompts in con
-000013d0: 7665 7273 6174 696f 6e73 2067 6f6e 6520  versations gone 
-000013e0: 6177 7279 206f 6e20 5769 6b69 7065 6469  awry on Wikipedi
-000013f0: 615d 2868 7474 7073 3a2f 2f67 6974 6875  a](https://githu
-00001400: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
-00001410: 2f43 6f72 6e65 6c6c 2d43 6f6e 7665 7273  /Cornell-Convers
-00001420: 6174 696f 6e61 6c2d 416e 616c 7973 6973  ational-Analysis
-00001430: 2d54 6f6f 6c6b 6974 2f62 6c6f 622f 6d61  -Toolkit/blob/ma
-00001440: 7374 6572 2f65 7861 6d70 6c65 732f 636f  ster/examples/co
-00001450: 6e76 6572 7361 7469 6f6e 732d 676f 6e65  nversations-gone
-00001460: 2d61 7772 792f 436f 6e76 6572 7361 7469  -awry/Conversati
-00001470: 6f6e 735f 476f 6e65 5f41 7772 795f 5072  ons_Gone_Awry_Pr
-00001480: 6564 6963 7469 6f6e 2e69 7079 6e62 292e  ediction.ipynb).
-00001490: 0a0a 416c 736f 2069 6e63 6c75 6465 7320  ..Also includes 
-000014a0: 6675 6e63 7469 6f6e 616c 6974 7920 746f  functionality to
-000014b0: 2065 7874 7261 6374 2073 7572 6661 6365   extract surface
-000014c0: 206d 6f74 6966 7320 746f 2072 6570 7265   motifs to repre
-000014d0: 7365 6e74 2075 7474 6572 616e 6365 732c  sent utterances,
-000014e0: 2075 7365 6420 696e 2074 6865 2061 626f   used in the abo
-000014f0: 7665 2070 6170 6572 205b 2841 5049 295d  ve paper [(API)]
-00001500: 2868 7474 7073 3a2f 2f63 6f6e 766f 6b69  (https://convoki
-00001510: 742e 636f 726e 656c 6c2e 6564 752f 646f  t.cornell.edu/do
-00001520: 6375 6d65 6e74 6174 696f 6e2f 7068 7261  cumentation/phra
-00001530: 7369 6e67 4d6f 7469 6673 2e68 746d 6c29  singMotifs.html)
-00001540: 2e20 2d2d 3e0a 0a23 2323 205b 4879 7065  . -->..### [Hype
-00001550: 7267 7261 7068 2063 6f6e 7665 7273 6174  rgraph conversat
-00001560: 696f 6e20 7265 7072 6573 656e 7461 7469  ion representati
-00001570: 6f6e 5d28 6874 7470 3a2f 2f77 7777 2e63  on](http://www.c
-00001580: 732e 636f 726e 656c 6c2e 6564 752f 7e63  s.cornell.edu/~c
-00001590: 7269 7374 6961 6e2f 5061 7474 6572 6e73  ristian/Patterns
-000015a0: 5f6f 665f 7061 7274 6963 6970 616e 745f  _of_participant_
-000015b0: 696e 7465 7261 6374 696f 6e73 2e68 746d  interactions.htm
-000015c0: 6c29 203c 7375 623e 3c73 7570 3e5b 2841  l) <sub><sup>[(A
-000015d0: 5049 295d 2868 7474 7073 3a2f 2f63 6f6e  PI)](https://con
-000015e0: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
-000015f0: 752f 646f 6375 6d65 6e74 6174 696f 6e2f  u/documentation/
-00001600: 6879 7065 7263 6f6e 766f 2e68 746d 6c29  hyperconvo.html)
-00001610: 3c2f 7375 703e 3c2f 7375 623e 0a41 206d  </sup></sub>.A m
-00001620: 6574 686f 6420 666f 7220 6578 7472 6163  ethod for extrac
-00001630: 7469 6e67 2073 7472 7563 7475 7261 6c20  ting structural 
-00001640: 6665 6174 7572 6573 206f 6620 636f 6e76  features of conv
-00001650: 6572 7361 7469 6f6e 7320 7468 726f 7567  ersations throug
-00001660: 6820 6120 6879 7065 7267 7261 7068 2072  h a hypergraph r
-00001670: 6570 7265 7365 6e74 6174 696f 6e2e 2020  epresentation.  
-00001680: 0a45 7861 6d70 6c65 3a20 5b68 7970 6572  .Example: [hyper
-00001690: 6772 6170 6820 6372 6561 7469 6f6e 2061  graph creation a
-000016a0: 6e64 2066 6561 7475 7265 2065 7874 7261  nd feature extra
-000016b0: 6374 696f 6e2c 2076 6973 7561 6c69 7a61  ction, visualiza
-000016c0: 7469 6f6e 2061 6e64 2069 6e74 6572 7072  tion and interpr
-000016d0: 6574 6174 696f 6e20 6f6e 2061 2073 7562  etation on a sub
-000016e0: 7361 6d70 6c65 206f 6620 5265 6464 6974  sample of Reddit
-000016f0: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
-00001700: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
-00001710: 436f 726e 656c 6c2d 436f 6e76 6572 7361  Cornell-Conversa
-00001720: 7469 6f6e 616c 2d41 6e61 6c79 7369 732d  tional-Analysis-
-00001730: 546f 6f6c 6b69 742f 626c 6f62 2f6d 6173  Toolkit/blob/mas
-00001740: 7465 722f 6578 616d 706c 6573 2f68 7970  ter/examples/hyp
-00001750: 6572 636f 6e76 6f2f 6465 6d6f 5f6e 6577  erconvo/demo_new
-00001760: 2e69 7079 6e62 292e 0a0a 2323 2320 5b4c  .ipynb)...### [L
-00001770: 696e 6775 6973 7469 6320 6469 7665 7273  inguistic divers
-00001780: 6974 7920 696e 2063 6f6e 7665 7273 6174  ity in conversat
-00001790: 696f 6e73 5d28 6874 7470 3a2f 2f77 7777  ions](http://www
-000017a0: 2e63 732e 636f 726e 656c 6c2e 6564 752f  .cs.cornell.edu/
-000017b0: 7e63 7269 7374 6961 6e2f 4669 6e64 696e  ~cristian/Findin
-000017c0: 675f 796f 7572 5f76 6f69 6365 5f5f 6c69  g_your_voice__li
-000017d0: 6e67 7569 7374 6963 5f64 6576 656c 6f70  nguistic_develop
-000017e0: 6d65 6e74 2e68 746d 6c29 203c 7375 623e  ment.html) <sub>
-000017f0: 3c73 7570 3e5b 2841 5049 295d 2868 7474  <sup>[(API)](htt
-00001800: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
-00001810: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
-00001820: 6e74 6174 696f 6e2f 7370 6561 6b65 7243  ntation/speakerC
-00001830: 6f6e 766f 4469 7665 7273 6974 792e 6874  onvoDiversity.ht
-00001840: 6d6c 293c 2f73 7570 3e3c 2f73 7562 3e0a  ml)</sup></sub>.
-00001850: 4120 6d65 7468 6f64 2074 6f20 636f 6d70  A method to comp
-00001860: 7574 6520 7468 6520 6c69 6e67 7569 7374  ute the linguist
-00001870: 6963 2064 6976 6572 7369 7479 206f 6620  ic diversity of 
-00001880: 696e 6469 7669 6475 616c 7320 7769 7468  individuals with
-00001890: 696e 2074 6865 6972 206f 776e 2063 6f6e  in their own con
-000018a0: 7665 7273 6174 696f 6e73 2c20 616e 6420  versations, and 
-000018b0: 6265 7477 6565 6e20 6f74 6865 7220 696e  between other in
-000018c0: 6469 7669 6475 616c 7320 696e 2061 2070  dividuals in a p
-000018d0: 6f70 756c 6174 696f 6e2e 2020 0a45 7861  opulation.  .Exa
-000018e0: 6d70 6c65 3a20 5b73 7065 616b 6572 2063  mple: [speaker c
-000018f0: 6f6e 7665 7273 6174 696f 6e20 6174 7472  onversation attr
-00001900: 6962 7574 6573 2061 6e64 2064 6976 6572  ibutes and diver
-00001910: 7369 7479 2065 7861 6d70 6c65 206f 6e20  sity example on 
-00001920: 4368 616e 6765 4d79 5669 6577 5d28 6874  ChangeMyView](ht
-00001930: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
-00001940: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 726e  /CornellNLP/Corn
-00001950: 656c 6c2d 436f 6e76 6572 7361 7469 6f6e  ell-Conversation
-00001960: 616c 2d41 6e61 6c79 7369 732d 546f 6f6c  al-Analysis-Tool
-00001970: 6b69 742f 626c 6f62 2f6d 6173 7465 722f  kit/blob/master/
-00001980: 6578 616d 706c 6573 2f73 7065 616b 6572  examples/speaker
-00001990: 2d63 6f6e 766f 2d61 7474 7269 6275 7465  -convo-attribute
-000019a0: 732f 7370 6561 6b65 722d 636f 6e76 6f2d  s/speaker-convo-
-000019b0: 6469 7665 7273 6974 792d 6465 6d6f 2e69  diversity-demo.i
-000019c0: 7079 6e62 290a 0a23 2323 205b 4352 4146  pynb)..### [CRAF
-000019d0: 543a 204f 6e6c 696e 6520 666f 7265 6361  T: Online foreca
-000019e0: 7374 696e 6720 6f66 2063 6f6e 7665 7273  sting of convers
-000019f0: 6174 696f 6e61 6c20 6f75 7463 6f6d 6573  ational outcomes
-00001a00: 5d28 6874 7470 733a 2f2f 6172 7869 762e  ](https://arxiv.
-00001a10: 6f72 672f 6162 732f 3139 3039 2e30 3133  org/abs/1909.013
-00001a20: 3632 2920 3c73 7562 3e3c 7375 703e 5b28  62) <sub><sup>[(
-00001a30: 4150 4929 5d28 6874 7470 733a 2f2f 636f  API)](https://co
-00001a40: 6e76 6f6b 6974 2e63 6f72 6e65 6c6c 2e65  nvokit.cornell.e
-00001a50: 6475 2f64 6f63 756d 656e 7461 7469 6f6e  du/documentation
-00001a60: 2f66 6f72 6563 6173 7465 722e 6874 6d6c  /forecaster.html
-00001a70: 293c 2f73 7570 3e3c 2f73 7562 3e0a 4120  )</sup></sub>.A 
-00001a80: 6e65 7572 616c 206d 6f64 656c 2066 6f72  neural model for
-00001a90: 2066 6f72 6563 6173 7469 6e67 2066 7574   forecasting fut
-00001aa0: 7572 6520 6f75 7463 6f6d 6573 206f 6620  ure outcomes of 
-00001ab0: 636f 6e76 6572 7361 7469 6f6e 7320 2865  conversations (e
-00001ac0: 2e67 2e2c 2064 6572 6169 6c6d 656e 7420  .g., derailment 
-00001ad0: 696e 746f 2070 6572 736f 6e61 6c20 6174  into personal at
-00001ae0: 7461 636b 7329 2061 7320 7468 6579 2064  tacks) as they d
-00001af0: 6576 656c 6f70 2e20 200a 4176 6169 6c61  evelop.  .Availa
-00001b00: 626c 6520 6173 2061 6e20 696e 7465 7261  ble as an intera
-00001b10: 6374 6976 6520 6e6f 7465 626f 6f6b 3a20  ctive notebook: 
-00001b20: 5b66 756c 6c20 7665 7273 696f 6e20 2866  [full version (f
-00001b30: 696e 652d 7475 6e69 6e67 202b 2069 6e66  ine-tuning + inf
-00001b40: 6572 656e 6365 295d 2868 7474 7073 3a2f  erence)](https:/
-00001b50: 2f63 6f6c 6162 2e72 6573 6561 7263 682e  /colab.research.
-00001b60: 676f 6f67 6c65 2e63 6f6d 2f64 7269 7665  google.com/drive
-00001b70: 2f31 5348 3469 4d45 4864 6f48 3449 6f76  /1SH4iMEHdoH4Iov
-00001b80: 4e2d 6239 514f 534b 346b 4734 4468 4177  N-b9QOSK4kG4DhAw
-00001b90: 6d62 2920 6f72 205b 696e 6665 7265 6e63  mb) or [inferenc
-00001ba0: 652d 6f6e 6c79 5d28 6874 7470 733a 2f2f  e-only](https://
-00001bb0: 636f 6c61 622e 7265 7365 6172 6368 2e67  colab.research.g
-00001bc0: 6f6f 676c 652e 636f 6d2f 6472 6976 652f  oogle.com/drive/
-00001bd0: 3147 7649 435a 4e30 5677 5a51 5357 7733  1GvICZN0VwZQSWw3
-00001be0: 704a 6145 5659 2d45 5147 6f4f 2d4c 356c  pJaEVY-EQGoO-L5l
-00001bf0: 4829 2e0a 0a0a 0a23 2320 4461 7461 7365  H).....## Datase
-00001c00: 7473 0a43 6f6e 766f 4b69 7420 7368 6970  ts.ConvoKit ship
-00001c10: 7320 7769 7468 2073 6576 6572 616c 2064  s with several d
-00001c20: 6174 6173 6574 7320 7265 6164 7920 666f  atasets ready fo
-00001c30: 7220 7573 6520 226f 7574 2d6f 662d 7468  r use "out-of-th
-00001c40: 652d 626f 7822 2e0a 5468 6573 6520 6461  e-box"..These da
-00001c50: 7461 7365 7473 2063 616e 2062 6520 646f  tasets can be do
-00001c60: 776e 6c6f 6164 6564 2075 7369 6e67 2074  wnloaded using t
-00001c70: 6865 2060 636f 6e76 6f6b 6974 2e64 6f77  he `convokit.dow
-00001c80: 6e6c 6f61 6428 2960 205b 6865 6c70 6572  nload()` [helper
-00001c90: 2066 756e 6374 696f 6e5d 2868 7474 7073   function](https
-00001ca0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
-00001cb0: 726e 656c 6c4e 4c50 2f43 6f72 6e65 6c6c  rnellNLP/Cornell
-00001cc0: 2d43 6f6e 7665 7273 6174 696f 6e61 6c2d  -Conversational-
-00001cd0: 416e 616c 7973 6973 2d54 6f6f 6c6b 6974  Analysis-Toolkit
-00001ce0: 2f62 6c6f 622f 6d61 7374 6572 2f63 6f6e  /blob/master/con
-00001cf0: 766f 6b69 742f 7574 696c 2e70 7929 2e20  vokit/util.py). 
-00001d00: 2041 6c74 6572 6e61 7469 7665 6c79 2079   Alternatively y
-00001d10: 6f75 2063 616e 2061 6363 6573 7320 7468  ou can access th
-00001d20: 656d 2064 6972 6563 746c 7920 5b68 6572  em directly [her
-00001d30: 655d 2868 7474 703a 2f2f 7a69 7373 6f75  e](http://zissou
-00001d40: 2e69 6e66 6f73 6369 2e63 6f72 6e65 6c6c  .infosci.cornell
-00001d50: 2e65 6475 2f63 6f6e 766f 6b69 742f 6461  .edu/convokit/da
-00001d60: 7461 7365 7473 2f29 2e0a 0a23 2323 205b  tasets/)...### [
-00001d70: 436f 6e76 6572 7361 7469 6f6e 7320 476f  Conversations Go
-00001d80: 6e65 2041 7772 7920 4461 7461 7365 745d  ne Awry Dataset]
-00001d90: 2868 7474 7073 3a2f 2f63 6f6e 766f 6b69  (https://convoki
-00001da0: 742e 636f 726e 656c 6c2e 6564 752f 646f  t.cornell.edu/do
-00001db0: 6375 6d65 6e74 6174 696f 6e2f 6177 7279  cumentation/awry
-00001dc0: 2e68 746d 6c29 0a0a 5477 6f20 7265 6c61  .html)..Two rela
-00001dd0: 7465 6420 636f 7270 6f72 6120 6f66 2063  ted corpora of c
-00001de0: 6f6e 7665 7273 6174 696f 6e73 2074 6861  onversations tha
-00001df0: 7420 6465 7261 696c 2069 6e74 6f20 616e  t derail into an
-00001e00: 7469 736f 6369 616c 2062 6568 6176 696f  tisocial behavio
-00001e10: 722e 204f 6e65 2063 6f72 7075 7320 636f  r. One corpus co
-00001e20: 6e73 6973 7473 206f 6620 5769 6b69 7065  nsists of Wikipe
-00001e30: 6469 6120 7461 6c6b 2070 6167 6520 636f  dia talk page co
-00001e40: 6e76 6572 7361 7469 6f6e 7320 7468 6174  nversations that
-00001e50: 2064 6572 6169 6c20 696e 746f 2070 6572   derail into per
-00001e60: 736f 6e61 6c20 6174 7461 636b 7320 6173  sonal attacks as
-00001e70: 206c 6162 656c 6564 2062 7920 6372 6f77   labeled by crow
-00001e80: 6477 6f72 6b65 7273 2028 342c 3138 3820  dworkers (4,188 
-00001e90: 636f 6e76 6572 7361 7469 6f6e 7320 636f  conversations co
-00001ea0: 6e74 6169 6e69 6e67 2033 302e 3032 3120  ntaining 30.021 
-00001eb0: 636f 6d6d 656e 7473 292e 2054 6865 206f  comments). The o
-00001ec0: 7468 6572 2063 6f6e 7369 7374 7320 6f66  ther consists of
-00001ed0: 2064 6973 6375 7373 696f 6e20 7468 7265   discussion thre
-00001ee0: 6164 7320 6f6e 2074 6865 2073 7562 7265  ads on the subre
-00001ef0: 6464 6974 2043 6861 6e67 654d 7956 6965  ddit ChangeMyVie
-00001f00: 7720 2843 4d56 2920 7468 6174 2064 6572  w (CMV) that der
-00001f10: 6169 6c20 696e 746f 2072 756c 652d 7669  ail into rule-vi
-00001f20: 6f6c 6174 696e 6720 6265 6861 7669 6f72  olating behavior
-00001f30: 2061 7320 6465 7465 726d 696e 6564 2062   as determined b
-00001f40: 7920 7468 6520 7072 6573 656e 6365 206f  y the presence o
-00001f50: 6620 6120 6d6f 6465 7261 746f 7220 696e  f a moderator in
-00001f60: 7465 7276 656e 7469 6f6e 2028 362c 3834  tervention (6,84
-00001f70: 3220 636f 6e76 6572 7361 7469 6f6e 7320  2 conversations 
-00001f80: 636f 6e74 6169 6e69 6e67 2034 322c 3936  containing 42,96
-00001f90: 3420 636f 6d6d 656e 7473 292e 2020 0a4e  4 comments).  .N
-00001fa0: 616d 6520 666f 7220 646f 776e 6c6f 6164  ame for download
-00001fb0: 3a20 6063 6f6e 7665 7273 6174 696f 6e73  : `conversations
-00001fc0: 2d67 6f6e 652d 6177 7279 2d63 6f72 7075  -gone-awry-corpu
-00001fd0: 7360 2028 5769 6b69 7065 6469 6120 7665  s` (Wikipedia ve
-00001fe0: 7273 696f 6e29 206f 7220 6063 6f6e 7665  rsion) or `conve
-00001ff0: 7273 6174 696f 6e73 2d67 6f6e 652d 6177  rsations-gone-aw
-00002000: 7279 2d63 6d76 2d63 6f72 7075 7360 2028  ry-cmv-corpus` (
-00002010: 5265 6464 6974 2043 4d56 2076 6572 7369  Reddit CMV versi
-00002020: 6f6e 290a 0a23 2323 205b 436f 726e 656c  on)..### [Cornel
-00002030: 6c20 4d6f 7669 652d 4469 616c 6f67 7320  l Movie-Dialogs 
-00002040: 436f 7270 7573 5d28 6874 7470 733a 2f2f  Corpus](https://
-00002050: 636f 6e76 6f6b 6974 2e63 6f72 6e65 6c6c  convokit.cornell
-00002060: 2e65 6475 2f64 6f63 756d 656e 7461 7469  .edu/documentati
-00002070: 6f6e 2f6d 6f76 6965 2e68 746d 6c29 0a0a  on/movie.html)..
-00002080: 4120 6c61 7267 6520 6d65 7461 6461 7461  A large metadata
-00002090: 2d72 6963 6820 636f 6c6c 6563 7469 6f6e  -rich collection
-000020a0: 206f 6620 6669 6374 696f 6e61 6c20 636f   of fictional co
-000020b0: 6e76 6572 7361 7469 6f6e 7320 6578 7472  nversations extr
-000020c0: 6163 7465 6420 6672 6f6d 2072 6177 206d  acted from raw m
-000020d0: 6f76 6965 2073 6372 6970 7473 2e20 2832  ovie scripts. (2
-000020e0: 3230 2c35 3739 2063 6f6e 7665 7273 6174  20,579 conversat
-000020f0: 696f 6e61 6c20 6578 6368 616e 6765 7320  ional exchanges 
-00002100: 6265 7477 6565 6e20 3130 2c32 3932 2070  between 10,292 p
-00002110: 6169 7273 206f 6620 6d6f 7669 6520 6368  airs of movie ch
-00002120: 6172 6163 7465 7273 2069 6e20 3631 3720  aracters in 617 
-00002130: 6d6f 7669 6573 292e 200a 4e61 6d65 2066  movies). .Name f
-00002140: 6f72 2064 6f77 6e6c 6f61 643a 2060 6d6f  or download: `mo
-00002150: 7669 652d 636f 7270 7573 600a 0a23 2323  vie-corpus`..###
-00002160: 205b 5061 726c 6961 6d65 6e74 2051 7565   [Parliament Que
-00002170: 7374 696f 6e20 5469 6d65 2043 6f72 7075  stion Time Corpu
-00002180: 735d 2868 7474 7073 3a2f 2f63 6f6e 766f  s](https://convo
-00002190: 6b69 742e 636f 726e 656c 6c2e 6564 752f  kit.cornell.edu/
-000021a0: 646f 6375 6d65 6e74 6174 696f 6e2f 7061  documentation/pa
-000021b0: 726c 6961 6d65 6e74 2e68 746d 6c29 0a0a  rliament.html)..
-000021c0: 5061 726c 6961 6d65 6e74 6172 7920 7175  Parliamentary qu
-000021d0: 6573 7469 6f6e 2070 6572 696f 6473 2066  estion periods f
-000021e0: 726f 6d20 4d61 7920 3139 3739 2074 6f20  rom May 1979 to 
-000021f0: 4465 6365 6d62 6572 2032 3031 3620 2832  December 2016 (2
-00002200: 3136 2c38 3934 2071 7565 7374 696f 6e2d  16,894 question-
-00002210: 616e 7377 6572 2070 6169 7273 292e 2020  answer pairs).  
-00002220: 0a4e 616d 6520 666f 7220 646f 776e 6c6f  .Name for downlo
-00002230: 6164 3a20 6070 6172 6c69 616d 656e 742d  ad: `parliament-
-00002240: 636f 7270 7573 600a 0a23 2323 205b 5375  corpus`..### [Su
-00002250: 7072 656d 6520 436f 7572 7420 436f 7270  preme Court Corp
-00002260: 7573 5d28 6874 7470 733a 2f2f 636f 6e76  us](https://conv
-00002270: 6f6b 6974 2e63 6f72 6e65 6c6c 2e65 6475  okit.cornell.edu
-00002280: 2f64 6f63 756d 656e 7461 7469 6f6e 2f73  /documentation/s
-00002290: 7570 7265 6d65 2e68 746d 6c29 0a0a 4120  upreme.html)..A 
-000022a0: 636f 6c6c 6563 7469 6f6e 206f 6620 636f  collection of co
-000022b0: 6e76 6572 7361 7469 6f6e 7320 6672 6f6d  nversations from
-000022c0: 2074 6865 2055 2e53 2e20 5375 7072 656d   the U.S. Suprem
-000022d0: 6520 436f 7572 7420 4f72 616c 2041 7267  e Court Oral Arg
-000022e0: 756d 656e 7473 2e20 200a 4e61 6d65 2066  uments.  .Name f
-000022f0: 6f72 2064 6f77 6e6c 6f61 643a 2060 7375  or download: `su
-00002300: 7072 656d 652d 636f 7270 7573 600a 0a23  preme-corpus`..#
-00002310: 2323 205b 5769 6b69 7065 6469 6120 5461  ## [Wikipedia Ta
-00002320: 6c6b 2050 6167 6573 2043 6f72 7075 735d  lk Pages Corpus]
-00002330: 2868 7474 7073 3a2f 2f63 6f6e 766f 6b69  (https://convoki
-00002340: 742e 636f 726e 656c 6c2e 6564 752f 646f  t.cornell.edu/do
-00002350: 6375 6d65 6e74 6174 696f 6e2f 7769 6b69  cumentation/wiki
-00002360: 2e68 746d 6c29 0a0a 4120 6d65 6469 756d  .html)..A medium
-00002370: 2d73 697a 6520 636f 6c6c 6563 7469 6f6e  -size collection
-00002380: 206f 6620 636f 6e76 6572 7361 7469 6f6e   of conversation
-00002390: 7320 6672 6f6d 2057 696b 6970 6564 6961  s from Wikipedia
-000023a0: 2065 6469 746f 7273 2720 7461 6c6b 2070   editors' talk p
-000023b0: 6167 6573 2e20 200a 4e61 6d65 2066 6f72  ages.  .Name for
-000023c0: 2064 6f77 6e6c 6f61 643a 2060 7769 6b69   download: `wiki
-000023d0: 2d63 6f72 7075 7360 0a0a 2323 2320 5b54  -corpus`..### [T
-000023e0: 656e 6e69 7320 496e 7465 7276 6965 7773  ennis Interviews
-000023f0: 5d28 6874 7470 733a 2f2f 636f 6e76 6f6b  ](https://convok
-00002400: 6974 2e63 6f72 6e65 6c6c 2e65 6475 2f64  it.cornell.edu/d
-00002410: 6f63 756d 656e 7461 7469 6f6e 2f74 656e  ocumentation/ten
-00002420: 6e69 732e 6874 6d6c 290a 0a54 7261 6e73  nis.html)..Trans
-00002430: 6372 6970 7473 2066 6f72 2074 656e 6e69  cripts for tenni
-00002440: 7320 7369 6e67 6c65 7320 706f 7374 2d6d  s singles post-m
-00002450: 6174 6368 2070 7265 7373 2063 6f6e 6665  atch press confe
-00002460: 7265 6e63 6573 2066 6f72 206d 616a 6f72  rences for major
-00002470: 2074 6f75 726e 616d 656e 7473 2062 6574   tournaments bet
-00002480: 7765 656e 2032 3030 3720 746f 2032 3031  ween 2007 to 201
-00002490: 3520 2836 2c34 3637 2070 6f73 742d 6d61  5 (6,467 post-ma
-000024a0: 7463 6820 7072 6573 7320 636f 6e66 6572  tch press confer
-000024b0: 656e 6365 7329 2e20 200a 4e61 6d65 2066  ences).  .Name f
-000024c0: 6f72 2064 6f77 6e6c 6f61 643a 2060 7465  or download: `te
-000024d0: 6e6e 6973 2d63 6f72 7075 7360 0a0a 2323  nnis-corpus`..##
-000024e0: 2320 5b52 6564 6469 7420 436f 7270 7573  # [Reddit Corpus
-000024f0: 5d28 6874 7470 733a 2f2f 636f 6e76 6f6b  ](https://convok
-00002500: 6974 2e63 6f72 6e65 6c6c 2e65 6475 2f64  it.cornell.edu/d
-00002510: 6f63 756d 656e 7461 7469 6f6e 2f73 7562  ocumentation/sub
-00002520: 7265 6464 6974 2e68 746d 6c29 0a0a 5265  reddit.html)..Re
-00002530: 6464 6974 2063 6f6e 7665 7273 6174 696f  ddit conversatio
-00002540: 6e73 2066 726f 6d20 6f76 6572 2039 3030  ns from over 900
-00002550: 6b20 7375 6272 6564 6469 7473 2c20 6172  k subreddits, ar
-00002560: 7261 6e67 6564 2062 7920 7375 6272 6564  ranged by subred
-00002570: 6469 742e 2041 205b 736d 616c 6c20 7375  dit. A [small su
-00002580: 6273 6574 5d28 6874 7470 733a 2f2f 636f  bset](https://co
-00002590: 6e76 6f6b 6974 2e63 6f72 6e65 6c6c 2e65  nvokit.cornell.e
-000025a0: 6475 2f64 6f63 756d 656e 7461 7469 6f6e  du/documentation
-000025b0: 2f72 6564 6469 742d 736d 616c 6c2e 6874  /reddit-small.ht
-000025c0: 6d6c 2920 7361 6d70 6c65 6420 6672 6f6d  ml) sampled from
-000025d0: 2031 3030 2068 6967 686c 7920 6163 7469   100 highly acti
-000025e0: 7665 2073 7562 7265 6464 6974 7320 6973  ve subreddits is
-000025f0: 2061 6c73 6f20 6176 6169 6c61 626c 652e   also available.
-00002600: 200a 200a 4e61 6d65 2066 6f72 2064 6f77   . .Name for dow
-00002610: 6e6c 6f61 643a 2060 7375 6272 6564 6469  nload: `subreddi
-00002620: 742d 3c6e 616d 655f 6f66 5f73 7562 7265  t-<name_of_subre
-00002630: 6464 6974 3e60 2066 6f72 2074 6865 2062  ddit>` for the b
-00002640: 792d 7375 6272 6564 6469 7420 6461 7461  y-subreddit data
-00002650: 2c20 6072 6564 6469 742d 636f 7270 7573  , `reddit-corpus
-00002660: 2d73 6d61 6c6c 6020 666f 7220 7468 6520  -small` for the 
-00002670: 736d 616c 6c20 7375 6273 6574 2e20 0a0a  small subset. ..
-00002680: 2323 2320 5b57 696b 6943 6f6e 7620 436f  ### [WikiConv Co
-00002690: 7270 7573 5d28 6874 7470 733a 2f2f 636f  rpus](https://co
-000026a0: 6e76 6f6b 6974 2e63 6f72 6e65 6c6c 2e65  nvokit.cornell.e
-000026b0: 6475 2f64 6f63 756d 656e 7461 7469 6f6e  du/documentation
-000026c0: 2f77 696b 6963 6f6e 762e 6874 6d6c 290a  /wikiconv.html).
-000026d0: 0a54 6865 2066 756c 6c20 636f 7270 7573  .The full corpus
-000026e0: 206f 6620 5769 6b69 7065 6469 6120 7461   of Wikipedia ta
-000026f0: 6c6b 2070 6167 6520 636f 6e76 6572 7361  lk page conversa
-00002700: 7469 6f6e 732c 2062 6173 6564 206f 6e20  tions, based on 
-00002710: 7468 6520 7265 636f 6e73 7472 7563 7469  the reconstructi
-00002720: 6f6e 2064 6573 6372 6962 6564 2069 6e20  on described in 
-00002730: 5b74 6869 7320 7061 7065 725d 2868 7474  [this paper](htt
-00002740: 703a 2f2f 7777 772e 6373 2e63 6f72 6e65  p://www.cs.corne
-00002750: 6c6c 2e65 6475 2f7e 6372 6973 7469 616e  ll.edu/~cristian
-00002760: 2f69 6e64 6578 5f66 696c 6573 2f77 696b  /index_files/wik
-00002770: 6963 6f6e 762d 636f 6e76 6572 7361 7469  iconv-conversati
-00002780: 6f6e 2d63 6f72 7075 732e 7064 6629 2e0a  on-corpus.pdf)..
-00002790: 4e6f 7465 2074 6861 7420 6475 6520 746f  Note that due to
-000027a0: 2074 6865 206c 6172 6765 2073 697a 6520   the large size 
-000027b0: 6f66 2074 6865 2064 6174 612c 2069 7420  of the data, it 
-000027c0: 6973 2073 706c 6974 2075 7020 6279 2079  is split up by y
-000027d0: 6561 722e 0a57 6520 7365 7061 7261 7465  ear..We separate
-000027e0: 6c79 2070 726f 7669 6465 205b 626c 6f63  ly provide [bloc
-000027f0: 6b20 6461 7461 2072 6574 7269 6576 6564  k data retrieved
-00002800: 2064 6972 6563 746c 7920 6672 6f6d 2074   directly from t
-00002810: 6865 2057 696b 6970 6564 6961 2062 6c6f  he Wikipedia blo
-00002820: 636b 206c 6f67 5d28 6874 7470 733a 2f2f  ck log](https://
-00002830: 7a69 7373 6f75 2e69 6e66 6f73 6369 2e63  zissou.infosci.c
-00002840: 6f72 6e65 6c6c 2e65 6475 2f63 6f6e 766f  ornell.edu/convo
-00002850: 6b69 742f 6461 7461 7365 7473 2f77 696b  kit/datasets/wik
-00002860: 6963 6f6e 762d 636f 7270 7573 2f62 6c6f  iconv-corpus/blo
-00002870: 636b 732e 6a73 6f6e 292c 2066 6f72 2072  cks.json), for r
-00002880: 6570 726f 6475 6369 6e67 2074 6865 205b  eproducing the [
-00002890: 5472 616a 6563 746f 7269 6573 206f 6620  Trajectories of 
-000028a0: 426c 6f63 6b65 6420 436f 6d6d 756e 6974  Blocked Communit
-000028b0: 7920 4d65 6d62 6572 735d 2868 7474 703a  y Members](http:
-000028c0: 2f2f 7777 772e 6373 2e63 6f72 6e65 6c6c  //www.cs.cornell
-000028d0: 2e65 6475 2f7e 6372 6973 7469 616e 2f52  .edu/~cristian/R
-000028e0: 6563 6964 6976 6973 6d5f 6f6e 6c69 6e65  ecidivism_online
-000028f0: 5f66 696c 6573 2f72 6563 6964 6976 6973  _files/recidivis
-00002900: 6d5f 6f6e 6c69 6e65 2e70 6466 2920 7061  m_online.pdf) pa
-00002910: 7065 722e 0a0a 4e61 6d65 2066 6f72 2064  per...Name for d
-00002920: 6f77 6e6c 6f61 643a 2060 7769 6b69 636f  ownload: `wikico
-00002930: 6e76 2d3c 7965 6172 3e60 2074 6f20 646f  nv-<year>` to do
-00002940: 776e 6c6f 6164 2077 696b 6963 6f6e 7620  wnload wikiconv 
-00002950: 6461 7461 2066 6f72 2074 6865 2073 7065  data for the spe
-00002960: 6369 6669 6564 2079 6561 722e 0a0a 2323  cified year...##
-00002970: 2320 5b43 6872 6f6d 6975 6d20 436f 6e76  # [Chromium Conv
-00002980: 6572 7361 7469 6f6e 7320 436f 7270 7573  ersations Corpus
-00002990: 5d28 6874 7470 733a 2f2f 636f 6e76 6f6b  ](https://convok
-000029a0: 6974 2e63 6f72 6e65 6c6c 2e65 6475 2f64  it.cornell.edu/d
-000029b0: 6f63 756d 656e 7461 7469 6f6e 2f63 6872  ocumentation/chr
-000029c0: 6f6d 6975 6d2e 6874 6d6c 290a 0a41 2063  omium.html)..A c
-000029d0: 6f6c 6c65 6374 696f 6e20 6f66 2061 6c6d  ollection of alm
-000029e0: 6f73 7420 312e 3520 6d69 6c6c 696f 6e20  ost 1.5 million 
-000029f0: 636f 6e76 6572 7361 7469 6f6e 7320 616e  conversations an
-00002a00: 6420 322e 3820 6d69 6c6c 696f 6e20 636f  d 2.8 million co
-00002a10: 6d6d 656e 7473 2070 6f73 7465 6420 6279  mments posted by
-00002a20: 2064 6576 656c 6f70 6572 7320 7265 7669   developers revi
-00002a30: 6577 696e 6720 7072 6f70 6f73 6564 2063  ewing proposed c
-00002a40: 6f64 6520 6368 616e 6765 7320 696e 2074  ode changes in t
-00002a50: 6865 2043 6872 6f6d 6975 6d20 7072 6f6a  he Chromium proj
-00002a60: 6563 742e 0a0a 4e61 6d65 2066 6f72 2064  ect...Name for d
-00002a70: 6f77 6e6c 6f61 643a 2060 6368 726f 6d69  ownload: `chromi
-00002a80: 756d 2d63 6f72 7075 7360 0a0a 2323 2320  um-corpus`..### 
-00002a90: 5b57 696e 6e69 6e67 2041 7267 756d 656e  [Winning Argumen
-00002aa0: 7473 2043 6f72 7075 735d 2868 7474 7073  ts Corpus](https
-00002ab0: 3a2f 2f63 6f6e 766f 6b69 742e 636f 726e  ://convokit.corn
-00002ac0: 656c 6c2e 6564 752f 646f 6375 6d65 6e74  ell.edu/document
-00002ad0: 6174 696f 6e2f 7769 6e6e 696e 672e 6874  ation/winning.ht
-00002ae0: 6d6c 290a 0a41 206d 6574 6164 6174 612d  ml)..A metadata-
-00002af0: 7269 6368 2073 7562 7365 7420 6f66 2063  rich subset of c
-00002b00: 6f6e 7665 7273 6174 696f 6e73 206d 6164  onversations mad
-00002b10: 6520 696e 2074 6865 2072 2f43 6861 6e67  e in the r/Chang
-00002b20: 654d 7956 6965 7720 7375 6272 6564 6469  eMyView subreddi
-00002b30: 7420 6265 7477 6565 6e20 3120 4a61 6e20  t between 1 Jan 
-00002b40: 3230 3133 202d 2037 204d 6179 2032 3031  2013 - 7 May 201
-00002b50: 352c 2077 6974 6820 696e 666f 726d 6174  5, with informat
-00002b60: 696f 6e20 6f6e 2074 6865 2064 656c 7461  ion on the delta
-00002b70: 2028 7375 6363 6573 7329 206f 6620 6120   (success) of a 
-00002b80: 7370 6561 6b65 7227 7320 7574 7465 7261  speaker's uttera
-00002b90: 6e63 6520 696e 2063 6f6e 7669 6e63 696e  nce in convincin
-00002ba0: 6720 7468 6520 706f 7374 6572 2e0a 0a4e  g the poster...N
-00002bb0: 616d 6520 666f 7220 646f 776e 6c6f 6164  ame for download
-00002bc0: 3a20 6077 696e 6e69 6e67 2d61 7267 732d  : `winning-args-
-00002bd0: 636f 7270 7573 600a 0a23 2323 205b 436f  corpus`..### [Co
-00002be0: 6172 7365 2044 6973 636f 7572 7365 2043  arse Discourse C
-00002bf0: 6f72 7075 735d 2868 7474 7073 3a2f 2f63  orpus](https://c
-00002c00: 6f6e 766f 6b69 742e 636f 726e 656c 6c2e  onvokit.cornell.
-00002c10: 6564 752f 646f 6375 6d65 6e74 6174 696f  edu/documentatio
-00002c20: 6e2f 636f 6172 7365 4469 7363 6f75 7273  n/coarseDiscours
-00002c30: 652e 6874 6d6c 290a 0a41 2073 7562 7365  e.html)..A subse
-00002c40: 7420 6f66 2052 6564 6469 7420 636f 6e76  t of Reddit conv
-00002c50: 6572 7361 7469 6f6e 7320 7468 6174 2068  ersations that h
-00002c60: 6176 6520 6265 656e 206d 616e 7561 6c6c  ave been manuall
-00002c70: 7920 616e 6e6f 7461 7465 6420 7769 7468  y annotated with
-00002c80: 2064 6973 636f 7572 7365 2061 6374 206c   discourse act l
-00002c90: 6162 656c 732e 0a0a 4e61 6d65 2066 6f72  abels...Name for
-00002ca0: 2064 6f77 6e6c 6f61 643a 2060 7265 6464   download: `redd
-00002cb0: 6974 2d63 6f61 7273 652d 6469 7363 6f75  it-coarse-discou
-00002cc0: 7273 652d 636f 7270 7573 600a 0a23 2323  rse-corpus`..###
-00002cd0: 205b 5065 7273 7561 7369 6f6e 2046 6f72   [Persuasion For
-00002ce0: 2047 6f6f 6420 436f 7270 7573 5d28 6874   Good Corpus](ht
-00002cf0: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
-00002d00: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
-00002d10: 656e 7461 7469 6f6e 2f70 6572 7375 6173  entation/persuas
-00002d20: 696f 6e66 6f72 676f 6f64 2e68 746d 6c29  ionforgood.html)
-00002d30: 0a0a 4120 636f 6c6c 6563 7469 6f6e 206f  ..A collection o
-00002d40: 6620 6f6e 6c69 6e65 2063 6f6e 7665 7273  f online convers
-00002d50: 6174 696f 6e73 2067 656e 6572 6174 6564  ations generated
-00002d60: 2062 7920 416d 617a 6f6e 204d 6563 6861   by Amazon Mecha
-00002d70: 6e69 6361 6c20 5475 726b 2077 6f72 6b65  nical Turk worke
-00002d80: 7273 2c20 7768 6572 6520 6f6e 6520 7061  rs, where one pa
-00002d90: 7274 6963 6970 616e 7420 2874 6865 202a  rticipant (the *
-00002da0: 7065 7273 7561 6465 722a 2920 7472 6965  persuader*) trie
-00002db0: 7320 746f 2063 6f6e 7669 6e63 6520 7468  s to convince th
-00002dc0: 6520 6f74 6865 7220 2874 6865 202a 7065  e other (the *pe
-00002dd0: 7273 7561 6465 652a 2920 746f 2064 6f6e  rsuadee*) to don
-00002de0: 6174 6520 746f 2061 2063 6861 7269 7479  ate to a charity
-00002df0: 2e0a 0a4e 616d 6520 666f 7220 646f 776e  ...Name for down
-00002e00: 6c6f 6164 3a20 6070 6572 7375 6173 696f  load: `persuasio
-00002e10: 6e66 6f72 676f 6f64 2d63 6f72 7075 7360  nforgood-corpus`
-00002e20: 0a0a 2323 2320 5b49 6e74 656c 6c69 6765  ..### [Intellige
-00002e30: 6e63 6520 5371 7561 7265 6420 4465 6261  nce Squared Deba
-00002e40: 7465 7320 436f 7270 7573 5d28 6874 7470  tes Corpus](http
-00002e50: 733a 2f2f 636f 6e76 6f6b 6974 2e63 6f72  s://convokit.cor
-00002e60: 6e65 6c6c 2e65 6475 2f64 6f63 756d 656e  nell.edu/documen
-00002e70: 7461 7469 6f6e 2f69 7132 2e68 746d 6c29  tation/iq2.html)
-00002e80: 0a0a 5472 616e 7363 7269 7074 7320 6f66  ..Transcripts of
-00002e90: 2064 6562 6174 6573 2068 656c 6420 6173   debates held as
-00002ea0: 2070 6172 7420 6f66 2049 6e74 656c 6c69   part of Intelli
-00002eb0: 6765 6e63 6520 5371 7561 7265 6420 4465  gence Squared De
-00002ec0: 6261 7465 732e 0a0a 4e61 6d65 2066 6f72  bates...Name for
-00002ed0: 2064 6f77 6e6c 6f61 643a 2060 6971 322d   download: `iq2-
-00002ee0: 636f 7270 7573 600a 0a23 2323 205b 4672  corpus`..### [Fr
-00002ef0: 6965 6e64 7320 436f 7270 7573 5d28 6874  iends Corpus](ht
-00002f00: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
-00002f10: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
-00002f20: 656e 7461 7469 6f6e 2f66 7269 656e 6473  entation/friends
-00002f30: 2e68 746d 6c29 0a0a 4120 636f 6c6c 6563  .html)..A collec
-00002f40: 7469 6f6e 206f 6620 616c 6c20 7468 6520  tion of all the 
-00002f50: 636f 6e76 6572 7361 7469 6f6e 7320 7468  conversations th
-00002f60: 6174 206f 6363 7572 7265 6420 6f76 6572  at occurred over
-00002f70: 2031 3020 7365 6173 6f6e 7320 6f66 2046   10 seasons of F
-00002f80: 7269 656e 6473 2c20 6120 706f 7075 6c61  riends, a popula
-00002f90: 7220 416d 6572 6963 616e 2054 5620 7369  r American TV si
-00002fa0: 7463 6f6d 2074 6861 7420 7261 6e20 696e  tcom that ran in
-00002fb0: 2074 6865 2031 3939 3073 2e0a 0a4e 616d   the 1990s...Nam
-00002fc0: 6520 666f 7220 646f 776e 6c6f 6164 3a20  e for download: 
-00002fd0: 6066 7269 656e 6473 2d63 6f72 7075 7360  `friends-corpus`
-00002fe0: 0a0a 2323 2320 5b53 7769 7463 6862 6f61  ..### [Switchboa
-00002ff0: 7264 2044 6961 6c6f 6720 4163 7420 436f  rd Dialog Act Co
-00003000: 7270 7573 5d28 6874 7470 733a 2f2f 636f  rpus](https://co
-00003010: 6e76 6f6b 6974 2e63 6f72 6e65 6c6c 2e65  nvokit.cornell.e
-00003020: 6475 2f64 6f63 756d 656e 7461 7469 6f6e  du/documentation
-00003030: 2f73 7769 7463 6862 6f61 7264 2e68 746d  /switchboard.htm
-00003040: 6c29 0a0a 4120 636f 6c6c 6563 7469 6f6e  l)..A collection
-00003050: 206f 6620 312c 3135 3520 6669 7665 2d6d   of 1,155 five-m
-00003060: 696e 7574 6520 7465 6c65 7068 6f6e 6520  inute telephone 
-00003070: 636f 6e76 6572 7361 7469 6f6e 7320 6265  conversations be
-00003080: 7477 6565 6e20 7477 6f20 7061 7274 6963  tween two partic
-00003090: 6970 616e 7473 2c20 616e 6e6f 7461 7465  ipants, annotate
-000030a0: 6420 7769 7468 2073 7065 6563 6820 6163  d with speech ac
-000030b0: 7420 7461 6773 2e0a 0a4e 616d 6520 666f  t tags...Name fo
-000030c0: 7220 646f 776e 6c6f 6164 3a20 6073 7769  r download: `swi
-000030d0: 7463 6862 6f61 7264 2d63 6f72 7075 7360  tchboard-corpus`
-000030e0: 0a0a 2323 2320 5374 616e 666f 7264 2050  ..### Stanford P
-000030f0: 6f6c 6974 656e 6573 7320 436f 7270 7573  oliteness Corpus
-00003100: 2028 5b57 696b 6970 6564 6961 5d28 6874   ([Wikipedia](ht
-00003110: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
-00003120: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
-00003130: 656e 7461 7469 6f6e 2f77 696b 695f 706f  entation/wiki_po
-00003140: 6c69 7465 6e65 7373 2e68 746d 6c29 2f5b  liteness.html)/[
-00003150: 5374 6163 6b20 4578 6368 616e 6765 5d28  Stack Exchange](
-00003160: 6874 7470 733a 2f2f 636f 6e76 6f6b 6974  https://convokit
-00003170: 2e63 6f72 6e65 6c6c 2e65 6475 2f64 6f63  .cornell.edu/doc
-00003180: 756d 656e 7461 7469 6f6e 2f73 7461 636b  umentation/stack
-00003190: 5f70 6f6c 6974 656e 6573 732e 6874 6d6c  _politeness.html
-000031a0: 2929 0a0a 5477 6f20 636f 6c6c 6563 7469  ))..Two collecti
-000031b0: 6f6e 7320 6f66 2072 6571 7565 7374 7320  ons of requests 
-000031c0: 2866 726f 6d20 5769 6b69 7065 6469 6120  (from Wikipedia 
-000031d0: 616e 6420 5374 6163 6b20 4578 6368 616e  and Stack Exchan
-000031e0: 6765 2072 6573 7065 6374 6976 656c 7929  ge respectively)
-000031f0: 2077 6974 6820 706f 6c69 7465 6e65 7373   with politeness
-00003200: 2061 6e6e 6f74 6174 696f 6e73 2e20 4e61   annotations. Na
-00003210: 6d65 2066 6f72 2064 6f77 6e6c 6f61 643a  me for download:
-00003220: 2060 7769 6b69 7065 6469 612d 706f 6c69   `wikipedia-poli
-00003230: 7465 6e65 7373 2d63 6f72 7075 7360 2028  teness-corpus` (
-00003240: 5769 6b69 7065 6469 6120 706f 7274 696f  Wikipedia portio
-00003250: 6e29 2c20 6073 7461 636b 2d65 7863 6861  n), `stack-excha
-00003260: 6e67 652d 706f 6c69 7465 6e65 7373 2d63  nge-politeness-c
-00003270: 6f72 7075 7360 2028 5374 6163 6b20 4578  orpus` (Stack Ex
-00003280: 6368 616e 6765 2070 6f72 7469 6f6e 292e  change portion).
-00003290: 0a0a 2323 2320 5b44 6563 6570 7469 6f6e  ..### [Deception
-000032a0: 2069 6e20 4469 706c 6f6d 6163 7920 436f   in Diplomacy Co
-000032b0: 6e76 6572 7361 7469 6f6e 735d 2868 7474  nversations](htt
-000032c0: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
-000032d0: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
-000032e0: 6e74 6174 696f 6e2f 6469 706c 6f6d 6163  ntation/diplomac
-000032f0: 792e 6874 6d6c 290a 0a43 6f6e 7665 7273  y.html)..Convers
-00003300: 6174 696f 6e61 6c20 6461 7461 7365 7420  ational dataset 
-00003310: 7769 7468 2069 6e74 656e 6465 6420 616e  with intended an
-00003320: 6420 7065 7263 6569 7665 6420 6465 6365  d perceived dece
-00003330: 7074 696f 6e20 6c61 6265 6c73 2e20 4f76  ption labels. Ov
-00003340: 6572 2031 372c 3030 3020 6d65 7373 6167  er 17,000 messag
-00003350: 6573 2061 6e6e 6f74 6174 6564 2062 7920  es annotated by 
-00003360: 7468 6520 7365 6e64 6572 2066 6f72 2074  the sender for t
-00003370: 6865 6972 2069 6e74 656e 6465 6420 7472  heir intended tr
-00003380: 7574 6866 756c 6e65 7373 2061 6e64 2062  uthfulness and b
-00003390: 7920 7468 6520 7265 6365 6976 6572 2066  y the receiver f
-000033a0: 6f72 2074 6865 6972 2070 6572 6365 6976  or their perceiv
-000033b0: 6564 2074 7275 7468 6675 6c6e 6573 732e  ed truthfulness.
-000033c0: 0a0a 4e61 6d65 2066 6f72 2064 6f77 6e6c  ..Name for downl
-000033d0: 6f61 643a 2060 6469 706c 6f6d 6163 792d  oad: `diplomacy-
-000033e0: 636f 7270 7573 600a 0a23 2323 205b 4772  corpus`..### [Gr
-000033f0: 6f75 7020 4166 6665 6374 2061 6e64 2050  oup Affect and P
-00003400: 6572 666f 726d 616e 6365 2028 4741 5029  erformance (GAP)
-00003410: 2043 6f72 7075 735d 2868 7474 7073 3a2f   Corpus](https:/
-00003420: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
-00003430: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
-00003440: 696f 6e2f 6761 702e 6874 6d6c 290a 0a41  ion/gap.html)..A
-00003450: 2063 6f6e 7665 7273 6174 696f 6e61 6c20   conversational 
-00003460: 6461 7461 7365 7420 636f 6d70 7269 7369  dataset comprisi
-00003470: 6e67 2067 726f 7570 206d 6565 7469 6e67  ng group meeting
-00003480: 7320 6f66 2074 776f 2074 6f20 666f 7572  s of two to four
-00003490: 2070 6172 7469 6369 7061 6e74 7320 7468   participants th
-000034a0: 6174 2064 656c 6962 6572 6174 6520 696e  at deliberate in
-000034b0: 2061 2067 726f 7570 2064 6563 6973 696f   a group decisio
-000034c0: 6e2d 6d61 6b69 6e67 2065 7865 7263 6973  n-making exercis
-000034d0: 652e 2054 6869 7320 6461 7461 7365 7420  e. This dataset 
-000034e0: 636f 6e74 6169 6e73 2032 3820 6772 6f75  contains 28 grou
-000034f0: 7020 6d65 6574 696e 6773 2077 6974 6820  p meetings with 
-00003500: 6120 746f 7461 6c20 6f66 2038 3420 7061  a total of 84 pa
-00003510: 7274 6963 6970 616e 7473 2e0a 0a4e 616d  rticipants...Nam
-00003520: 6520 666f 7220 646f 776e 6c6f 6164 3a20  e for download: 
-00003530: 6067 6170 2d63 6f72 7075 7360 0a0a 2323  `gap-corpus`..##
-00003540: 2320 5b57 696b 6970 6564 6961 2041 7274  # [Wikipedia Art
-00003550: 6963 6c65 7320 666f 7220 4465 6c65 7469  icles for Deleti
-00003560: 6f6e 2043 6f72 7075 735d 2868 7474 7073  on Corpus](https
-00003570: 3a2f 2f63 6f6e 766f 6b69 742e 636f 726e  ://convokit.corn
-00003580: 656c 6c2e 6564 752f 646f 6375 6d65 6e74  ell.edu/document
-00003590: 6174 696f 6e2f 7769 6b69 2d61 7274 6963  ation/wiki-artic
-000035a0: 6c65 732d 666f 722d 6465 6c65 7469 6f6e  les-for-deletion
-000035b0: 2d63 6f72 7075 732e 6874 6d6c 290a 0a41  -corpus.html)..A
-000035c0: 2063 6f6c 6c65 6374 696f 6e20 6f66 2057   collection of W
-000035d0: 696b 6970 6564 6961 2773 2041 7274 6963  ikipedia's Artic
-000035e0: 6c65 7320 666f 7220 4465 6c65 7469 6f6e  les for Deletion
-000035f0: 2065 6469 746f 7220 6465 6261 7465 7320   editor debates 
-00003600: 7468 6174 206f 6363 7572 7265 6420 6265  that occurred be
-00003610: 7477 6565 6e20 4a61 6e75 6172 7920 312c  tween January 1,
-00003620: 2032 3030 3520 616e 6420 4465 6365 6d62   2005 and Decemb
-00003630: 6572 2033 312c 2032 3031 382e 2054 6869  er 31, 2018. Thi
-00003640: 7320 636f 7270 7573 2063 6f6e 7461 696e  s corpus contain
-00003650: 7320 6162 6f75 7420 332c 3230 302c 3030  s about 3,200,00
-00003660: 3020 636f 6e74 7269 6275 7469 6f6e 7320  0 contributions 
-00003670: 6279 2061 7070 726f 7869 6d61 7465 6c79  by approximately
-00003680: 2031 3530 2c30 3030 2057 696b 6970 6564   150,000 Wikiped
-00003690: 6961 2065 6469 746f 7273 2061 6372 6f73  ia editors acros
-000036a0: 7320 616c 6d6f 7374 2034 3030 2c30 3030  s almost 400,000
-000036b0: 2064 6562 6174 6573 2e0a 0a4e 616d 6520   debates...Name 
-000036c0: 666f 7220 646f 776e 6c6f 6164 3a20 6077  for download: `w
-000036d0: 696b 692d 6172 7469 636c 6573 2d66 6f72  iki-articles-for
-000036e0: 2d64 656c 6574 696f 6e2d 636f 7270 7573  -deletion-corpus
-000036f0: 600a 0a23 2323 205b 4361 5369 4e6f 2043  `..### [CaSiNo C
-00003700: 6f72 7075 735d 2868 7474 7073 3a2f 2f63  orpus](https://c
-00003710: 6f6e 766f 6b69 742e 636f 726e 656c 6c2e  onvokit.cornell.
-00003720: 6564 752f 646f 6375 6d65 6e74 6174 696f  edu/documentatio
-00003730: 6e2f 6361 7369 6e6f 2d63 6f72 7075 732e  n/casino-corpus.
-00003740: 6874 6d6c 290a 4361 5369 4e6f 2028 7374  html).CaSiNo (st
-00003750: 616e 6473 2066 6f72 2043 616d 7053 6974  ands for CampSit
-00003760: 6520 4e65 676f 7469 6174 696f 6e73 2920  e Negotiations) 
-00003770: 6973 2061 206e 6f76 656c 2064 6174 6173  is a novel datas
-00003780: 6574 206f 6620 3130 3330 206e 6567 6f74  et of 1030 negot
-00003790: 6961 7469 6f6e 2064 6961 6c6f 6775 6573  iation dialogues
-000037a0: 2e20 5477 6f20 7061 7274 6963 6970 616e  . Two participan
-000037b0: 7473 2074 616b 6520 7468 6520 726f 6c65  ts take the role
-000037c0: 206f 6620 6361 6d70 7369 7465 206e 6569   of campsite nei
-000037d0: 6768 626f 7273 2061 6e64 206e 6567 6f74  ghbors and negot
-000037e0: 6961 7465 2066 6f72 2046 6f6f 642c 2057  iate for Food, W
-000037f0: 6174 6572 2c20 616e 6420 4669 7265 776f  ater, and Firewo
-00003800: 6f64 2070 6163 6b61 6765 732c 2062 6173  od packages, bas
-00003810: 6564 206f 6e20 7468 6569 7220 696e 6469  ed on their indi
-00003820: 7669 6475 616c 2070 7265 6665 7265 6e63  vidual preferenc
-00003830: 6573 2061 6e64 2072 6571 7569 7265 6d65  es and requireme
-00003840: 6e74 732e 0a0a 4e61 6d65 2066 6f72 2064  nts...Name for d
-00003850: 6f77 6e6c 6f61 643a 2060 6361 7369 6e6f  ownload: `casino
-00003860: 2d63 6f72 7075 7360 0a0a 2323 2320 2e2e  -corpus`..### ..
-00003870: 2e41 6e64 2079 6f75 7220 6f77 6e20 636f  .And your own co
-00003880: 7270 7573 210a 0a49 6e20 6164 6469 7469  rpus!..In additi
-00003890: 6f6e 2074 6f20 7468 6520 7072 6f76 6964  on to the provid
-000038a0: 6564 2064 6174 6173 6574 732c 2079 6f75  ed datasets, you
-000038b0: 206d 6179 2061 6c73 6f20 7573 6520 436f   may also use Co
-000038c0: 6e76 6f4b 6974 2077 6974 6820 796f 7572  nvoKit with your
-000038d0: 206f 776e 2063 7573 746f 6d20 6461 7461   own custom data
-000038e0: 7365 7473 2062 7920 6c6f 6164 696e 6720  sets by loading 
-000038f0: 7468 656d 2069 6e74 6f20 6120 6063 6f6e  them into a `con
-00003900: 766f 6b69 742e 436f 7270 7573 6020 6f62  vokit.Corpus` ob
-00003910: 6a65 6374 2e20 5b54 6869 7320 6578 616d  ject. [This exam
-00003920: 706c 6520 7363 7269 7074 5d28 6874 7470  ple script](http
-00003930: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
-00003940: 6f72 6e65 6c6c 4e4c 502f 436f 726e 656c  ornellNLP/Cornel
-00003950: 6c2d 436f 6e76 6572 7361 7469 6f6e 616c  l-Conversational
-00003960: 2d41 6e61 6c79 7369 732d 546f 6f6c 6b69  -Analysis-Toolki
-00003970: 742f 626c 6f62 2f6d 6173 7465 722f 6578  t/blob/master/ex
-00003980: 616d 706c 6573 2f63 6f6e 7665 7274 696e  amples/convertin
-00003990: 675f 6d6f 7669 655f 636f 7270 7573 2e69  g_movie_corpus.i
-000039a0: 7079 6e62 2920 7368 6f77 7320 686f 7720  pynb) shows how 
-000039b0: 746f 2063 6f6e 7374 7275 6374 2061 2043  to construct a C
-000039c0: 6f72 7075 7320 6672 6f6d 2063 7573 746f  orpus from custo
-000039d0: 6d20 6461 7461 2e0a 0a23 2320 496e 7374  m data...## Inst
-000039e0: 616c 6c61 7469 6f6e 0a54 6869 7320 746f  allation.This to
-000039f0: 6f6c 6b69 7420 7265 7175 6972 6573 2050  olkit requires P
-00003a00: 7974 686f 6e20 3e3d 2033 2e36 2e0a 0a31  ython >= 3.6...1
-00003a10: 2e20 446f 776e 6c6f 6164 2074 6865 2074  . Download the t
-00003a20: 6f6f 6c6b 6974 3a20 6070 6970 3320 696e  oolkit: `pip3 in
-00003a30: 7374 616c 6c20 636f 6e76 6f6b 6974 600a  stall convokit`.
-00003a40: 322e 2044 6f77 6e6c 6f61 6420 5370 6163  2. Download Spac
-00003a50: 7927 7320 456e 676c 6973 6820 6d6f 6465  y's English mode
-00003a60: 6c3a 2060 7079 7468 6f6e 3320 2d6d 2073  l: `python3 -m s
-00003a70: 7061 6379 2064 6f77 6e6c 6f61 6420 656e  pacy download en
-00003a80: 600a 332e 2044 6f77 6e6c 6f61 6420 4e4c  `.3. Download NL
-00003a90: 544b 2773 2027 7075 6e6b 7427 206d 6f64  TK's 'punkt' mod
-00003aa0: 656c 3a20 6069 6d70 6f72 7420 6e6c 746b  el: `import nltk
-00003ab0: 3b20 6e6c 746b 2e64 6f77 6e6c 6f61 6428  ; nltk.download(
-00003ac0: 2770 756e 6b74 2729 6020 2869 6e20 5079  'punkt')` (in Py
-00003ad0: 7468 6f6e 2069 6e74 6572 7072 6574 6572  thon interpreter
-00003ae0: 290a 0a41 6c74 6572 6e61 7469 7665 6c79  )..Alternatively
-00003af0: 2c20 7669 7369 7420 6f75 7220 5b47 6974  , visit our [Git
-00003b00: 6875 6220 5061 6765 5d28 6874 7470 733a  hub Page](https:
-00003b10: 2f2f 6769 7468 7562 2e63 6f6d 2f43 6f72  //github.com/Cor
-00003b20: 6e65 6c6c 4e4c 502f 436f 726e 656c 6c2d  nellNLP/Cornell-
-00003b30: 436f 6e76 6572 7361 7469 6f6e 616c 2d41  Conversational-A
-00003b40: 6e61 6c79 7369 732d 546f 6f6c 6b69 7429  nalysis-Toolkit)
-00003b50: 2074 6f20 696e 7374 616c 6c20 6672 6f6d   to install from
-00003b60: 2073 6f75 7263 652e 200a 0a2a 2a49 6620   source. ..**If 
-00003b70: 796f 7520 656e 636f 756e 7465 7220 6469  you encounter di
-00003b80: 6666 6963 756c 7469 6573 2077 6974 6820  fficulties with 
-00003b90: 696e 7374 616c 6c61 7469 6f6e 2a2a 2c20  installation**, 
-00003ba0: 6368 6563 6b20 6f75 7420 6f75 7220 2a2a  check out our **
-00003bb0: 5b54 726f 7562 6c65 7368 6f6f 7469 6e67  [Troubleshooting
-00003bc0: 2047 7569 6465 5d28 6874 7470 733a 2f2f   Guide](https://
-00003bd0: 636f 6e76 6f6b 6974 2e63 6f72 6e65 6c6c  convokit.cornell
-00003be0: 2e65 6475 2f64 6f63 756d 656e 7461 7469  .edu/documentati
-00003bf0: 6f6e 2f74 726f 7562 6c65 7368 6f6f 7469  on/troubleshooti
-00003c00: 6e67 2e68 746d 6c29 2a2a 2066 6f72 2061  ng.html)** for a
-00003c10: 206c 6973 7420 6f66 2073 6f6c 7574 696f   list of solutio
-00003c20: 6e73 2074 6f20 636f 6d6d 6f6e 2069 7373  ns to common iss
-00003c30: 7565 732e 0a0a 2323 2044 6f63 756d 656e  ues...## Documen
-00003c40: 7461 7469 6f6e 0a44 6f63 756d 656e 7461  tation.Documenta
-00003c50: 7469 6f6e 2069 7320 686f 7374 6564 205b  tion is hosted [
-00003c60: 6865 7265 5d28 6874 7470 733a 2f2f 636f  here](https://co
-00003c70: 6e76 6f6b 6974 2e63 6f72 6e65 6c6c 2e65  nvokit.cornell.e
-00003c80: 6475 2f64 6f63 756d 656e 7461 7469 6f6e  du/documentation
-00003c90: 2f29 2e20 4966 2079 6f75 2061 7265 206e  /). If you are n
-00003ca0: 6577 2074 6f20 436f 6e76 6f4b 6974 2c20  ew to ConvoKit, 
-00003cb0: 6772 6561 7420 706c 6163 6573 2074 6f20  great places to 
-00003cc0: 6765 7420 7374 6172 7465 6420 6172 6520  get started are 
-00003cd0: 7468 6520 5b43 6f72 6520 436f 6e63 6570  the [Core Concep
-00003ce0: 7473 2074 7574 6f72 6961 6c5d 2868 7474  ts tutorial](htt
-00003cf0: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
-00003d00: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
-00003d10: 6e74 6174 696f 6e2f 6172 6368 6974 6563  ntation/architec
-00003d20: 7475 7265 2e68 746d 6c29 2066 6f72 2061  ture.html) for a
-00003d30: 6e20 6f76 6572 7669 6577 206f 6620 7468  n overview of th
-00003d40: 6520 436f 6e76 6f4b 6974 2022 7068 696c  e ConvoKit "phil
-00003d50: 6f73 6f70 6879 2220 616e 6420 6f62 6a65  osophy" and obje
-00003d60: 6374 206d 6f64 656c 2c20 616e 6420 7468  ct model, and th
-00003d70: 6520 5b48 6967 682d 6c65 7665 6c20 7475  e [High-level tu
-00003d80: 746f 7269 616c 5d28 6874 7470 733a 2f2f  torial](https://
-00003d90: 636f 6e76 6f6b 6974 2e63 6f72 6e65 6c6c  convokit.cornell
-00003da0: 2e65 6475 2f64 6f63 756d 656e 7461 7469  .edu/documentati
-00003db0: 6f6e 2f74 7574 6f72 6961 6c2e 6874 6d6c  on/tutorial.html
-00003dc0: 2920 666f 7220 6120 7761 6c6b 7468 726f  ) for a walkthro
-00003dd0: 7567 6820 6f66 2068 6f77 2074 6f20 696d  ugh of how to im
-00003de0: 706f 7274 2043 6f6e 766f 4b69 7420 696e  port ConvoKit in
-00003df0: 746f 2079 6f75 7220 7072 6f6a 6563 742c  to your project,
-00003e00: 206c 6f61 6420 6120 436f 7270 7573 2c20   load a Corpus, 
-00003e10: 616e 6420 7573 6520 436f 6e76 6f4b 6974  and use ConvoKit
-00003e20: 2066 756e 6374 696f 6e73 2e0a 0a46 6f72   functions...For
-00003e30: 2061 6e20 6f76 6572 7669 6577 2c20 7761   an overview, wa
-00003e40: 7463 6820 6f75 7220 5349 4744 4941 4c20  tch our SIGDIAL 
-00003e50: 7461 6c6b 2069 6e74 726f 6475 6369 6e67  talk introducing
-00003e60: 2074 6865 2074 6f6f 6c6b 6974 3a0a 5b21   the toolkit:.[!
-00003e70: 5b53 4947 4449 414c 2032 3032 303a 2049  [SIGDIAL 2020: I
-00003e80: 6e74 726f 6475 6369 6e67 2043 6f6e 766f  ntroducing Convo
-00003e90: 4b69 745d 2868 7474 703a 2f2f 6933 2e79  Kit](http://i3.y
-00003ea0: 7469 6d67 2e63 6f6d 2f76 692f 6e6f 667a  timg.com/vi/nofz
-00003eb0: 7978 4d34 6831 6b2f 6871 6465 6661 756c  yxM4h1k/hqdefaul
-00003ec0: 742e 6a70 6729 5d28 6874 7470 733a 2f2f  t.jpg)](https://
-00003ed0: 796f 7574 752e 6265 2f6e 6f66 7a79 784d  youtu.be/nofzyxM
-00003ee0: 3468 316b 2022 5349 4744 4941 4c20 3230  4h1k "SIGDIAL 20
-00003ef0: 3230 3a20 496e 7472 6f64 7563 696e 6720  20: Introducing 
-00003f00: 436f 6e76 6f4b 6974 2229 0a0a 2323 2043  ConvoKit")..## C
-00003f10: 6f6e 7472 6962 7574 696e 670a 0a57 6520  ontributing..We 
-00003f20: 7765 6c63 6f6d 6520 636f 6d6d 756e 6974  welcome communit
-00003f30: 7920 636f 6e74 7269 6275 7469 6f6e 732e  y contributions.
-00003f40: 2054 6f20 7365 6520 686f 7720 796f 7520   To see how you 
-00003f50: 6361 6e20 6865 6c70 206f 7574 2c20 6368  can help out, ch
-00003f60: 6563 6b20 7468 6520 5b63 6f6e 7472 6962  eck the [contrib
-00003f70: 7574 696f 6e20 6775 6964 656c 696e 6573  ution guidelines
-00003f80: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
-00003f90: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
-00003fa0: 436f 726e 656c 6c2d 436f 6e76 6572 7361  Cornell-Conversa
-00003fb0: 7469 6f6e 616c 2d41 6e61 6c79 7369 732d  tional-Analysis-
-00003fc0: 546f 6f6c 6b69 742f 626c 6f62 2f6d 6173  Toolkit/blob/mas
-00003fd0: 7465 722f 434f 4e54 5249 4255 5449 4e47  ter/CONTRIBUTING
-00003fe0: 2e6d 6429 2e0a 0a23 2320 4369 7469 6e67  .md)...## Citing
-00003ff0: 0a0a 4966 2079 6f75 2075 7365 2074 6865  ..If you use the
-00004000: 2063 6f64 6520 6f72 2064 6174 6173 6574   code or dataset
-00004010: 7320 6469 7374 7269 6275 7465 6420 7769  s distributed wi
-00004020: 7468 2043 6f6e 766f 4b69 7420 706c 6561  th ConvoKit plea
-00004030: 7365 2061 636b 6e6f 776c 6564 6765 2074  se acknowledge t
-00004040: 6865 2077 6f72 6b20 7469 6564 2074 6f20  he work tied to 
-00004050: 7468 6520 7265 7370 6563 7469 7665 2063  the respective c
-00004060: 6f6d 706f 6e65 6e74 2028 696e 6469 6361  omponent (indica
-00004070: 7465 6420 696e 2074 6865 2064 6f63 756d  ted in the docum
-00004080: 656e 7461 7469 6f6e 2920 696e 2061 6464  entation) in add
-00004090: 6974 696f 6e20 746f 3a0a 0a4a 6f6e 6174  ition to:..Jonat
-000040a0: 6861 6e20 502e 2043 6861 6e67 2c20 4361  han P. Chang, Ca
-000040b0: 6c65 6220 4368 6961 6d2c 204c 6979 6520  leb Chiam, Liye 
-000040c0: 4675 2c20 416e 6472 6577 2057 616e 672c  Fu, Andrew Wang,
-000040d0: 204a 7573 7469 6e65 205a 6861 6e67 2c20   Justine Zhang, 
-000040e0: 4372 6973 7469 616e 2044 616e 6573 6375  Cristian Danescu
-000040f0: 2d4e 6963 756c 6573 6375 2d4d 697a 696c  -Niculescu-Mizil
-00004100: 2e20 3230 3230 2e20 225b 436f 6e76 6f4b  . 2020. "[ConvoK
-00004110: 6974 3a20 4120 546f 6f6c 6b69 7420 666f  it: A Toolkit fo
-00004120: 7220 7468 6520 416e 616c 7973 6973 206f  r the Analysis o
-00004130: 6620 436f 6e76 6572 7361 7469 6f6e 735d  f Conversations]
-00004140: 2868 7474 7073 3a2f 2f77 7777 2e63 732e  (https://www.cs.
-00004150: 636f 726e 656c 6c2e 6564 752f 7e63 7269  cornell.edu/~cri
-00004160: 7374 6961 6e2f 436f 6e76 6f4b 6974 5f44  stian/ConvoKit_D
-00004170: 656d 6f5f 5061 7065 725f 6669 6c65 732f  emo_Paper_files/
-00004180: 636f 6e76 6f6b 6974 2d64 656d 6f2d 7061  convokit-demo-pa
-00004190: 7065 722e 7064 6629 222e 2050 726f 6365  per.pdf)". Proce
-000041a0: 6564 696e 6773 206f 6620 5349 4744 4941  edings of SIGDIA
-000041b0: 4c2e 0a0a 5b43 6f6e 766f 4b69 745d 2868  L...[ConvoKit](h
-000041c0: 7474 703a 2f2f 636f 6e76 6f6b 6974 2e63  ttp://convokit.c
-000041d0: 6f72 6e65 6c6c 2e65 6475 2f29 0a0a 2323  ornell.edu/)..##
-000041e0: 2043 6f6e 7472 6962 7574 6f72 7320 e29c   Contributors ..
-000041f0: a80a 0a54 6861 6e6b 7320 676f 6573 2074  ...Thanks goes t
-00004200: 6f20 7468 6573 6520 776f 6e64 6572 6675  o these wonderfu
-00004210: 6c20 7065 6f70 6c65 2028 5b65 6d6f 6a69  l people ([emoji
-00004220: 206b 6579 5d28 6874 7470 733a 2f2f 616c   key](https://al
-00004230: 6c63 6f6e 7472 6962 7574 6f72 732e 6f72  lcontributors.or
-00004240: 672f 646f 6373 2f65 6e2f 656d 6f6a 692d  g/docs/en/emoji-
-00004250: 6b65 7929 293a 0a0a 3c21 2d2d 2041 4c4c  key)):..<!-- ALL
-00004260: 2d43 4f4e 5452 4942 5554 4f52 532d 4c49  -CONTRIBUTORS-LI
-00004270: 5354 3a53 5441 5254 202d 2044 6f20 6e6f  ST:START - Do no
-00004280: 7420 7265 6d6f 7665 206f 7220 6d6f 6469  t remove or modi
-00004290: 6679 2074 6869 7320 7365 6374 696f 6e20  fy this section 
-000042a0: 2d2d 3e0a 3c21 2d2d 2070 7265 7474 6965  -->.<!-- prettie
-000042b0: 722d 6967 6e6f 7265 2d73 7461 7274 202d  r-ignore-start -
-000042c0: 2d3e 0a3c 212d 2d20 6d61 726b 646f 776e  ->.<!-- markdown
-000042d0: 6c69 6e74 2d64 6973 6162 6c65 202d 2d3e  lint-disable -->
-000042e0: 0a3c 7461 626c 653e 0a20 203c 7472 3e0a  .<table>.  <tr>.
-000042f0: 2020 2020 3c74 6420 616c 6967 6e3d 2263      <td align="c
-00004300: 656e 7465 7222 3e3c 6120 6872 6566 3d22  enter"><a href="
-00004310: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-00004320: 6f6d 2f72 6761 6e67 656c 6139 3922 3e3c  om/rgangela99"><
-00004330: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
-00004340: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
-00004350: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
-00004360: 2f33 3537 3338 3133 323f 763d 343f 733d  /35738132?v=4?s=
-00004370: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
-00004380: 783b 2220 616c 743d 2222 2f3e 3c62 7220  x;" alt=""/><br 
-00004390: 2f3e 3c73 7562 3e3c 623e 7267 616e 6765  /><sub><b>rgange
-000043a0: 6c61 3939 3c2f 623e 3c2f 7375 623e 3c2f  la99</b></sub></
-000043b0: 613e 3c62 7220 2f3e 3c61 2068 7265 663d  a><br /><a href=
-000043c0: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
-000043d0: 636f 6d2f 436f 726e 656c 6c4e 4c50 2f43  com/CornellNLP/C
-000043e0: 6f72 6e65 6c6c 2d43 6f6e 7665 7273 6174  ornell-Conversat
-000043f0: 696f 6e61 6c2d 416e 616c 7973 6973 2d54  ional-Analysis-T
-00004400: 6f6f 6c6b 6974 2f63 6f6d 6d69 7473 3f61  oolkit/commits?a
-00004410: 7574 686f 723d 7267 616e 6765 6c61 3939  uthor=rgangela99
-00004420: 2220 7469 746c 653d 2243 6f64 6522 3ef0  " title="Code">.
-00004430: 9f92 bb3c 2f61 3e3c 2f74 643e 0a20 2020  ...</a></td>.   
-00004440: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
-00004450: 6572 223e 3c61 2068 7265 663d 2268 7474  er"><a href="htt
-00004460: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00004470: 4b68 6f6e 7a6f 6461 223e 3c69 6d67 2073  Khonzoda"><img s
-00004480: 7263 3d22 6874 7470 733a 2f2f 6176 6174  rc="https://avat
-00004490: 6172 732e 6769 7468 7562 7573 6572 636f  ars.githubuserco
-000044a0: 6e74 656e 742e 636f 6d2f 752f 3236 3037  ntent.com/u/2607
-000044b0: 3237 3732 3f76 3d34 3f73 3d31 3030 2220  2772?v=4?s=100" 
-000044c0: 7769 6474 683d 2231 3030 7078 3b22 2061  width="100px;" a
-000044d0: 6c74 3d22 222f 3e3c 6272 202f 3e3c 7375  lt=""/><br /><su
-000044e0: 623e 3c62 3e4b 686f 6e7a 6f64 6120 556d  b><b>Khonzoda Um
-000044f0: 6172 6f76 613c 2f62 3e3c 2f73 7562 3e3c  arova</b></sub><
-00004500: 2f61 3e3c 6272 202f 3e3c 6120 6872 6566  /a><br /><a href
-00004510: 3d22 2364 6174 612d 4b68 6f6e 7a6f 6461  ="#data-Khonzoda
-00004520: 2220 7469 746c 653d 2244 6174 6122 3ef0  " title="Data">.
-00004530: 9f94 a33c 2f61 3e20 3c61 2068 7265 663d  ...</a> <a href=
-00004540: 2223 6d61 696e 7465 6e61 6e63 652d 4b68  "#maintenance-Kh
-00004550: 6f6e 7a6f 6461 2220 7469 746c 653d 224d  onzoda" title="M
-00004560: 6169 6e74 656e 616e 6365 223e f09f 9aa7  aintenance">....
-00004570: 3c2f 613e 3c2f 7464 3e0a 2020 2020 3c74  </a></td>.    <t
-00004580: 6420 616c 6967 6e3d 2263 656e 7465 7222  d align="center"
-00004590: 3e3c 6120 6872 6566 3d22 6874 7470 733a  ><a href="https:
-000045a0: 2f2f 6769 7468 7562 2e63 6f6d 2f6d 7769  //github.com/mwi
-000045b0: 6c62 7a22 3e3c 696d 6720 7372 633d 2268  lbz"><img src="h
-000045c0: 7474 7073 3a2f 2f61 7661 7461 7273 2e67  ttps://avatars.g
-000045d0: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
-000045e0: 2e63 6f6d 2f75 2f31 3431 3135 3634 313f  .com/u/14115641?
-000045f0: 763d 343f 733d 3130 3022 2077 6964 7468  v=4?s=100" width
-00004600: 3d22 3130 3070 783b 2220 616c 743d 2222  ="100px;" alt=""
-00004610: 2f3e 3c62 7220 2f3e 3c73 7562 3e3c 623e  /><br /><sub><b>
-00004620: 6d77 696c 627a 3c2f 623e 3c2f 7375 623e  mwilbz</b></sub>
-00004630: 3c2f 613e 3c62 7220 2f3e 3c61 2068 7265  </a><br /><a hre
-00004640: 663d 2268 7474 7073 3a2f 2f67 6974 6875  f="https://githu
-00004650: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
-00004660: 2f43 6f72 6e65 6c6c 2d43 6f6e 7665 7273  /Cornell-Convers
-00004670: 6174 696f 6e61 6c2d 416e 616c 7973 6973  ational-Analysis
-00004680: 2d54 6f6f 6c6b 6974 2f63 6f6d 6d69 7473  -Toolkit/commits
-00004690: 3f61 7574 686f 723d 6d77 696c 627a 2220  ?author=mwilbz" 
-000046a0: 7469 746c 653d 2254 6573 7473 223e e29a  title="Tests">..
-000046b0: a0ef b88f 3c2f 613e 3c2f 7464 3e0a 2020  ....</a></td>.  
-000046c0: 2020 3c74 6420 616c 6967 6e3d 2263 656e    <td align="cen
-000046d0: 7465 7222 3e3c 6120 6872 6566 3d22 6874  ter"><a href="ht
-000046e0: 7470 733a 2f2f 7777 772e 616c 6578 6b6f  tps://www.alexko
-000046f0: 656e 2e63 6f6d 223e 3c69 6d67 2073 7263  en.com"><img src
-00004700: 3d22 6874 7470 733a 2f2f 6176 6174 6172  ="https://avatar
-00004710: 732e 6769 7468 7562 7573 6572 636f 6e74  s.githubusercont
-00004720: 656e 742e 636f 6d2f 752f 3433 3931 3339  ent.com/u/439139
-00004730: 3032 3f76 3d34 3f73 3d31 3030 2220 7769  02?v=4?s=100" wi
-00004740: 6474 683d 2231 3030 7078 3b22 2061 6c74  dth="100px;" alt
-00004750: 3d22 222f 3e3c 6272 202f 3e3c 7375 623e  =""/><br /><sub>
-00004760: 3c62 3e41 6c65 7820 4b6f 656e 3c2f 623e  <b>Alex Koen</b>
-00004770: 3c2f 7375 623e 3c2f 613e 3c62 7220 2f3e  </sub></a><br />
-00004780: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
-00004790: 2f67 6974 6875 622e 636f 6d2f 436f 726e  /github.com/Corn
-000047a0: 656c 6c4e 4c50 2f43 6f72 6e65 6c6c 2d43  ellNLP/Cornell-C
-000047b0: 6f6e 7665 7273 6174 696f 6e61 6c2d 416e  onversational-An
-000047c0: 616c 7973 6973 2d54 6f6f 6c6b 6974 2f69  alysis-Toolkit/i
-000047d0: 7373 7565 733f 713d 6175 7468 6f72 2533  ssues?q=author%3
-000047e0: 4161 6b6f 656e 2220 7469 746c 653d 2242  Aakoen" title="B
-000047f0: 7567 2072 6570 6f72 7473 223e f09f 909b  ug reports">....
-00004800: 3c2f 613e 3c2f 7464 3e0a 2020 2020 3c74  </a></td>.    <t
-00004810: 6420 616c 6967 6e3d 2263 656e 7465 7222  d align="center"
-00004820: 3e3c 6120 6872 6566 3d22 6874 7470 3a2f  ><a href="http:/
-00004830: 2f65 6d74 7365 6e67 2e6d 6522 3e3c 696d  /emtseng.me"><im
-00004840: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
-00004850: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
-00004860: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f35  rcontent.com/u/5
-00004870: 3237 3038 3532 3f76 3d34 3f73 3d31 3030  270852?v=4?s=100
-00004880: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
-00004890: 2061 6c74 3d22 222f 3e3c 6272 202f 3e3c   alt=""/><br /><
-000048a0: 7375 623e 3c62 3e45 6d69 6c79 2054 7365  sub><b>Emily Tse
-000048b0: 6e67 3c2f 623e 3c2f 7375 623e 3c2f 613e  ng</b></sub></a>
-000048c0: 3c62 7220 2f3e 3c61 2068 7265 663d 2268  <br /><a href="h
-000048d0: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
-000048e0: 6d2f 436f 726e 656c 6c4e 4c50 2f43 6f72  m/CornellNLP/Cor
-000048f0: 6e65 6c6c 2d43 6f6e 7665 7273 6174 696f  nell-Conversatio
-00004900: 6e61 6c2d 416e 616c 7973 6973 2d54 6f6f  nal-Analysis-Too
-00004910: 6c6b 6974 2f69 7373 7565 733f 713d 6175  lkit/issues?q=au
-00004920: 7468 6f72 2533 4165 6d74 7365 6e67 2220  thor%3Aemtseng" 
-00004930: 7469 746c 653d 2242 7567 2072 6570 6f72  title="Bug repor
-00004940: 7473 223e f09f 909b 3c2f 613e 203c 6120  ts">....</a> <a 
-00004950: 6872 6566 3d22 2364 6174 612d 656d 7473  href="#data-emts
-00004960: 656e 6722 2074 6974 6c65 3d22 4461 7461  eng" title="Data
-00004970: 223e f09f 94a3 3c2f 613e 3c2f 7464 3e0a  ">....</a></td>.
-00004980: 2020 2020 3c74 6420 616c 6967 6e3d 2263      <td align="c
-00004990: 656e 7465 7222 3e3c 6120 6872 6566 3d22  enter"><a href="
-000049a0: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-000049b0: 6f6d 2f5a 6967 6779 466c 6f61 7422 3e3c  om/ZiggyFloat"><
-000049c0: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
-000049d0: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
-000049e0: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
-000049f0: 2f34 3139 3237 3630 373f 763d 343f 733d  /41927607?v=4?s=
-00004a00: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
-00004a10: 783b 2220 616c 743d 2222 2f3e 3c62 7220  x;" alt=""/><br 
-00004a20: 2f3e 3c73 7562 3e3c 623e 556c 6979 616e  /><sub><b>Uliyan
-00004a30: 6120 4b75 6261 736f 7661 3c2f 623e 3c2f  a Kubasova</b></
-00004a40: 7375 623e 3c2f 613e 3c62 7220 2f3e 3c61  sub></a><br /><a
-00004a50: 2068 7265 663d 2223 6461 7461 2d5a 6967   href="#data-Zig
-00004a60: 6779 466c 6f61 7422 2074 6974 6c65 3d22  gyFloat" title="
-00004a70: 4461 7461 223e f09f 94a3 3c2f 613e 3c2f  Data">....</a></
-00004a80: 7464 3e0a 2020 2020 3c74 6420 616c 6967  td>.    <td alig
-00004a90: 6e3d 2263 656e 7465 7222 3e3c 6120 6872  n="center"><a hr
-00004aa0: 6566 3d22 6874 7470 733a 2f2f 6a73 6368  ef="https://jsch
-00004ab0: 6c75 6765 722e 6769 7468 7562 2e69 6f2f  luger.github.io/
-00004ac0: 223e 3c69 6d67 2073 7263 3d22 6874 7470  "><img src="http
-00004ad0: 733a 2f2f 6176 6174 6172 732e 6769 7468  s://avatars.gith
-00004ae0: 7562 7573 6572 636f 6e74 656e 742e 636f  ubusercontent.co
-00004af0: 6d2f 752f 3134 3935 3630 3038 3f76 3d34  m/u/14956008?v=4
-00004b00: 3f73 3d31 3030 2220 7769 6474 683d 2231  ?s=100" width="1
-00004b10: 3030 7078 3b22 2061 6c74 3d22 222f 3e3c  00px;" alt=""/><
-00004b20: 6272 202f 3e3c 7375 623e 3c62 3e4a 6163  br /><sub><b>Jac
-00004b30: 6b20 5363 686c 7567 6572 3c2f 623e 3c2f  k Schluger</b></
-00004b40: 7375 623e 3c2f 613e 3c62 7220 2f3e 3c61  sub></a><br /><a
-00004b50: 2068 7265 663d 2268 7474 7073 3a2f 2f67   href="https://g
-00004b60: 6974 6875 622e 636f 6d2f 436f 726e 656c  ithub.com/Cornel
-00004b70: 6c4e 4c50 2f43 6f72 6e65 6c6c 2d43 6f6e  lNLP/Cornell-Con
-00004b80: 7665 7273 6174 696f 6e61 6c2d 416e 616c  versational-Anal
-00004b90: 7973 6973 2d54 6f6f 6c6b 6974 2f69 7373  ysis-Toolkit/iss
-00004ba0: 7565 733f 713d 6175 7468 6f72 2533 416a  ues?q=author%3Aj
-00004bb0: 7363 686c 7567 6572 2220 7469 746c 653d  schluger" title=
-00004bc0: 2242 7567 2072 6570 6f72 7473 223e f09f  "Bug reports">..
-00004bd0: 909b 3c2f 613e 3c2f 7464 3e0a 2020 3c2f  ..</a></td>.  </
-00004be0: 7472 3e0a 2020 3c74 723e 0a20 2020 203c  tr>.  <tr>.    <
-00004bf0: 7464 2061 6c69 676e 3d22 6365 6e74 6572  td align="center
-00004c00: 223e 3c61 2068 7265 663d 2268 7474 7073  "><a href="https
-00004c10: 3a2f 2f67 6974 6875 622e 636f 6d2f 6b75  ://github.com/ku
-00004c20: 7368 616c 6368 6177 6c61 223e 3c69 6d67  shalchawla"><img
-00004c30: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
-00004c40: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
-00004c50: 636f 6e74 656e 742e 636f 6d2f 752f 3834  content.com/u/84
-00004c60: 3136 3836 333f 763d 343f 733d 3130 3022  16863?v=4?s=100"
-00004c70: 2077 6964 7468 3d22 3130 3070 783b 2220   width="100px;" 
-00004c80: 616c 743d 2222 2f3e 3c62 7220 2f3e 3c73  alt=""/><br /><s
-00004c90: 7562 3e3c 623e 4b75 7368 616c 2043 6861  ub><b>Kushal Cha
-00004ca0: 776c 613c 2f62 3e3c 2f73 7562 3e3c 2f61  wla</b></sub></a
-00004cb0: 3e3c 6272 202f 3e3c 6120 6872 6566 3d22  ><br /><a href="
-00004cc0: 2364 6174 612d 6b75 7368 616c 6368 6177  #data-kushalchaw
-00004cd0: 6c61 2220 7469 746c 653d 2244 6174 6122  la" title="Data"
-00004ce0: 3ef0 9f94 a33c 2f61 3e3c 2f74 643e 0a20  >....</a></td>. 
-00004cf0: 2020 203c 7464 2061 6c69 676e 3d22 6365     <td align="ce
-00004d00: 6e74 6572 223e 3c61 2068 7265 663d 2268  nter"><a href="h
-00004d10: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
-00004d20: 6d2f 7363 3738 3222 3e3c 696d 6720 7372  m/sc782"><img sr
-00004d30: 633d 2268 7474 7073 3a2f 2f61 7661 7461  c="https://avata
-00004d40: 7273 2e67 6974 6875 6275 7365 7263 6f6e  rs.githubusercon
-00004d50: 7465 6e74 2e63 6f6d 2f75 2f31 3439 3730  tent.com/u/14970
-00004d60: 3933 303f 763d 343f 733d 3130 3022 2077  930?v=4?s=100" w
-00004d70: 6964 7468 3d22 3130 3070 783b 2220 616c  idth="100px;" al
-00004d80: 743d 2222 2f3e 3c62 7220 2f3e 3c73 7562  t=""/><br /><sub
-00004d90: 3e3c 623e 4a75 6e65 2043 686f 3c2f 623e  ><b>June Cho</b>
-00004da0: 3c2f 7375 623e 3c2f 613e 3c62 7220 2f3e  </sub></a><br />
-00004db0: 3c61 2068 7265 663d 2223 6461 7461 2d73  <a href="#data-s
-00004dc0: 6337 3832 2220 7469 746c 653d 2244 6174  c782" title="Dat
-00004dd0: 6122 3ef0 9f94 a33c 2f61 3e3c 2f74 643e  a">....</a></td>
-00004de0: 0a20 2020 203c 7464 2061 6c69 676e 3d22  .    <td align="
-00004df0: 6365 6e74 6572 223e 3c61 2068 7265 663d  center"><a href=
-00004e00: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
-00004e10: 636f 6d2f 6e6f 616d 6573 6865 6422 3e3c  com/noameshed"><
-00004e20: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
-00004e30: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
-00004e40: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
-00004e50: 2f34 3036 3332 3736 363f 763d 343f 733d  /40632766?v=4?s=
-00004e60: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
-00004e70: 783b 2220 616c 743d 2222 2f3e 3c62 7220  x;" alt=""/><br 
-00004e80: 2f3e 3c73 7562 3e3c 623e 4e6f 616d 2045  /><sub><b>Noam E
-00004e90: 7368 6564 3c2f 623e 3c2f 7375 623e 3c2f  shed</b></sub></
-00004ea0: 613e 3c62 7220 2f3e 3c61 2068 7265 663d  a><br /><a href=
-00004eb0: 2223 6461 7461 2d6e 6f61 6d65 7368 6564  "#data-noameshed
-00004ec0: 2220 7469 746c 653d 2244 6174 6122 3ef0  " title="Data">.
-00004ed0: 9f94 a33c 2f61 3e3c 2f74 643e 0a20 2020  ...</a></td>.   
-00004ee0: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
-00004ef0: 6572 223e 3c61 2068 7265 663d 2268 7474  er"><a href="htt
-00004f00: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00004f10: 737a 6d75 726c 6f22 3e3c 696d 6720 7372  szmurlo"><img sr
-00004f20: 633d 2268 7474 7073 3a2f 2f61 7661 7461  c="https://avata
-00004f30: 7273 2e67 6974 6875 6275 7365 7263 6f6e  rs.githubusercon
-00004f40: 7465 6e74 2e63 6f6d 2f75 2f33 3131 3932  tent.com/u/31192
-00004f50: 3334 303f 763d 343f 733d 3130 3022 2077  340?v=4?s=100" w
-00004f60: 6964 7468 3d22 3130 3070 783b 2220 616c  idth="100px;" al
-00004f70: 743d 2222 2f3e 3c62 7220 2f3e 3c73 7562  t=""/><br /><sub
-00004f80: 3e3c 623e 416e 6472 6577 2053 7a6d 7572  ><b>Andrew Szmur
-00004f90: 6c6f 3c2f 623e 3c2f 7375 623e 3c2f 613e  lo</b></sub></a>
-00004fa0: 3c62 7220 2f3e 3c61 2068 7265 663d 2223  <br /><a href="#
-00004fb0: 6461 7461 2d73 7a6d 7572 6c6f 2220 7469  data-szmurlo" ti
-00004fc0: 746c 653d 2244 6174 6122 3ef0 9f94 a33c  tle="Data">....<
-00004fd0: 2f61 3e3c 2f74 643e 0a20 2020 203c 7464  /a></td>.    <td
-00004fe0: 2061 6c69 676e 3d22 6365 6e74 6572 223e   align="center">
-00004ff0: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
-00005000: 2f67 6974 6875 622e 636f 6d2f 6b63 7361  /github.com/kcsa
-00005010: 646f 7722 3e3c 696d 6720 7372 633d 2268  dow"><img src="h
-00005020: 7474 7073 3a2f 2f61 7661 7461 7273 2e67  ttps://avatars.g
-00005030: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
-00005040: 2e63 6f6d 2f75 2f33 3430 3734 3135 313f  .com/u/34074151?
-00005050: 763d 343f 733d 3130 3022 2077 6964 7468  v=4?s=100" width
-00005060: 3d22 3130 3070 783b 2220 616c 743d 2222  ="100px;" alt=""
-00005070: 2f3e 3c62 7220 2f3e 3c73 7562 3e3c 623e  /><br /><sub><b>
-00005080: 4b61 7468 6172 696e 6520 5361 646f 7773  Katharine Sadows
-00005090: 6b69 3c2f 623e 3c2f 7375 623e 3c2f 613e  ki</b></sub></a>
-000050a0: 3c62 7220 2f3e 3c61 2068 7265 663d 2223  <br /><a href="#
-000050b0: 6461 7461 2d6b 6373 6164 6f77 2220 7469  data-kcsadow" ti
-000050c0: 746c 653d 2244 6174 6122 3ef0 9f94 a33c  tle="Data">....<
-000050d0: 2f61 3e3c 2f74 643e 0a20 2020 203c 7464  /a></td>.    <td
-000050e0: 2061 6c69 676e 3d22 6365 6e74 6572 223e   align="center">
-000050f0: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
-00005100: 2f67 6974 6875 622e 636f 6d2f 6c75 6361  /github.com/luca
-00005110: 7376 616e 6272 616d 6572 223e 3c69 6d67  svanbramer"><img
-00005120: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
-00005130: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
-00005140: 636f 6e74 656e 742e 636f 6d2f 752f 3332  content.com/u/32
-00005150: 3535 3336 3736 3f76 3d34 3f73 3d31 3030  553676?v=4?s=100
-00005160: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
-00005170: 2061 6c74 3d22 222f 3e3c 6272 202f 3e3c   alt=""/><br /><
-00005180: 7375 623e 3c62 3e4c 7563 6173 2056 616e  sub><b>Lucas Van
-00005190: 2042 7261 6d65 723c 2f62 3e3c 2f73 7562   Bramer</b></sub
-000051a0: 3e3c 2f61 3e3c 6272 202f 3e3c 6120 6872  ></a><br /><a hr
-000051b0: 6566 3d22 2364 6174 612d 6c75 6361 7376  ef="#data-lucasv
-000051c0: 616e 6272 616d 6572 2220 7469 746c 653d  anbramer" title=
-000051d0: 2244 6174 6122 3ef0 9f94 a33c 2f61 3e3c  "Data">....</a><
-000051e0: 2f74 643e 0a20 2020 203c 7464 2061 6c69  /td>.    <td ali
-000051f0: 676e 3d22 6365 6e74 6572 223e 3c61 2068  gn="center"><a h
-00005200: 7265 663d 2268 7474 703a 2f2f 6d61 7269  ref="http://mari
-00005210: 616e 6e65 616c 712e 636f 6d22 3e3c 696d  annealq.com"><im
-00005220: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
-00005230: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
-00005240: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f31  rcontent.com/u/1
-00005250: 3639 3439 3539 313f 763d 343f 733d 3130  6949591?v=4?s=10
-00005260: 3022 2077 6964 7468 3d22 3130 3070 783b  0" width="100px;
-00005270: 2220 616c 743d 2222 2f3e 3c62 7220 2f3e  " alt=""/><br />
-00005280: 3c73 7562 3e3c 623e 4d61 7269 616e 6e65  <sub><b>Marianne
-00005290: 2041 7562 696e 3c2f 623e 3c2f 7375 623e   Aubin</b></sub>
-000052a0: 3c2f 613e 3c62 7220 2f3e 3c61 2068 7265  </a><br /><a hre
-000052b0: 663d 2223 6461 7461 2d6d 6175 6269 6e6c  f="#data-maubinl
-000052c0: 6522 2074 6974 6c65 3d22 4461 7461 223e  e" title="Data">
-000052d0: f09f 94a3 3c2f 613e 3c2f 7464 3e0a 2020  ....</a></td>.  
-000052e0: 3c2f 7472 3e0a 2020 3c74 723e 0a20 2020  </tr>.  <tr>.   
-000052f0: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
-00005300: 6572 223e 3c61 2068 7265 663d 2268 7474  er"><a href="htt
-00005310: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00005320: 646e 3237 3322 3e3c 696d 6720 7372 633d  dn273"><img src=
-00005330: 2268 7474 7073 3a2f 2f61 7661 7461 7273  "https://avatars
-00005340: 2e67 6974 6875 6275 7365 7263 6f6e 7465  .githubuserconte
-00005350: 6e74 2e63 6f6d 2f75 2f32 3739 3236 3636  nt.com/u/2792666
-00005360: 323f 763d 343f 733d 3130 3022 2077 6964  2?v=4?s=100" wid
-00005370: 7468 3d22 3130 3070 783b 2220 616c 743d  th="100px;" alt=
-00005380: 2222 2f3e 3c62 7220 2f3e 3c73 7562 3e3c  ""/><br /><sub><
-00005390: 623e 4469 204e 693c 2f62 3e3c 2f73 7562  b>Di Ni</b></sub
-000053a0: 3e3c 2f61 3e3c 6272 202f 3e3c 6120 6872  ></a><br /><a hr
-000053b0: 6566 3d22 2364 6174 612d 646e 3237 3322  ef="#data-dn273"
-000053c0: 2074 6974 6c65 3d22 4461 7461 223e f09f   title="Data">..
-000053d0: 94a3 3c2f 613e 3c2f 7464 3e0a 2020 2020  ..</a></td>.    
-000053e0: 3c74 6420 616c 6967 6e3d 2263 656e 7465  <td align="cente
-000053f0: 7222 3e3c 6120 6872 6566 3d22 6874 7470  r"><a href="http
-00005400: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f67  s://github.com/g
-00005410: 6465 6e67 3936 223e 3c69 6d67 2073 7263  deng96"><img src
-00005420: 3d22 6874 7470 733a 2f2f 6176 6174 6172  ="https://avatar
-00005430: 732e 6769 7468 7562 7573 6572 636f 6e74  s.githubusercont
-00005440: 656e 742e 636f 6d2f 752f 3836 3030 3735  ent.com/u/860075
-00005450: 313f 763d 343f 733d 3130 3022 2077 6964  1?v=4?s=100" wid
-00005460: 7468 3d22 3130 3070 783b 2220 616c 743d  th="100px;" alt=
-00005470: 2222 2f3e 3c62 7220 2f3e 3c73 7562 3e3c  ""/><br /><sub><
-00005480: 623e 6764 656e 6739 363c 2f62 3e3c 2f73  b>gdeng96</b></s
-00005490: 7562 3e3c 2f61 3e3c 6272 202f 3e3c 6120  ub></a><br /><a 
-000054a0: 6872 6566 3d22 2364 6174 612d 6764 656e  href="#data-gden
-000054b0: 6739 3622 2074 6974 6c65 3d22 4461 7461  g96" title="Data
-000054c0: 223e f09f 94a3 3c2f 613e 3c2f 7464 3e0a  ">....</a></td>.
-000054d0: 2020 2020 3c74 6420 616c 6967 6e3d 2263      <td align="c
-000054e0: 656e 7465 7222 3e3c 6120 6872 6566 3d22  enter"><a href="
-000054f0: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-00005500: 6f6d 2f6a 756e 6672 616e 6b6c 6922 3e3c  om/junfrankli"><
-00005510: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
-00005520: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
-00005530: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
-00005540: 2f32 3234 3632 3538 343f 763d 343f 733d  /22462584?v=4?s=
-00005550: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
-00005560: 783b 2220 616c 743d 2222 2f3e 3c62 7220  x;" alt=""/><br 
-00005570: 2f3e 3c73 7562 3e3c 623e 4672 616e 6b20  /><sub><b>Frank 
-00005580: 4c69 3c2f 623e 3c2f 7375 623e 3c2f 613e  Li</b></sub></a>
-00005590: 3c62 7220 2f3e 3c61 2068 7265 663d 2223  <br /><a href="#
-000055a0: 6461 7461 2d6a 756e 6672 616e 6b6c 6922  data-junfrankli"
-000055b0: 2074 6974 6c65 3d22 4461 7461 223e f09f   title="Data">..
-000055c0: 94a3 3c2f 613e 3c2f 7464 3e0a 2020 2020  ..</a></td>.    
-000055d0: 3c74 6420 616c 6967 6e3d 2263 656e 7465  <td align="cente
-000055e0: 7222 3e3c 6120 6872 6566 3d22 6874 7470  r"><a href="http
-000055f0: 3a2f 2f72 756a 7a68 616f 2e63 6f6d 223e  ://rujzhao.com">
-00005600: 3c69 6d67 2073 7263 3d22 6874 7470 733a  <img src="https:
-00005610: 2f2f 6176 6174 6172 732e 6769 7468 7562  //avatars.github
-00005620: 7573 6572 636f 6e74 656e 742e 636f 6d2f  usercontent.com/
-00005630: 752f 3331 3135 3837 3438 3f76 3d34 3f73  u/31158748?v=4?s
-00005640: 3d31 3030 2220 7769 6474 683d 2231 3030  =100" width="100
-00005650: 7078 3b22 2061 6c74 3d22 222f 3e3c 6272  px;" alt=""/><br
-00005660: 202f 3e3c 7375 623e 3c62 3e72 6a7a 3436   /><sub><b>rjz46
-00005670: 3c2f 623e 3c2f 7375 623e 3c2f 613e 3c62  </b></sub></a><b
-00005680: 7220 2f3e 3c61 2068 7265 663d 2223 6461  r /><a href="#da
-00005690: 7461 2d72 6a7a 3436 2220 7469 746c 653d  ta-rjz46" title=
-000056a0: 2244 6174 6122 3ef0 9f94 a33c 2f61 3e3c  "Data">....</a><
-000056b0: 2f74 643e 0a20 2020 203c 7464 2061 6c69  /td>.    <td ali
-000056c0: 676e 3d22 6365 6e74 6572 223e 3c61 2068  gn="center"><a h
-000056d0: 7265 663d 2268 7474 7073 3a2f 2f67 6974  ref="https://git
-000056e0: 6875 622e 636f 6d2f 4b61 7479 426c 756d  hub.com/KatyBlum
-000056f0: 6572 223e 3c69 6d67 2073 7263 3d22 6874  er"><img src="ht
-00005700: 7470 733a 2f2f 6176 6174 6172 732e 6769  tps://avatars.gi
-00005710: 7468 7562 7573 6572 636f 6e74 656e 742e  thubusercontent.
-00005720: 636f 6d2f 752f 3336 3639 3036 393f 763d  com/u/3669069?v=
-00005730: 343f 733d 3130 3022 2077 6964 7468 3d22  4?s=100" width="
-00005740: 3130 3070 783b 2220 616c 743d 2222 2f3e  100px;" alt=""/>
-00005750: 3c62 7220 2f3e 3c73 7562 3e3c 623e 4b61  <br /><sub><b>Ka
-00005760: 7479 426c 756d 6572 3c2f 623e 3c2f 7375  tyBlumer</b></su
-00005770: 623e 3c2f 613e 3c62 7220 2f3e 3c61 2068  b></a><br /><a h
-00005780: 7265 663d 2223 6461 7461 2d4b 6174 7942  ref="#data-KatyB
-00005790: 6c75 6d65 7222 2074 6974 6c65 3d22 4461  lumer" title="Da
-000057a0: 7461 223e f09f 94a3 3c2f 613e 3c2f 7464  ta">....</a></td
-000057b0: 3e0a 2020 2020 3c74 6420 616c 6967 6e3d  >.    <td align=
-000057c0: 2263 656e 7465 7222 3e3c 6120 6872 6566  "center"><a href
-000057d0: 3d22 6874 7470 733a 2f2f 6769 7468 7562  ="https://github
-000057e0: 2e63 6f6d 2f61 6c73 3435 3222 3e3c 696d  .com/als452"><im
-000057f0: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
-00005800: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
-00005810: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f31  rcontent.com/u/1
-00005820: 3538 3338 3235 383f 763d 343f 733d 3130  5838258?v=4?s=10
-00005830: 3022 2077 6964 7468 3d22 3130 3070 783b  0" width="100px;
-00005840: 2220 616c 743d 2222 2f3e 3c62 7220 2f3e  " alt=""/><br />
-00005850: 3c73 7562 3e3c 623e 616c 7334 3532 3c2f  <sub><b>als452</
-00005860: 623e 3c2f 7375 623e 3c2f 613e 3c62 7220  b></sub></a><br 
-00005870: 2f3e 3c61 2068 7265 663d 2223 6461 7461  /><a href="#data
-00005880: 2d61 6c73 3435 3222 2074 6974 6c65 3d22  -als452" title="
-00005890: 4461 7461 223e f09f 94a3 3c2f 613e 3c2f  Data">....</a></
-000058a0: 7464 3e0a 2020 2020 3c74 6420 616c 6967  td>.    <td alig
-000058b0: 6e3d 2263 656e 7465 7222 3e3c 6120 6872  n="center"><a hr
-000058c0: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
-000058d0: 7562 2e63 6f6d 2f4b 616d 696e 736b 794a  ub.com/KaminskyJ
-000058e0: 223e 3c69 6d67 2073 7263 3d22 6874 7470  "><img src="http
-000058f0: 733a 2f2f 6176 6174 6172 732e 6769 7468  s://avatars.gith
-00005900: 7562 7573 6572 636f 6e74 656e 742e 636f  ubusercontent.co
-00005910: 6d2f 752f 3236 3339 3537 3732 3f76 3d34  m/u/26395772?v=4
-00005920: 3f73 3d31 3030 2220 7769 6474 683d 2231  ?s=100" width="1
-00005930: 3030 7078 3b22 2061 6c74 3d22 222f 3e3c  00px;" alt=""/><
-00005940: 6272 202f 3e3c 7375 623e 3c62 3e4b 616d  br /><sub><b>Kam
-00005950: 696e 736b 794a 3c2f 623e 3c2f 7375 623e  inskyJ</b></sub>
-00005960: 3c2f 613e 3c62 7220 2f3e 3c61 2068 7265  </a><br /><a hre
-00005970: 663d 2268 7474 7073 3a2f 2f67 6974 6875  f="https://githu
-00005980: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
-00005990: 2f43 6f72 6e65 6c6c 2d43 6f6e 7665 7273  /Cornell-Convers
-000059a0: 6174 696f 6e61 6c2d 416e 616c 7973 6973  ational-Analysis
-000059b0: 2d54 6f6f 6c6b 6974 2f63 6f6d 6d69 7473  -Toolkit/commits
-000059c0: 3f61 7574 686f 723d 4b61 6d69 6e73 6b79  ?author=Kaminsky
-000059d0: 4a22 2074 6974 6c65 3d22 436f 6465 223e  J" title="Code">
-000059e0: f09f 92bb 3c2f 613e 3c2f 7464 3e0a 2020  ....</a></td>.  
-000059f0: 3c2f 7472 3e0a 2020 3c74 723e 0a20 2020  </tr>.  <tr>.   
-00005a00: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
-00005a10: 6572 223e 3c61 2068 7265 663d 2268 7474  er"><a href="htt
-00005a20: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00005a30: 6372 6973 7469 616e 646e 6d22 3e3c 696d  cristiandnm"><im
-00005a40: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
-00005a50: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
-00005a60: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f38  rcontent.com/u/8
-00005a70: 3730 3035 3633 3f76 3d34 3f73 3d31 3030  700563?v=4?s=100
-00005a80: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
-00005a90: 2061 6c74 3d22 222f 3e3c 6272 202f 3e3c   alt=""/><br /><
-00005aa0: 7375 623e 3c62 3e43 7269 7374 6961 6e20  sub><b>Cristian 
-00005ab0: 4461 6e65 7363 752d 4e69 6375 6c65 7363  Danescu-Niculesc
-00005ac0: 752d 4d69 7a69 6c3c 2f62 3e3c 2f73 7562  u-Mizil</b></sub
-00005ad0: 3e3c 2f61 3e3c 6272 202f 3e3c 6120 6872  ></a><br /><a hr
-00005ae0: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
-00005af0: 7562 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c  ub.com/CornellNL
-00005b00: 502f 436f 726e 656c 6c2d 436f 6e76 6572  P/Cornell-Conver
-00005b10: 7361 7469 6f6e 616c 2d41 6e61 6c79 7369  sational-Analysi
-00005b20: 732d 546f 6f6c 6b69 742f 636f 6d6d 6974  s-Toolkit/commit
-00005b30: 733f 6175 7468 6f72 3d63 7269 7374 6961  s?author=cristia
-00005b40: 6e64 6e6d 2220 7469 746c 653d 2243 6f64  ndnm" title="Cod
-00005b50: 6522 3ef0 9f92 bb3c 2f61 3e20 3c61 2068  e">....</a> <a h
-00005b60: 7265 663d 2223 6461 7461 2d63 7269 7374  ref="#data-crist
-00005b70: 6961 6e64 6e6d 2220 7469 746c 653d 2244  iandnm" title="D
-00005b80: 6174 6122 3ef0 9f94 a33c 2f61 3e20 3c61  ata">....</a> <a
-00005b90: 2068 7265 663d 2223 6964 6561 732d 6372   href="#ideas-cr
-00005ba0: 6973 7469 616e 646e 6d22 2074 6974 6c65  istiandnm" title
-00005bb0: 3d22 4964 6561 732c 2050 6c61 6e6e 696e  ="Ideas, Plannin
-00005bc0: 672c 2026 2046 6565 6462 6163 6b22 3ef0  g, & Feedback">.
-00005bd0: 9fa4 943c 2f61 3e20 3c61 2068 7265 663d  ...</a> <a href=
-00005be0: 2223 6d61 696e 7465 6e61 6e63 652d 6372  "#maintenance-cr
-00005bf0: 6973 7469 616e 646e 6d22 2074 6974 6c65  istiandnm" title
-00005c00: 3d22 4d61 696e 7465 6e61 6e63 6522 3ef0  ="Maintenance">.
-00005c10: 9f9a a73c 2f61 3e20 3c61 2068 7265 663d  ...</a> <a href=
-00005c20: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
-00005c30: 636f 6d2f 436f 726e 656c 6c4e 4c50 2f43  com/CornellNLP/C
-00005c40: 6f72 6e65 6c6c 2d43 6f6e 7665 7273 6174  ornell-Conversat
-00005c50: 696f 6e61 6c2d 416e 616c 7973 6973 2d54  ional-Analysis-T
-00005c60: 6f6f 6c6b 6974 2f63 6f6d 6d69 7473 3f61  oolkit/commits?a
-00005c70: 7574 686f 723d 6372 6973 7469 616e 646e  uthor=cristiandn
-00005c80: 6d22 2074 6974 6c65 3d22 446f 6375 6d65  m" title="Docume
-00005c90: 6e74 6174 696f 6e22 3ef0 9f93 963c 2f61  ntation">....</a
-00005ca0: 3e20 3c61 2068 7265 663d 2268 7474 7073  > <a href="https
-00005cb0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
-00005cc0: 726e 656c 6c4e 4c50 2f43 6f72 6e65 6c6c  rnellNLP/Cornell
-00005cd0: 2d43 6f6e 7665 7273 6174 696f 6e61 6c2d  -Conversational-
-00005ce0: 416e 616c 7973 6973 2d54 6f6f 6c6b 6974  Analysis-Toolkit
-00005cf0: 2f70 756c 6c73 3f71 3d69 7325 3341 7072  /pulls?q=is%3Apr
-00005d00: 2b72 6576 6965 7765 642d 6279 2533 4163  +reviewed-by%3Ac
-00005d10: 7269 7374 6961 6e64 6e6d 2220 7469 746c  ristiandnm" titl
-00005d20: 653d 2252 6576 6965 7765 6420 5075 6c6c  e="Reviewed Pull
-00005d30: 2052 6571 7565 7374 7322 3ef0 9f91 803c   Requests">....<
-00005d40: 2f61 3e3c 2f74 643e 0a20 2020 203c 7464  /a></td>.    <td
-00005d50: 2061 6c69 676e 3d22 6365 6e74 6572 223e   align="center">
-00005d60: 3c61 2068 7265 663d 2268 7474 703a 2f2f  <a href="http://
-00005d70: 7761 6e67 616e 7a68 6f75 2e63 6f6d 223e  wanganzhou.com">
-00005d80: 3c69 6d67 2073 7263 3d22 6874 7470 733a  <img src="https:
-00005d90: 2f2f 6176 6174 6172 732e 6769 7468 7562  //avatars.github
-00005da0: 7573 6572 636f 6e74 656e 742e 636f 6d2f  usercontent.com/
-00005db0: 752f 3436 3833 3432 333f 763d 343f 733d  u/4683423?v=4?s=
-00005dc0: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
-00005dd0: 783b 2220 616c 743d 2222 2f3e 3c62 7220  x;" alt=""/><br 
-00005de0: 2f3e 3c73 7562 3e3c 623e 416e 6472 6577  /><sub><b>Andrew
-00005df0: 2057 616e 673c 2f62 3e3c 2f73 7562 3e3c   Wang</b></sub><
-00005e00: 2f61 3e3c 6272 202f 3e3c 6120 6872 6566  /a><br /><a href
-00005e10: 3d22 6874 7470 733a 2f2f 6769 7468 7562  ="https://github
-00005e20: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
-00005e30: 436f 726e 656c 6c2d 436f 6e76 6572 7361  Cornell-Conversa
-00005e40: 7469 6f6e 616c 2d41 6e61 6c79 7369 732d  tional-Analysis-
-00005e50: 546f 6f6c 6b69 742f 636f 6d6d 6974 733f  Toolkit/commits?
-00005e60: 6175 7468 6f72 3d71 656d 6122 2074 6974  author=qema" tit
-00005e70: 6c65 3d22 436f 6465 223e f09f 92bb 3c2f  le="Code">....</
-00005e80: 613e 203c 6120 6872 6566 3d22 2364 6174  a> <a href="#dat
-00005e90: 612d 7165 6d61 2220 7469 746c 653d 2244  a-qema" title="D
-00005ea0: 6174 6122 3ef0 9f94 a33c 2f61 3e20 3c61  ata">....</a> <a
-00005eb0: 2068 7265 663d 2223 6964 6561 732d 7165   href="#ideas-qe
-00005ec0: 6d61 2220 7469 746c 653d 2249 6465 6173  ma" title="Ideas
-00005ed0: 2c20 506c 616e 6e69 6e67 2c20 2620 4665  , Planning, & Fe
-00005ee0: 6564 6261 636b 223e f09f a494 3c2f 613e  edback">....</a>
-00005ef0: 203c 6120 6872 6566 3d22 236d 6169 6e74   <a href="#maint
-00005f00: 656e 616e 6365 2d71 656d 6122 2074 6974  enance-qema" tit
-00005f10: 6c65 3d22 4d61 696e 7465 6e61 6e63 6522  le="Maintenance"
-00005f20: 3ef0 9f9a a73c 2f61 3e20 3c61 2068 7265  >....</a> <a hre
-00005f30: 663d 2268 7474 7073 3a2f 2f67 6974 6875  f="https://githu
-00005f40: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
-00005f50: 2f43 6f72 6e65 6c6c 2d43 6f6e 7665 7273  /Cornell-Convers
-00005f60: 6174 696f 6e61 6c2d 416e 616c 7973 6973  ational-Analysis
-00005f70: 2d54 6f6f 6c6b 6974 2f63 6f6d 6d69 7473  -Toolkit/commits
-00005f80: 3f61 7574 686f 723d 7165 6d61 2220 7469  ?author=qema" ti
-00005f90: 746c 653d 2244 6f63 756d 656e 7461 7469  tle="Documentati
-00005fa0: 6f6e 223e f09f 9396 3c2f 613e 203c 6120  on">....</a> <a 
-00005fb0: 6872 6566 3d22 6874 7470 733a 2f2f 6769  href="https://gi
-00005fc0: 7468 7562 2e63 6f6d 2f43 6f72 6e65 6c6c  thub.com/Cornell
-00005fd0: 4e4c 502f 436f 726e 656c 6c2d 436f 6e76  NLP/Cornell-Conv
-00005fe0: 6572 7361 7469 6f6e 616c 2d41 6e61 6c79  ersational-Analy
-00005ff0: 7369 732d 546f 6f6c 6b69 742f 7075 6c6c  sis-Toolkit/pull
-00006000: 733f 713d 6973 2533 4170 722b 7265 7669  s?q=is%3Apr+revi
-00006010: 6577 6564 2d62 7925 3341 7165 6d61 2220  ewed-by%3Aqema" 
-00006020: 7469 746c 653d 2252 6576 6965 7765 6420  title="Reviewed 
-00006030: 5075 6c6c 2052 6571 7565 7374 7322 3ef0  Pull Requests">.
-00006040: 9f91 803c 2f61 3e3c 2f74 643e 0a20 2020  ...</a></td>.   
-00006050: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
-00006060: 6572 223e 3c61 2068 7265 663d 2268 7474  er"><a href="htt
-00006070: 703a 2f2f 7469 736a 756e 652e 6769 7468  p://tisjune.gith
-00006080: 7562 2e69 6f22 3e3c 696d 6720 7372 633d  ub.io"><img src=
-00006090: 2268 7474 7073 3a2f 2f61 7661 7461 7273  "https://avatars
-000060a0: 2e67 6974 6875 6275 7365 7263 6f6e 7465  .githubuserconte
-000060b0: 6e74 2e63 6f6d 2f75 2f38 3533 3430 3732  nt.com/u/8534072
-000060c0: 3f76 3d34 3f73 3d31 3030 2220 7769 6474  ?v=4?s=100" widt
-000060d0: 683d 2231 3030 7078 3b22 2061 6c74 3d22  h="100px;" alt="
-000060e0: 222f 3e3c 6272 202f 3e3c 7375 623e 3c62  "/><br /><sub><b
-000060f0: 3e4a 7573 7469 6e65 205a 6861 6e67 3c2f  >Justine Zhang</
-00006100: 623e 3c2f 7375 623e 3c2f 613e 3c62 7220  b></sub></a><br 
-00006110: 2f3e 3c61 2068 7265 663d 2268 7474 7073  /><a href="https
-00006120: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
-00006130: 726e 656c 6c4e 4c50 2f43 6f72 6e65 6c6c  rnellNLP/Cornell
-00006140: 2d43 6f6e 7665 7273 6174 696f 6e61 6c2d  -Conversational-
-00006150: 416e 616c 7973 6973 2d54 6f6f 6c6b 6974  Analysis-Toolkit
-00006160: 2f63 6f6d 6d69 7473 3f61 7574 686f 723d  /commits?author=
-00006170: 7469 736a 756e 6522 2074 6974 6c65 3d22  tisjune" title="
-00006180: 436f 6465 223e f09f 92bb 3c2f 613e 203c  Code">....</a> <
-00006190: 6120 6872 6566 3d22 2364 6174 612d 7469  a href="#data-ti
-000061a0: 736a 756e 6522 2074 6974 6c65 3d22 4461  sjune" title="Da
-000061b0: 7461 223e f09f 94a3 3c2f 613e 203c 6120  ta">....</a> <a 
-000061c0: 6872 6566 3d22 2369 6465 6173 2d74 6973  href="#ideas-tis
-000061d0: 6a75 6e65 2220 7469 746c 653d 2249 6465  june" title="Ide
-000061e0: 6173 2c20 506c 616e 6e69 6e67 2c20 2620  as, Planning, & 
-000061f0: 4665 6564 6261 636b 223e f09f a494 3c2f  Feedback">....</
-00006200: 613e 203c 6120 6872 6566 3d22 236d 6169  a> <a href="#mai
-00006210: 6e74 656e 616e 6365 2d74 6973 6a75 6e65  ntenance-tisjune
-00006220: 2220 7469 746c 653d 224d 6169 6e74 656e  " title="Mainten
-00006230: 616e 6365 223e f09f 9aa7 3c2f 613e 203c  ance">....</a> <
-00006240: 6120 6872 6566 3d22 6874 7470 733a 2f2f  a href="https://
-00006250: 6769 7468 7562 2e63 6f6d 2f43 6f72 6e65  github.com/Corne
-00006260: 6c6c 4e4c 502f 436f 726e 656c 6c2d 436f  llNLP/Cornell-Co
-00006270: 6e76 6572 7361 7469 6f6e 616c 2d41 6e61  nversational-Ana
-00006280: 6c79 7369 732d 546f 6f6c 6b69 742f 636f  lysis-Toolkit/co
-00006290: 6d6d 6974 733f 6175 7468 6f72 3d74 6973  mmits?author=tis
-000062a0: 6a75 6e65 2220 7469 746c 653d 2244 6f63  june" title="Doc
-000062b0: 756d 656e 7461 7469 6f6e 223e f09f 9396  umentation">....
-000062c0: 3c2f 613e 203c 6120 6872 6566 3d22 6874  </a> <a href="ht
-000062d0: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
-000062e0: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 726e  /CornellNLP/Corn
-000062f0: 656c 6c2d 436f 6e76 6572 7361 7469 6f6e  ell-Conversation
-00006300: 616c 2d41 6e61 6c79 7369 732d 546f 6f6c  al-Analysis-Tool
-00006310: 6b69 742f 7075 6c6c 733f 713d 6973 2533  kit/pulls?q=is%3
-00006320: 4170 722b 7265 7669 6577 6564 2d62 7925  Apr+reviewed-by%
-00006330: 3341 7469 736a 756e 6522 2074 6974 6c65  3Atisjune" title
-00006340: 3d22 5265 7669 6577 6564 2050 756c 6c20  ="Reviewed Pull 
-00006350: 5265 7175 6573 7473 223e f09f 9180 3c2f  Requests">....</
-00006360: 613e 3c2f 7464 3e0a 2020 2020 3c74 6420  a></td>.    <td 
-00006370: 616c 6967 6e3d 2263 656e 7465 7222 3e3c  align="center"><
-00006380: 6120 6872 6566 3d22 6874 7470 3a2f 2f63  a href="http://c
-00006390: 732e 636f 726e 656c 6c2e 6564 752f 7e6a  s.cornell.edu/~j
-000063a0: 7063 6861 6e67 223e 3c69 6d67 2073 7263  pchang"><img src
-000063b0: 3d22 6874 7470 733a 2f2f 6176 6174 6172  ="https://avatar
-000063c0: 732e 6769 7468 7562 7573 6572 636f 6e74  s.githubusercont
-000063d0: 656e 742e 636f 6d2f 752f 3938 3939 3036  ent.com/u/989906
-000063e0: 3f76 3d34 3f73 3d31 3030 2220 7769 6474  ?v=4?s=100" widt
-000063f0: 683d 2231 3030 7078 3b22 2061 6c74 3d22  h="100px;" alt="
-00006400: 222f 3e3c 6272 202f 3e3c 7375 623e 3c62  "/><br /><sub><b
-00006410: 3e4a 6f6e 6174 6861 6e20 4368 616e 673c  >Jonathan Chang<
-00006420: 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c 6272  /b></sub></a><br
-00006430: 202f 3e3c 6120 6872 6566 3d22 6874 7470   /><a href="http
-00006440: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
-00006450: 6f72 6e65 6c6c 4e4c 502f 436f 726e 656c  ornellNLP/Cornel
-00006460: 6c2d 436f 6e76 6572 7361 7469 6f6e 616c  l-Conversational
-00006470: 2d41 6e61 6c79 7369 732d 546f 6f6c 6b69  -Analysis-Toolki
-00006480: 742f 636f 6d6d 6974 733f 6175 7468 6f72  t/commits?author
-00006490: 3d6a 7077 6368 616e 6722 2074 6974 6c65  =jpwchang" title
-000064a0: 3d22 436f 6465 223e f09f 92bb 3c2f 613e  ="Code">....</a>
-000064b0: 203c 6120 6872 6566 3d22 2364 6174 612d   <a href="#data-
-000064c0: 6a70 7763 6861 6e67 2220 7469 746c 653d  jpwchang" title=
-000064d0: 2244 6174 6122 3ef0 9f94 a33c 2f61 3e20  "Data">....</a> 
-000064e0: 3c61 2068 7265 663d 2223 6964 6561 732d  <a href="#ideas-
-000064f0: 6a70 7763 6861 6e67 2220 7469 746c 653d  jpwchang" title=
-00006500: 2249 6465 6173 2c20 506c 616e 6e69 6e67  "Ideas, Planning
-00006510: 2c20 2620 4665 6564 6261 636b 223e f09f  , & Feedback">..
-00006520: a494 3c2f 613e 203c 6120 6872 6566 3d22  ..</a> <a href="
-00006530: 236d 6169 6e74 656e 616e 6365 2d6a 7077  #maintenance-jpw
-00006540: 6368 616e 6722 2074 6974 6c65 3d22 4d61  chang" title="Ma
-00006550: 696e 7465 6e61 6e63 6522 3ef0 9f9a a73c  intenance">....<
-00006560: 2f61 3e20 3c61 2068 7265 663d 2268 7474  /a> <a href="htt
-00006570: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00006580: 436f 726e 656c 6c4e 4c50 2f43 6f72 6e65  CornellNLP/Corne
-00006590: 6c6c 2d43 6f6e 7665 7273 6174 696f 6e61  ll-Conversationa
-000065a0: 6c2d 416e 616c 7973 6973 2d54 6f6f 6c6b  l-Analysis-Toolk
-000065b0: 6974 2f63 6f6d 6d69 7473 3f61 7574 686f  it/commits?autho
-000065c0: 723d 6a70 7763 6861 6e67 2220 7469 746c  r=jpwchang" titl
-000065d0: 653d 2244 6f63 756d 656e 7461 7469 6f6e  e="Documentation
-000065e0: 223e f09f 9396 3c2f 613e 203c 6120 6872  ">....</a> <a hr
-000065f0: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
-00006600: 7562 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c  ub.com/CornellNL
-00006610: 502f 436f 726e 656c 6c2d 436f 6e76 6572  P/Cornell-Conver
-00006620: 7361 7469 6f6e 616c 2d41 6e61 6c79 7369  sational-Analysi
-00006630: 732d 546f 6f6c 6b69 742f 7075 6c6c 733f  s-Toolkit/pulls?
-00006640: 713d 6973 2533 4170 722b 7265 7669 6577  q=is%3Apr+review
-00006650: 6564 2d62 7925 3341 6a70 7763 6861 6e67  ed-by%3Ajpwchang
-00006660: 2220 7469 746c 653d 2252 6576 6965 7765  " title="Reviewe
-00006670: 6420 5075 6c6c 2052 6571 7565 7374 7322  d Pull Requests"
-00006680: 3ef0 9f91 803c 2f61 3e3c 2f74 643e 0a20  >....</a></td>. 
-00006690: 2020 203c 7464 2061 6c69 676e 3d22 6365     <td align="ce
-000066a0: 6e74 6572 223e 3c61 2068 7265 663d 2268  nter"><a href="h
-000066b0: 7474 703a 2f2f 7777 772e 6373 2e63 6f72  ttp://www.cs.cor
-000066c0: 6e65 6c6c 2e65 6475 2f7e 6c69 7965 2f22  nell.edu/~liye/"
-000066d0: 3e3c 696d 6720 7372 633d 2268 7474 7073  ><img src="https
-000066e0: 3a2f 2f61 7661 7461 7273 2e67 6974 6875  ://avatars.githu
-000066f0: 6275 7365 7263 6f6e 7465 6e74 2e63 6f6d  busercontent.com
-00006700: 2f75 2f31 3232 3234 3637 333f 763d 343f  /u/12224673?v=4?
-00006710: 733d 3130 3022 2077 6964 7468 3d22 3130  s=100" width="10
-00006720: 3070 783b 2220 616c 743d 2222 2f3e 3c62  0px;" alt=""/><b
-00006730: 7220 2f3e 3c73 7562 3e3c 623e 4c69 7965  r /><sub><b>Liye
-00006740: 2046 753c 2f62 3e3c 2f73 7562 3e3c 2f61   Fu</b></sub></a
-00006750: 3e3c 6272 202f 3e3c 6120 6872 6566 3d22  ><br /><a href="
-00006760: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-00006770: 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f 436f  om/CornellNLP/Co
-00006780: 726e 656c 6c2d 436f 6e76 6572 7361 7469  rnell-Conversati
-00006790: 6f6e 616c 2d41 6e61 6c79 7369 732d 546f  onal-Analysis-To
-000067a0: 6f6c 6b69 742f 636f 6d6d 6974 733f 6175  olkit/commits?au
-000067b0: 7468 6f72 3d6c 6979 6522 2074 6974 6c65  thor=liye" title
-000067c0: 3d22 436f 6465 223e f09f 92bb 3c2f 613e  ="Code">....</a>
-000067d0: 203c 6120 6872 6566 3d22 2364 6174 612d   <a href="#data-
-000067e0: 6c69 7965 2220 7469 746c 653d 2244 6174  liye" title="Dat
-000067f0: 6122 3ef0 9f94 a33c 2f61 3e20 3c61 2068  a">....</a> <a h
-00006800: 7265 663d 2223 6964 6561 732d 6c69 7965  ref="#ideas-liye
-00006810: 2220 7469 746c 653d 2249 6465 6173 2c20  " title="Ideas, 
-00006820: 506c 616e 6e69 6e67 2c20 2620 4665 6564  Planning, & Feed
-00006830: 6261 636b 223e f09f a494 3c2f 613e 203c  back">....</a> <
-00006840: 6120 6872 6566 3d22 236d 6169 6e74 656e  a href="#mainten
-00006850: 616e 6365 2d6c 6979 6522 2074 6974 6c65  ance-liye" title
-00006860: 3d22 4d61 696e 7465 6e61 6e63 6522 3ef0  ="Maintenance">.
-00006870: 9f9a a73c 2f61 3e20 3c61 2068 7265 663d  ...</a> <a href=
-00006880: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
-00006890: 636f 6d2f 436f 726e 656c 6c4e 4c50 2f43  com/CornellNLP/C
-000068a0: 6f72 6e65 6c6c 2d43 6f6e 7665 7273 6174  ornell-Conversat
-000068b0: 696f 6e61 6c2d 416e 616c 7973 6973 2d54  ional-Analysis-T
-000068c0: 6f6f 6c6b 6974 2f63 6f6d 6d69 7473 3f61  oolkit/commits?a
-000068d0: 7574 686f 723d 6c69 7965 2220 7469 746c  uthor=liye" titl
-000068e0: 653d 2244 6f63 756d 656e 7461 7469 6f6e  e="Documentation
-000068f0: 223e f09f 9396 3c2f 613e 203c 6120 6872  ">....</a> <a hr
-00006900: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
-00006910: 7562 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c  ub.com/CornellNL
-00006920: 502f 436f 726e 656c 6c2d 436f 6e76 6572  P/Cornell-Conver
-00006930: 7361 7469 6f6e 616c 2d41 6e61 6c79 7369  sational-Analysi
-00006940: 732d 546f 6f6c 6b69 742f 7075 6c6c 733f  s-Toolkit/pulls?
-00006950: 713d 6973 2533 4170 722b 7265 7669 6577  q=is%3Apr+review
-00006960: 6564 2d62 7925 3341 6c69 7965 2220 7469  ed-by%3Aliye" ti
-00006970: 746c 653d 2252 6576 6965 7765 6420 5075  tle="Reviewed Pu
-00006980: 6c6c 2052 6571 7565 7374 7322 3ef0 9f91  ll Requests">...
-00006990: 803c 2f61 3e3c 2f74 643e 0a20 2020 203c  .</a></td>.    <
-000069a0: 7464 2061 6c69 676e 3d22 6365 6e74 6572  td align="center
-000069b0: 223e 3c61 2068 7265 663d 2268 7474 7073  "><a href="https
-000069c0: 3a2f 2f67 6974 6875 622e 636f 6d2f 6361  ://github.com/ca
-000069d0: 6c65 6263 6869 616d 223e 3c69 6d67 2073  lebchiam"><img s
-000069e0: 7263 3d22 6874 7470 733a 2f2f 6176 6174  rc="https://avat
-000069f0: 6172 732e 6769 7468 7562 7573 6572 636f  ars.githubuserco
-00006a00: 6e74 656e 742e 636f 6d2f 752f 3134 3238  ntent.com/u/1428
-00006a10: 3639 3936 3f76 3d34 3f73 3d31 3030 2220  6996?v=4?s=100" 
-00006a20: 7769 6474 683d 2231 3030 7078 3b22 2061  width="100px;" a
-00006a30: 6c74 3d22 222f 3e3c 6272 202f 3e3c 7375  lt=""/><br /><su
-00006a40: 623e 3c62 3e63 616c 6562 6368 6961 6d3c  b><b>calebchiam<
-00006a50: 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c 6272  /b></sub></a><br
-00006a60: 202f 3e3c 6120 6872 6566 3d22 6874 7470   /><a href="http
-00006a70: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
-00006a80: 6f72 6e65 6c6c 4e4c 502f 436f 726e 656c  ornellNLP/Cornel
-00006a90: 6c2d 436f 6e76 6572 7361 7469 6f6e 616c  l-Conversational
-00006aa0: 2d41 6e61 6c79 7369 732d 546f 6f6c 6b69  -Analysis-Toolki
-00006ab0: 742f 636f 6d6d 6974 733f 6175 7468 6f72  t/commits?author
-00006ac0: 3d63 616c 6562 6368 6961 6d22 2074 6974  =calebchiam" tit
-00006ad0: 6c65 3d22 436f 6465 223e f09f 92bb 3c2f  le="Code">....</
-00006ae0: 613e 203c 6120 6872 6566 3d22 2364 6174  a> <a href="#dat
-00006af0: 612d 6361 6c65 6263 6869 616d 2220 7469  a-calebchiam" ti
-00006b00: 746c 653d 2244 6174 6122 3ef0 9f94 a33c  tle="Data">....<
-00006b10: 2f61 3e20 3c61 2068 7265 663d 2223 6964  /a> <a href="#id
-00006b20: 6561 732d 6361 6c65 6263 6869 616d 2220  eas-calebchiam" 
-00006b30: 7469 746c 653d 2249 6465 6173 2c20 506c  title="Ideas, Pl
-00006b40: 616e 6e69 6e67 2c20 2620 4665 6564 6261  anning, & Feedba
-00006b50: 636b 223e f09f a494 3c2f 613e 203c 6120  ck">....</a> <a 
-00006b60: 6872 6566 3d22 236d 6169 6e74 656e 616e  href="#maintenan
-00006b70: 6365 2d63 616c 6562 6368 6961 6d22 2074  ce-calebchiam" t
-00006b80: 6974 6c65 3d22 4d61 696e 7465 6e61 6e63  itle="Maintenanc
-00006b90: 6522 3ef0 9f9a a73c 2f61 3e20 3c61 2068  e">....</a> <a h
-00006ba0: 7265 663d 2268 7474 7073 3a2f 2f67 6974  ref="https://git
-00006bb0: 6875 622e 636f 6d2f 436f 726e 656c 6c4e  hub.com/CornellN
-00006bc0: 4c50 2f43 6f72 6e65 6c6c 2d43 6f6e 7665  LP/Cornell-Conve
-00006bd0: 7273 6174 696f 6e61 6c2d 416e 616c 7973  rsational-Analys
-00006be0: 6973 2d54 6f6f 6c6b 6974 2f63 6f6d 6d69  is-Toolkit/commi
-00006bf0: 7473 3f61 7574 686f 723d 6361 6c65 6263  ts?author=calebc
-00006c00: 6869 616d 2220 7469 746c 653d 2244 6f63  hiam" title="Doc
-00006c10: 756d 656e 7461 7469 6f6e 223e f09f 9396  umentation">....
-00006c20: 3c2f 613e 203c 6120 6872 6566 3d22 6874  </a> <a href="ht
-00006c30: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
-00006c40: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 726e  /CornellNLP/Corn
-00006c50: 656c 6c2d 436f 6e76 6572 7361 7469 6f6e  ell-Conversation
-00006c60: 616c 2d41 6e61 6c79 7369 732d 546f 6f6c  al-Analysis-Tool
-00006c70: 6b69 742f 7075 6c6c 733f 713d 6973 2533  kit/pulls?q=is%3
-00006c80: 4170 722b 7265 7669 6577 6564 2d62 7925  Apr+reviewed-by%
-00006c90: 3341 6361 6c65 6263 6869 616d 2220 7469  3Acalebchiam" ti
-00006ca0: 746c 653d 2252 6576 6965 7765 6420 5075  tle="Reviewed Pu
-00006cb0: 6c6c 2052 6571 7565 7374 7322 3ef0 9f91  ll Requests">...
-00006cc0: 803c 2f61 3e3c 2f74 643e 0a20 2020 203c  .</a></td>.    <
-00006cd0: 7464 2061 6c69 676e 3d22 6365 6e74 6572  td align="center
-00006ce0: 223e 3c61 2068 7265 663d 2268 7474 7073  "><a href="https
-00006cf0: 3a2f 2f67 6974 6875 622e 636f 6d2f 4170  ://github.com/Ap
-00006d00: 3130 3735 223e 3c69 6d67 2073 7263 3d22  1075"><img src="
-00006d10: 6874 7470 733a 2f2f 6176 6174 6172 732e  https://avatars.
-00006d20: 6769 7468 7562 7573 6572 636f 6e74 656e  githubuserconten
-00006d30: 742e 636f 6d2f 752f 3235 3739 3030 3932  t.com/u/25790092
-00006d40: 3f76 3d34 3f73 3d31 3030 2220 7769 6474  ?v=4?s=100" widt
-00006d50: 683d 2231 3030 7078 3b22 2061 6c74 3d22  h="100px;" alt="
-00006d60: 222f 3e3c 6272 202f 3e3c 7375 623e 3c62  "/><br /><sub><b
-00006d70: 3e41 726d 6161 6e20 5075 7269 3c2f 623e  >Armaan Puri</b>
-00006d80: 3c2f 7375 623e 3c2f 613e 3c62 7220 2f3e  </sub></a><br />
-00006d90: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
-00006da0: 2f67 6974 6875 622e 636f 6d2f 436f 726e  /github.com/Corn
-00006db0: 656c 6c4e 4c50 2f43 6f72 6e65 6c6c 2d43  ellNLP/Cornell-C
-00006dc0: 6f6e 7665 7273 6174 696f 6e61 6c2d 416e  onversational-An
-00006dd0: 616c 7973 6973 2d54 6f6f 6c6b 6974 2f63  alysis-Toolkit/c
-00006de0: 6f6d 6d69 7473 3f61 7574 686f 723d 4170  ommits?author=Ap
-00006df0: 3130 3735 2220 7469 746c 653d 2243 6f64  1075" title="Cod
-00006e00: 6522 3ef0 9f92 bb3c 2f61 3e3c 2f74 643e  e">....</a></td>
-00006e10: 0a20 203c 2f74 723e 0a3c 2f74 6162 6c65  .  </tr>.</table
-00006e20: 3e0a 0a3c 212d 2d20 6d61 726b 646f 776e  >..<!-- markdown
-00006e30: 6c69 6e74 2d72 6573 746f 7265 202d 2d3e  lint-restore -->
-00006e40: 0a3c 212d 2d20 7072 6574 7469 6572 2d69  .<!-- prettier-i
-00006e50: 676e 6f72 652d 656e 6420 2d2d 3e0a 0a3c  gnore-end -->..<
-00006e60: 212d 2d20 414c 4c2d 434f 4e54 5249 4255  !-- ALL-CONTRIBU
-00006e70: 544f 5253 2d4c 4953 543a 454e 4420 2d2d  TORS-LIST:END --
-00006e80: 3e0a 0a54 6869 7320 7072 6f6a 6563 7420  >..This project 
-00006e90: 666f 6c6c 6f77 7320 7468 6520 5b61 6c6c  follows the [all
-00006ea0: 2d63 6f6e 7472 6962 7574 6f72 735d 2868  -contributors](h
-00006eb0: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
-00006ec0: 6d2f 616c 6c2d 636f 6e74 7269 6275 746f  m/all-contributo
-00006ed0: 7273 2f61 6c6c 2d63 6f6e 7472 6962 7574  rs/all-contribut
-00006ee0: 6f72 7329 2073 7065 6369 6669 6361 7469  ors) specificati
-00006ef0: 6f6e 2e20 436f 6e74 7269 6275 7469 6f6e  on. Contribution
-00006f00: 7320 6f66 2061 6e79 206b 696e 6420 7765  s of any kind we
-00006f10: 6c63 6f6d 6521 0a                        lcome!.
+00000000: 2320 5b43 6f6e 766f 4b69 745d 2868 7474  # [ConvoKit](htt
+00000010: 703a 2f2f 636f 6e76 6f6b 6974 2e63 6f72  p://convokit.cor
+00000020: 6e65 6c6c 2e65 6475 2f29 0a3c 212d 2d20  nell.edu/).<!-- 
+00000030: 414c 4c2d 434f 4e54 5249 4255 544f 5253  ALL-CONTRIBUTORS
+00000040: 2d42 4144 4745 3a53 5441 5254 202d 2044  -BADGE:START - D
+00000050: 6f20 6e6f 7420 7265 6d6f 7665 206f 7220  o not remove or 
+00000060: 6d6f 6469 6679 2074 6869 7320 7365 6374  modify this sect
+00000070: 696f 6e20 2d2d 3e0a 5b21 5b41 6c6c 2043  ion -->.[![All C
+00000080: 6f6e 7472 6962 7574 6f72 735d 2868 7474  ontributors](htt
+00000090: 7073 3a2f 2f69 6d67 2e73 6869 656c 6473  ps://img.shields
+000000a0: 2e69 6f2f 6261 6467 652f 616c 6c5f 636f  .io/badge/all_co
+000000b0: 6e74 7269 6275 746f 7273 2d33 302d 6f72  ntributors-30-or
+000000c0: 616e 6765 2e73 7667 3f73 7479 6c65 3d66  ange.svg?style=f
+000000d0: 6c61 742d 7371 7561 7265 295d 2823 636f  lat-square)](#co
+000000e0: 6e74 7269 6275 746f 7273 2d29 0a3c 212d  ntributors-).<!-
+000000f0: 2d20 414c 4c2d 434f 4e54 5249 4255 544f  - ALL-CONTRIBUTO
+00000100: 5253 2d42 4144 4745 3a45 4e44 202d 2d3e  RS-BADGE:END -->
+00000110: 0a0a 5b21 5b70 7970 695d 2868 7474 7073  ..[![pypi](https
+00000120: 3a2f 2f69 6d67 2e73 6869 656c 6473 2e69  ://img.shields.i
+00000130: 6f2f 7079 7069 2f76 2f63 6f6e 766f 6b69  o/pypi/v/convoki
+00000140: 742e 7376 6729 5d28 6874 7470 733a 2f2f  t.svg)](https://
+00000150: 7079 7069 2e6f 7267 2f70 7970 692f 636f  pypi.org/pypi/co
+00000160: 6e76 6f6b 6974 2f29 0a5b 215b 7079 5c5f  nvokit/).[![py\_
+00000170: 7665 7273 696f 6e73 5d28 6874 7470 733a  versions](https:
+00000180: 2f2f 696d 672e 7368 6965 6c64 732e 696f  //img.shields.io
+00000190: 2f62 6164 6765 2f70 7974 686f 6e2d 332e  /badge/python-3.
+000001a0: 3825 3242 2d62 6c75 6529 5d28 6874 7470  8%2B-blue)](http
+000001b0: 733a 2f2f 7079 7069 2e6f 7267 2f70 7970  s://pypi.org/pyp
+000001c0: 692f 636f 6e76 6f6b 6974 2f29 0a5b 215b  i/convokit/).[![
+000001d0: 436f 6465 2073 7479 6c65 3a20 626c 6163  Code style: blac
+000001e0: 6b5d 2868 7474 7073 3a2f 2f69 6d67 2e73  k](https://img.s
+000001f0: 6869 656c 6473 2e69 6f2f 6261 6467 652f  hields.io/badge/
+00000200: 636f 6465 2532 3073 7479 6c65 2d62 6c61  code%20style-bla
+00000210: 636b 2d30 3030 3030 302e 7376 6729 5d28  ck-000000.svg)](
+00000220: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
+00000230: 6f6d 2f70 7366 2f62 6c61 636b 290a 5b21  om/psf/black).[!
+00000240: 5b6c 6963 656e 7365 5d28 6874 7470 733a  [license](https:
+00000250: 2f2f 696d 672e 7368 6965 6c64 732e 696f  //img.shields.io
+00000260: 2f62 6164 6765 2f6c 6963 656e 7365 2d4d  /badge/license-M
+00000270: 4954 2d67 7265 656e 295d 2868 7474 7073  IT-green)](https
+00000280: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
+00000290: 726e 656c 6c4e 4c50 2f43 6f6e 766f 4b69  rnellNLP/ConvoKi
+000002a0: 742f 626c 6f62 2f6d 6173 7465 722f 4c49  t/blob/master/LI
+000002b0: 4345 4e53 452e 6d64 290a 5b21 5b53 6c61  CENSE.md).[![Sla
+000002c0: 636b 2043 6f6d 6d75 6e69 7479 5d28 6874  ck Community](ht
+000002d0: 7470 733a 2f2f 696d 672e 7368 6965 6c64  tps://img.shield
+000002e0: 732e 696f 2f73 7461 7469 632f 7631 3f6c  s.io/static/v1?l
+000002f0: 6f67 6f3d 736c 6163 6b26 7374 796c 653d  ogo=slack&style=
+00000300: 666c 6174 2663 6f6c 6f72 3d72 6564 266c  flat&color=red&l
+00000310: 6162 656c 3d73 6c61 636b 266d 6573 7361  abel=slack&messa
+00000320: 6765 3d63 6f6d 6d75 6e69 7479 295d 2868  ge=community)](h
+00000330: 7474 7073 3a2f 2f6a 6f69 6e2e 736c 6163  ttps://join.slac
+00000340: 6b2e 636f 6d2f 742f 636f 6e76 6f6b 6974  k.com/t/convokit
+00000350: 2f73 6861 7265 645f 696e 7669 7465 2f7a  /shared_invite/z
+00000360: 742d 3161 7871 3334 7172 702d 3168 4458  t-1axq34qrp-1hDX
+00000370: 5172 7653 5843 6c49 624a 4f71 7734 5330  QrvSXClIbJOqw4S0
+00000380: 3351 290a 0a0a 5468 6973 2074 6f6f 6c6b  3Q)...This toolk
+00000390: 6974 2063 6f6e 7461 696e 7320 746f 6f6c  it contains tool
+000003a0: 7320 746f 2065 7874 7261 6374 2063 6f6e  s to extract con
+000003b0: 7665 7273 6174 696f 6e61 6c20 6665 6174  versational feat
+000003c0: 7572 6573 2061 6e64 2061 6e61 6c79 7a65  ures and analyze
+000003d0: 2073 6f63 6961 6c20 7068 656e 6f6d 656e   social phenomen
+000003e0: 6120 696e 2063 6f6e 7665 7273 6174 696f  a in conversatio
+000003f0: 6e73 2c20 7573 696e 6720 6120 5b73 696e  ns, using a [sin
+00000400: 676c 6520 756e 6966 6965 6420 696e 7465  gle unified inte
+00000410: 7266 6163 655d 2868 7474 7073 3a2f 2f63  rface](https://c
+00000420: 6f6e 766f 6b69 742e 636f 726e 656c 6c2e  onvokit.cornell.
+00000430: 6564 752f 646f 6375 6d65 6e74 6174 696f  edu/documentatio
+00000440: 6e2f 6172 6368 6974 6563 7475 7265 2e68  n/architecture.h
+00000450: 746d 6c29 2069 6e73 7069 7265 6420 6279  tml) inspired by
+00000460: 2028 616e 6420 636f 6d70 6174 6962 6c65   (and compatible
+00000470: 2077 6974 6829 2073 6369 6b69 742d 6c65   with) scikit-le
+00000480: 6172 6e2e 2020 5365 7665 7261 6c20 6c61  arn.  Several la
+00000490: 7267 6520 5b63 6f6e 7665 7273 6174 696f  rge [conversatio
+000004a0: 6e61 6c20 6461 7461 7365 7473 5d28 6874  nal datasets](ht
+000004b0: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
+000004c0: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 6e76  /CornellNLP/Conv
+000004d0: 6f4b 6974 2364 6174 6173 6574 7329 2061  oKit#datasets) a
+000004e0: 7265 2069 6e63 6c75 6465 6420 746f 6765  re included toge
+000004f0: 7468 6572 2077 6974 6820 7363 7269 7074  ther with script
+00000500: 7320 6578 656d 706c 6966 7969 6e67 2074  s exemplifying t
+00000510: 6865 2075 7365 206f 6620 7468 6520 746f  he use of the to
+00000520: 6f6c 6b69 7420 6f6e 2074 6865 7365 2064  olkit on these d
+00000530: 6174 6173 6574 732e 2054 6865 206c 6174  atasets. The lat
+00000540: 6573 7420 7665 7273 696f 6e20 6973 205b  est version is [
+00000550: 332e 302e 305d 2868 7474 7073 3a2f 2f67  3.0.0](https://g
+00000560: 6974 6875 622e 636f 6d2f 436f 726e 656c  ithub.com/Cornel
+00000570: 6c4e 4c50 2f43 6f6e 766f 4b69 742f 7265  lNLP/ConvoKit/re
+00000580: 6c65 6173 6573 2f74 6167 2f76 332e 302e  leases/tag/v3.0.
+00000590: 3029 2028 7265 6c65 6173 6564 204a 756c  0) (released Jul
+000005a0: 7920 3137 2c20 3230 3233 293b 2066 6f6c  y 17, 2023); fol
+000005b0: 6c6f 7720 7468 6520 5b70 726f 6a65 6374  low the [project
+000005c0: 206f 6e20 4769 7448 7562 5d28 6874 7470   on GitHub](http
+000005d0: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
+000005e0: 6f72 6e65 6c6c 4e4c 502f 436f 6e76 6f4b  ornellNLP/ConvoK
+000005f0: 6974 2920 746f 206b 6565 7020 7472 6163  it) to keep trac
+00000600: 6b20 6f66 2075 7064 6174 6573 2e0a 0a52  k of updates...R
+00000610: 6561 6420 6f75 7220 5b64 6f63 756d 656e  ead our [documen
+00000620: 7461 7469 6f6e 5d28 6874 7470 733a 2f2f  tation](https://
+00000630: 636f 6e76 6f6b 6974 2e63 6f72 6e65 6c6c  convokit.cornell
+00000640: 2e65 6475 2f64 6f63 756d 656e 7461 7469  .edu/documentati
+00000650: 6f6e 2920 6f72 2074 7279 2043 6f6e 766f  on) or try Convo
+00000660: 4b69 7420 696e 206f 7572 205b 696e 7465  Kit in our [inte
+00000670: 7261 6374 6976 6520 7475 746f 7269 616c  ractive tutorial
+00000680: 5d28 6874 7470 733a 2f2f 636f 6c61 622e  ](https://colab.
+00000690: 7265 7365 6172 6368 2e67 6f6f 676c 652e  research.google.
+000006a0: 636f 6d2f 6769 7468 7562 2f43 6f72 6e65  com/github/Corne
+000006b0: 6c6c 4e4c 502f 436f 6e76 6f4b 6974 2f62  llNLP/ConvoKit/b
+000006c0: 6c6f 622f 6d61 7374 6572 2f65 7861 6d70  lob/master/examp
+000006d0: 6c65 732f 496e 7472 6f64 7563 7469 6f6e  les/Introduction
+000006e0: 5f74 6f5f 436f 6e76 6f4b 6974 2e69 7079  _to_ConvoKit.ipy
+000006f0: 6e62 292e 0a0a 5468 6520 746f 6f6c 6b69  nb)...The toolki
+00000700: 7420 6375 7272 656e 746c 7920 696d 706c  t currently impl
+00000710: 656d 656e 7473 2066 6561 7475 7265 7320  ements features 
+00000720: 666f 723a 0a0a 2323 2320 5b4c 696e 6775  for:..### [Lingu
+00000730: 6973 7469 6320 636f 6f72 6469 6e61 7469  istic coordinati
+00000740: 6f6e 5d28 6874 7470 733a 2f2f 7777 772e  on](https://www.
+00000750: 6373 2e63 6f72 6e65 6c6c 2e65 6475 2f7e  cs.cornell.edu/~
+00000760: 6372 6973 7469 616e 2f45 6368 6f65 735f  cristian/Echoes_
+00000770: 6f66 5f70 6f77 6572 2e68 746d 6c29 203c  of_power.html) <
+00000780: 7375 623e 3c73 7570 3e5b 2841 5049 295d  sub><sup>[(API)]
+00000790: 2868 7474 7073 3a2f 2f63 6f6e 766f 6b69  (https://convoki
+000007a0: 742e 636f 726e 656c 6c2e 6564 752f 646f  t.cornell.edu/do
+000007b0: 6375 6d65 6e74 6174 696f 6e2f 636f 6f72  cumentation/coor
+000007c0: 6469 6e61 7469 6f6e 2e68 746d 6c29 3c2f  dination.html)</
+000007d0: 7375 703e 3c2f 7375 623e 0a0a 4120 6d65  sup></sub>..A me
+000007e0: 6173 7572 6520 6f66 206c 696e 6775 6973  asure of linguis
+000007f0: 7469 6320 696e 666c 7565 6e63 6520 2861  tic influence (a
+00000800: 6e64 2072 656c 6174 6976 6520 706f 7765  nd relative powe
+00000810: 7229 2062 6574 7765 656e 2069 6e64 6976  r) between indiv
+00000820: 6964 7561 6c73 206f 7220 6772 6f75 7073  iduals or groups
+00000830: 2062 6173 6564 206f 6e20 7468 6569 7220   based on their 
+00000840: 7573 6520 6f66 2066 756e 6374 696f 6e20  use of function 
+00000850: 776f 7264 732e 0a45 7861 6d70 6c65 3a20  words..Example: 
+00000860: 5b65 7870 6c6f 7269 6e67 2074 6865 2062  [exploring the b
+00000870: 616c 616e 6365 206f 6620 706f 7765 7220  alance of power 
+00000880: 696e 2074 6865 2055 2e53 2e20 5375 7072  in the U.S. Supr
+00000890: 656d 6520 436f 7572 745d 2868 7474 7073  eme Court](https
+000008a0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
+000008b0: 726e 656c 6c4e 4c50 2f43 6f6e 766f 4b69  rnellNLP/ConvoKi
+000008c0: 742f 626c 6f62 2f6d 6173 7465 722f 6578  t/blob/master/ex
+000008d0: 616d 706c 6573 2f63 6f6f 7264 696e 6174  amples/coordinat
+000008e0: 696f 6e2f 6578 616d 706c 6573 2e69 7079  ion/examples.ipy
+000008f0: 6e62 292e 0a0a 2323 2320 5b50 6f6c 6974  nb)...### [Polit
+00000900: 656e 6573 7320 7374 7261 7465 6769 6573  eness strategies
+00000910: 5d28 6874 7470 733a 2f2f 7777 772e 6373  ](https://www.cs
+00000920: 2e63 6f72 6e65 6c6c 2e65 6475 2f7e 6372  .cornell.edu/~cr
+00000930: 6973 7469 616e 2f50 6f6c 6974 656e 6573  istian/Politenes
+00000940: 732e 6874 6d6c 2920 3c73 7562 3e3c 7375  s.html) <sub><su
+00000950: 703e 5b28 4150 4929 5d28 6874 7470 733a  p>[(API)](https:
+00000960: 2f2f 636f 6e76 6f6b 6974 2e63 6f72 6e65  //convokit.corne
+00000970: 6c6c 2e65 6475 2f64 6f63 756d 656e 7461  ll.edu/documenta
+00000980: 7469 6f6e 2f70 6f6c 6974 656e 6573 7353  tion/politenessS
+00000990: 7472 6174 6567 6965 732e 6874 6d6c 293c  trategies.html)<
+000009a0: 2f73 7570 3e3c 2f73 7562 3e0a 0a41 2073  /sup></sub>..A s
+000009b0: 6574 206f 6620 6c65 7869 6361 6c20 616e  et of lexical an
+000009c0: 6420 7061 7273 652d 6261 7365 6420 6665  d parse-based fe
+000009d0: 6174 7572 6573 2063 6f72 7265 6c61 7469  atures correlati
+000009e0: 6e67 2077 6974 6820 706f 6c69 7465 6e65  ng with politene
+000009f0: 7373 2061 6e64 2069 6d70 6f6c 6974 656e  ss and impoliten
+00000a00: 6573 732e 0a45 7861 6d70 6c65 3a20 5b75  ess..Example: [u
+00000a10: 6e64 6572 7374 616e 6469 6e67 2074 6865  nderstanding the
+00000a20: 2028 6d69 7329 7573 6520 6f66 2070 6f6c   (mis)use of pol
+00000a30: 6974 656e 6573 7320 7374 7261 7465 6769  iteness strategi
+00000a40: 6573 2069 6e20 636f 6e76 6572 7361 7469  es in conversati
+00000a50: 6f6e 7320 676f 6e65 2061 7772 7920 6f6e  ons gone awry on
+00000a60: 2057 696b 6970 6564 6961 5d28 6874 7470   Wikipedia](http
+00000a70: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
+00000a80: 6f72 6e65 6c6c 4e4c 502f 436f 6e76 6f4b  ornellNLP/ConvoK
+00000a90: 6974 2f62 6c6f 622f 6d61 7374 6572 2f65  it/blob/master/e
+00000aa0: 7861 6d70 6c65 732f 636f 6e76 6572 7361  xamples/conversa
+00000ab0: 7469 6f6e 732d 676f 6e65 2d61 7772 792f  tions-gone-awry/
+00000ac0: 436f 6e76 6572 7361 7469 6f6e 735f 476f  Conversations_Go
+00000ad0: 6e65 5f41 7772 795f 5072 6564 6963 7469  ne_Awry_Predicti
+00000ae0: 6f6e 2e69 7079 6e62 292e 0a0a 2323 2320  on.ipynb)...### 
+00000af0: 5b45 7870 6563 7465 6420 436f 6e76 6572  [Expected Conver
+00000b00: 7361 7469 6f6e 616c 2043 6f6e 7465 7874  sational Context
+00000b10: 2046 7261 6d65 776f 726b 5d28 6874 7470   Framework](http
+00000b20: 733a 2f2f 7469 736a 756e 652e 6769 7468  s://tisjune.gith
+00000b30: 7562 2e69 6f2f 7265 7365 6172 6368 2f64  ub.io/research/d
+00000b40: 6973 7365 7274 6174 696f 6e29 203c 7375  issertation) <su
+00000b50: 623e 3c73 7570 3e5b 2841 5049 295d 2868  b><sup>[(API)](h
+00000b60: 7474 7073 3a2f 2f63 6f6e 766f 6b69 742e  ttps://convokit.
+00000b70: 636f 726e 656c 6c2e 6564 752f 646f 6375  cornell.edu/docu
+00000b80: 6d65 6e74 6174 696f 6e2f 6578 7065 6374  mentation/expect
+00000b90: 6564 5f63 6f6e 7465 7874 5f6d 6f64 656c  ed_context_model
+00000ba0: 2e68 746d 6c29 3c2f 7375 703e 3c2f 7375  .html)</sup></su
+00000bb0: 623e 0a0a 4120 6672 616d 6577 6f72 6b20  b>..A framework 
+00000bc0: 666f 7220 6368 6172 6163 7465 7269 7a69  for characterizi
+00000bd0: 6e67 2075 7474 6572 616e 6365 7320 616e  ng utterances an
+00000be0: 6420 7465 726d 7320 6261 7365 6420 6f6e  d terms based on
+00000bf0: 2074 6865 6972 2065 7870 6563 7465 6420   their expected 
+00000c00: 636f 6e76 6572 7361 7469 6f6e 616c 2063  conversational c
+00000c10: 6f6e 7465 7874 2c20 636f 6e73 6973 7469  ontext, consisti
+00000c20: 6e67 206f 6620 6d6f 6465 6c20 696d 706c  ng of model impl
+00000c30: 656d 656e 7461 7469 6f6e 7320 616e 6420  ementations and 
+00000c40: 7772 6170 7065 7220 7069 7065 6c69 6e65  wrapper pipeline
+00000c50: 732e 0a45 7861 6d70 6c65 733a 205b 6465  s..Examples: [de
+00000c60: 7269 7669 6e67 2071 7565 7374 696f 6e20  riving question 
+00000c70: 7479 7065 7320 616e 6420 6f74 6865 7220  types and other 
+00000c80: 6368 6172 6163 7465 7269 7a61 7469 6f6e  characterization
+00000c90: 7320 696e 2042 7269 7469 7368 2070 6172  s in British par
+00000ca0: 6c69 616d 656e 7461 7279 2071 7565 7374  liamentary quest
+00000cb0: 696f 6e20 7065 7269 6f64 735d 2868 7474  ion periods](htt
+00000cc0: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+00000cd0: 436f 726e 656c 6c4e 4c50 2f43 6f6e 766f  CornellNLP/Convo
+00000ce0: 4b69 742f 626c 6f62 2f6d 6173 7465 722f  Kit/blob/master/
+00000cf0: 636f 6e76 6f6b 6974 2f65 7870 6563 7465  convokit/expecte
+00000d00: 645f 636f 6e74 6578 745f 6672 616d 6577  d_context_framew
+00000d10: 6f72 6b2f 6465 6d6f 732f 7061 726c 6961  ork/demos/parlia
+00000d20: 6d65 6e74 5f64 656d 6f2e 6970 796e 6229  ment_demo.ipynb)
+00000d30: 2c0a 5b65 7870 6c6f 7261 7469 6f6e 206f  ,.[exploration o
+00000d40: 6620 5377 6974 6368 626f 6172 6420 6469  f Switchboard di
+00000d50: 616c 6f67 2061 6374 7320 636f 7270 7573  alog acts corpus
+00000d60: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
+00000d70: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
+00000d80: 436f 6e76 6f4b 6974 2f62 6c6f 622f 6d61  ConvoKit/blob/ma
+00000d90: 7374 6572 2f63 6f6e 766f 6b69 742f 6578  ster/convokit/ex
+00000da0: 7065 6374 6564 5f63 6f6e 7465 7874 5f66  pected_context_f
+00000db0: 7261 6d65 776f 726b 2f64 656d 6f73 2f73  ramework/demos/s
+00000dc0: 7769 7463 6862 6f61 7264 5f65 7870 6c6f  witchboard_explo
+00000dd0: 7261 7469 6f6e 5f64 656d 6f2e 6970 796e  ration_demo.ipyn
+00000de0: 6229 2c20 205b 6578 616d 696e 696e 6720  b),  [examining 
+00000df0: 5769 6b69 7065 6469 6120 7461 6c6b 2070  Wikipedia talk p
+00000e00: 6167 6520 6469 7363 7573 7369 6f6e 735d  age discussions]
+00000e10: 2868 7474 7073 3a2f 2f67 6974 6875 622e  (https://github.
+00000e20: 636f 6d2f 436f 726e 656c 6c4e 4c50 2f43  com/CornellNLP/C
+00000e30: 6f6e 766f 4b69 742f 626c 6f62 2f6d 6173  onvoKit/blob/mas
+00000e40: 7465 722f 636f 6e76 6f6b 6974 2f65 7870  ter/convokit/exp
+00000e50: 6563 7465 645f 636f 6e74 6578 745f 6672  ected_context_fr
+00000e60: 616d 6577 6f72 6b2f 6465 6d6f 732f 7769  amework/demos/wi
+00000e70: 6b69 5f61 7772 795f 6465 6d6f 2e69 7079  ki_awry_demo.ipy
+00000e80: 6e62 2920 616e 6420 5b63 6f6d 7075 7469  nb) and [computi
+00000e90: 6e67 2074 6865 206f 7269 656e 7461 7469  ng the orientati
+00000ea0: 6f6e 206f 6620 6a75 7374 6963 6520 7574  on of justice ut
+00000eb0: 7465 7261 6e63 6573 2069 6e20 7468 6520  terances in the 
+00000ec0: 5553 2053 7570 7265 6d65 2043 6f75 7274  US Supreme Court
+00000ed0: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
+00000ee0: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
+00000ef0: 436f 6e76 6f4b 6974 2f62 6c6f 622f 6d61  ConvoKit/blob/ma
+00000f00: 7374 6572 2f63 6f6e 766f 6b69 742f 6578  ster/convokit/ex
+00000f10: 7065 6374 6564 5f63 6f6e 7465 7874 5f66  pected_context_f
+00000f20: 7261 6d65 776f 726b 2f64 656d 6f73 2f73  ramework/demos/s
+00000f30: 636f 7475 735f 6f72 6965 6e74 6174 696f  cotus_orientatio
+00000f40: 6e5f 6465 6d6f 2e69 7079 6e62 290a 0a3c  n_demo.ipynb)..<
+00000f50: 212d 2d20 2323 2320 5b50 726f 6d70 7420  !-- ### [Prompt 
+00000f60: 7479 7065 735d 2868 7474 703a 2f2f 7777  types](http://ww
+00000f70: 772e 6373 2e63 6f72 6e65 6c6c 2e65 6475  w.cs.cornell.edu
+00000f80: 2f7e 6372 6973 7469 616e 2f41 736b 696e  /~cristian/Askin
+00000f90: 675f 746f 6f5f 6d75 6368 2e68 746d 6c29  g_too_much.html)
+00000fa0: 203c 7375 623e 3c73 7570 3e5b 2841 5049   <sub><sup>[(API
+00000fb0: 295d 2868 7474 7073 3a2f 2f63 6f6e 766f  )](https://convo
+00000fc0: 6b69 742e 636f 726e 656c 6c2e 6564 752f  kit.cornell.edu/
+00000fd0: 646f 6375 6d65 6e74 6174 696f 6e2f 7072  documentation/pr
+00000fe0: 6f6d 7074 5479 7065 732e 6874 6d6c 293c  omptTypes.html)<
+00000ff0: 2f73 7570 3e3c 2f73 7562 3e0a 0a41 6e20  /sup></sub>..An 
+00001000: 756e 7375 7065 7276 6973 6564 206d 6574  unsupervised met
+00001010: 686f 6420 666f 7220 6772 6f75 7069 6e67  hod for grouping
+00001020: 2075 7474 6572 616e 6365 7320 616e 6420   utterances and 
+00001030: 7574 7465 7261 6e63 6520 6665 6174 7572  utterance featur
+00001040: 6573 2062 7920 7468 6569 7220 7268 6574  es by their rhet
+00001050: 6f72 6963 616c 2072 6f6c 652e 0a45 7861  orical role..Exa
+00001060: 6d70 6c65 733a 205b 6578 7472 6163 7469  mples: [extracti
+00001070: 6e67 2071 7565 7374 696f 6e20 7479 7065  ng question type
+00001080: 7320 696e 2074 6865 2055 2e4b 2e20 7061  s in the U.K. pa
+00001090: 726c 6961 6d65 6e74 5d28 6874 7470 733a  rliament](https:
+000010a0: 2f2f 6769 7468 7562 2e63 6f6d 2f43 6f72  //github.com/Cor
+000010b0: 6e65 6c6c 4e4c 502f 436f 6e76 6f4b 6974  nellNLP/ConvoKit
+000010c0: 2f62 6c6f 622f 6d61 7374 6572 2f65 7861  /blob/master/exa
+000010d0: 6d70 6c65 732f 7072 6f6d 7074 2d74 7970  mples/prompt-typ
+000010e0: 6573 2f70 726f 6d70 742d 7479 7065 2d77  es/prompt-type-w
+000010f0: 7261 7070 6572 2d64 656d 6f2e 6970 796e  rapper-demo.ipyn
+00001100: 6229 2c20 5b65 7874 656e 6465 6420 7665  b), [extended ve
+00001110: 7273 696f 6e20 6465 6d6f 6e73 7472 6174  rsion demonstrat
+00001120: 696e 6720 6164 6469 7469 6f6e 616c 2066  ing additional f
+00001130: 756e 6374 696f 6e61 6c69 7479 5d28 6874  unctionality](ht
+00001140: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
+00001150: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 6e76  /CornellNLP/Conv
+00001160: 6f4b 6974 2f62 6c6f 622f 6d61 7374 6572  oKit/blob/master
+00001170: 2f65 7861 6d70 6c65 732f 7072 6f6d 7074  /examples/prompt
+00001180: 2d74 7970 6573 2f70 726f 6d70 742d 7479  -types/prompt-ty
+00001190: 7065 2d64 656d 6f2e 6970 796e 6229 2c20  pe-demo.ipynb), 
+000011a0: 5b75 6e64 6572 7374 616e 6469 6e67 2074  [understanding t
+000011b0: 6865 2075 7365 206f 6620 636f 6e76 6572  he use of conver
+000011c0: 7361 7469 6f6e 616c 2070 726f 6d70 7473  sational prompts
+000011d0: 2069 6e20 636f 6e76 6572 7361 7469 6f6e   in conversation
+000011e0: 7320 676f 6e65 2061 7772 7920 6f6e 2057  s gone awry on W
+000011f0: 696b 6970 6564 6961 5d28 6874 7470 733a  ikipedia](https:
+00001200: 2f2f 6769 7468 7562 2e63 6f6d 2f43 6f72  //github.com/Cor
+00001210: 6e65 6c6c 4e4c 502f 436f 6e76 6f4b 6974  nellNLP/ConvoKit
+00001220: 2f62 6c6f 622f 6d61 7374 6572 2f65 7861  /blob/master/exa
+00001230: 6d70 6c65 732f 636f 6e76 6572 7361 7469  mples/conversati
+00001240: 6f6e 732d 676f 6e65 2d61 7772 792f 436f  ons-gone-awry/Co
+00001250: 6e76 6572 7361 7469 6f6e 735f 476f 6e65  nversations_Gone
+00001260: 5f41 7772 795f 5072 6564 6963 7469 6f6e  _Awry_Prediction
+00001270: 2e69 7079 6e62 292e 0a0a 416c 736f 2069  .ipynb)...Also i
+00001280: 6e63 6c75 6465 7320 6675 6e63 7469 6f6e  ncludes function
+00001290: 616c 6974 7920 746f 2065 7874 7261 6374  ality to extract
+000012a0: 2073 7572 6661 6365 206d 6f74 6966 7320   surface motifs 
+000012b0: 746f 2072 6570 7265 7365 6e74 2075 7474  to represent utt
+000012c0: 6572 616e 6365 732c 2075 7365 6420 696e  erances, used in
+000012d0: 2074 6865 2061 626f 7665 2070 6170 6572   the above paper
+000012e0: 205b 2841 5049 295d 2868 7474 7073 3a2f   [(API)](https:/
+000012f0: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
+00001300: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
+00001310: 696f 6e2f 7068 7261 7369 6e67 4d6f 7469  ion/phrasingMoti
+00001320: 6673 2e68 746d 6c29 2e20 2d2d 3e0a 0a23  fs.html). -->..#
+00001330: 2323 205b 4879 7065 7267 7261 7068 2063  ## [Hypergraph c
+00001340: 6f6e 7665 7273 6174 696f 6e20 7265 7072  onversation repr
+00001350: 6573 656e 7461 7469 6f6e 5d28 6874 7470  esentation](http
+00001360: 3a2f 2f77 7777 2e63 732e 636f 726e 656c  ://www.cs.cornel
+00001370: 6c2e 6564 752f 7e63 7269 7374 6961 6e2f  l.edu/~cristian/
+00001380: 5061 7474 6572 6e73 5f6f 665f 7061 7274  Patterns_of_part
+00001390: 6963 6970 616e 745f 696e 7465 7261 6374  icipant_interact
+000013a0: 696f 6e73 2e68 746d 6c29 203c 7375 623e  ions.html) <sub>
+000013b0: 3c73 7570 3e5b 2841 5049 295d 2868 7474  <sup>[(API)](htt
+000013c0: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
+000013d0: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
+000013e0: 6e74 6174 696f 6e2f 6879 7065 7263 6f6e  ntation/hypercon
+000013f0: 766f 2e68 746d 6c29 3c2f 7375 703e 3c2f  vo.html)</sup></
+00001400: 7375 623e 0a41 206d 6574 686f 6420 666f  sub>.A method fo
+00001410: 7220 6578 7472 6163 7469 6e67 2073 7472  r extracting str
+00001420: 7563 7475 7261 6c20 6665 6174 7572 6573  uctural features
+00001430: 206f 6620 636f 6e76 6572 7361 7469 6f6e   of conversation
+00001440: 7320 7468 726f 7567 6820 6120 6879 7065  s through a hype
+00001450: 7267 7261 7068 2072 6570 7265 7365 6e74  rgraph represent
+00001460: 6174 696f 6e2e 0a45 7861 6d70 6c65 3a20  ation..Example: 
+00001470: 5b68 7970 6572 6772 6170 6820 6372 6561  [hypergraph crea
+00001480: 7469 6f6e 2061 6e64 2066 6561 7475 7265  tion and feature
+00001490: 2065 7874 7261 6374 696f 6e2c 2076 6973   extraction, vis
+000014a0: 7561 6c69 7a61 7469 6f6e 2061 6e64 2069  ualization and i
+000014b0: 6e74 6572 7072 6574 6174 696f 6e20 6f6e  nterpretation on
+000014c0: 2061 2073 7562 7361 6d70 6c65 206f 6620   a subsample of 
+000014d0: 5265 6464 6974 5d28 6874 7470 733a 2f2f  Reddit](https://
+000014e0: 6769 7468 7562 2e63 6f6d 2f43 6f72 6e65  github.com/Corne
+000014f0: 6c6c 4e4c 502f 436f 6e76 6f4b 6974 2f62  llNLP/ConvoKit/b
+00001500: 6c6f 622f 6d61 7374 6572 2f65 7861 6d70  lob/master/examp
+00001510: 6c65 732f 6879 7065 7263 6f6e 766f 2f64  les/hyperconvo/d
+00001520: 656d 6f5f 6e65 772e 6970 796e 6229 2e0a  emo_new.ipynb)..
+00001530: 0a23 2323 205b 4c69 6e67 7569 7374 6963  .### [Linguistic
+00001540: 2064 6976 6572 7369 7479 2069 6e20 636f   diversity in co
+00001550: 6e76 6572 7361 7469 6f6e 735d 2868 7474  nversations](htt
+00001560: 703a 2f2f 7777 772e 6373 2e63 6f72 6e65  p://www.cs.corne
+00001570: 6c6c 2e65 6475 2f7e 6372 6973 7469 616e  ll.edu/~cristian
+00001580: 2f46 696e 6469 6e67 5f79 6f75 725f 766f  /Finding_your_vo
+00001590: 6963 655f 5f6c 696e 6775 6973 7469 635f  ice__linguistic_
+000015a0: 6465 7665 6c6f 706d 656e 742e 6874 6d6c  development.html
+000015b0: 2920 3c73 7562 3e3c 7375 703e 5b28 4150  ) <sub><sup>[(AP
+000015c0: 4929 5d28 6874 7470 733a 2f2f 636f 6e76  I)](https://conv
+000015d0: 6f6b 6974 2e63 6f72 6e65 6c6c 2e65 6475  okit.cornell.edu
+000015e0: 2f64 6f63 756d 656e 7461 7469 6f6e 2f73  /documentation/s
+000015f0: 7065 616b 6572 436f 6e76 6f44 6976 6572  peakerConvoDiver
+00001600: 7369 7479 2e68 746d 6c29 3c2f 7375 703e  sity.html)</sup>
+00001610: 3c2f 7375 623e 0a41 206d 6574 686f 6420  </sub>.A method 
+00001620: 746f 2063 6f6d 7075 7465 2074 6865 206c  to compute the l
+00001630: 696e 6775 6973 7469 6320 6469 7665 7273  inguistic divers
+00001640: 6974 7920 6f66 2069 6e64 6976 6964 7561  ity of individua
+00001650: 6c73 2077 6974 6869 6e20 7468 6569 7220  ls within their 
+00001660: 6f77 6e20 636f 6e76 6572 7361 7469 6f6e  own conversation
+00001670: 732c 2061 6e64 2062 6574 7765 656e 206f  s, and between o
+00001680: 7468 6572 2069 6e64 6976 6964 7561 6c73  ther individuals
+00001690: 2069 6e20 6120 706f 7075 6c61 7469 6f6e   in a population
+000016a0: 2e0a 4578 616d 706c 653a 205b 7370 6561  ..Example: [spea
+000016b0: 6b65 7220 636f 6e76 6572 7361 7469 6f6e  ker conversation
+000016c0: 2061 7474 7269 6275 7465 7320 616e 6420   attributes and 
+000016d0: 6469 7665 7273 6974 7920 6578 616d 706c  diversity exampl
+000016e0: 6520 6f6e 2043 6861 6e67 654d 7956 6965  e on ChangeMyVie
+000016f0: 775d 2868 7474 7073 3a2f 2f67 6974 6875  w](https://githu
+00001700: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
+00001710: 2f43 6f6e 766f 4b69 742f 626c 6f62 2f6d  /ConvoKit/blob/m
+00001720: 6173 7465 722f 6578 616d 706c 6573 2f73  aster/examples/s
+00001730: 7065 616b 6572 2d63 6f6e 766f 2d61 7474  peaker-convo-att
+00001740: 7269 6275 7465 732f 7370 6561 6b65 722d  ributes/speaker-
+00001750: 636f 6e76 6f2d 6469 7665 7273 6974 792d  convo-diversity-
+00001760: 6465 6d6f 2e69 7079 6e62 290a 0a23 2323  demo.ipynb)..###
+00001770: 205b 4352 4146 543a 204f 6e6c 696e 6520   [CRAFT: Online 
+00001780: 666f 7265 6361 7374 696e 6720 6f66 2063  forecasting of c
+00001790: 6f6e 7665 7273 6174 696f 6e61 6c20 6f75  onversational ou
+000017a0: 7463 6f6d 6573 5d28 6874 7470 733a 2f2f  tcomes](https://
+000017b0: 6172 7869 762e 6f72 672f 6162 732f 3139  arxiv.org/abs/19
+000017c0: 3039 2e30 3133 3632 2920 3c73 7562 3e3c  09.01362) <sub><
+000017d0: 7375 703e 5b28 4150 4929 5d28 6874 7470  sup>[(API)](http
+000017e0: 733a 2f2f 636f 6e76 6f6b 6974 2e63 6f72  s://convokit.cor
+000017f0: 6e65 6c6c 2e65 6475 2f64 6f63 756d 656e  nell.edu/documen
+00001800: 7461 7469 6f6e 2f66 6f72 6563 6173 7465  tation/forecaste
+00001810: 722e 6874 6d6c 293c 2f73 7570 3e3c 2f73  r.html)</sup></s
+00001820: 7562 3e0a 4120 6e65 7572 616c 206d 6f64  ub>.A neural mod
+00001830: 656c 2066 6f72 2066 6f72 6563 6173 7469  el for forecasti
+00001840: 6e67 2066 7574 7572 6520 6f75 7463 6f6d  ng future outcom
+00001850: 6573 206f 6620 636f 6e76 6572 7361 7469  es of conversati
+00001860: 6f6e 7320 2865 2e67 2e2c 2064 6572 6169  ons (e.g., derai
+00001870: 6c6d 656e 7420 696e 746f 2070 6572 736f  lment into perso
+00001880: 6e61 6c20 6174 7461 636b 7329 2061 7320  nal attacks) as 
+00001890: 7468 6579 2064 6576 656c 6f70 2e0a 4176  they develop..Av
+000018a0: 6169 6c61 626c 6520 6173 2061 6e20 696e  ailable as an in
+000018b0: 7465 7261 6374 6976 6520 6e6f 7465 626f  teractive notebo
+000018c0: 6f6b 3a20 5b66 756c 6c20 7665 7273 696f  ok: [full versio
+000018d0: 6e20 2866 696e 652d 7475 6e69 6e67 202b  n (fine-tuning +
+000018e0: 2069 6e66 6572 656e 6365 295d 2868 7474   inference)](htt
+000018f0: 7073 3a2f 2f63 6f6c 6162 2e72 6573 6561  ps://colab.resea
+00001900: 7263 682e 676f 6f67 6c65 2e63 6f6d 2f64  rch.google.com/d
+00001910: 7269 7665 2f31 5348 3469 4d45 4864 6f48  rive/1SH4iMEHdoH
+00001920: 3449 6f76 4e2d 6239 514f 534b 346b 4734  4IovN-b9QOSK4kG4
+00001930: 4468 4177 6d62 2920 6f72 205b 696e 6665  DhAwmb) or [infe
+00001940: 7265 6e63 652d 6f6e 6c79 5d28 6874 7470  rence-only](http
+00001950: 733a 2f2f 636f 6c61 622e 7265 7365 6172  s://colab.resear
+00001960: 6368 2e67 6f6f 676c 652e 636f 6d2f 6472  ch.google.com/dr
+00001970: 6976 652f 3147 7649 435a 4e30 5677 5a51  ive/1GvICZN0VwZQ
+00001980: 5357 7733 704a 6145 5659 2d45 5147 6f4f  SWw3pJaEVY-EQGoO
+00001990: 2d4c 356c 4829 2e0a 0a0a 0a23 2320 4461  -L5lH).....## Da
+000019a0: 7461 7365 7473 0a43 6f6e 766f 4b69 7420  tasets.ConvoKit 
+000019b0: 7368 6970 7320 7769 7468 2073 6576 6572  ships with sever
+000019c0: 616c 2064 6174 6173 6574 7320 7265 6164  al datasets read
+000019d0: 7920 666f 7220 7573 6520 226f 7574 2d6f  y for use "out-o
+000019e0: 662d 7468 652d 626f 7822 2e0a 5468 6573  f-the-box"..Thes
+000019f0: 6520 6461 7461 7365 7473 2063 616e 2062  e datasets can b
+00001a00: 6520 646f 776e 6c6f 6164 6564 2075 7369  e downloaded usi
+00001a10: 6e67 2074 6865 2060 636f 6e76 6f6b 6974  ng the `convokit
+00001a20: 2e64 6f77 6e6c 6f61 6428 2960 205b 6865  .download()` [he
+00001a30: 6c70 6572 2066 756e 6374 696f 6e5d 2868  lper function](h
+00001a40: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
+00001a50: 6d2f 436f 726e 656c 6c4e 4c50 2f43 6f6e  m/CornellNLP/Con
+00001a60: 766f 4b69 742f 626c 6f62 2f6d 6173 7465  voKit/blob/maste
+00001a70: 722f 636f 6e76 6f6b 6974 2f75 7469 6c2e  r/convokit/util.
+00001a80: 7079 292e 2020 416c 7465 726e 6174 6976  py).  Alternativ
+00001a90: 656c 7920 796f 7520 6361 6e20 6163 6365  ely you can acce
+00001aa0: 7373 2074 6865 6d20 6469 7265 6374 6c79  ss them directly
+00001ab0: 205b 6865 7265 5d28 6874 7470 3a2f 2f7a   [here](http://z
+00001ac0: 6973 736f 752e 696e 666f 7363 692e 636f  issou.infosci.co
+00001ad0: 726e 656c 6c2e 6564 752f 636f 6e76 6f6b  rnell.edu/convok
+00001ae0: 6974 2f64 6174 6173 6574 732f 292e 0a0a  it/datasets/)...
+00001af0: 2323 2320 5b43 6f6e 7665 7273 6174 696f  ### [Conversatio
+00001b00: 6e73 2047 6f6e 6520 4177 7279 2044 6174  ns Gone Awry Dat
+00001b10: 6173 6574 5d28 6874 7470 733a 2f2f 636f  aset](https://co
+00001b20: 6e76 6f6b 6974 2e63 6f72 6e65 6c6c 2e65  nvokit.cornell.e
+00001b30: 6475 2f64 6f63 756d 656e 7461 7469 6f6e  du/documentation
+00001b40: 2f61 7772 792e 6874 6d6c 290a 0a54 776f  /awry.html)..Two
+00001b50: 2072 656c 6174 6564 2063 6f72 706f 7261   related corpora
+00001b60: 206f 6620 636f 6e76 6572 7361 7469 6f6e   of conversation
+00001b70: 7320 7468 6174 2064 6572 6169 6c20 696e  s that derail in
+00001b80: 746f 2061 6e74 6973 6f63 6961 6c20 6265  to antisocial be
+00001b90: 6861 7669 6f72 2e20 4f6e 6520 636f 7270  havior. One corp
+00001ba0: 7573 2063 6f6e 7369 7374 7320 6f66 2057  us consists of W
+00001bb0: 696b 6970 6564 6961 2074 616c 6b20 7061  ikipedia talk pa
+00001bc0: 6765 2063 6f6e 7665 7273 6174 696f 6e73  ge conversations
+00001bd0: 2074 6861 7420 6465 7261 696c 2069 6e74   that derail int
+00001be0: 6f20 7065 7273 6f6e 616c 2061 7474 6163  o personal attac
+00001bf0: 6b73 2061 7320 6c61 6265 6c65 6420 6279  ks as labeled by
+00001c00: 2063 726f 7764 776f 726b 6572 7320 2834   crowdworkers (4
+00001c10: 2c31 3838 2063 6f6e 7665 7273 6174 696f  ,188 conversatio
+00001c20: 6e73 2063 6f6e 7461 696e 696e 6720 3330  ns containing 30
+00001c30: 2e30 3231 2063 6f6d 6d65 6e74 7329 2e20  .021 comments). 
+00001c40: 5468 6520 6f74 6865 7220 636f 6e73 6973  The other consis
+00001c50: 7473 206f 6620 6469 7363 7573 7369 6f6e  ts of discussion
+00001c60: 2074 6872 6561 6473 206f 6e20 7468 6520   threads on the 
+00001c70: 7375 6272 6564 6469 7420 4368 616e 6765  subreddit Change
+00001c80: 4d79 5669 6577 2028 434d 5629 2074 6861  MyView (CMV) tha
+00001c90: 7420 6465 7261 696c 2069 6e74 6f20 7275  t derail into ru
+00001ca0: 6c65 2d76 696f 6c61 7469 6e67 2062 6568  le-violating beh
+00001cb0: 6176 696f 7220 6173 2064 6574 6572 6d69  avior as determi
+00001cc0: 6e65 6420 6279 2074 6865 2070 7265 7365  ned by the prese
+00001cd0: 6e63 6520 6f66 2061 206d 6f64 6572 6174  nce of a moderat
+00001ce0: 6f72 2069 6e74 6572 7665 6e74 696f 6e20  or intervention 
+00001cf0: 2836 2c38 3432 2063 6f6e 7665 7273 6174  (6,842 conversat
+00001d00: 696f 6e73 2063 6f6e 7461 696e 696e 6720  ions containing 
+00001d10: 3432 2c39 3634 2063 6f6d 6d65 6e74 7329  42,964 comments)
+00001d20: 2e0a 4e61 6d65 2066 6f72 2064 6f77 6e6c  ..Name for downl
+00001d30: 6f61 643a 2060 636f 6e76 6572 7361 7469  oad: `conversati
+00001d40: 6f6e 732d 676f 6e65 2d61 7772 792d 636f  ons-gone-awry-co
+00001d50: 7270 7573 6020 2857 696b 6970 6564 6961  rpus` (Wikipedia
+00001d60: 2076 6572 7369 6f6e 2920 6f72 2060 636f   version) or `co
+00001d70: 6e76 6572 7361 7469 6f6e 732d 676f 6e65  nversations-gone
+00001d80: 2d61 7772 792d 636d 762d 636f 7270 7573  -awry-cmv-corpus
+00001d90: 6020 2852 6564 6469 7420 434d 5620 7665  ` (Reddit CMV ve
+00001da0: 7273 696f 6e29 0a0a 2323 2320 5b43 6f72  rsion)..### [Cor
+00001db0: 6e65 6c6c 204d 6f76 6965 2d44 6961 6c6f  nell Movie-Dialo
+00001dc0: 6773 2043 6f72 7075 735d 2868 7474 7073  gs Corpus](https
+00001dd0: 3a2f 2f63 6f6e 766f 6b69 742e 636f 726e  ://convokit.corn
+00001de0: 656c 6c2e 6564 752f 646f 6375 6d65 6e74  ell.edu/document
+00001df0: 6174 696f 6e2f 6d6f 7669 652e 6874 6d6c  ation/movie.html
+00001e00: 290a 0a41 206c 6172 6765 206d 6574 6164  )..A large metad
+00001e10: 6174 612d 7269 6368 2063 6f6c 6c65 6374  ata-rich collect
+00001e20: 696f 6e20 6f66 2066 6963 7469 6f6e 616c  ion of fictional
+00001e30: 2063 6f6e 7665 7273 6174 696f 6e73 2065   conversations e
+00001e40: 7874 7261 6374 6564 2066 726f 6d20 7261  xtracted from ra
+00001e50: 7720 6d6f 7669 6520 7363 7269 7074 732e  w movie scripts.
+00001e60: 2028 3232 302c 3537 3920 636f 6e76 6572   (220,579 conver
+00001e70: 7361 7469 6f6e 616c 2065 7863 6861 6e67  sational exchang
+00001e80: 6573 2062 6574 7765 656e 2031 302c 3239  es between 10,29
+00001e90: 3220 7061 6972 7320 6f66 206d 6f76 6965  2 pairs of movie
+00001ea0: 2063 6861 7261 6374 6572 7320 696e 2036   characters in 6
+00001eb0: 3137 206d 6f76 6965 7329 2e0a 4e61 6d65  17 movies)..Name
+00001ec0: 2066 6f72 2064 6f77 6e6c 6f61 643a 2060   for download: `
+00001ed0: 6d6f 7669 652d 636f 7270 7573 600a 0a23  movie-corpus`..#
+00001ee0: 2323 205b 5061 726c 6961 6d65 6e74 2051  ## [Parliament Q
+00001ef0: 7565 7374 696f 6e20 5469 6d65 2043 6f72  uestion Time Cor
+00001f00: 7075 735d 2868 7474 7073 3a2f 2f63 6f6e  pus](https://con
+00001f10: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
+00001f20: 752f 646f 6375 6d65 6e74 6174 696f 6e2f  u/documentation/
+00001f30: 7061 726c 6961 6d65 6e74 2e68 746d 6c29  parliament.html)
+00001f40: 0a0a 5061 726c 6961 6d65 6e74 6172 7920  ..Parliamentary 
+00001f50: 7175 6573 7469 6f6e 2070 6572 696f 6473  question periods
+00001f60: 2066 726f 6d20 4d61 7920 3139 3739 2074   from May 1979 t
+00001f70: 6f20 4465 6365 6d62 6572 2032 3031 3620  o December 2016 
+00001f80: 2832 3136 2c38 3934 2071 7565 7374 696f  (216,894 questio
+00001f90: 6e2d 616e 7377 6572 2070 6169 7273 292e  n-answer pairs).
+00001fa0: 0a4e 616d 6520 666f 7220 646f 776e 6c6f  .Name for downlo
+00001fb0: 6164 3a20 6070 6172 6c69 616d 656e 742d  ad: `parliament-
+00001fc0: 636f 7270 7573 600a 0a23 2323 205b 5375  corpus`..### [Su
+00001fd0: 7072 656d 6520 436f 7572 7420 436f 7270  preme Court Corp
+00001fe0: 7573 5d28 6874 7470 733a 2f2f 636f 6e76  us](https://conv
+00001ff0: 6f6b 6974 2e63 6f72 6e65 6c6c 2e65 6475  okit.cornell.edu
+00002000: 2f64 6f63 756d 656e 7461 7469 6f6e 2f73  /documentation/s
+00002010: 7570 7265 6d65 2e68 746d 6c29 0a0a 4120  upreme.html)..A 
+00002020: 636f 6c6c 6563 7469 6f6e 206f 6620 636f  collection of co
+00002030: 6e76 6572 7361 7469 6f6e 7320 6672 6f6d  nversations from
+00002040: 2074 6865 2055 2e53 2e20 5375 7072 656d   the U.S. Suprem
+00002050: 6520 436f 7572 7420 4f72 616c 2041 7267  e Court Oral Arg
+00002060: 756d 656e 7473 2e0a 4e61 6d65 2066 6f72  uments..Name for
+00002070: 2064 6f77 6e6c 6f61 643a 2060 7375 7072   download: `supr
+00002080: 656d 652d 636f 7270 7573 600a 0a23 2323  eme-corpus`..###
+00002090: 205b 5769 6b69 7065 6469 6120 5461 6c6b   [Wikipedia Talk
+000020a0: 2050 6167 6573 2043 6f72 7075 735d 2868   Pages Corpus](h
+000020b0: 7474 7073 3a2f 2f63 6f6e 766f 6b69 742e  ttps://convokit.
+000020c0: 636f 726e 656c 6c2e 6564 752f 646f 6375  cornell.edu/docu
+000020d0: 6d65 6e74 6174 696f 6e2f 7769 6b69 2e68  mentation/wiki.h
+000020e0: 746d 6c29 0a0a 4120 6d65 6469 756d 2d73  tml)..A medium-s
+000020f0: 697a 6520 636f 6c6c 6563 7469 6f6e 206f  ize collection o
+00002100: 6620 636f 6e76 6572 7361 7469 6f6e 7320  f conversations 
+00002110: 6672 6f6d 2057 696b 6970 6564 6961 2065  from Wikipedia e
+00002120: 6469 746f 7273 2720 7461 6c6b 2070 6167  ditors' talk pag
+00002130: 6573 2e0a 4e61 6d65 2066 6f72 2064 6f77  es..Name for dow
+00002140: 6e6c 6f61 643a 2060 7769 6b69 2d63 6f72  nload: `wiki-cor
+00002150: 7075 7360 0a0a 2323 2320 5b54 656e 6e69  pus`..### [Tenni
+00002160: 7320 496e 7465 7276 6965 7773 5d28 6874  s Interviews](ht
+00002170: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
+00002180: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
+00002190: 656e 7461 7469 6f6e 2f74 656e 6e69 732e  entation/tennis.
+000021a0: 6874 6d6c 290a 0a54 7261 6e73 6372 6970  html)..Transcrip
+000021b0: 7473 2066 6f72 2074 656e 6e69 7320 7369  ts for tennis si
+000021c0: 6e67 6c65 7320 706f 7374 2d6d 6174 6368  ngles post-match
+000021d0: 2070 7265 7373 2063 6f6e 6665 7265 6e63   press conferenc
+000021e0: 6573 2066 6f72 206d 616a 6f72 2074 6f75  es for major tou
+000021f0: 726e 616d 656e 7473 2062 6574 7765 656e  rnaments between
+00002200: 2032 3030 3720 746f 2032 3031 3520 2836   2007 to 2015 (6
+00002210: 2c34 3637 2070 6f73 742d 6d61 7463 6820  ,467 post-match 
+00002220: 7072 6573 7320 636f 6e66 6572 656e 6365  press conference
+00002230: 7329 2e0a 4e61 6d65 2066 6f72 2064 6f77  s)..Name for dow
+00002240: 6e6c 6f61 643a 2060 7465 6e6e 6973 2d63  nload: `tennis-c
+00002250: 6f72 7075 7360 0a0a 2323 2320 5b52 6564  orpus`..### [Red
+00002260: 6469 7420 436f 7270 7573 5d28 6874 7470  dit Corpus](http
+00002270: 733a 2f2f 636f 6e76 6f6b 6974 2e63 6f72  s://convokit.cor
+00002280: 6e65 6c6c 2e65 6475 2f64 6f63 756d 656e  nell.edu/documen
+00002290: 7461 7469 6f6e 2f73 7562 7265 6464 6974  tation/subreddit
+000022a0: 2e68 746d 6c29 0a0a 5265 6464 6974 2063  .html)..Reddit c
+000022b0: 6f6e 7665 7273 6174 696f 6e73 2066 726f  onversations fro
+000022c0: 6d20 6f76 6572 2039 3030 6b20 7375 6272  m over 900k subr
+000022d0: 6564 6469 7473 2c20 6172 7261 6e67 6564  eddits, arranged
+000022e0: 2062 7920 7375 6272 6564 6469 742e 2041   by subreddit. A
+000022f0: 205b 736d 616c 6c20 7375 6273 6574 5d28   [small subset](
+00002300: 6874 7470 733a 2f2f 636f 6e76 6f6b 6974  https://convokit
+00002310: 2e63 6f72 6e65 6c6c 2e65 6475 2f64 6f63  .cornell.edu/doc
+00002320: 756d 656e 7461 7469 6f6e 2f72 6564 6469  umentation/reddi
+00002330: 742d 736d 616c 6c2e 6874 6d6c 2920 7361  t-small.html) sa
+00002340: 6d70 6c65 6420 6672 6f6d 2031 3030 2068  mpled from 100 h
+00002350: 6967 686c 7920 6163 7469 7665 2073 7562  ighly active sub
+00002360: 7265 6464 6974 7320 6973 2061 6c73 6f20  reddits is also 
+00002370: 6176 6169 6c61 626c 652e 0a0a 4e61 6d65  available...Name
+00002380: 2066 6f72 2064 6f77 6e6c 6f61 643a 2060   for download: `
+00002390: 7375 6272 6564 6469 742d 3c6e 616d 655f  subreddit-<name_
+000023a0: 6f66 5f73 7562 7265 6464 6974 3e60 2066  of_subreddit>` f
+000023b0: 6f72 2074 6865 2062 792d 7375 6272 6564  or the by-subred
+000023c0: 6469 7420 6461 7461 2c20 6072 6564 6469  dit data, `reddi
+000023d0: 742d 636f 7270 7573 2d73 6d61 6c6c 6020  t-corpus-small` 
+000023e0: 666f 7220 7468 6520 736d 616c 6c20 7375  for the small su
+000023f0: 6273 6574 2e0a 0a23 2323 205b 5769 6b69  bset...### [Wiki
+00002400: 436f 6e76 2043 6f72 7075 735d 2868 7474  Conv Corpus](htt
+00002410: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
+00002420: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
+00002430: 6e74 6174 696f 6e2f 7769 6b69 636f 6e76  ntation/wikiconv
+00002440: 2e68 746d 6c29 0a0a 5468 6520 6675 6c6c  .html)..The full
+00002450: 2063 6f72 7075 7320 6f66 2057 696b 6970   corpus of Wikip
+00002460: 6564 6961 2074 616c 6b20 7061 6765 2063  edia talk page c
+00002470: 6f6e 7665 7273 6174 696f 6e73 2c20 6261  onversations, ba
+00002480: 7365 6420 6f6e 2074 6865 2072 6563 6f6e  sed on the recon
+00002490: 7374 7275 6374 696f 6e20 6465 7363 7269  struction descri
+000024a0: 6265 6420 696e 205b 7468 6973 2070 6170  bed in [this pap
+000024b0: 6572 5d28 6874 7470 3a2f 2f77 7777 2e63  er](http://www.c
+000024c0: 732e 636f 726e 656c 6c2e 6564 752f 7e63  s.cornell.edu/~c
+000024d0: 7269 7374 6961 6e2f 696e 6465 785f 6669  ristian/index_fi
+000024e0: 6c65 732f 7769 6b69 636f 6e76 2d63 6f6e  les/wikiconv-con
+000024f0: 7665 7273 6174 696f 6e2d 636f 7270 7573  versation-corpus
+00002500: 2e70 6466 292e 0a4e 6f74 6520 7468 6174  .pdf)..Note that
+00002510: 2064 7565 2074 6f20 7468 6520 6c61 7267   due to the larg
+00002520: 6520 7369 7a65 206f 6620 7468 6520 6461  e size of the da
+00002530: 7461 2c20 6974 2069 7320 7370 6c69 7420  ta, it is split 
+00002540: 7570 2062 7920 7965 6172 2e0a 5765 2073  up by year..We s
+00002550: 6570 6172 6174 656c 7920 7072 6f76 6964  eparately provid
+00002560: 6520 5b62 6c6f 636b 2064 6174 6120 7265  e [block data re
+00002570: 7472 6965 7665 6420 6469 7265 6374 6c79  trieved directly
+00002580: 2066 726f 6d20 7468 6520 5769 6b69 7065   from the Wikipe
+00002590: 6469 6120 626c 6f63 6b20 6c6f 675d 2868  dia block log](h
+000025a0: 7474 7073 3a2f 2f7a 6973 736f 752e 696e  ttps://zissou.in
+000025b0: 666f 7363 692e 636f 726e 656c 6c2e 6564  fosci.cornell.ed
+000025c0: 752f 636f 6e76 6f6b 6974 2f64 6174 6173  u/convokit/datas
+000025d0: 6574 732f 7769 6b69 636f 6e76 2d63 6f72  ets/wikiconv-cor
+000025e0: 7075 732f 626c 6f63 6b73 2e6a 736f 6e29  pus/blocks.json)
+000025f0: 2c20 666f 7220 7265 7072 6f64 7563 696e  , for reproducin
+00002600: 6720 7468 6520 5b54 7261 6a65 6374 6f72  g the [Trajector
+00002610: 6965 7320 6f66 2042 6c6f 636b 6564 2043  ies of Blocked C
+00002620: 6f6d 6d75 6e69 7479 204d 656d 6265 7273  ommunity Members
+00002630: 5d28 6874 7470 3a2f 2f77 7777 2e63 732e  ](http://www.cs.
+00002640: 636f 726e 656c 6c2e 6564 752f 7e63 7269  cornell.edu/~cri
+00002650: 7374 6961 6e2f 5265 6369 6469 7669 736d  stian/Recidivism
+00002660: 5f6f 6e6c 696e 655f 6669 6c65 732f 7265  _online_files/re
+00002670: 6369 6469 7669 736d 5f6f 6e6c 696e 652e  cidivism_online.
+00002680: 7064 6629 2070 6170 6572 2e0a 0a4e 616d  pdf) paper...Nam
+00002690: 6520 666f 7220 646f 776e 6c6f 6164 3a20  e for download: 
+000026a0: 6077 696b 6963 6f6e 762d 3c79 6561 723e  `wikiconv-<year>
+000026b0: 6020 746f 2064 6f77 6e6c 6f61 6420 7769  ` to download wi
+000026c0: 6b69 636f 6e76 2064 6174 6120 666f 7220  kiconv data for 
+000026d0: 7468 6520 7370 6563 6966 6965 6420 7965  the specified ye
+000026e0: 6172 2e0a 0a23 2323 205b 4368 726f 6d69  ar...### [Chromi
+000026f0: 756d 2043 6f6e 7665 7273 6174 696f 6e73  um Conversations
+00002700: 2043 6f72 7075 735d 2868 7474 7073 3a2f   Corpus](https:/
+00002710: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
+00002720: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
+00002730: 696f 6e2f 6368 726f 6d69 756d 2e68 746d  ion/chromium.htm
+00002740: 6c29 0a0a 4120 636f 6c6c 6563 7469 6f6e  l)..A collection
+00002750: 206f 6620 616c 6d6f 7374 2031 2e35 206d   of almost 1.5 m
+00002760: 696c 6c69 6f6e 2063 6f6e 7665 7273 6174  illion conversat
+00002770: 696f 6e73 2061 6e64 2032 2e38 206d 696c  ions and 2.8 mil
+00002780: 6c69 6f6e 2063 6f6d 6d65 6e74 7320 706f  lion comments po
+00002790: 7374 6564 2062 7920 6465 7665 6c6f 7065  sted by develope
+000027a0: 7273 2072 6576 6965 7769 6e67 2070 726f  rs reviewing pro
+000027b0: 706f 7365 6420 636f 6465 2063 6861 6e67  posed code chang
+000027c0: 6573 2069 6e20 7468 6520 4368 726f 6d69  es in the Chromi
+000027d0: 756d 2070 726f 6a65 6374 2e0a 0a4e 616d  um project...Nam
+000027e0: 6520 666f 7220 646f 776e 6c6f 6164 3a20  e for download: 
+000027f0: 6063 6872 6f6d 6975 6d2d 636f 7270 7573  `chromium-corpus
+00002800: 600a 0a23 2323 205b 5769 6e6e 696e 6720  `..### [Winning 
+00002810: 4172 6775 6d65 6e74 7320 436f 7270 7573  Arguments Corpus
+00002820: 5d28 6874 7470 733a 2f2f 636f 6e76 6f6b  ](https://convok
+00002830: 6974 2e63 6f72 6e65 6c6c 2e65 6475 2f64  it.cornell.edu/d
+00002840: 6f63 756d 656e 7461 7469 6f6e 2f77 696e  ocumentation/win
+00002850: 6e69 6e67 2e68 746d 6c29 0a0a 4120 6d65  ning.html)..A me
+00002860: 7461 6461 7461 2d72 6963 6820 7375 6273  tadata-rich subs
+00002870: 6574 206f 6620 636f 6e76 6572 7361 7469  et of conversati
+00002880: 6f6e 7320 6d61 6465 2069 6e20 7468 6520  ons made in the 
+00002890: 722f 4368 616e 6765 4d79 5669 6577 2073  r/ChangeMyView s
+000028a0: 7562 7265 6464 6974 2062 6574 7765 656e  ubreddit between
+000028b0: 2031 204a 616e 2032 3031 3320 2d20 3720   1 Jan 2013 - 7 
+000028c0: 4d61 7920 3230 3135 2c20 7769 7468 2069  May 2015, with i
+000028d0: 6e66 6f72 6d61 7469 6f6e 206f 6e20 7468  nformation on th
+000028e0: 6520 6465 6c74 6120 2873 7563 6365 7373  e delta (success
+000028f0: 2920 6f66 2061 2073 7065 616b 6572 2773  ) of a speaker's
+00002900: 2075 7474 6572 616e 6365 2069 6e20 636f   utterance in co
+00002910: 6e76 696e 6369 6e67 2074 6865 2070 6f73  nvincing the pos
+00002920: 7465 722e 0a0a 4e61 6d65 2066 6f72 2064  ter...Name for d
+00002930: 6f77 6e6c 6f61 643a 2060 7769 6e6e 696e  ownload: `winnin
+00002940: 672d 6172 6773 2d63 6f72 7075 7360 0a0a  g-args-corpus`..
+00002950: 2323 2320 5b43 6f61 7273 6520 4469 7363  ### [Coarse Disc
+00002960: 6f75 7273 6520 436f 7270 7573 5d28 6874  ourse Corpus](ht
+00002970: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
+00002980: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
+00002990: 656e 7461 7469 6f6e 2f63 6f61 7273 6544  entation/coarseD
+000029a0: 6973 636f 7572 7365 2e68 746d 6c29 0a0a  iscourse.html)..
+000029b0: 4120 7375 6273 6574 206f 6620 5265 6464  A subset of Redd
+000029c0: 6974 2063 6f6e 7665 7273 6174 696f 6e73  it conversations
+000029d0: 2074 6861 7420 6861 7665 2062 6565 6e20   that have been 
+000029e0: 6d61 6e75 616c 6c79 2061 6e6e 6f74 6174  manually annotat
+000029f0: 6564 2077 6974 6820 6469 7363 6f75 7273  ed with discours
+00002a00: 6520 6163 7420 6c61 6265 6c73 2e0a 0a4e  e act labels...N
+00002a10: 616d 6520 666f 7220 646f 776e 6c6f 6164  ame for download
+00002a20: 3a20 6072 6564 6469 742d 636f 6172 7365  : `reddit-coarse
+00002a30: 2d64 6973 636f 7572 7365 2d63 6f72 7075  -discourse-corpu
+00002a40: 7360 0a0a 2323 2320 5b50 6572 7375 6173  s`..### [Persuas
+00002a50: 696f 6e20 466f 7220 476f 6f64 2043 6f72  ion For Good Cor
+00002a60: 7075 735d 2868 7474 7073 3a2f 2f63 6f6e  pus](https://con
+00002a70: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
+00002a80: 752f 646f 6375 6d65 6e74 6174 696f 6e2f  u/documentation/
+00002a90: 7065 7273 7561 7369 6f6e 666f 7267 6f6f  persuasionforgoo
+00002aa0: 642e 6874 6d6c 290a 0a41 2063 6f6c 6c65  d.html)..A colle
+00002ab0: 6374 696f 6e20 6f66 206f 6e6c 696e 6520  ction of online 
+00002ac0: 636f 6e76 6572 7361 7469 6f6e 7320 6765  conversations ge
+00002ad0: 6e65 7261 7465 6420 6279 2041 6d61 7a6f  nerated by Amazo
+00002ae0: 6e20 4d65 6368 616e 6963 616c 2054 7572  n Mechanical Tur
+00002af0: 6b20 776f 726b 6572 732c 2077 6865 7265  k workers, where
+00002b00: 206f 6e65 2070 6172 7469 6369 7061 6e74   one participant
+00002b10: 2028 7468 6520 2a70 6572 7375 6164 6572   (the *persuader
+00002b20: 2a29 2074 7269 6573 2074 6f20 636f 6e76  *) tries to conv
+00002b30: 696e 6365 2074 6865 206f 7468 6572 2028  ince the other (
+00002b40: 7468 6520 2a70 6572 7375 6164 6565 2a29  the *persuadee*)
+00002b50: 2074 6f20 646f 6e61 7465 2074 6f20 6120   to donate to a 
+00002b60: 6368 6172 6974 792e 0a0a 4e61 6d65 2066  charity...Name f
+00002b70: 6f72 2064 6f77 6e6c 6f61 643a 2060 7065  or download: `pe
+00002b80: 7273 7561 7369 6f6e 666f 7267 6f6f 642d  rsuasionforgood-
+00002b90: 636f 7270 7573 600a 0a23 2323 205b 496e  corpus`..### [In
+00002ba0: 7465 6c6c 6967 656e 6365 2053 7175 6172  telligence Squar
+00002bb0: 6564 2044 6562 6174 6573 2043 6f72 7075  ed Debates Corpu
+00002bc0: 735d 2868 7474 7073 3a2f 2f63 6f6e 766f  s](https://convo
+00002bd0: 6b69 742e 636f 726e 656c 6c2e 6564 752f  kit.cornell.edu/
+00002be0: 646f 6375 6d65 6e74 6174 696f 6e2f 6971  documentation/iq
+00002bf0: 322e 6874 6d6c 290a 0a54 7261 6e73 6372  2.html)..Transcr
+00002c00: 6970 7473 206f 6620 6465 6261 7465 7320  ipts of debates 
+00002c10: 6865 6c64 2061 7320 7061 7274 206f 6620  held as part of 
+00002c20: 496e 7465 6c6c 6967 656e 6365 2053 7175  Intelligence Squ
+00002c30: 6172 6564 2044 6562 6174 6573 2e0a 0a4e  ared Debates...N
+00002c40: 616d 6520 666f 7220 646f 776e 6c6f 6164  ame for download
+00002c50: 3a20 6069 7132 2d63 6f72 7075 7360 0a0a  : `iq2-corpus`..
+00002c60: 2323 2320 5b46 7269 656e 6473 2043 6f72  ### [Friends Cor
+00002c70: 7075 735d 2868 7474 7073 3a2f 2f63 6f6e  pus](https://con
+00002c80: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
+00002c90: 752f 646f 6375 6d65 6e74 6174 696f 6e2f  u/documentation/
+00002ca0: 6672 6965 6e64 732e 6874 6d6c 290a 0a41  friends.html)..A
+00002cb0: 2063 6f6c 6c65 6374 696f 6e20 6f66 2061   collection of a
+00002cc0: 6c6c 2074 6865 2063 6f6e 7665 7273 6174  ll the conversat
+00002cd0: 696f 6e73 2074 6861 7420 6f63 6375 7272  ions that occurr
+00002ce0: 6564 206f 7665 7220 3130 2073 6561 736f  ed over 10 seaso
+00002cf0: 6e73 206f 6620 4672 6965 6e64 732c 2061  ns of Friends, a
+00002d00: 2070 6f70 756c 6172 2041 6d65 7269 6361   popular America
+00002d10: 6e20 5456 2073 6974 636f 6d20 7468 6174  n TV sitcom that
+00002d20: 2072 616e 2069 6e20 7468 6520 3139 3930   ran in the 1990
+00002d30: 732e 0a0a 4e61 6d65 2066 6f72 2064 6f77  s...Name for dow
+00002d40: 6e6c 6f61 643a 2060 6672 6965 6e64 732d  nload: `friends-
+00002d50: 636f 7270 7573 600a 0a23 2323 205b 5377  corpus`..### [Sw
+00002d60: 6974 6368 626f 6172 6420 4469 616c 6f67  itchboard Dialog
+00002d70: 2041 6374 2043 6f72 7075 735d 2868 7474   Act Corpus](htt
+00002d80: 7073 3a2f 2f63 6f6e 766f 6b69 742e 636f  ps://convokit.co
+00002d90: 726e 656c 6c2e 6564 752f 646f 6375 6d65  rnell.edu/docume
+00002da0: 6e74 6174 696f 6e2f 7377 6974 6368 626f  ntation/switchbo
+00002db0: 6172 642e 6874 6d6c 290a 0a41 2063 6f6c  ard.html)..A col
+00002dc0: 6c65 6374 696f 6e20 6f66 2031 2c31 3535  lection of 1,155
+00002dd0: 2066 6976 652d 6d69 6e75 7465 2074 656c   five-minute tel
+00002de0: 6570 686f 6e65 2063 6f6e 7665 7273 6174  ephone conversat
+00002df0: 696f 6e73 2062 6574 7765 656e 2074 776f  ions between two
+00002e00: 2070 6172 7469 6369 7061 6e74 732c 2061   participants, a
+00002e10: 6e6e 6f74 6174 6564 2077 6974 6820 7370  nnotated with sp
+00002e20: 6565 6368 2061 6374 2074 6167 732e 0a0a  eech act tags...
+00002e30: 4e61 6d65 2066 6f72 2064 6f77 6e6c 6f61  Name for downloa
+00002e40: 643a 2060 7377 6974 6368 626f 6172 642d  d: `switchboard-
+00002e50: 636f 7270 7573 600a 0a23 2323 2053 7461  corpus`..### Sta
+00002e60: 6e66 6f72 6420 506f 6c69 7465 6e65 7373  nford Politeness
+00002e70: 2043 6f72 7075 7320 285b 5769 6b69 7065   Corpus ([Wikipe
+00002e80: 6469 615d 2868 7474 7073 3a2f 2f63 6f6e  dia](https://con
+00002e90: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
+00002ea0: 752f 646f 6375 6d65 6e74 6174 696f 6e2f  u/documentation/
+00002eb0: 7769 6b69 5f70 6f6c 6974 656e 6573 732e  wiki_politeness.
+00002ec0: 6874 6d6c 292f 5b53 7461 636b 2045 7863  html)/[Stack Exc
+00002ed0: 6861 6e67 655d 2868 7474 7073 3a2f 2f63  hange](https://c
+00002ee0: 6f6e 766f 6b69 742e 636f 726e 656c 6c2e  onvokit.cornell.
+00002ef0: 6564 752f 646f 6375 6d65 6e74 6174 696f  edu/documentatio
+00002f00: 6e2f 7374 6163 6b5f 706f 6c69 7465 6e65  n/stack_politene
+00002f10: 7373 2e68 746d 6c29 290a 0a54 776f 2063  ss.html))..Two c
+00002f20: 6f6c 6c65 6374 696f 6e73 206f 6620 7265  ollections of re
+00002f30: 7175 6573 7473 2028 6672 6f6d 2057 696b  quests (from Wik
+00002f40: 6970 6564 6961 2061 6e64 2053 7461 636b  ipedia and Stack
+00002f50: 2045 7863 6861 6e67 6520 7265 7370 6563   Exchange respec
+00002f60: 7469 7665 6c79 2920 7769 7468 2070 6f6c  tively) with pol
+00002f70: 6974 656e 6573 7320 616e 6e6f 7461 7469  iteness annotati
+00002f80: 6f6e 732e 204e 616d 6520 666f 7220 646f  ons. Name for do
+00002f90: 776e 6c6f 6164 3a20 6077 696b 6970 6564  wnload: `wikiped
+00002fa0: 6961 2d70 6f6c 6974 656e 6573 732d 636f  ia-politeness-co
+00002fb0: 7270 7573 6020 2857 696b 6970 6564 6961  rpus` (Wikipedia
+00002fc0: 2070 6f72 7469 6f6e 292c 2060 7374 6163   portion), `stac
+00002fd0: 6b2d 6578 6368 616e 6765 2d70 6f6c 6974  k-exchange-polit
+00002fe0: 656e 6573 732d 636f 7270 7573 6020 2853  eness-corpus` (S
+00002ff0: 7461 636b 2045 7863 6861 6e67 6520 706f  tack Exchange po
+00003000: 7274 696f 6e29 2e0a 0a23 2323 205b 4465  rtion)...### [De
+00003010: 6365 7074 696f 6e20 696e 2044 6970 6c6f  ception in Diplo
+00003020: 6d61 6379 2043 6f6e 7665 7273 6174 696f  macy Conversatio
+00003030: 6e73 5d28 6874 7470 733a 2f2f 636f 6e76  ns](https://conv
+00003040: 6f6b 6974 2e63 6f72 6e65 6c6c 2e65 6475  okit.cornell.edu
+00003050: 2f64 6f63 756d 656e 7461 7469 6f6e 2f64  /documentation/d
+00003060: 6970 6c6f 6d61 6379 2e68 746d 6c29 0a0a  iplomacy.html)..
+00003070: 436f 6e76 6572 7361 7469 6f6e 616c 2064  Conversational d
+00003080: 6174 6173 6574 2077 6974 6820 696e 7465  ataset with inte
+00003090: 6e64 6564 2061 6e64 2070 6572 6365 6976  nded and perceiv
+000030a0: 6564 2064 6563 6570 7469 6f6e 206c 6162  ed deception lab
+000030b0: 656c 732e 204f 7665 7220 3137 2c30 3030  els. Over 17,000
+000030c0: 206d 6573 7361 6765 7320 616e 6e6f 7461   messages annota
+000030d0: 7465 6420 6279 2074 6865 2073 656e 6465  ted by the sende
+000030e0: 7220 666f 7220 7468 6569 7220 696e 7465  r for their inte
+000030f0: 6e64 6564 2074 7275 7468 6675 6c6e 6573  nded truthfulnes
+00003100: 7320 616e 6420 6279 2074 6865 2072 6563  s and by the rec
+00003110: 6569 7665 7220 666f 7220 7468 6569 7220  eiver for their 
+00003120: 7065 7263 6569 7665 6420 7472 7574 6866  perceived truthf
+00003130: 756c 6e65 7373 2e0a 0a4e 616d 6520 666f  ulness...Name fo
+00003140: 7220 646f 776e 6c6f 6164 3a20 6064 6970  r download: `dip
+00003150: 6c6f 6d61 6379 2d63 6f72 7075 7360 0a0a  lomacy-corpus`..
+00003160: 2323 2320 5b47 726f 7570 2041 6666 6563  ### [Group Affec
+00003170: 7420 616e 6420 5065 7266 6f72 6d61 6e63  t and Performanc
+00003180: 6520 2847 4150 2920 436f 7270 7573 5d28  e (GAP) Corpus](
+00003190: 6874 7470 733a 2f2f 636f 6e76 6f6b 6974  https://convokit
+000031a0: 2e63 6f72 6e65 6c6c 2e65 6475 2f64 6f63  .cornell.edu/doc
+000031b0: 756d 656e 7461 7469 6f6e 2f67 6170 2e68  umentation/gap.h
+000031c0: 746d 6c29 0a0a 4120 636f 6e76 6572 7361  tml)..A conversa
+000031d0: 7469 6f6e 616c 2064 6174 6173 6574 2063  tional dataset c
+000031e0: 6f6d 7072 6973 696e 6720 6772 6f75 7020  omprising group 
+000031f0: 6d65 6574 696e 6773 206f 6620 7477 6f20  meetings of two 
+00003200: 746f 2066 6f75 7220 7061 7274 6963 6970  to four particip
+00003210: 616e 7473 2074 6861 7420 6465 6c69 6265  ants that delibe
+00003220: 7261 7465 2069 6e20 6120 6772 6f75 7020  rate in a group 
+00003230: 6465 6369 7369 6f6e 2d6d 616b 696e 6720  decision-making 
+00003240: 6578 6572 6369 7365 2e20 5468 6973 2064  exercise. This d
+00003250: 6174 6173 6574 2063 6f6e 7461 696e 7320  ataset contains 
+00003260: 3238 2067 726f 7570 206d 6565 7469 6e67  28 group meeting
+00003270: 7320 7769 7468 2061 2074 6f74 616c 206f  s with a total o
+00003280: 6620 3834 2070 6172 7469 6369 7061 6e74  f 84 participant
+00003290: 732e 0a0a 4e61 6d65 2066 6f72 2064 6f77  s...Name for dow
+000032a0: 6e6c 6f61 643a 2060 6761 702d 636f 7270  nload: `gap-corp
+000032b0: 7573 600a 0a23 2323 205b 5769 6b69 7065  us`..### [Wikipe
+000032c0: 6469 6120 4172 7469 636c 6573 2066 6f72  dia Articles for
+000032d0: 2044 656c 6574 696f 6e20 436f 7270 7573   Deletion Corpus
+000032e0: 5d28 6874 7470 733a 2f2f 636f 6e76 6f6b  ](https://convok
+000032f0: 6974 2e63 6f72 6e65 6c6c 2e65 6475 2f64  it.cornell.edu/d
+00003300: 6f63 756d 656e 7461 7469 6f6e 2f77 696b  ocumentation/wik
+00003310: 692d 6172 7469 636c 6573 2d66 6f72 2d64  i-articles-for-d
+00003320: 656c 6574 696f 6e2d 636f 7270 7573 2e68  eletion-corpus.h
+00003330: 746d 6c29 0a0a 4120 636f 6c6c 6563 7469  tml)..A collecti
+00003340: 6f6e 206f 6620 5769 6b69 7065 6469 6127  on of Wikipedia'
+00003350: 7320 4172 7469 636c 6573 2066 6f72 2044  s Articles for D
+00003360: 656c 6574 696f 6e20 6564 6974 6f72 2064  eletion editor d
+00003370: 6562 6174 6573 2074 6861 7420 6f63 6375  ebates that occu
+00003380: 7272 6564 2062 6574 7765 656e 204a 616e  rred between Jan
+00003390: 7561 7279 2031 2c20 3230 3035 2061 6e64  uary 1, 2005 and
+000033a0: 2044 6563 656d 6265 7220 3331 2c20 3230   December 31, 20
+000033b0: 3138 2e20 5468 6973 2063 6f72 7075 7320  18. This corpus 
+000033c0: 636f 6e74 6169 6e73 2061 626f 7574 2033  contains about 3
+000033d0: 2c32 3030 2c30 3030 2063 6f6e 7472 6962  ,200,000 contrib
+000033e0: 7574 696f 6e73 2062 7920 6170 7072 6f78  utions by approx
+000033f0: 696d 6174 656c 7920 3135 302c 3030 3020  imately 150,000 
+00003400: 5769 6b69 7065 6469 6120 6564 6974 6f72  Wikipedia editor
+00003410: 7320 6163 726f 7373 2061 6c6d 6f73 7420  s across almost 
+00003420: 3430 302c 3030 3020 6465 6261 7465 732e  400,000 debates.
+00003430: 0a0a 4e61 6d65 2066 6f72 2064 6f77 6e6c  ..Name for downl
+00003440: 6f61 643a 2060 7769 6b69 2d61 7274 6963  oad: `wiki-artic
+00003450: 6c65 732d 666f 722d 6465 6c65 7469 6f6e  les-for-deletion
+00003460: 2d63 6f72 7075 7360 0a0a 2323 2320 5b43  -corpus`..### [C
+00003470: 6153 694e 6f20 436f 7270 7573 5d28 6874  aSiNo Corpus](ht
+00003480: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
+00003490: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
+000034a0: 656e 7461 7469 6f6e 2f63 6173 696e 6f2d  entation/casino-
+000034b0: 636f 7270 7573 2e68 746d 6c29 0a43 6153  corpus.html).CaS
+000034c0: 694e 6f20 2873 7461 6e64 7320 666f 7220  iNo (stands for 
+000034d0: 4361 6d70 5369 7465 204e 6567 6f74 6961  CampSite Negotia
+000034e0: 7469 6f6e 7329 2069 7320 6120 6e6f 7665  tions) is a nove
+000034f0: 6c20 6461 7461 7365 7420 6f66 2031 3033  l dataset of 103
+00003500: 3020 6e65 676f 7469 6174 696f 6e20 6469  0 negotiation di
+00003510: 616c 6f67 7565 732e 2054 776f 2070 6172  alogues. Two par
+00003520: 7469 6369 7061 6e74 7320 7461 6b65 2074  ticipants take t
+00003530: 6865 2072 6f6c 6520 6f66 2063 616d 7073  he role of camps
+00003540: 6974 6520 6e65 6967 6862 6f72 7320 616e  ite neighbors an
+00003550: 6420 6e65 676f 7469 6174 6520 666f 7220  d negotiate for 
+00003560: 466f 6f64 2c20 5761 7465 722c 2061 6e64  Food, Water, and
+00003570: 2046 6972 6577 6f6f 6420 7061 636b 6167   Firewood packag
+00003580: 6573 2c20 6261 7365 6420 6f6e 2074 6865  es, based on the
+00003590: 6972 2069 6e64 6976 6964 7561 6c20 7072  ir individual pr
+000035a0: 6566 6572 656e 6365 7320 616e 6420 7265  eferences and re
+000035b0: 7175 6972 656d 656e 7473 2e0a 0a4e 616d  quirements...Nam
+000035c0: 6520 666f 7220 646f 776e 6c6f 6164 3a20  e for download: 
+000035d0: 6063 6173 696e 6f2d 636f 7270 7573 600a  `casino-corpus`.
+000035e0: 0a23 2323 205b 5350 4f4c 494e 2043 6f72  .### [SPOLIN Cor
+000035f0: 7075 735d 2868 7474 7073 3a2f 2f63 6f6e  pus](https://con
+00003600: 766f 6b69 742e 636f 726e 656c 6c2e 6564  vokit.cornell.ed
+00003610: 752f 646f 6375 6d65 6e74 6174 696f 6e2f  u/documentation/
+00003620: 7370 6f6c 696e 2e68 746d 6c29 0a53 656c  spolin.html).Sel
+00003630: 6563 7465 6420 5061 6972 7320 6f66 204c  ected Pairs of L
+00003640: 6561 726e 6162 6c65 2049 6d70 726f 7669  earnable Improvi
+00003650: 7361 7469 6f4e 2028 5350 4f4c 494e 2920  satioN (SPOLIN) 
+00003660: 6973 2061 2063 6f6c 6c65 6374 696f 6e20  is a collection 
+00003670: 6f66 206d 6f72 6520 7468 616e 2036 382c  of more than 68,
+00003680: 3030 3020 2259 6573 2c20 616e 6422 2074  000 "Yes, and" t
+00003690: 7970 6520 7574 7465 7261 6e63 6520 7061  ype utterance pa
+000036a0: 6972 7320 6578 7472 6163 7465 6420 6672  irs extracted fr
+000036b0: 6f6d 2074 6865 206c 6f6e 672d 666f 726d  om the long-form
+000036c0: 2069 6d70 726f 7669 7361 7469 6f6e 2070   improvisation p
+000036d0: 6f64 6361 7374 2053 706f 6e74 616e 6561  odcast Spontanea
+000036e0: 6e61 7469 6f6e 2062 7920 5061 756c 2046  nation by Paul F
+000036f0: 2e20 546f 6d70 6b69 6e73 2c20 7468 6520  . Tompkins, the 
+00003700: 436f 726e 656c 6c20 4d6f 7669 652d 4469  Cornell Movie-Di
+00003710: 616c 6f67 7320 436f 7270 7573 2c20 616e  alogs Corpus, an
+00003720: 6420 7468 6520 5375 6254 6c65 2063 6f72  d the SubTle cor
+00003730: 7075 732e 0a0a 4e61 6d65 2066 6f72 2064  pus...Name for d
+00003740: 6f77 6e6c 6f61 643a 2060 7370 6f6c 696e  ownload: `spolin
+00003750: 2d63 6f72 7075 7360 0a0a 2323 2320 2e2e  -corpus`..### ..
+00003760: 2e41 6e64 2079 6f75 7220 6f77 6e20 636f  .And your own co
+00003770: 7270 7573 210a 0a49 6e20 6164 6469 7469  rpus!..In additi
+00003780: 6f6e 2074 6f20 7468 6520 7072 6f76 6964  on to the provid
+00003790: 6564 2064 6174 6173 6574 732c 2079 6f75  ed datasets, you
+000037a0: 206d 6179 2061 6c73 6f20 7573 6520 436f   may also use Co
+000037b0: 6e76 6f4b 6974 2077 6974 6820 796f 7572  nvoKit with your
+000037c0: 206f 776e 2063 7573 746f 6d20 6461 7461   own custom data
+000037d0: 7365 7473 2062 7920 6c6f 6164 696e 6720  sets by loading 
+000037e0: 7468 656d 2069 6e74 6f20 6120 6063 6f6e  them into a `con
+000037f0: 766f 6b69 742e 436f 7270 7573 6020 6f62  vokit.Corpus` ob
+00003800: 6a65 6374 2e20 5b54 6869 7320 6578 616d  ject. [This exam
+00003810: 706c 6520 7363 7269 7074 5d28 6874 7470  ple script](http
+00003820: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
+00003830: 6f72 6e65 6c6c 4e4c 502f 436f 6e76 6f4b  ornellNLP/ConvoK
+00003840: 6974 2f62 6c6f 622f 6d61 7374 6572 2f65  it/blob/master/e
+00003850: 7861 6d70 6c65 732f 636f 6e76 6572 7469  xamples/converti
+00003860: 6e67 5f6d 6f76 6965 5f63 6f72 7075 732e  ng_movie_corpus.
+00003870: 6970 796e 6229 2073 686f 7773 2068 6f77  ipynb) shows how
+00003880: 2074 6f20 636f 6e73 7472 7563 7420 6120   to construct a 
+00003890: 436f 7270 7573 2066 726f 6d20 6375 7374  Corpus from cust
+000038a0: 6f6d 2064 6174 612e 0a0a 2323 2049 6e73  om data...## Ins
+000038b0: 7461 6c6c 6174 696f 6e0a 5468 6973 2074  tallation.This t
+000038c0: 6f6f 6c6b 6974 2072 6571 7569 7265 7320  oolkit requires 
+000038d0: 5079 7468 6f6e 203e 3d20 332e 382e 0a0a  Python >= 3.8...
+000038e0: 312e 2044 6f77 6e6c 6f61 6420 7468 6520  1. Download the 
+000038f0: 746f 6f6c 6b69 743a 2060 7069 7033 2069  toolkit: `pip3 i
+00003900: 6e73 7461 6c6c 2063 6f6e 766f 6b69 7460  nstall convokit`
+00003910: 0a32 2e20 446f 776e 6c6f 6164 2053 7061  .2. Download Spa
+00003920: 6379 2773 2045 6e67 6c69 7368 206d 6f64  cy's English mod
+00003930: 656c 3a20 6070 7974 686f 6e33 202d 6d20  el: `python3 -m 
+00003940: 7370 6163 7920 646f 776e 6c6f 6164 2065  spacy download e
+00003950: 6e60 0a33 2e20 446f 776e 6c6f 6164 204e  n`.3. Download N
+00003960: 4c54 4b27 7320 2770 756e 6b74 2720 6d6f  LTK's 'punkt' mo
+00003970: 6465 6c3a 2060 696d 706f 7274 206e 6c74  del: `import nlt
+00003980: 6b3b 206e 6c74 6b2e 646f 776e 6c6f 6164  k; nltk.download
+00003990: 2827 7075 6e6b 7427 2960 2028 696e 2050  ('punkt')` (in P
+000039a0: 7974 686f 6e20 696e 7465 7270 7265 7465  ython interprete
+000039b0: 7229 0a0a 416c 7465 726e 6174 6976 656c  r)..Alternativel
+000039c0: 792c 2076 6973 6974 206f 7572 205b 4769  y, visit our [Gi
+000039d0: 7468 7562 2050 6167 655d 2868 7474 7073  thub Page](https
+000039e0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
+000039f0: 726e 656c 6c4e 4c50 2f43 6f6e 766f 4b69  rnellNLP/ConvoKi
+00003a00: 7429 2074 6f20 696e 7374 616c 6c20 6672  t) to install fr
+00003a10: 6f6d 2073 6f75 7263 652e 0a0a 2a2a 4966  om source...**If
+00003a20: 2079 6f75 2065 6e63 6f75 6e74 6572 2064   you encounter d
+00003a30: 6966 6669 6375 6c74 6965 7320 7769 7468  ifficulties with
+00003a40: 2069 6e73 7461 6c6c 6174 696f 6e2a 2a2c   installation**,
+00003a50: 2063 6865 636b 206f 7574 206f 7572 202a   check out our *
+00003a60: 2a5b 5472 6f75 626c 6573 686f 6f74 696e  *[Troubleshootin
+00003a70: 6720 4775 6964 655d 2868 7474 7073 3a2f  g Guide](https:/
+00003a80: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
+00003a90: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
+00003aa0: 696f 6e2f 7472 6f75 626c 6573 686f 6f74  ion/troubleshoot
+00003ab0: 696e 672e 6874 6d6c 292a 2a20 666f 7220  ing.html)** for 
+00003ac0: 6120 6c69 7374 206f 6620 736f 6c75 7469  a list of soluti
+00003ad0: 6f6e 7320 746f 2063 6f6d 6d6f 6e20 6973  ons to common is
+00003ae0: 7375 6573 2e0a 0a23 2320 446f 6375 6d65  sues...## Docume
+00003af0: 6e74 6174 696f 6e0a 446f 6375 6d65 6e74  ntation.Document
+00003b00: 6174 696f 6e20 6973 2068 6f73 7465 6420  ation is hosted 
+00003b10: 5b68 6572 655d 2868 7474 7073 3a2f 2f63  [here](https://c
+00003b20: 6f6e 766f 6b69 742e 636f 726e 656c 6c2e  onvokit.cornell.
+00003b30: 6564 752f 646f 6375 6d65 6e74 6174 696f  edu/documentatio
+00003b40: 6e2f 292e 2049 6620 796f 7520 6172 6520  n/). If you are 
+00003b50: 6e65 7720 746f 2043 6f6e 766f 4b69 742c  new to ConvoKit,
+00003b60: 2067 7265 6174 2070 6c61 6365 7320 746f   great places to
+00003b70: 2067 6574 2073 7461 7274 6564 2061 7265   get started are
+00003b80: 2074 6865 205b 436f 7265 2043 6f6e 6365   the [Core Conce
+00003b90: 7074 7320 7475 746f 7269 616c 5d28 6874  pts tutorial](ht
+00003ba0: 7470 733a 2f2f 636f 6e76 6f6b 6974 2e63  tps://convokit.c
+00003bb0: 6f72 6e65 6c6c 2e65 6475 2f64 6f63 756d  ornell.edu/docum
+00003bc0: 656e 7461 7469 6f6e 2f61 7263 6869 7465  entation/archite
+00003bd0: 6374 7572 652e 6874 6d6c 2920 666f 7220  cture.html) for 
+00003be0: 616e 206f 7665 7276 6965 7720 6f66 2074  an overview of t
+00003bf0: 6865 2043 6f6e 766f 4b69 7420 2270 6869  he ConvoKit "phi
+00003c00: 6c6f 736f 7068 7922 2061 6e64 206f 626a  losophy" and obj
+00003c10: 6563 7420 6d6f 6465 6c2c 2061 6e64 2074  ect model, and t
+00003c20: 6865 205b 4869 6768 2d6c 6576 656c 2074  he [High-level t
+00003c30: 7574 6f72 6961 6c5d 2868 7474 7073 3a2f  utorial](https:/
+00003c40: 2f63 6f6e 766f 6b69 742e 636f 726e 656c  /convokit.cornel
+00003c50: 6c2e 6564 752f 646f 6375 6d65 6e74 6174  l.edu/documentat
+00003c60: 696f 6e2f 7475 746f 7269 616c 2e68 746d  ion/tutorial.htm
+00003c70: 6c29 2066 6f72 2061 2077 616c 6b74 6872  l) for a walkthr
+00003c80: 6f75 6768 206f 6620 686f 7720 746f 2069  ough of how to i
+00003c90: 6d70 6f72 7420 436f 6e76 6f4b 6974 2069  mport ConvoKit i
+00003ca0: 6e74 6f20 796f 7572 2070 726f 6a65 6374  nto your project
+00003cb0: 2c20 6c6f 6164 2061 2043 6f72 7075 732c  , load a Corpus,
+00003cc0: 2061 6e64 2075 7365 2043 6f6e 766f 4b69   and use ConvoKi
+00003cd0: 7420 6675 6e63 7469 6f6e 732e 0a0a 466f  t functions...Fo
+00003ce0: 7220 616e 206f 7665 7276 6965 772c 2077  r an overview, w
+00003cf0: 6174 6368 206f 7572 2053 4947 4449 414c  atch our SIGDIAL
+00003d00: 2074 616c 6b20 696e 7472 6f64 7563 696e   talk introducin
+00003d10: 6720 7468 6520 746f 6f6c 6b69 743a 0a5b  g the toolkit:.[
+00003d20: 215b 5349 4744 4941 4c20 3230 3230 3a20  ![SIGDIAL 2020: 
+00003d30: 496e 7472 6f64 7563 696e 6720 436f 6e76  Introducing Conv
+00003d40: 6f4b 6974 5d28 6874 7470 3a2f 2f69 332e  oKit](http://i3.
+00003d50: 7974 696d 672e 636f 6d2f 7669 2f6e 6f66  ytimg.com/vi/nof
+00003d60: 7a79 784d 3468 316b 2f68 7164 6566 6175  zyxM4h1k/hqdefau
+00003d70: 6c74 2e6a 7067 295d 2868 7474 7073 3a2f  lt.jpg)](https:/
+00003d80: 2f79 6f75 7475 2e62 652f 6e6f 667a 7978  /youtu.be/nofzyx
+00003d90: 4d34 6831 6b20 2253 4947 4449 414c 2032  M4h1k "SIGDIAL 2
+00003da0: 3032 303a 2049 6e74 726f 6475 6369 6e67  020: Introducing
+00003db0: 2043 6f6e 766f 4b69 7422 290a 0a23 2320   ConvoKit")..## 
+00003dc0: 436f 6e74 7269 6275 7469 6e67 0a0a 5765  Contributing..We
+00003dd0: 2077 656c 636f 6d65 2063 6f6d 6d75 6e69   welcome communi
+00003de0: 7479 2063 6f6e 7472 6962 7574 696f 6e73  ty contributions
+00003df0: 2e20 546f 2073 6565 2068 6f77 2079 6f75  . To see how you
+00003e00: 2063 616e 2068 656c 7020 6f75 742c 2063   can help out, c
+00003e10: 6865 636b 2074 6865 205b 636f 6e74 7269  heck the [contri
+00003e20: 6275 7469 6f6e 2067 7569 6465 6c69 6e65  bution guideline
+00003e30: 735d 2868 7474 7073 3a2f 2f67 6974 6875  s](https://githu
+00003e40: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
+00003e50: 2f43 6f6e 766f 4b69 742f 626c 6f62 2f6d  /ConvoKit/blob/m
+00003e60: 6173 7465 722f 434f 4e54 5249 4255 5449  aster/CONTRIBUTI
+00003e70: 4e47 2e6d 6429 2e0a 0a23 2320 4369 7469  NG.md)...## Citi
+00003e80: 6e67 0a0a 4966 2079 6f75 2075 7365 2074  ng..If you use t
+00003e90: 6865 2063 6f64 6520 6f72 2064 6174 6173  he code or datas
+00003ea0: 6574 7320 6469 7374 7269 6275 7465 6420  ets distributed 
+00003eb0: 7769 7468 2043 6f6e 766f 4b69 7420 706c  with ConvoKit pl
+00003ec0: 6561 7365 2061 636b 6e6f 776c 6564 6765  ease acknowledge
+00003ed0: 2074 6865 2077 6f72 6b20 7469 6564 2074   the work tied t
+00003ee0: 6f20 7468 6520 7265 7370 6563 7469 7665  o the respective
+00003ef0: 2063 6f6d 706f 6e65 6e74 2028 696e 6469   component (indi
+00003f00: 6361 7465 6420 696e 2074 6865 2064 6f63  cated in the doc
+00003f10: 756d 656e 7461 7469 6f6e 2920 696e 2061  umentation) in a
+00003f20: 6464 6974 696f 6e20 746f 3a0a 0a4a 6f6e  ddition to:..Jon
+00003f30: 6174 6861 6e20 502e 2043 6861 6e67 2c20  athan P. Chang, 
+00003f40: 4361 6c65 6220 4368 6961 6d2c 204c 6979  Caleb Chiam, Liy
+00003f50: 6520 4675 2c20 416e 6472 6577 2057 616e  e Fu, Andrew Wan
+00003f60: 672c 204a 7573 7469 6e65 205a 6861 6e67  g, Justine Zhang
+00003f70: 2c20 4372 6973 7469 616e 2044 616e 6573  , Cristian Danes
+00003f80: 6375 2d4e 6963 756c 6573 6375 2d4d 697a  cu-Niculescu-Miz
+00003f90: 696c 2e20 3230 3230 2e20 225b 436f 6e76  il. 2020. "[Conv
+00003fa0: 6f4b 6974 3a20 4120 546f 6f6c 6b69 7420  oKit: A Toolkit 
+00003fb0: 666f 7220 7468 6520 416e 616c 7973 6973  for the Analysis
+00003fc0: 206f 6620 436f 6e76 6572 7361 7469 6f6e   of Conversation
+00003fd0: 735d 2868 7474 7073 3a2f 2f77 7777 2e63  s](https://www.c
+00003fe0: 732e 636f 726e 656c 6c2e 6564 752f 7e63  s.cornell.edu/~c
+00003ff0: 7269 7374 6961 6e2f 436f 6e76 6f4b 6974  ristian/ConvoKit
+00004000: 5f44 656d 6f5f 5061 7065 725f 6669 6c65  _Demo_Paper_file
+00004010: 732f 636f 6e76 6f6b 6974 2d64 656d 6f2d  s/convokit-demo-
+00004020: 7061 7065 722e 7064 6629 222e 2050 726f  paper.pdf)". Pro
+00004030: 6365 6564 696e 6773 206f 6620 5349 4744  ceedings of SIGD
+00004040: 4941 4c2e 0a0a 5b43 6f6e 766f 4b69 745d  IAL...[ConvoKit]
+00004050: 2868 7474 703a 2f2f 636f 6e76 6f6b 6974  (http://convokit
+00004060: 2e63 6f72 6e65 6c6c 2e65 6475 2f29 0a0a  .cornell.edu/)..
+00004070: 2323 2043 6f6e 7472 6962 7574 6f72 7320  ## Contributors 
+00004080: e29c a80a 0a54 6861 6e6b 7320 676f 6573  .....Thanks goes
+00004090: 2074 6f20 7468 6573 6520 776f 6e64 6572   to these wonder
+000040a0: 6675 6c20 7065 6f70 6c65 2028 5b65 6d6f  ful people ([emo
+000040b0: 6a69 206b 6579 5d28 6874 7470 733a 2f2f  ji key](https://
+000040c0: 616c 6c63 6f6e 7472 6962 7574 6f72 732e  allcontributors.
+000040d0: 6f72 672f 646f 6373 2f65 6e2f 656d 6f6a  org/docs/en/emoj
+000040e0: 692d 6b65 7929 293a 0a0a 3c21 2d2d 2041  i-key)):..<!-- A
+000040f0: 4c4c 2d43 4f4e 5452 4942 5554 4f52 532d  LL-CONTRIBUTORS-
+00004100: 4c49 5354 3a53 5441 5254 202d 2044 6f20  LIST:START - Do 
+00004110: 6e6f 7420 7265 6d6f 7665 206f 7220 6d6f  not remove or mo
+00004120: 6469 6679 2074 6869 7320 7365 6374 696f  dify this sectio
+00004130: 6e20 2d2d 3e0a 3c21 2d2d 2070 7265 7474  n -->.<!-- prett
+00004140: 6965 722d 6967 6e6f 7265 2d73 7461 7274  ier-ignore-start
+00004150: 202d 2d3e 0a3c 212d 2d20 6d61 726b 646f   -->.<!-- markdo
+00004160: 776e 6c69 6e74 2d64 6973 6162 6c65 202d  wnlint-disable -
+00004170: 2d3e 0a3c 7461 626c 653e 0a20 203c 7462  ->.<table>.  <tb
+00004180: 6f64 793e 0a20 2020 203c 7472 3e0a 2020  ody>.    <tr>.  
+00004190: 2020 2020 3c74 6420 616c 6967 6e3d 2263      <td align="c
+000041a0: 656e 7465 7222 2076 616c 6967 6e3d 2274  enter" valign="t
+000041b0: 6f70 2220 7769 6474 683d 2231 342e 3238  op" width="14.28
+000041c0: 2522 3e3c 6120 6872 6566 3d22 6874 7470  %"><a href="http
+000041d0: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f63  s://github.com/c
+000041e0: 7269 7374 6961 6e64 6e6d 223e 3c69 6d67  ristiandnm"><img
+000041f0: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
+00004200: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
+00004210: 636f 6e74 656e 742e 636f 6d2f 752f 3837  content.com/u/87
+00004220: 3030 3536 333f 763d 343f 733d 3130 3022  00563?v=4?s=100"
+00004230: 2077 6964 7468 3d22 3130 3070 783b 2220   width="100px;" 
+00004240: 616c 743d 2243 7269 7374 6961 6e20 4461  alt="Cristian Da
+00004250: 6e65 7363 752d 4e69 6375 6c65 7363 752d  nescu-Niculescu-
+00004260: 4d69 7a69 6c22 2f3e 3c62 7220 2f3e 3c73  Mizil"/><br /><s
+00004270: 7562 3e3c 623e 4372 6973 7469 616e 2044  ub><b>Cristian D
+00004280: 616e 6573 6375 2d4e 6963 756c 6573 6375  anescu-Niculescu
+00004290: 2d4d 697a 696c 3c2f 623e 3c2f 7375 623e  -Mizil</b></sub>
+000042a0: 3c2f 613e 3c62 7220 2f3e 3c61 2068 7265  </a><br /><a hre
+000042b0: 663d 2268 7474 7073 3a2f 2f67 6974 6875  f="https://githu
+000042c0: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
+000042d0: 2f43 6f6e 766f 4b69 742f 636f 6d6d 6974  /ConvoKit/commit
+000042e0: 733f 6175 7468 6f72 3d63 7269 7374 6961  s?author=cristia
+000042f0: 6e64 6e6d 2220 7469 746c 653d 2243 6f64  ndnm" title="Cod
+00004300: 6522 3ef0 9f92 bb3c 2f61 3e20 3c61 2068  e">....</a> <a h
+00004310: 7265 663d 2223 6461 7461 2d63 7269 7374  ref="#data-crist
+00004320: 6961 6e64 6e6d 2220 7469 746c 653d 2244  iandnm" title="D
+00004330: 6174 6122 3ef0 9f94 a33c 2f61 3e20 3c61  ata">....</a> <a
+00004340: 2068 7265 663d 2223 6964 6561 732d 6372   href="#ideas-cr
+00004350: 6973 7469 616e 646e 6d22 2074 6974 6c65  istiandnm" title
+00004360: 3d22 4964 6561 732c 2050 6c61 6e6e 696e  ="Ideas, Plannin
+00004370: 672c 2026 2046 6565 6462 6163 6b22 3ef0  g, & Feedback">.
+00004380: 9fa4 943c 2f61 3e20 3c61 2068 7265 663d  ...</a> <a href=
+00004390: 2223 6d61 696e 7465 6e61 6e63 652d 6372  "#maintenance-cr
+000043a0: 6973 7469 616e 646e 6d22 2074 6974 6c65  istiandnm" title
+000043b0: 3d22 4d61 696e 7465 6e61 6e63 6522 3ef0  ="Maintenance">.
+000043c0: 9f9a a73c 2f61 3e20 3c61 2068 7265 663d  ...</a> <a href=
+000043d0: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
+000043e0: 636f 6d2f 436f 726e 656c 6c4e 4c50 2f43  com/CornellNLP/C
+000043f0: 6f6e 766f 4b69 742f 636f 6d6d 6974 733f  onvoKit/commits?
+00004400: 6175 7468 6f72 3d63 7269 7374 6961 6e64  author=cristiand
+00004410: 6e6d 2220 7469 746c 653d 2244 6f63 756d  nm" title="Docum
+00004420: 656e 7461 7469 6f6e 223e f09f 9396 3c2f  entation">....</
+00004430: 613e 203c 6120 6872 6566 3d22 6874 7470  a> <a href="http
+00004440: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
+00004450: 6f72 6e65 6c6c 4e4c 502f 436f 6e76 6f4b  ornellNLP/ConvoK
+00004460: 6974 2f70 756c 6c73 3f71 3d69 7325 3341  it/pulls?q=is%3A
+00004470: 7072 2b72 6576 6965 7765 642d 6279 2533  pr+reviewed-by%3
+00004480: 4163 7269 7374 6961 6e64 6e6d 2220 7469  Acristiandnm" ti
+00004490: 746c 653d 2252 6576 6965 7765 6420 5075  tle="Reviewed Pu
+000044a0: 6c6c 2052 6571 7565 7374 7322 3ef0 9f91  ll Requests">...
+000044b0: 803c 2f61 3e3c 2f74 643e 0a20 2020 2020  .</a></td>.     
+000044c0: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
+000044d0: 6572 2220 7661 6c69 676e 3d22 746f 7022  er" valign="top"
+000044e0: 2077 6964 7468 3d22 3134 2e32 3825 223e   width="14.28%">
+000044f0: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+00004500: 2f77 7777 2e6c 696e 6b65 6469 6e2e 636f  /www.linkedin.co
+00004510: 6d2f 696e 2f61 6e64 7265 777a 686f 7577  m/in/andrewzhouw
+00004520: 616e 6722 3e3c 696d 6720 7372 633d 2268  ang"><img src="h
+00004530: 7474 7073 3a2f 2f61 7661 7461 7273 2e67  ttps://avatars.g
+00004540: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
+00004550: 2e63 6f6d 2f75 2f34 3638 3334 3233 3f76  .com/u/4683423?v
+00004560: 3d34 3f73 3d31 3030 2220 7769 6474 683d  =4?s=100" width=
+00004570: 2231 3030 7078 3b22 2061 6c74 3d22 416e  "100px;" alt="An
+00004580: 6472 6577 2057 616e 6722 2f3e 3c62 7220  drew Wang"/><br 
+00004590: 2f3e 3c73 7562 3e3c 623e 416e 6472 6577  /><sub><b>Andrew
+000045a0: 2057 616e 673c 2f62 3e3c 2f73 7562 3e3c   Wang</b></sub><
+000045b0: 2f61 3e3c 6272 202f 3e3c 6120 6872 6566  /a><br /><a href
+000045c0: 3d22 6874 7470 733a 2f2f 6769 7468 7562  ="https://github
+000045d0: 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f  .com/CornellNLP/
+000045e0: 436f 6e76 6f4b 6974 2f63 6f6d 6d69 7473  ConvoKit/commits
+000045f0: 3f61 7574 686f 723d 7165 6d61 2220 7469  ?author=qema" ti
+00004600: 746c 653d 2243 6f64 6522 3ef0 9f92 bb3c  tle="Code">....<
+00004610: 2f61 3e20 3c61 2068 7265 663d 2223 6461  /a> <a href="#da
+00004620: 7461 2d71 656d 6122 2074 6974 6c65 3d22  ta-qema" title="
+00004630: 4461 7461 223e f09f 94a3 3c2f 613e 203c  Data">....</a> <
+00004640: 6120 6872 6566 3d22 2369 6465 6173 2d71  a href="#ideas-q
+00004650: 656d 6122 2074 6974 6c65 3d22 4964 6561  ema" title="Idea
+00004660: 732c 2050 6c61 6e6e 696e 672c 2026 2046  s, Planning, & F
+00004670: 6565 6462 6163 6b22 3ef0 9fa4 943c 2f61  eedback">....</a
+00004680: 3e20 3c61 2068 7265 663d 2223 6d61 696e  > <a href="#main
+00004690: 7465 6e61 6e63 652d 7165 6d61 2220 7469  tenance-qema" ti
+000046a0: 746c 653d 224d 6169 6e74 656e 616e 6365  tle="Maintenance
+000046b0: 223e f09f 9aa7 3c2f 613e 203c 6120 6872  ">....</a> <a hr
+000046c0: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
+000046d0: 7562 2e63 6f6d 2f43 6f72 6e65 6c6c 4e4c  ub.com/CornellNL
+000046e0: 502f 436f 6e76 6f4b 6974 2f63 6f6d 6d69  P/ConvoKit/commi
+000046f0: 7473 3f61 7574 686f 723d 7165 6d61 2220  ts?author=qema" 
+00004700: 7469 746c 653d 2244 6f63 756d 656e 7461  title="Documenta
+00004710: 7469 6f6e 223e f09f 9396 3c2f 613e 203c  tion">....</a> <
+00004720: 6120 6872 6566 3d22 6874 7470 733a 2f2f  a href="https://
+00004730: 6769 7468 7562 2e63 6f6d 2f43 6f72 6e65  github.com/Corne
+00004740: 6c6c 4e4c 502f 436f 6e76 6f4b 6974 2f70  llNLP/ConvoKit/p
+00004750: 756c 6c73 3f71 3d69 7325 3341 7072 2b72  ulls?q=is%3Apr+r
+00004760: 6576 6965 7765 642d 6279 2533 4171 656d  eviewed-by%3Aqem
+00004770: 6122 2074 6974 6c65 3d22 5265 7669 6577  a" title="Review
+00004780: 6564 2050 756c 6c20 5265 7175 6573 7473  ed Pull Requests
+00004790: 223e f09f 9180 3c2f 613e 3c2f 7464 3e0a  ">....</a></td>.
+000047a0: 2020 2020 2020 3c74 6420 616c 6967 6e3d        <td align=
+000047b0: 2263 656e 7465 7222 2076 616c 6967 6e3d  "center" valign=
+000047c0: 2274 6f70 2220 7769 6474 683d 2231 342e  "top" width="14.
+000047d0: 3238 2522 3e3c 6120 6872 6566 3d22 6874  28%"><a href="ht
+000047e0: 7470 3a2f 2f74 6973 6a75 6e65 2e67 6974  tp://tisjune.git
+000047f0: 6875 622e 696f 223e 3c69 6d67 2073 7263  hub.io"><img src
+00004800: 3d22 6874 7470 733a 2f2f 6176 6174 6172  ="https://avatar
+00004810: 732e 6769 7468 7562 7573 6572 636f 6e74  s.githubusercont
+00004820: 656e 742e 636f 6d2f 752f 3835 3334 3037  ent.com/u/853407
+00004830: 323f 763d 343f 733d 3130 3022 2077 6964  2?v=4?s=100" wid
+00004840: 7468 3d22 3130 3070 783b 2220 616c 743d  th="100px;" alt=
+00004850: 224a 7573 7469 6e65 205a 6861 6e67 222f  "Justine Zhang"/
+00004860: 3e3c 6272 202f 3e3c 7375 623e 3c62 3e4a  ><br /><sub><b>J
+00004870: 7573 7469 6e65 205a 6861 6e67 3c2f 623e  ustine Zhang</b>
+00004880: 3c2f 7375 623e 3c2f 613e 3c62 7220 2f3e  </sub></a><br />
+00004890: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+000048a0: 2f67 6974 6875 622e 636f 6d2f 436f 726e  /github.com/Corn
+000048b0: 656c 6c4e 4c50 2f43 6f6e 766f 4b69 742f  ellNLP/ConvoKit/
+000048c0: 636f 6d6d 6974 733f 6175 7468 6f72 3d74  commits?author=t
+000048d0: 6973 6a75 6e65 2220 7469 746c 653d 2243  isjune" title="C
+000048e0: 6f64 6522 3ef0 9f92 bb3c 2f61 3e20 3c61  ode">....</a> <a
+000048f0: 2068 7265 663d 2223 6461 7461 2d74 6973   href="#data-tis
+00004900: 6a75 6e65 2220 7469 746c 653d 2244 6174  june" title="Dat
+00004910: 6122 3ef0 9f94 a33c 2f61 3e20 3c61 2068  a">....</a> <a h
+00004920: 7265 663d 2223 6964 6561 732d 7469 736a  ref="#ideas-tisj
+00004930: 756e 6522 2074 6974 6c65 3d22 4964 6561  une" title="Idea
+00004940: 732c 2050 6c61 6e6e 696e 672c 2026 2046  s, Planning, & F
+00004950: 6565 6462 6163 6b22 3ef0 9fa4 943c 2f61  eedback">....</a
+00004960: 3e20 3c61 2068 7265 663d 2223 6d61 696e  > <a href="#main
+00004970: 7465 6e61 6e63 652d 7469 736a 756e 6522  tenance-tisjune"
+00004980: 2074 6974 6c65 3d22 4d61 696e 7465 6e61   title="Maintena
+00004990: 6e63 6522 3ef0 9f9a a73c 2f61 3e20 3c61  nce">....</a> <a
+000049a0: 2068 7265 663d 2268 7474 7073 3a2f 2f67   href="https://g
+000049b0: 6974 6875 622e 636f 6d2f 436f 726e 656c  ithub.com/Cornel
+000049c0: 6c4e 4c50 2f43 6f6e 766f 4b69 742f 636f  lNLP/ConvoKit/co
+000049d0: 6d6d 6974 733f 6175 7468 6f72 3d74 6973  mmits?author=tis
+000049e0: 6a75 6e65 2220 7469 746c 653d 2244 6f63  june" title="Doc
+000049f0: 756d 656e 7461 7469 6f6e 223e f09f 9396  umentation">....
+00004a00: 3c2f 613e 203c 6120 6872 6566 3d22 6874  </a> <a href="ht
+00004a10: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
+00004a20: 2f43 6f72 6e65 6c6c 4e4c 502f 436f 6e76  /CornellNLP/Conv
+00004a30: 6f4b 6974 2f70 756c 6c73 3f71 3d69 7325  oKit/pulls?q=is%
+00004a40: 3341 7072 2b72 6576 6965 7765 642d 6279  3Apr+reviewed-by
+00004a50: 2533 4174 6973 6a75 6e65 2220 7469 746c  %3Atisjune" titl
+00004a60: 653d 2252 6576 6965 7765 6420 5075 6c6c  e="Reviewed Pull
+00004a70: 2052 6571 7565 7374 7322 3ef0 9f91 803c   Requests">....<
+00004a80: 2f61 3e3c 2f74 643e 0a20 2020 2020 203c  /a></td>.      <
+00004a90: 7464 2061 6c69 676e 3d22 6365 6e74 6572  td align="center
+00004aa0: 2220 7661 6c69 676e 3d22 746f 7022 2077  " valign="top" w
+00004ab0: 6964 7468 3d22 3134 2e32 3825 223e 3c61  idth="14.28%"><a
+00004ac0: 2068 7265 663d 2268 7474 703a 2f2f 6373   href="http://cs
+00004ad0: 2e63 6f72 6e65 6c6c 2e65 6475 2f7e 6a70  .cornell.edu/~jp
+00004ae0: 6368 616e 6722 3e3c 696d 6720 7372 633d  chang"><img src=
+00004af0: 2268 7474 7073 3a2f 2f61 7661 7461 7273  "https://avatars
+00004b00: 2e67 6974 6875 6275 7365 7263 6f6e 7465  .githubuserconte
+00004b10: 6e74 2e63 6f6d 2f75 2f39 3839 3930 363f  nt.com/u/989906?
+00004b20: 763d 343f 733d 3130 3022 2077 6964 7468  v=4?s=100" width
+00004b30: 3d22 3130 3070 783b 2220 616c 743d 224a  ="100px;" alt="J
+00004b40: 6f6e 6174 6861 6e20 4368 616e 6722 2f3e  onathan Chang"/>
+00004b50: 3c62 7220 2f3e 3c73 7562 3e3c 623e 4a6f  <br /><sub><b>Jo
+00004b60: 6e61 7468 616e 2043 6861 6e67 3c2f 623e  nathan Chang</b>
+00004b70: 3c2f 7375 623e 3c2f 613e 3c62 7220 2f3e  </sub></a><br />
+00004b80: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+00004b90: 2f67 6974 6875 622e 636f 6d2f 436f 726e  /github.com/Corn
+00004ba0: 656c 6c4e 4c50 2f43 6f6e 766f 4b69 742f  ellNLP/ConvoKit/
+00004bb0: 636f 6d6d 6974 733f 6175 7468 6f72 3d6a  commits?author=j
+00004bc0: 7077 6368 616e 6722 2074 6974 6c65 3d22  pwchang" title="
+00004bd0: 436f 6465 223e f09f 92bb 3c2f 613e 203c  Code">....</a> <
+00004be0: 6120 6872 6566 3d22 2364 6174 612d 6a70  a href="#data-jp
+00004bf0: 7763 6861 6e67 2220 7469 746c 653d 2244  wchang" title="D
+00004c00: 6174 6122 3ef0 9f94 a33c 2f61 3e20 3c61  ata">....</a> <a
+00004c10: 2068 7265 663d 2223 6964 6561 732d 6a70   href="#ideas-jp
+00004c20: 7763 6861 6e67 2220 7469 746c 653d 2249  wchang" title="I
+00004c30: 6465 6173 2c20 506c 616e 6e69 6e67 2c20  deas, Planning, 
+00004c40: 2620 4665 6564 6261 636b 223e f09f a494  & Feedback">....
+00004c50: 3c2f 613e 203c 6120 6872 6566 3d22 236d  </a> <a href="#m
+00004c60: 6169 6e74 656e 616e 6365 2d6a 7077 6368  aintenance-jpwch
+00004c70: 616e 6722 2074 6974 6c65 3d22 4d61 696e  ang" title="Main
+00004c80: 7465 6e61 6e63 6522 3ef0 9f9a a73c 2f61  tenance">....</a
+00004c90: 3e20 3c61 2068 7265 663d 2268 7474 7073  > <a href="https
+00004ca0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
+00004cb0: 726e 656c 6c4e 4c50 2f43 6f6e 766f 4b69  rnellNLP/ConvoKi
+00004cc0: 742f 636f 6d6d 6974 733f 6175 7468 6f72  t/commits?author
+00004cd0: 3d6a 7077 6368 616e 6722 2074 6974 6c65  =jpwchang" title
+00004ce0: 3d22 446f 6375 6d65 6e74 6174 696f 6e22  ="Documentation"
+00004cf0: 3ef0 9f93 963c 2f61 3e20 3c61 2068 7265  >....</a> <a hre
+00004d00: 663d 2268 7474 7073 3a2f 2f67 6974 6875  f="https://githu
+00004d10: 622e 636f 6d2f 436f 726e 656c 6c4e 4c50  b.com/CornellNLP
+00004d20: 2f43 6f6e 766f 4b69 742f 7075 6c6c 733f  /ConvoKit/pulls?
+00004d30: 713d 6973 2533 4170 722b 7265 7669 6577  q=is%3Apr+review
+00004d40: 6564 2d62 7925 3341 6a70 7763 6861 6e67  ed-by%3Ajpwchang
+00004d50: 2220 7469 746c 653d 2252 6576 6965 7765  " title="Reviewe
+00004d60: 6420 5075 6c6c 2052 6571 7565 7374 7322  d Pull Requests"
+00004d70: 3ef0 9f91 803c 2f61 3e3c 2f74 643e 0a20  >....</a></td>. 
+00004d80: 2020 2020 203c 7464 2061 6c69 676e 3d22       <td align="
+00004d90: 6365 6e74 6572 2220 7661 6c69 676e 3d22  center" valign="
+00004da0: 746f 7022 2077 6964 7468 3d22 3134 2e32  top" width="14.2
+00004db0: 3825 223e 3c61 2068 7265 663d 2268 7474  8%"><a href="htt
+00004dc0: 703a 2f2f 7777 772e 6373 2e63 6f72 6e65  p://www.cs.corne
+00004dd0: 6c6c 2e65 6475 2f7e 6c69 7965 2f22 3e3c  ll.edu/~liye/"><
+00004de0: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
+00004df0: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
+00004e00: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
+00004e10: 2f31 3232 3234 3637 333f 763d 343f 733d  /12224673?v=4?s=
+00004e20: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
+00004e30: 783b 2220 616c 743d 224c 6979 6520 4675  x;" alt="Liye Fu
+00004e40: 222f 3e3c 6272 202f 3e3c 7375 623e 3c62  "/><br /><sub><b
+00004e50: 3e4c 6979 6520 4675 3c2f 623e 3c2f 7375  >Liye Fu</b></su
+00004e60: 623e 3c2f 613e 3c62 7220 2f3e 3c61 2068  b></a><br /><a h
+00004e70: 7265 663d 2268 7474 7073 3a2f 2f67 6974  ref="https://git
+00004e80: 6875 622e 636f 6d2f 436f 726e 656c 6c4e  hub.com/CornellN
+00004e90: 4c50 2f43 6f6e 766f 4b69 742f 636f 6d6d  LP/ConvoKit/comm
+00004ea0: 6974 733f 6175 7468 6f72 3d6c 6979 6522  its?author=liye"
+00004eb0: 2074 6974 6c65 3d22 436f 6465 223e f09f   title="Code">..
+00004ec0: 92bb 3c2f 613e 203c 6120 6872 6566 3d22  ..</a> <a href="
+00004ed0: 2364 6174 612d 6c69 7965 2220 7469 746c  #data-liye" titl
+00004ee0: 653d 2244 6174 6122 3ef0 9f94 a33c 2f61  e="Data">....</a
+00004ef0: 3e20 3c61 2068 7265 663d 2223 6964 6561  > <a href="#idea
+00004f00: 732d 6c69 7965 2220 7469 746c 653d 2249  s-liye" title="I
+00004f10: 6465 6173 2c20 506c 616e 6e69 6e67 2c20  deas, Planning, 
+00004f20: 2620 4665 6564 6261 636b 223e f09f a494  & Feedback">....
+00004f30: 3c2f 613e 203c 6120 6872 6566 3d22 236d  </a> <a href="#m
+00004f40: 6169 6e74 656e 616e 6365 2d6c 6979 6522  aintenance-liye"
+00004f50: 2074 6974 6c65 3d22 4d61 696e 7465 6e61   title="Maintena
+00004f60: 6e63 6522 3ef0 9f9a a73c 2f61 3e20 3c61  nce">....</a> <a
+00004f70: 2068 7265 663d 2268 7474 7073 3a2f 2f67   href="https://g
+00004f80: 6974 6875 622e 636f 6d2f 436f 726e 656c  ithub.com/Cornel
+00004f90: 6c4e 4c50 2f43 6f6e 766f 4b69 742f 636f  lNLP/ConvoKit/co
+00004fa0: 6d6d 6974 733f 6175 7468 6f72 3d6c 6979  mmits?author=liy
+00004fb0: 6522 2074 6974 6c65 3d22 446f 6375 6d65  e" title="Docume
+00004fc0: 6e74 6174 696f 6e22 3ef0 9f93 963c 2f61  ntation">....</a
+00004fd0: 3e20 3c61 2068 7265 663d 2268 7474 7073  > <a href="https
+00004fe0: 3a2f 2f67 6974 6875 622e 636f 6d2f 436f  ://github.com/Co
+00004ff0: 726e 656c 6c4e 4c50 2f43 6f6e 766f 4b69  rnellNLP/ConvoKi
+00005000: 742f 7075 6c6c 733f 713d 6973 2533 4170  t/pulls?q=is%3Ap
+00005010: 722b 7265 7669 6577 6564 2d62 7925 3341  r+reviewed-by%3A
+00005020: 6c69 7965 2220 7469 746c 653d 2252 6576  liye" title="Rev
+00005030: 6965 7765 6420 5075 6c6c 2052 6571 7565  iewed Pull Reque
+00005040: 7374 7322 3ef0 9f91 803c 2f61 3e3c 2f74  sts">....</a></t
+00005050: 643e 0a20 2020 2020 203c 7464 2061 6c69  d>.      <td ali
+00005060: 676e 3d22 6365 6e74 6572 2220 7661 6c69  gn="center" vali
+00005070: 676e 3d22 746f 7022 2077 6964 7468 3d22  gn="top" width="
+00005080: 3134 2e32 3825 223e 3c61 2068 7265 663d  14.28%"><a href=
+00005090: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
+000050a0: 636f 6d2f 6361 6c65 6263 6869 616d 223e  com/calebchiam">
+000050b0: 3c69 6d67 2073 7263 3d22 6874 7470 733a  <img src="https:
+000050c0: 2f2f 6176 6174 6172 732e 6769 7468 7562  //avatars.github
+000050d0: 7573 6572 636f 6e74 656e 742e 636f 6d2f  usercontent.com/
+000050e0: 752f 3134 3238 3639 3936 3f76 3d34 3f73  u/14286996?v=4?s
+000050f0: 3d31 3030 2220 7769 6474 683d 2231 3030  =100" width="100
+00005100: 7078 3b22 2061 6c74 3d22 6361 6c65 6263  px;" alt="calebc
+00005110: 6869 616d 222f 3e3c 6272 202f 3e3c 7375  hiam"/><br /><su
+00005120: 623e 3c62 3e63 616c 6562 6368 6961 6d3c  b><b>calebchiam<
+00005130: 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c 6272  /b></sub></a><br
+00005140: 202f 3e3c 6120 6872 6566 3d22 6874 7470   /><a href="http
+00005150: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
+00005160: 6f72 6e65 6c6c 4e4c 502f 436f 6e76 6f4b  ornellNLP/ConvoK
+00005170: 6974 2f63 6f6d 6d69 7473 3f61 7574 686f  it/commits?autho
+00005180: 723d 6361 6c65 6263 6869 616d 2220 7469  r=calebchiam" ti
+00005190: 746c 653d 2243 6f64 6522 3ef0 9f92 bb3c  tle="Code">....<
+000051a0: 2f61 3e20 3c61 2068 7265 663d 2223 6461  /a> <a href="#da
+000051b0: 7461 2d63 616c 6562 6368 6961 6d22 2074  ta-calebchiam" t
+000051c0: 6974 6c65 3d22 4461 7461 223e f09f 94a3  itle="Data">....
+000051d0: 3c2f 613e 203c 6120 6872 6566 3d22 2369  </a> <a href="#i
+000051e0: 6465 6173 2d63 616c 6562 6368 6961 6d22  deas-calebchiam"
+000051f0: 2074 6974 6c65 3d22 4964 6561 732c 2050   title="Ideas, P
+00005200: 6c61 6e6e 696e 672c 2026 2046 6565 6462  lanning, & Feedb
+00005210: 6163 6b22 3ef0 9fa4 943c 2f61 3e20 3c61  ack">....</a> <a
+00005220: 2068 7265 663d 2223 6d61 696e 7465 6e61   href="#maintena
+00005230: 6e63 652d 6361 6c65 6263 6869 616d 2220  nce-calebchiam" 
+00005240: 7469 746c 653d 224d 6169 6e74 656e 616e  title="Maintenan
+00005250: 6365 223e f09f 9aa7 3c2f 613e 203c 6120  ce">....</a> <a 
+00005260: 6872 6566 3d22 6874 7470 733a 2f2f 6769  href="https://gi
+00005270: 7468 7562 2e63 6f6d 2f43 6f72 6e65 6c6c  thub.com/Cornell
+00005280: 4e4c 502f 436f 6e76 6f4b 6974 2f63 6f6d  NLP/ConvoKit/com
+00005290: 6d69 7473 3f61 7574 686f 723d 6361 6c65  mits?author=cale
+000052a0: 6263 6869 616d 2220 7469 746c 653d 2244  bchiam" title="D
+000052b0: 6f63 756d 656e 7461 7469 6f6e 223e f09f  ocumentation">..
+000052c0: 9396 3c2f 613e 203c 6120 6872 6566 3d22  ..</a> <a href="
+000052d0: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
+000052e0: 6f6d 2f43 6f72 6e65 6c6c 4e4c 502f 436f  om/CornellNLP/Co
+000052f0: 6e76 6f4b 6974 2f70 756c 6c73 3f71 3d69  nvoKit/pulls?q=i
+00005300: 7325 3341 7072 2b72 6576 6965 7765 642d  s%3Apr+reviewed-
+00005310: 6279 2533 4163 616c 6562 6368 6961 6d22  by%3Acalebchiam"
+00005320: 2074 6974 6c65 3d22 5265 7669 6577 6564   title="Reviewed
+00005330: 2050 756c 6c20 5265 7175 6573 7473 223e   Pull Requests">
+00005340: f09f 9180 3c2f 613e 3c2f 7464 3e0a 2020  ....</a></td>.  
+00005350: 2020 2020 3c74 6420 616c 6967 6e3d 2263      <td align="c
+00005360: 656e 7465 7222 2076 616c 6967 6e3d 2274  enter" valign="t
+00005370: 6f70 2220 7769 6474 683d 2231 342e 3238  op" width="14.28
+00005380: 2522 3e3c 6120 6872 6566 3d22 6874 7470  %"><a href="http
+00005390: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f72  s://github.com/r
+000053a0: 6761 6e67 656c 6139 3922 3e3c 696d 6720  gangela99"><img 
+000053b0: 7372 633d 2268 7474 7073 3a2f 2f61 7661  src="https://ava
+000053c0: 7461 7273 2e67 6974 6875 6275 7365 7263  tars.githubuserc
+000053d0: 6f6e 7465 6e74 2e63 6f6d 2f75 2f33 3537  ontent.com/u/357
+000053e0: 3338 3133 323f 763d 343f 733d 3130 3022  38132?v=4?s=100"
+000053f0: 2077 6964 7468 3d22 3130 3070 783b 2220   width="100px;" 
+00005400: 616c 743d 2272 6761 6e67 656c 6139 3922  alt="rgangela99"
+00005410: 2f3e 3c62 7220 2f3e 3c73 7562 3e3c 623e  /><br /><sub><b>
+00005420: 7267 616e 6765 6c61 3939 3c2f 623e 3c2f  rgangela99</b></
+00005430: 7375 623e 3c2f 613e 3c62 7220 2f3e 3c61  sub></a><br /><a
+00005440: 2068 7265 663d 2268 7474 7073 3a2f 2f67   href="https://g
+00005450: 6974 6875 622e 636f 6d2f 436f 726e 656c  ithub.com/Cornel
+00005460: 6c4e 4c50 2f43 6f6e 766f 4b69 742f 636f  lNLP/ConvoKit/co
+00005470: 6d6d 6974 733f 6175 7468 6f72 3d72 6761  mmits?author=rga
+00005480: 6e67 656c 6139 3922 2074 6974 6c65 3d22  ngela99" title="
+00005490: 436f 6465 223e f09f 92bb 3c2f 613e 3c2f  Code">....</a></
+000054a0: 7464 3e0a 2020 2020 3c2f 7472 3e0a 2020  td>.    </tr>.  
+000054b0: 2020 3c74 723e 0a20 2020 2020 203c 7464    <tr>.      <td
+000054c0: 2061 6c69 676e 3d22 6365 6e74 6572 2220   align="center" 
+000054d0: 7661 6c69 676e 3d22 746f 7022 2077 6964  valign="top" wid
+000054e0: 7468 3d22 3134 2e32 3825 223e 3c61 2068  th="14.28%"><a h
+000054f0: 7265 663d 2268 7474 7073 3a2f 2f67 6974  ref="https://git
+00005500: 6875 622e 636f 6d2f 4b68 6f6e 7a6f 6461  hub.com/Khonzoda
+00005510: 223e 3c69 6d67 2073 7263 3d22 6874 7470  "><img src="http
+00005520: 733a 2f2f 6176 6174 6172 732e 6769 7468  s://avatars.gith
+00005530: 7562 7573 6572 636f 6e74 656e 742e 636f  ubusercontent.co
+00005540: 6d2f 752f 3236 3037 3237 3732 3f76 3d34  m/u/26072772?v=4
+00005550: 3f73 3d31 3030 2220 7769 6474 683d 2231  ?s=100" width="1
+00005560: 3030 7078 3b22 2061 6c74 3d22 4b68 6f6e  00px;" alt="Khon
+00005570: 7a6f 6461 2055 6d61 726f 7661 222f 3e3c  zoda Umarova"/><
+00005580: 6272 202f 3e3c 7375 623e 3c62 3e4b 686f  br /><sub><b>Kho
+00005590: 6e7a 6f64 6120 556d 6172 6f76 613c 2f62  nzoda Umarova</b
+000055a0: 3e3c 2f73 7562 3e3c 2f61 3e3c 6272 202f  ></sub></a><br /
+000055b0: 3e3c 6120 6872 6566 3d22 2364 6174 612d  ><a href="#data-
+000055c0: 4b68 6f6e 7a6f 6461 2220 7469 746c 653d  Khonzoda" title=
+000055d0: 2244 6174 6122 3ef0 9f94 a33c 2f61 3e20  "Data">....</a> 
+000055e0: 3c61 2068 7265 663d 2223 6d61 696e 7465  <a href="#mainte
+000055f0: 6e61 6e63 652d 4b68 6f6e 7a6f 6461 2220  nance-Khonzoda" 
+00005600: 7469 746c 653d 224d 6169 6e74 656e 616e  title="Maintenan
+00005610: 6365 223e f09f 9aa7 3c2f 613e 3c2f 7464  ce">....</a></td
+00005620: 3e0a 2020 2020 2020 3c74 6420 616c 6967  >.      <td alig
+00005630: 6e3d 2263 656e 7465 7222 2076 616c 6967  n="center" valig
+00005640: 6e3d 2274 6f70 2220 7769 6474 683d 2231  n="top" width="1
+00005650: 342e 3238 2522 3e3c 6120 6872 6566 3d22  4.28%"><a href="
+00005660: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
+00005670: 6f6d 2f6d 7769 6c62 7a22 3e3c 696d 6720  om/mwilbz"><img 
+00005680: 7372 633d 2268 7474 7073 3a2f 2f61 7661  src="https://ava
+00005690: 7461 7273 2e67 6974 6875 6275 7365 7263  tars.githubuserc
+000056a0: 6f6e 7465 6e74 2e63 6f6d 2f75 2f31 3431  ontent.com/u/141
+000056b0: 3135 3634 313f 763d 343f 733d 3130 3022  15641?v=4?s=100"
+000056c0: 2077 6964 7468 3d22 3130 3070 783b 2220   width="100px;" 
+000056d0: 616c 743d 226d 7769 6c62 7a22 2f3e 3c62  alt="mwilbz"/><b
+000056e0: 7220 2f3e 3c73 7562 3e3c 623e 6d77 696c  r /><sub><b>mwil
+000056f0: 627a 3c2f 623e 3c2f 7375 623e 3c2f 613e  bz</b></sub></a>
+00005700: 3c62 7220 2f3e 3c61 2068 7265 663d 2268  <br /><a href="h
+00005710: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
+00005720: 6d2f 436f 726e 656c 6c4e 4c50 2f43 6f6e  m/CornellNLP/Con
+00005730: 766f 4b69 742f 636f 6d6d 6974 733f 6175  voKit/commits?au
+00005740: 7468 6f72 3d6d 7769 6c62 7a22 2074 6974  thor=mwilbz" tit
+00005750: 6c65 3d22 5465 7374 7322 3ee2 9aa0 efb8  le="Tests">.....
+00005760: 8f3c 2f61 3e3c 2f74 643e 0a20 2020 2020  .</a></td>.     
+00005770: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
+00005780: 6572 2220 7661 6c69 676e 3d22 746f 7022  er" valign="top"
+00005790: 2077 6964 7468 3d22 3134 2e32 3825 223e   width="14.28%">
+000057a0: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+000057b0: 2f77 7777 2e61 6c65 786b 6f65 6e2e 636f  /www.alexkoen.co
+000057c0: 6d22 3e3c 696d 6720 7372 633d 2268 7474  m"><img src="htt
+000057d0: 7073 3a2f 2f61 7661 7461 7273 2e67 6974  ps://avatars.git
+000057e0: 6875 6275 7365 7263 6f6e 7465 6e74 2e63  hubusercontent.c
+000057f0: 6f6d 2f75 2f34 3339 3133 3930 323f 763d  om/u/43913902?v=
+00005800: 343f 733d 3130 3022 2077 6964 7468 3d22  4?s=100" width="
+00005810: 3130 3070 783b 2220 616c 743d 2241 6c65  100px;" alt="Ale
+00005820: 7820 4b6f 656e 222f 3e3c 6272 202f 3e3c  x Koen"/><br /><
+00005830: 7375 623e 3c62 3e41 6c65 7820 4b6f 656e  sub><b>Alex Koen
+00005840: 3c2f 623e 3c2f 7375 623e 3c2f 613e 3c62  </b></sub></a><b
+00005850: 7220 2f3e 3c61 2068 7265 663d 2268 7474  r /><a href="htt
+00005860: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+00005870: 436f 726e 656c 6c4e 4c50 2f43 6f6e 766f  CornellNLP/Convo
+00005880: 4b69 742f 6973 7375 6573 3f71 3d61 7574  Kit/issues?q=aut
+00005890: 686f 7225 3341 616b 6f65 6e22 2074 6974  hor%3Aakoen" tit
+000058a0: 6c65 3d22 4275 6720 7265 706f 7274 7322  le="Bug reports"
+000058b0: 3ef0 9f90 9b3c 2f61 3e3c 2f74 643e 0a20  >....</a></td>. 
+000058c0: 2020 2020 203c 7464 2061 6c69 676e 3d22       <td align="
+000058d0: 6365 6e74 6572 2220 7661 6c69 676e 3d22  center" valign="
+000058e0: 746f 7022 2077 6964 7468 3d22 3134 2e32  top" width="14.2
+000058f0: 3825 223e 3c61 2068 7265 663d 2268 7474  8%"><a href="htt
+00005900: 703a 2f2f 656d 7473 656e 672e 6d65 223e  p://emtseng.me">
+00005910: 3c69 6d67 2073 7263 3d22 6874 7470 733a  <img src="https:
+00005920: 2f2f 6176 6174 6172 732e 6769 7468 7562  //avatars.github
+00005930: 7573 6572 636f 6e74 656e 742e 636f 6d2f  usercontent.com/
+00005940: 752f 3532 3730 3835 323f 763d 343f 733d  u/5270852?v=4?s=
+00005950: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
+00005960: 783b 2220 616c 743d 2245 6d69 6c79 2054  x;" alt="Emily T
+00005970: 7365 6e67 222f 3e3c 6272 202f 3e3c 7375  seng"/><br /><su
+00005980: 623e 3c62 3e45 6d69 6c79 2054 7365 6e67  b><b>Emily Tseng
+00005990: 3c2f 623e 3c2f 7375 623e 3c2f 613e 3c62  </b></sub></a><b
+000059a0: 7220 2f3e 3c61 2068 7265 663d 2268 7474  r /><a href="htt
+000059b0: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+000059c0: 436f 726e 656c 6c4e 4c50 2f43 6f6e 766f  CornellNLP/Convo
+000059d0: 4b69 742f 6973 7375 6573 3f71 3d61 7574  Kit/issues?q=aut
+000059e0: 686f 7225 3341 656d 7473 656e 6722 2074  hor%3Aemtseng" t
+000059f0: 6974 6c65 3d22 4275 6720 7265 706f 7274  itle="Bug report
+00005a00: 7322 3ef0 9f90 9b3c 2f61 3e20 3c61 2068  s">....</a> <a h
+00005a10: 7265 663d 2223 6461 7461 2d65 6d74 7365  ref="#data-emtse
+00005a20: 6e67 2220 7469 746c 653d 2244 6174 6122  ng" title="Data"
+00005a30: 3ef0 9f94 a33c 2f61 3e3c 2f74 643e 0a20  >....</a></td>. 
+00005a40: 2020 2020 203c 7464 2061 6c69 676e 3d22       <td align="
+00005a50: 6365 6e74 6572 2220 7661 6c69 676e 3d22  center" valign="
+00005a60: 746f 7022 2077 6964 7468 3d22 3134 2e32  top" width="14.2
+00005a70: 3825 223e 3c61 2068 7265 663d 2268 7474  8%"><a href="htt
+00005a80: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+00005a90: 5a69 6767 7946 6c6f 6174 223e 3c69 6d67  ZiggyFloat"><img
+00005aa0: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
+00005ab0: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
+00005ac0: 636f 6e74 656e 742e 636f 6d2f 752f 3431  content.com/u/41
+00005ad0: 3932 3736 3037 3f76 3d34 3f73 3d31 3030  927607?v=4?s=100
+00005ae0: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
+00005af0: 2061 6c74 3d22 556c 6979 616e 6120 4b75   alt="Uliyana Ku
+00005b00: 6261 736f 7661 222f 3e3c 6272 202f 3e3c  basova"/><br /><
+00005b10: 7375 623e 3c62 3e55 6c69 7961 6e61 204b  sub><b>Uliyana K
+00005b20: 7562 6173 6f76 613c 2f62 3e3c 2f73 7562  ubasova</b></sub
+00005b30: 3e3c 2f61 3e3c 6272 202f 3e3c 6120 6872  ></a><br /><a hr
+00005b40: 6566 3d22 2364 6174 612d 5a69 6767 7946  ef="#data-ZiggyF
+00005b50: 6c6f 6174 2220 7469 746c 653d 2244 6174  loat" title="Dat
+00005b60: 6122 3ef0 9f94 a33c 2f61 3e3c 2f74 643e  a">....</a></td>
+00005b70: 0a20 2020 2020 203c 7464 2061 6c69 676e  .      <td align
+00005b80: 3d22 6365 6e74 6572 2220 7661 6c69 676e  ="center" valign
+00005b90: 3d22 746f 7022 2077 6964 7468 3d22 3134  ="top" width="14
+00005ba0: 2e32 3825 223e 3c61 2068 7265 663d 2268  .28%"><a href="h
+00005bb0: 7474 7073 3a2f 2f6a 7363 686c 7567 6572  ttps://jschluger
+00005bc0: 2e67 6974 6875 622e 696f 2f22 3e3c 696d  .github.io/"><im
+00005bd0: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
+00005be0: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
+00005bf0: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f31  rcontent.com/u/1
+00005c00: 3439 3536 3030 383f 763d 343f 733d 3130  4956008?v=4?s=10
+00005c10: 3022 2077 6964 7468 3d22 3130 3070 783b  0" width="100px;
+00005c20: 2220 616c 743d 224a 6163 6b20 5363 686c  " alt="Jack Schl
+00005c30: 7567 6572 222f 3e3c 6272 202f 3e3c 7375  uger"/><br /><su
+00005c40: 623e 3c62 3e4a 6163 6b20 5363 686c 7567  b><b>Jack Schlug
+00005c50: 6572 3c2f 623e 3c2f 7375 623e 3c2f 613e  er</b></sub></a>
+00005c60: 3c62 7220 2f3e 3c61 2068 7265 663d 2268  <br /><a href="h
+00005c70: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
+00005c80: 6d2f 436f 726e 656c 6c4e 4c50 2f43 6f6e  m/CornellNLP/Con
+00005c90: 766f 4b69 742f 6973 7375 6573 3f71 3d61  voKit/issues?q=a
+00005ca0: 7574 686f 7225 3341 6a73 6368 6c75 6765  uthor%3Ajschluge
+00005cb0: 7222 2074 6974 6c65 3d22 4275 6720 7265  r" title="Bug re
+00005cc0: 706f 7274 7322 3ef0 9f90 9b3c 2f61 3e20  ports">....</a> 
+00005cd0: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+00005ce0: 2f67 6974 6875 622e 636f 6d2f 436f 726e  /github.com/Corn
+00005cf0: 656c 6c4e 4c50 2f43 6f6e 766f 4b69 742f  ellNLP/ConvoKit/
+00005d00: 636f 6d6d 6974 733f 6175 7468 6f72 3d6a  commits?author=j
+00005d10: 7363 686c 7567 6572 2220 7469 746c 653d  schluger" title=
+00005d20: 2243 6f64 6522 3ef0 9f92 bb3c 2f61 3e3c  "Code">....</a><
+00005d30: 2f74 643e 0a20 2020 2020 203c 7464 2061  /td>.      <td a
+00005d40: 6c69 676e 3d22 6365 6e74 6572 2220 7661  lign="center" va
+00005d50: 6c69 676e 3d22 746f 7022 2077 6964 7468  lign="top" width
+00005d60: 3d22 3134 2e32 3825 223e 3c61 2068 7265  ="14.28%"><a hre
+00005d70: 663d 2268 7474 7073 3a2f 2f67 6974 6875  f="https://githu
+00005d80: 622e 636f 6d2f 6b75 7368 616c 6368 6177  b.com/kushalchaw
+00005d90: 6c61 223e 3c69 6d67 2073 7263 3d22 6874  la"><img src="ht
+00005da0: 7470 733a 2f2f 6176 6174 6172 732e 6769  tps://avatars.gi
+00005db0: 7468 7562 7573 6572 636f 6e74 656e 742e  thubusercontent.
+00005dc0: 636f 6d2f 752f 3834 3136 3836 333f 763d  com/u/8416863?v=
+00005dd0: 343f 733d 3130 3022 2077 6964 7468 3d22  4?s=100" width="
+00005de0: 3130 3070 783b 2220 616c 743d 224b 7573  100px;" alt="Kus
+00005df0: 6861 6c20 4368 6177 6c61 222f 3e3c 6272  hal Chawla"/><br
+00005e00: 202f 3e3c 7375 623e 3c62 3e4b 7573 6861   /><sub><b>Kusha
+00005e10: 6c20 4368 6177 6c61 3c2f 623e 3c2f 7375  l Chawla</b></su
+00005e20: 623e 3c2f 613e 3c62 7220 2f3e 3c61 2068  b></a><br /><a h
+00005e30: 7265 663d 2223 6461 7461 2d6b 7573 6861  ref="#data-kusha
+00005e40: 6c63 6861 776c 6122 2074 6974 6c65 3d22  lchawla" title="
+00005e50: 4461 7461 223e f09f 94a3 3c2f 613e 3c2f  Data">....</a></
+00005e60: 7464 3e0a 2020 2020 3c2f 7472 3e0a 2020  td>.    </tr>.  
+00005e70: 2020 3c74 723e 0a20 2020 2020 203c 7464    <tr>.      <td
+00005e80: 2061 6c69 676e 3d22 6365 6e74 6572 2220   align="center" 
+00005e90: 7661 6c69 676e 3d22 746f 7022 2077 6964  valign="top" wid
+00005ea0: 7468 3d22 3134 2e32 3825 223e 3c61 2068  th="14.28%"><a h
+00005eb0: 7265 663d 2268 7474 7073 3a2f 2f67 6974  ref="https://git
+00005ec0: 6875 622e 636f 6d2f 7363 3738 3222 3e3c  hub.com/sc782"><
+00005ed0: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
+00005ee0: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
+00005ef0: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
+00005f00: 2f31 3439 3730 3933 303f 763d 343f 733d  /14970930?v=4?s=
+00005f10: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
+00005f20: 783b 2220 616c 743d 224a 756e 6520 4368  x;" alt="June Ch
+00005f30: 6f22 2f3e 3c62 7220 2f3e 3c73 7562 3e3c  o"/><br /><sub><
+00005f40: 623e 4a75 6e65 2043 686f 3c2f 623e 3c2f  b>June Cho</b></
+00005f50: 7375 623e 3c2f 613e 3c62 7220 2f3e 3c61  sub></a><br /><a
+00005f60: 2068 7265 663d 2223 6461 7461 2d73 6337   href="#data-sc7
+00005f70: 3832 2220 7469 746c 653d 2244 6174 6122  82" title="Data"
+00005f80: 3ef0 9f94 a33c 2f61 3e3c 2f74 643e 0a20  >....</a></td>. 
+00005f90: 2020 2020 203c 7464 2061 6c69 676e 3d22       <td align="
+00005fa0: 6365 6e74 6572 2220 7661 6c69 676e 3d22  center" valign="
+00005fb0: 746f 7022 2077 6964 7468 3d22 3134 2e32  top" width="14.2
+00005fc0: 3825 223e 3c61 2068 7265 663d 2268 7474  8%"><a href="htt
+00005fd0: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+00005fe0: 6e6f 616d 6573 6865 6422 3e3c 696d 6720  noameshed"><img 
+00005ff0: 7372 633d 2268 7474 7073 3a2f 2f61 7661  src="https://ava
+00006000: 7461 7273 2e67 6974 6875 6275 7365 7263  tars.githubuserc
+00006010: 6f6e 7465 6e74 2e63 6f6d 2f75 2f34 3036  ontent.com/u/406
+00006020: 3332 3736 363f 763d 343f 733d 3130 3022  32766?v=4?s=100"
+00006030: 2077 6964 7468 3d22 3130 3070 783b 2220   width="100px;" 
+00006040: 616c 743d 224e 6f61 6d20 4573 6865 6422  alt="Noam Eshed"
+00006050: 2f3e 3c62 7220 2f3e 3c73 7562 3e3c 623e  /><br /><sub><b>
+00006060: 4e6f 616d 2045 7368 6564 3c2f 623e 3c2f  Noam Eshed</b></
+00006070: 7375 623e 3c2f 613e 3c62 7220 2f3e 3c61  sub></a><br /><a
+00006080: 2068 7265 663d 2223 6461 7461 2d6e 6f61   href="#data-noa
+00006090: 6d65 7368 6564 2220 7469 746c 653d 2244  meshed" title="D
+000060a0: 6174 6122 3ef0 9f94 a33c 2f61 3e3c 2f74  ata">....</a></t
+000060b0: 643e 0a20 2020 2020 203c 7464 2061 6c69  d>.      <td ali
+000060c0: 676e 3d22 6365 6e74 6572 2220 7661 6c69  gn="center" vali
+000060d0: 676e 3d22 746f 7022 2077 6964 7468 3d22  gn="top" width="
+000060e0: 3134 2e32 3825 223e 3c61 2068 7265 663d  14.28%"><a href=
+000060f0: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
+00006100: 636f 6d2f 737a 6d75 726c 6f22 3e3c 696d  com/szmurlo"><im
+00006110: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
+00006120: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
+00006130: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f33  rcontent.com/u/3
+00006140: 3131 3932 3334 303f 763d 343f 733d 3130  1192340?v=4?s=10
+00006150: 3022 2077 6964 7468 3d22 3130 3070 783b  0" width="100px;
+00006160: 2220 616c 743d 2241 6e64 7265 7720 537a  " alt="Andrew Sz
+00006170: 6d75 726c 6f22 2f3e 3c62 7220 2f3e 3c73  murlo"/><br /><s
+00006180: 7562 3e3c 623e 416e 6472 6577 2053 7a6d  ub><b>Andrew Szm
+00006190: 7572 6c6f 3c2f 623e 3c2f 7375 623e 3c2f  urlo</b></sub></
+000061a0: 613e 3c62 7220 2f3e 3c61 2068 7265 663d  a><br /><a href=
+000061b0: 2223 6461 7461 2d73 7a6d 7572 6c6f 2220  "#data-szmurlo" 
+000061c0: 7469 746c 653d 2244 6174 6122 3ef0 9f94  title="Data">...
+000061d0: a33c 2f61 3e3c 2f74 643e 0a20 2020 2020  .</a></td>.     
+000061e0: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
+000061f0: 6572 2220 7661 6c69 676e 3d22 746f 7022  er" valign="top"
+00006200: 2077 6964 7468 3d22 3134 2e32 3825 223e   width="14.28%">
+00006210: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+00006220: 2f67 6974 6875 622e 636f 6d2f 6b63 7361  /github.com/kcsa
+00006230: 646f 7722 3e3c 696d 6720 7372 633d 2268  dow"><img src="h
+00006240: 7474 7073 3a2f 2f61 7661 7461 7273 2e67  ttps://avatars.g
+00006250: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
+00006260: 2e63 6f6d 2f75 2f33 3430 3734 3135 313f  .com/u/34074151?
+00006270: 763d 343f 733d 3130 3022 2077 6964 7468  v=4?s=100" width
+00006280: 3d22 3130 3070 783b 2220 616c 743d 224b  ="100px;" alt="K
+00006290: 6174 6861 7269 6e65 2053 6164 6f77 736b  atharine Sadowsk
+000062a0: 6922 2f3e 3c62 7220 2f3e 3c73 7562 3e3c  i"/><br /><sub><
+000062b0: 623e 4b61 7468 6172 696e 6520 5361 646f  b>Katharine Sado
+000062c0: 7773 6b69 3c2f 623e 3c2f 7375 623e 3c2f  wski</b></sub></
+000062d0: 613e 3c62 7220 2f3e 3c61 2068 7265 663d  a><br /><a href=
+000062e0: 2223 6461 7461 2d6b 6373 6164 6f77 2220  "#data-kcsadow" 
+000062f0: 7469 746c 653d 2244 6174 6122 3ef0 9f94  title="Data">...
+00006300: a33c 2f61 3e3c 2f74 643e 0a20 2020 2020  .</a></td>.     
+00006310: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
+00006320: 6572 2220 7661 6c69 676e 3d22 746f 7022  er" valign="top"
+00006330: 2077 6964 7468 3d22 3134 2e32 3825 223e   width="14.28%">
+00006340: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+00006350: 2f67 6974 6875 622e 636f 6d2f 6c75 6361  /github.com/luca
+00006360: 7376 616e 6272 616d 6572 223e 3c69 6d67  svanbramer"><img
+00006370: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
+00006380: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
+00006390: 636f 6e74 656e 742e 636f 6d2f 752f 3332  content.com/u/32
+000063a0: 3535 3336 3736 3f76 3d34 3f73 3d31 3030  553676?v=4?s=100
+000063b0: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
+000063c0: 2061 6c74 3d22 4c75 6361 7320 5661 6e20   alt="Lucas Van 
+000063d0: 4272 616d 6572 222f 3e3c 6272 202f 3e3c  Bramer"/><br /><
+000063e0: 7375 623e 3c62 3e4c 7563 6173 2056 616e  sub><b>Lucas Van
+000063f0: 2042 7261 6d65 723c 2f62 3e3c 2f73 7562   Bramer</b></sub
+00006400: 3e3c 2f61 3e3c 6272 202f 3e3c 6120 6872  ></a><br /><a hr
+00006410: 6566 3d22 2364 6174 612d 6c75 6361 7376  ef="#data-lucasv
+00006420: 616e 6272 616d 6572 2220 7469 746c 653d  anbramer" title=
+00006430: 2244 6174 6122 3ef0 9f94 a33c 2f61 3e3c  "Data">....</a><
+00006440: 2f74 643e 0a20 2020 2020 203c 7464 2061  /td>.      <td a
+00006450: 6c69 676e 3d22 6365 6e74 6572 2220 7661  lign="center" va
+00006460: 6c69 676e 3d22 746f 7022 2077 6964 7468  lign="top" width
+00006470: 3d22 3134 2e32 3825 223e 3c61 2068 7265  ="14.28%"><a hre
+00006480: 663d 2268 7474 703a 2f2f 6d61 7269 616e  f="http://marian
+00006490: 6e65 616c 712e 636f 6d22 3e3c 696d 6720  nealq.com"><img 
+000064a0: 7372 633d 2268 7474 7073 3a2f 2f61 7661  src="https://ava
+000064b0: 7461 7273 2e67 6974 6875 6275 7365 7263  tars.githubuserc
+000064c0: 6f6e 7465 6e74 2e63 6f6d 2f75 2f31 3639  ontent.com/u/169
+000064d0: 3439 3539 313f 763d 343f 733d 3130 3022  49591?v=4?s=100"
+000064e0: 2077 6964 7468 3d22 3130 3070 783b 2220   width="100px;" 
+000064f0: 616c 743d 224d 6172 6961 6e6e 6520 4175  alt="Marianne Au
+00006500: 6269 6e22 2f3e 3c62 7220 2f3e 3c73 7562  bin"/><br /><sub
+00006510: 3e3c 623e 4d61 7269 616e 6e65 2041 7562  ><b>Marianne Aub
+00006520: 696e 3c2f 623e 3c2f 7375 623e 3c2f 613e  in</b></sub></a>
+00006530: 3c62 7220 2f3e 3c61 2068 7265 663d 2223  <br /><a href="#
+00006540: 6461 7461 2d6d 6175 6269 6e6c 6522 2074  data-maubinle" t
+00006550: 6974 6c65 3d22 4461 7461 223e f09f 94a3  itle="Data">....
+00006560: 3c2f 613e 3c2f 7464 3e0a 2020 2020 2020  </a></td>.      
+00006570: 3c74 6420 616c 6967 6e3d 2263 656e 7465  <td align="cente
+00006580: 7222 2076 616c 6967 6e3d 2274 6f70 2220  r" valign="top" 
+00006590: 7769 6474 683d 2231 342e 3238 2522 3e3c  width="14.28%"><
+000065a0: 6120 6872 6566 3d22 6874 7470 733a 2f2f  a href="https://
+000065b0: 6769 7468 7562 2e63 6f6d 2f64 6e32 3733  github.com/dn273
+000065c0: 223e 3c69 6d67 2073 7263 3d22 6874 7470  "><img src="http
+000065d0: 733a 2f2f 6176 6174 6172 732e 6769 7468  s://avatars.gith
+000065e0: 7562 7573 6572 636f 6e74 656e 742e 636f  ubusercontent.co
+000065f0: 6d2f 752f 3237 3932 3636 3632 3f76 3d34  m/u/27926662?v=4
+00006600: 3f73 3d31 3030 2220 7769 6474 683d 2231  ?s=100" width="1
+00006610: 3030 7078 3b22 2061 6c74 3d22 4469 204e  00px;" alt="Di N
+00006620: 6922 2f3e 3c62 7220 2f3e 3c73 7562 3e3c  i"/><br /><sub><
+00006630: 623e 4469 204e 693c 2f62 3e3c 2f73 7562  b>Di Ni</b></sub
+00006640: 3e3c 2f61 3e3c 6272 202f 3e3c 6120 6872  ></a><br /><a hr
+00006650: 6566 3d22 2364 6174 612d 646e 3237 3322  ef="#data-dn273"
+00006660: 2074 6974 6c65 3d22 4461 7461 223e f09f   title="Data">..
+00006670: 94a3 3c2f 613e 3c2f 7464 3e0a 2020 2020  ..</a></td>.    
+00006680: 3c2f 7472 3e0a 2020 2020 3c74 723e 0a20  </tr>.    <tr>. 
+00006690: 2020 2020 203c 7464 2061 6c69 676e 3d22       <td align="
+000066a0: 6365 6e74 6572 2220 7661 6c69 676e 3d22  center" valign="
+000066b0: 746f 7022 2077 6964 7468 3d22 3134 2e32  top" width="14.2
+000066c0: 3825 223e 3c61 2068 7265 663d 2268 7474  8%"><a href="htt
+000066d0: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+000066e0: 6764 656e 6739 3622 3e3c 696d 6720 7372  gdeng96"><img sr
+000066f0: 633d 2268 7474 7073 3a2f 2f61 7661 7461  c="https://avata
+00006700: 7273 2e67 6974 6875 6275 7365 7263 6f6e  rs.githubusercon
+00006710: 7465 6e74 2e63 6f6d 2f75 2f38 3630 3037  tent.com/u/86007
+00006720: 3531 3f76 3d34 3f73 3d31 3030 2220 7769  51?v=4?s=100" wi
+00006730: 6474 683d 2231 3030 7078 3b22 2061 6c74  dth="100px;" alt
+00006740: 3d22 6764 656e 6739 3622 2f3e 3c62 7220  ="gdeng96"/><br 
+00006750: 2f3e 3c73 7562 3e3c 623e 6764 656e 6739  /><sub><b>gdeng9
+00006760: 363c 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c  6</b></sub></a><
+00006770: 6272 202f 3e3c 6120 6872 6566 3d22 2364  br /><a href="#d
+00006780: 6174 612d 6764 656e 6739 3622 2074 6974  ata-gdeng96" tit
+00006790: 6c65 3d22 4461 7461 223e f09f 94a3 3c2f  le="Data">....</
+000067a0: 613e 3c2f 7464 3e0a 2020 2020 2020 3c74  a></td>.      <t
+000067b0: 6420 616c 6967 6e3d 2263 656e 7465 7222  d align="center"
+000067c0: 2076 616c 6967 6e3d 2274 6f70 2220 7769   valign="top" wi
+000067d0: 6474 683d 2231 342e 3238 2522 3e3c 6120  dth="14.28%"><a 
+000067e0: 6872 6566 3d22 6874 7470 733a 2f2f 6769  href="https://gi
+000067f0: 7468 7562 2e63 6f6d 2f6a 756e 6672 616e  thub.com/junfran
+00006800: 6b6c 6922 3e3c 696d 6720 7372 633d 2268  kli"><img src="h
+00006810: 7474 7073 3a2f 2f61 7661 7461 7273 2e67  ttps://avatars.g
+00006820: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
+00006830: 2e63 6f6d 2f75 2f32 3234 3632 3538 343f  .com/u/22462584?
+00006840: 763d 343f 733d 3130 3022 2077 6964 7468  v=4?s=100" width
+00006850: 3d22 3130 3070 783b 2220 616c 743d 2246  ="100px;" alt="F
+00006860: 7261 6e6b 204c 6922 2f3e 3c62 7220 2f3e  rank Li"/><br />
+00006870: 3c73 7562 3e3c 623e 4672 616e 6b20 4c69  <sub><b>Frank Li
+00006880: 3c2f 623e 3c2f 7375 623e 3c2f 613e 3c62  </b></sub></a><b
+00006890: 7220 2f3e 3c61 2068 7265 663d 2223 6461  r /><a href="#da
+000068a0: 7461 2d6a 756e 6672 616e 6b6c 6922 2074  ta-junfrankli" t
+000068b0: 6974 6c65 3d22 4461 7461 223e f09f 94a3  itle="Data">....
+000068c0: 3c2f 613e 3c2f 7464 3e0a 2020 2020 2020  </a></td>.      
+000068d0: 3c74 6420 616c 6967 6e3d 2263 656e 7465  <td align="cente
+000068e0: 7222 2076 616c 6967 6e3d 2274 6f70 2220  r" valign="top" 
+000068f0: 7769 6474 683d 2231 342e 3238 2522 3e3c  width="14.28%"><
+00006900: 6120 6872 6566 3d22 6874 7470 3a2f 2f72  a href="http://r
+00006910: 756a 7a68 616f 2e63 6f6d 223e 3c69 6d67  ujzhao.com"><img
+00006920: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
+00006930: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
+00006940: 636f 6e74 656e 742e 636f 6d2f 752f 3331  content.com/u/31
+00006950: 3135 3837 3438 3f76 3d34 3f73 3d31 3030  158748?v=4?s=100
+00006960: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
+00006970: 2061 6c74 3d22 726a 7a34 3622 2f3e 3c62   alt="rjz46"/><b
+00006980: 7220 2f3e 3c73 7562 3e3c 623e 726a 7a34  r /><sub><b>rjz4
+00006990: 363c 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c  6</b></sub></a><
+000069a0: 6272 202f 3e3c 6120 6872 6566 3d22 2364  br /><a href="#d
+000069b0: 6174 612d 726a 7a34 3622 2074 6974 6c65  ata-rjz46" title
+000069c0: 3d22 4461 7461 223e f09f 94a3 3c2f 613e  ="Data">....</a>
+000069d0: 3c2f 7464 3e0a 2020 2020 2020 3c74 6420  </td>.      <td 
+000069e0: 616c 6967 6e3d 2263 656e 7465 7222 2076  align="center" v
+000069f0: 616c 6967 6e3d 2274 6f70 2220 7769 6474  align="top" widt
+00006a00: 683d 2231 342e 3238 2522 3e3c 6120 6872  h="14.28%"><a hr
+00006a10: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
+00006a20: 7562 2e63 6f6d 2f4b 6174 7942 6c75 6d65  ub.com/KatyBlume
+00006a30: 7222 3e3c 696d 6720 7372 633d 2268 7474  r"><img src="htt
+00006a40: 7073 3a2f 2f61 7661 7461 7273 2e67 6974  ps://avatars.git
+00006a50: 6875 6275 7365 7263 6f6e 7465 6e74 2e63  hubusercontent.c
+00006a60: 6f6d 2f75 2f33 3636 3930 3639 3f76 3d34  om/u/3669069?v=4
+00006a70: 3f73 3d31 3030 2220 7769 6474 683d 2231  ?s=100" width="1
+00006a80: 3030 7078 3b22 2061 6c74 3d22 4b61 7479  00px;" alt="Katy
+00006a90: 426c 756d 6572 222f 3e3c 6272 202f 3e3c  Blumer"/><br /><
+00006aa0: 7375 623e 3c62 3e4b 6174 7942 6c75 6d65  sub><b>KatyBlume
+00006ab0: 723c 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c  r</b></sub></a><
+00006ac0: 6272 202f 3e3c 6120 6872 6566 3d22 2364  br /><a href="#d
+00006ad0: 6174 612d 4b61 7479 426c 756d 6572 2220  ata-KatyBlumer" 
+00006ae0: 7469 746c 653d 2244 6174 6122 3ef0 9f94  title="Data">...
+00006af0: a33c 2f61 3e3c 2f74 643e 0a20 2020 2020  .</a></td>.     
+00006b00: 203c 7464 2061 6c69 676e 3d22 6365 6e74   <td align="cent
+00006b10: 6572 2220 7661 6c69 676e 3d22 746f 7022  er" valign="top"
+00006b20: 2077 6964 7468 3d22 3134 2e32 3825 223e   width="14.28%">
+00006b30: 3c61 2068 7265 663d 2268 7474 7073 3a2f  <a href="https:/
+00006b40: 2f67 6974 6875 622e 636f 6d2f 616c 7334  /github.com/als4
+00006b50: 3532 223e 3c69 6d67 2073 7263 3d22 6874  52"><img src="ht
+00006b60: 7470 733a 2f2f 6176 6174 6172 732e 6769  tps://avatars.gi
+00006b70: 7468 7562 7573 6572 636f 6e74 656e 742e  thubusercontent.
+00006b80: 636f 6d2f 752f 3135 3833 3832 3538 3f76  com/u/15838258?v
+00006b90: 3d34 3f73 3d31 3030 2220 7769 6474 683d  =4?s=100" width=
+00006ba0: 2231 3030 7078 3b22 2061 6c74 3d22 616c  "100px;" alt="al
+00006bb0: 7334 3532 222f 3e3c 6272 202f 3e3c 7375  s452"/><br /><su
+00006bc0: 623e 3c62 3e61 6c73 3435 323c 2f62 3e3c  b><b>als452</b><
+00006bd0: 2f73 7562 3e3c 2f61 3e3c 6272 202f 3e3c  /sub></a><br /><
+00006be0: 6120 6872 6566 3d22 2364 6174 612d 616c  a href="#data-al
+00006bf0: 7334 3532 2220 7469 746c 653d 2244 6174  s452" title="Dat
+00006c00: 6122 3ef0 9f94 a33c 2f61 3e3c 2f74 643e  a">....</a></td>
+00006c10: 0a20 2020 2020 203c 7464 2061 6c69 676e  .      <td align
+00006c20: 3d22 6365 6e74 6572 2220 7661 6c69 676e  ="center" valign
+00006c30: 3d22 746f 7022 2077 6964 7468 3d22 3134  ="top" width="14
+00006c40: 2e32 3825 223e 3c61 2068 7265 663d 2268  .28%"><a href="h
+00006c50: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
+00006c60: 6d2f 4b61 6d69 6e73 6b79 4a22 3e3c 696d  m/KaminskyJ"><im
+00006c70: 6720 7372 633d 2268 7474 7073 3a2f 2f61  g src="https://a
+00006c80: 7661 7461 7273 2e67 6974 6875 6275 7365  vatars.githubuse
+00006c90: 7263 6f6e 7465 6e74 2e63 6f6d 2f75 2f32  rcontent.com/u/2
+00006ca0: 3633 3935 3737 323f 763d 343f 733d 3130  6395772?v=4?s=10
+00006cb0: 3022 2077 6964 7468 3d22 3130 3070 783b  0" width="100px;
+00006cc0: 2220 616c 743d 224b 616d 696e 736b 794a  " alt="KaminskyJ
+00006cd0: 222f 3e3c 6272 202f 3e3c 7375 623e 3c62  "/><br /><sub><b
+00006ce0: 3e4b 616d 696e 736b 794a 3c2f 623e 3c2f  >KaminskyJ</b></
+00006cf0: 7375 623e 3c2f 613e 3c62 7220 2f3e 3c61  sub></a><br /><a
+00006d00: 2068 7265 663d 2268 7474 7073 3a2f 2f67   href="https://g
+00006d10: 6974 6875 622e 636f 6d2f 436f 726e 656c  ithub.com/Cornel
+00006d20: 6c4e 4c50 2f43 6f6e 766f 4b69 742f 636f  lNLP/ConvoKit/co
+00006d30: 6d6d 6974 733f 6175 7468 6f72 3d4b 616d  mmits?author=Kam
+00006d40: 696e 736b 794a 2220 7469 746c 653d 2243  inskyJ" title="C
+00006d50: 6f64 6522 3ef0 9f92 bb3c 2f61 3e3c 2f74  ode">....</a></t
+00006d60: 643e 0a20 2020 2020 203c 7464 2061 6c69  d>.      <td ali
+00006d70: 676e 3d22 6365 6e74 6572 2220 7661 6c69  gn="center" vali
+00006d80: 676e 3d22 746f 7022 2077 6964 7468 3d22  gn="top" width="
+00006d90: 3134 2e32 3825 223e 3c61 2068 7265 663d  14.28%"><a href=
+00006da0: 2268 7474 7073 3a2f 2f67 6974 6875 622e  "https://github.
+00006db0: 636f 6d2f 4170 3130 3735 223e 3c69 6d67  com/Ap1075"><img
+00006dc0: 2073 7263 3d22 6874 7470 733a 2f2f 6176   src="https://av
+00006dd0: 6174 6172 732e 6769 7468 7562 7573 6572  atars.githubuser
+00006de0: 636f 6e74 656e 742e 636f 6d2f 752f 3235  content.com/u/25
+00006df0: 3739 3030 3932 3f76 3d34 3f73 3d31 3030  790092?v=4?s=100
+00006e00: 2220 7769 6474 683d 2231 3030 7078 3b22  " width="100px;"
+00006e10: 2061 6c74 3d22 4172 6d61 616e 2050 7572   alt="Armaan Pur
+00006e20: 6922 2f3e 3c62 7220 2f3e 3c73 7562 3e3c  i"/><br /><sub><
+00006e30: 623e 4172 6d61 616e 2050 7572 693c 2f62  b>Armaan Puri</b
+00006e40: 3e3c 2f73 7562 3e3c 2f61 3e3c 6272 202f  ></sub></a><br /
+00006e50: 3e3c 6120 6872 6566 3d22 6874 7470 733a  ><a href="https:
+00006e60: 2f2f 6769 7468 7562 2e63 6f6d 2f43 6f72  //github.com/Cor
+00006e70: 6e65 6c6c 4e4c 502f 436f 6e76 6f4b 6974  nellNLP/ConvoKit
+00006e80: 2f63 6f6d 6d69 7473 3f61 7574 686f 723d  /commits?author=
+00006e90: 4170 3130 3735 2220 7469 746c 653d 2243  Ap1075" title="C
+00006ea0: 6f64 6522 3ef0 9f92 bb3c 2f61 3e3c 2f74  ode">....</a></t
+00006eb0: 643e 0a20 2020 203c 2f74 723e 0a20 2020  d>.    </tr>.   
+00006ec0: 203c 7472 3e0a 2020 2020 2020 3c74 6420   <tr>.      <td 
+00006ed0: 616c 6967 6e3d 2263 656e 7465 7222 2076  align="center" v
+00006ee0: 616c 6967 6e3d 2274 6f70 2220 7769 6474  align="top" widt
+00006ef0: 683d 2231 342e 3238 2522 3e3c 6120 6872  h="14.28%"><a hr
+00006f00: 6566 3d22 6874 7470 733a 2f2f 6769 7468  ef="https://gith
+00006f10: 7562 2e63 6f6d 2f6f 7363 6172 736f 3230  ub.com/oscarso20
+00006f20: 3030 223e 3c69 6d67 2073 7263 3d22 6874  00"><img src="ht
+00006f30: 7470 733a 2f2f 6176 6174 6172 732e 6769  tps://avatars.gi
+00006f40: 7468 7562 7573 6572 636f 6e74 656e 742e  thubusercontent.
+00006f50: 636f 6d2f 752f 3230 3137 3235 3733 3f76  com/u/20172573?v
+00006f60: 3d34 3f73 3d31 3030 2220 7769 6474 683d  =4?s=100" width=
+00006f70: 2231 3030 7078 3b22 2061 6c74 3d22 4f73  "100px;" alt="Os
+00006f80: 6361 7220 536f 222f 3e3c 6272 202f 3e3c  car So"/><br /><
+00006f90: 7375 623e 3c62 3e4f 7363 6172 2053 6f3c  sub><b>Oscar So<
+00006fa0: 2f62 3e3c 2f73 7562 3e3c 2f61 3e3c 6272  /b></sub></a><br
+00006fb0: 202f 3e3c 6120 6872 6566 3d22 6874 7470   /><a href="http
+00006fc0: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f43  s://github.com/C
+00006fd0: 6f72 6e65 6c6c 4e4c 502f 436f 6e76 6f4b  ornellNLP/ConvoK
+00006fe0: 6974 2f63 6f6d 6d69 7473 3f61 7574 686f  it/commits?autho
+00006ff0: 723d 6f73 6361 7273 6f32 3030 3022 2074  r=oscarso2000" t
+00007000: 6974 6c65 3d22 436f 6465 223e f09f 92bb  itle="Code">....
+00007010: 3c2f 613e 3c2f 7464 3e0a 2020 2020 2020  </a></td>.      
+00007020: 3c74 6420 616c 6967 6e3d 2263 656e 7465  <td align="cente
+00007030: 7222 2076 616c 6967 6e3d 2274 6f70 2220  r" valign="top" 
+00007040: 7769 6474 683d 2231 342e 3238 2522 3e3c  width="14.28%"><
+00007050: 6120 6872 6566 3d22 6874 7470 3a2f 2f6a  a href="http://j
+00007060: 7573 7469 6e2d 6368 6f2e 636f 6d22 3e3c  ustin-cho.com"><
+00007070: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
+00007080: 2f61 7661 7461 7273 2e67 6974 6875 6275  /avatars.githubu
+00007090: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f75  sercontent.com/u
+000070a0: 2f33 3139 3737 3138 363f 763d 343f 733d  /31977186?v=4?s=
+000070b0: 3130 3022 2077 6964 7468 3d22 3130 3070  100" width="100p
+000070c0: 783b 2220 616c 743d 224a 7573 7469 6e20  x;" alt="Justin 
+000070d0: 4368 6f22 2f3e 3c62 7220 2f3e 3c73 7562  Cho"/><br /><sub
+000070e0: 3e3c 623e 4a75 7374 696e 2043 686f 3c2f  ><b>Justin Cho</
+000070f0: 623e 3c2f 7375 623e 3c2f 613e 3c62 7220  b></sub></a><br 
+00007100: 2f3e 3c61 2068 7265 663d 2223 6461 7461  /><a href="#data
+00007110: 2d77 6973 652d 6561 7374 2220 7469 746c  -wise-east" titl
+00007120: 653d 2244 6174 6122 3ef0 9f94 a33c 2f61  e="Data">....</a
+00007130: 3e3c 2f74 643e 0a20 2020 203c 2f74 723e  ></td>.    </tr>
+00007140: 0a20 203c 2f74 626f 6479 3e0a 3c2f 7461  .  </tbody>.</ta
+00007150: 626c 653e 0a0a 3c21 2d2d 206d 6172 6b64  ble>..<!-- markd
+00007160: 6f77 6e6c 696e 742d 7265 7374 6f72 6520  ownlint-restore 
+00007170: 2d2d 3e0a 3c21 2d2d 2070 7265 7474 6965  -->.<!-- prettie
+00007180: 722d 6967 6e6f 7265 2d65 6e64 202d 2d3e  r-ignore-end -->
+00007190: 0a0a 3c21 2d2d 2041 4c4c 2d43 4f4e 5452  ..<!-- ALL-CONTR
+000071a0: 4942 5554 4f52 532d 4c49 5354 3a45 4e44  IBUTORS-LIST:END
+000071b0: 202d 2d3e 0a0a 5468 6973 2070 726f 6a65   -->..This proje
+000071c0: 6374 2066 6f6c 6c6f 7773 2074 6865 205b  ct follows the [
+000071d0: 616c 6c2d 636f 6e74 7269 6275 746f 7273  all-contributors
+000071e0: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
+000071f0: 2e63 6f6d 2f61 6c6c 2d63 6f6e 7472 6962  .com/all-contrib
+00007200: 7574 6f72 732f 616c 6c2d 636f 6e74 7269  utors/all-contri
+00007210: 6275 746f 7273 2920 7370 6563 6966 6963  butors) specific
+00007220: 6174 696f 6e2e 2043 6f6e 7472 6962 7574  ation. Contribut
+00007230: 696f 6e73 206f 6620 616e 7920 6b69 6e64  ions of any kind
+00007240: 2077 656c 636f 6d65 210a                  welcome!.
```

### Comparing `convokit-2.5.3/convokit/__init__.py` & `convokit-3.0.0/convokit/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,9 +13,10 @@
 from .ranker import *
 from .forecaster import *
 from .fighting_words import *
 from .paired_prediction import *
 from .bag_of_words import *
 from .expected_context_framework import *
 from .surprise import *
+from .convokitConfig import *
 
-#__path__ = __import__('pkgutil').extend_path(__path__, __name__)
+# __path__ = __import__('pkgutil').extend_path(__path__, __name__)
```

### Comparing `convokit-2.5.3/convokit/bag_of_words/bow_transformer.py` & `convokit-3.0.0/convokit/bag_of_words/bow_transformer.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,56 +24,75 @@
     :param vectorizer: a sklearn vectorizer object; default is CountVectorizer(min_df=10, max_df=.5, ngram_range(1, 1),
         binary=False, max_features=15000)
     :param vector_name: name for the vector matrix generated in the transform() step
     :param text_func: function for getting text from the Corpus component object. By default, this is configured
         based on the `obj_type`.
 
     """
-    def __init__(self, obj_type: str, vector_name="bow_vector",
-                 text_func: Callable[[CorpusComponent], str] = None, vectorizer=None):
 
+    def __init__(
+        self,
+        obj_type: str,
+        vector_name="bow_vector",
+        text_func: Callable[[CorpusComponent], str] = None,
+        vectorizer=None,
+    ):
         if vectorizer is None:
             print("Initializing default unigram CountVectorizer...", end="")
-            self.vectorizer = CV(decode_error='ignore', min_df=10, max_df=.5,
-                                 ngram_range=(1, 1), binary=False, max_features=15000)
+            self.vectorizer = CV(
+                decode_error="ignore",
+                min_df=10,
+                max_df=0.5,
+                ngram_range=(1, 1),
+                binary=False,
+                max_features=15000,
+            )
             print("Done.")
         else:
             self.vectorizer = vectorizer
 
         self.obj_type = obj_type
         self.vector_name = vector_name
 
         if text_func is None:
             if obj_type == "utterance":
                 self.text_func = lambda utt: utt.text
             elif obj_type == "conversation":
                 self.text_func = lambda convo: " ".join(utt.text for utt in convo.iter_utterances())
             elif obj_type == "speaker":
-                self.text_func = lambda speaker: " ".join(utt.text for utt in speaker.iter_utterances())
+                self.text_func = lambda speaker: " ".join(
+                    utt.text for utt in speaker.iter_utterances()
+                )
             else:
-                raise ValueError("Invalid corpus object type. Use 'utterance', 'conversation', or 'speaker'")
+                raise ValueError(
+                    "Invalid corpus object type. Use 'utterance', 'conversation', or 'speaker'"
+                )
         else:
             self.text_func = text_func
 
-    def fit(self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def fit(
+        self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Fit the Transformer's internal vectorizer on the Corpus objects' texts, with an optional selector that selects
         for objects to be fit on.
 
         :param corpus: the target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False
             (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
         :return: the fitted BoWTransformer
         """
         # collect texts for vectorization
         docs = [self.text_func(obj) for obj in corpus.iter_objs(self.obj_type, selector)]
         self.vectorizer.fit(docs)
         return self
 
-    def transform(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True) -> Corpus:
+    def transform(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ) -> Corpus:
         """
         Computes the vector matrix for the Corpus component objects and then stores it in a ConvoKitMatrix object,
         which is saved in the Corpus as `vector_name`.
 
         :param corpus: the target Corpus
         :param selector: a (lambda) function that takes a Corpus component object and returns True or False
             (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
@@ -92,15 +111,17 @@
         corpus.set_vector_matrix(self.vector_name, matrix=matrix, ids=ids, columns=column_names)
 
         for obj in objs:
             obj.add_vector(self.vector_name)
 
         return corpus
 
-    def fit_transform(self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True) -> Corpus:
+    def fit_transform(
+        self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ) -> Corpus:
         """
         Fit the Transformer's internal vectorizer on the Corpus component objects' texts, and then compute
         vector representations for them and stores it in the Corpus object as `vector_name`.
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Corpus component object and returns True or False
             (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
```

### Comparing `convokit-2.5.3/convokit/classifier/classifier.py` & `convokit-3.0.0/convokit/classifier/classifier.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-from sklearn.model_selection import train_test_split, cross_val_score, KFold
+from sklearn.linear_model import LogisticRegression
 from sklearn.metrics import confusion_matrix, classification_report
+from sklearn.model_selection import train_test_split, cross_val_score, KFold
 from sklearn.pipeline import Pipeline
 from sklearn.preprocessing import StandardScaler
-from sklearn.linear_model import LogisticRegression
 
+from convokit import Transformer
 from convokit.classifier.util import *
-from convokit import Transformer, CorpusComponent
-from convokit.util import deprecation
+
 
 class Classifier(Transformer):
     """
     Transformer that trains a classifier on the specified features of a Corpus's objects.
 
     Runs on the Corpus's Speakers, Utterances, or Conversations (as specified by obj_type).
 
@@ -21,65 +21,75 @@
     :param labeller: a (lambda) function that takes a Corpus object and returns True (y=1) or False (y=0)
         - i.e. labeller defines the y value of the object for fitting
     :param clf: optional sklearn classifier model. By default, clf is a Pipeline with StandardScaler and LogisticRegression.
     :param clf_attribute_name: the metadata attribute name to store the classifier prediction value under; default: "prediction"
     :param clf_prob_attribute_name: the metadata attribute name to store the classifier prediction score under; default: "pred_score"
 
     """
-    def __init__(self, obj_type: str, pred_feats: List[str],
-                 labeller: Callable[[CorpusComponent], bool] = lambda x: True,
-                 clf=None, clf_attribute_name: str = "prediction", clf_feat_name=None,
-                 clf_prob_attribute_name: str = "pred_score", clf_prob_feat_name=None,
-                 ):
+
+    def __init__(
+        self,
+        obj_type: str,
+        pred_feats: List[str],
+        labeller: Callable[[CorpusComponent], bool] = lambda x: True,
+        clf=None,
+        clf_attribute_name: str = "prediction",
+        clf_prob_attribute_name: str = "pred_score",
+    ):
         self.pred_feats = pred_feats
         self.labeller = labeller
         self.obj_type = obj_type
         if clf is None:
-            clf = Pipeline([("standardScaler", StandardScaler(with_mean=False)),
-                            ("logreg", LogisticRegression(solver='liblinear'))])
+            clf = Pipeline(
+                [
+                    ("standardScaler", StandardScaler(with_mean=False)),
+                    ("logreg", LogisticRegression(solver="liblinear")),
+                ]
+            )
             print("Initialized default classification model (standard scaled logistic regression).")
         self.clf = clf
-        self.clf_attribute_name = clf_attribute_name if clf_feat_name is None else clf_feat_name
-        self.clf_prob_attribute_name = clf_prob_attribute_name if clf_prob_feat_name is None else clf_prob_feat_name
+        self.clf_attribute_name = clf_attribute_name
+        self.clf_prob_attribute_name = clf_prob_attribute_name
 
-        if clf_feat_name is not None:
-            deprecation("Classifier's clf_feat_name parameter", 'clf_attribute_name')
-
-        if clf_prob_feat_name is not None:
-            deprecation("Classifier's clf_prob_feat_name parameter", 'clf_prob_attribute_name')
-
-
-    def fit(self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def fit(
+        self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Trains the Transformer's classifier model, with an optional selector that filters for objects to be fit on.
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude).
             By default, the selector includes all objects of the specified type in the Corpus.
         :return: the fitted Classifier Transformer
         """
-        X, y = extract_feats_and_label(corpus, self.obj_type, self.pred_feats, self.labeller, selector)
+        X, y = extract_feats_and_label(
+            corpus, self.obj_type, self.pred_feats, self.labeller, selector
+        )
         self.clf.fit(X, y)
         return self
 
-    def transform(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True) -> Corpus:
+    def transform(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ) -> Corpus:
         """
         Run classifier on given corpus's objects and annotate them with the predictions and prediction scores,
         with an optional selector that filters for objects to be classified. Objects that are not selected will get
         a metadata value of 'None' instead of the classifier prediction.
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude).
             By default, the selector includes all objects of the specified type in the Corpus.
 
         :return: annotated Corpus
         """
         obj_id_to_feats = extract_feats_dict(corpus, self.obj_type, self.pred_feats, selector)
-        feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))
-        X = csr_matrix(feats_df.values.astype('float64'))
+        feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient="index").reindex(
+            index=list(obj_id_to_feats)
+        )
+        X = csr_matrix(feats_df.values.astype("float64"))
         idx_to_id = {idx: obj_id for idx, obj_id in enumerate(list(obj_id_to_feats))}
         clfs, clfs_probs = self.clf.predict(X), self.clf.predict_proba(X)[:, 1]
 
         for idx, (clf, clf_prob) in enumerate(list(zip(clfs, clfs_probs))):
             corpus_obj = corpus.get_object(self.obj_type, idx_to_id[idx])
             corpus_obj.add_meta(self.clf_attribute_name, clf)
             corpus_obj.add_meta(self.clf_prob_attribute_name, clf_prob)
@@ -87,15 +97,17 @@
         for obj in corpus.iter_objs(self.obj_type, selector):
             if self.clf_attribute_name not in obj.meta:
                 obj.meta[self.clf_attribute_name] = None
                 obj.meta[self.clf_prob_attribute_name] = None
 
         return corpus
 
-    def fit_transform(self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True) -> Corpus:
+    def fit_transform(
+        self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ) -> Corpus:
         self.fit(corpus, selector=selector)
         return self.transform(corpus, selector=selector)
 
     def transform_objs(self, objs: List[CorpusComponent]) -> List[CorpusComponent]:
         """
         Run classifier on list of Corpus objects and annotate them with the predictions and prediction scores
 
@@ -110,75 +122,102 @@
         for idx, (clf, clf_prob) in enumerate(list(zip(clfs, clfs_probs))):
             obj = objs[idx]
             obj.add_meta(self.clf_attribute_name, clf)
             obj.add_meta(self.clf_prob_attribute_name, clf_prob)
 
         return objs
 
-    def summarize(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def summarize(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Generate a pandas DataFrame (indexed by object id, with prediction and prediction score columns) of classification results.
 
         Run either on a target Corpus or a list of Corpus objects
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
 
         :return: pandas DataFrame indexed by Corpus object id
         """
         objId_clf_prob = []
 
         for obj in corpus.iter_objs(self.obj_type, selector):
-            objId_clf_prob.append((obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name]))
-
-        return pd.DataFrame(list(objId_clf_prob),
-                            columns=['id', self.clf_attribute_name, self.clf_prob_attribute_name]).set_index('id').sort_values(self.clf_prob_attribute_name)
+            objId_clf_prob.append(
+                (obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name])
+            )
+
+        return (
+            pd.DataFrame(
+                list(objId_clf_prob),
+                columns=["id", self.clf_attribute_name, self.clf_prob_attribute_name],
+            )
+            .set_index("id")
+            .sort_values(self.clf_prob_attribute_name)
+        )
 
     def summarize_objs(self, objs: List[CorpusComponent]):
         """
         Generate a pandas DataFrame (indexed by object id, with prediction and prediction score columns) of classification results.
 
         Runs on a list of Corpus objects.
 
         :param objs: list of Corpus objects
         :return: pandas DataFrame indexed by Corpus object id
         """
         objId_clf_prob = []
         for obj in objs:
-            objId_clf_prob.append((obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name]))
-
-        return pd.DataFrame(list(objId_clf_prob),
-                            columns=['id', self.clf_attribute_name, self.clf_prob_attribute_name]).set_index('id').sort_values(self.clf_prob_attribute_name)
-
-    def evaluate_with_train_test_split(self, corpus: Corpus = None,
-                                       objs: List[CorpusComponent] = None,
-                                       selector: Callable[[CorpusComponent], bool] = lambda x: True,
-                                       test_size: float = 0.2):
+            objId_clf_prob.append(
+                (obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name])
+            )
+
+        return (
+            pd.DataFrame(
+                list(objId_clf_prob),
+                columns=["id", self.clf_attribute_name, self.clf_prob_attribute_name],
+            )
+            .set_index("id")
+            .sort_values(self.clf_prob_attribute_name)
+        )
+
+    def evaluate_with_train_test_split(
+        self,
+        corpus: Corpus = None,
+        objs: List[CorpusComponent] = None,
+        selector: Callable[[CorpusComponent], bool] = lambda x: True,
+        test_size: float = 0.2,
+    ):
         """
         Evaluate the performance of predictive features (Classifier.pred_feats) in predicting for the label,
         using a train-test split.
 
         Run either on a Corpus (with Classifier labeller, selector, obj_type settings) or a list of Corpus objects
 
         :param corpus: target Corpus
         :param objs: target list of Corpus objects
         :param selector: if running on a Corpus, this is a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
         :param test_size: size of test set
         :return: accuracy and confusion matrix
         """
         if ((corpus is None) and (objs is None)) or ((corpus is not None) and (objs is not None)):
-            raise ValueError("This function takes in either a Corpus or a list of speakers / utterances / conversations")
+            raise ValueError(
+                "This function takes in either a Corpus or a list of speakers / utterances / conversations"
+            )
 
         if corpus:
             print("Using corpus objects...")
-            X, y = extract_feats_and_label(corpus, self.obj_type, self.pred_feats, self.labeller, selector)
+            X, y = extract_feats_and_label(
+                corpus, self.obj_type, self.pred_feats, self.labeller, selector
+            )
         else:
             assert objs is not None
             print("Using input list of corpus objects...")
-            X = np.array([list(extract_feats_from_obj(obj, self.pred_feats).values()) for obj in objs])
+            X = np.array(
+                [list(extract_feats_from_obj(obj, self.pred_feats).values()) for obj in objs]
+            )
             y = np.array([self.labeller(obj) for obj in objs])
 
         print("Running a train-test-split evaluation...")
         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)
         self.clf.fit(X_train, y_train)
         preds = self.clf.predict(X_test)
         accuracy = np.mean(preds == y_test)
@@ -187,19 +226,21 @@
 
     # def evaluate_with_cv(self, corpus: Corpus = None,
     #                      objs: List[CorpusComponent] = None,
     #                      cv=KFold(n_splits=5),
     #                      selector: Callable[[CorpusComponent], bool] = lambda x: True
     #                      ):
     #     return
-    def evaluate_with_cv(self, corpus: Corpus = None,
-                         objs: List[CorpusComponent] = None,
-                         cv=KFold(n_splits=5, shuffle=True),
-                         selector: Callable[[CorpusComponent], bool] = lambda x: True
-                         ):
+    def evaluate_with_cv(
+        self,
+        corpus: Corpus = None,
+        objs: List[CorpusComponent] = None,
+        cv=KFold(n_splits=5, shuffle=True),
+        selector: Callable[[CorpusComponent], bool] = lambda x: True,
+    ):
         """
         Evaluate the performance of predictive features (Classifier.pred_feats) in predicting for the label,
         using cross-validation for data splitting.
 
         This method can be run on either a Corpus (passed in as the `corpus` parameter) or a list of Corpus
         component objects (passed in as the `objs` parameter). If run on a Corpus, the cross-validation will be run
         with the Classifier's `labeller` and `obj_type` settings, and the `selector` parameter of this function.
@@ -210,31 +251,39 @@
         :param selector: if running on a Corpus, this is a (lambda) function that takes a Corpus object and returns
             True or False (i.e. include / exclude). By default, the selector includes all objects of the specified type
             in the Corpus.
 
         :return: cross-validated accuracy score
         """
         if ((corpus is None) and (objs is None)) or ((corpus is not None) and (objs is not None)):
-            raise ValueError("This function takes in either a Corpus or a list of speakers / utterances / conversations")
+            raise ValueError(
+                "This function takes in either a Corpus or a list of speakers / utterances / conversations"
+            )
 
         if corpus:
             print("Using corpus objects...")
-            X, y = extract_feats_and_label(corpus, self.obj_type, self.pred_feats, self.labeller, selector)
+            X, y = extract_feats_and_label(
+                corpus, self.obj_type, self.pred_feats, self.labeller, selector
+            )
         else:
             assert objs is not None
             print("Using input list of corpus objects...")
-            X = np.array([list(extract_feats_from_obj(obj, self.pred_feats).values()) for obj in objs])
+            X = np.array(
+                [list(extract_feats_from_obj(obj, self.pred_feats).values()) for obj in objs]
+            )
             y = np.array([self.labeller(obj) for obj in objs])
 
         print("Running a cross-validated evaluation...")
         score = cross_val_score(self.clf, X, y, cv=cv)
         print("Done.")
         return score
 
-    def confusion_matrix(self, corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def confusion_matrix(
+        self, corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Generate confusion matrix for transformed corpus using labeller for y_true and clf_attribute_name as y_pred
 
         :param corpus: target Corpus
         :param selector: (lambda) function selecting objects to include in this confusion_matrix; uses all objects by default
         :return: sklearn confusion matrix
         """
@@ -252,15 +301,15 @@
 
         :param corpus: the classified Corpus
         :param selector: (lambda) function selecting objects to include in this accuracy calculation; uses all objects by default
         :return: float value
         """
         y_true, y_pred = self.get_y_true_pred(corpus, selector)
         all_true_accuracy = np.array(y_true).mean()
-        return max(all_true_accuracy, 1-all_true_accuracy)
+        return max(all_true_accuracy, 1 - all_true_accuracy)
 
     def accuracy(self, corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True):
         """
         Calculate the accuracy of the classification
 
         :param corpus: target Corpus
         :param selector: (lambda) function selecting objects to include in this accuracy calculation; uses all objects by default
@@ -281,15 +330,17 @@
         y_pred = []
         for obj in corpus.iter_objs(self.obj_type, selector):
             y_true.append(self.labeller(obj))
             y_pred.append(obj.meta[self.clf_attribute_name])
 
         return y_true, y_pred
 
-    def classification_report(self, corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def classification_report(
+        self, corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Generate classification report for transformed corpus using labeller for y_true and clf_attribute_name as y_pred
 
         :param corpus: target Corpus
         :param selector: (lambda) function selecting objects to include in this classification report
         :return: classification report
         """
```

### Comparing `convokit-2.5.3/convokit/classifier/util.py` & `convokit-3.0.0/convokit/classifier/util.py`

 * *Files 7% similar despite different names*

```diff
@@ -21,84 +21,103 @@
         if type(feat_val) == dict:
             retval.update(feat_val)
         else:
             retval[feat_name] = feat_val
     return retval
 
 
-def extract_feats_dict(corpus: Corpus, obj_type: str, pred_feats: List[str],
-                       selector: Callable[[CorpusComponent], bool] = lambda x: True):
+def extract_feats_dict(
+    corpus: Corpus,
+    obj_type: str,
+    pred_feats: List[str],
+    selector: Callable[[CorpusComponent], bool] = lambda x: True,
+):
     """
     Extract features dictionary from a corpus
     :param corpus: target corpus
     :param obj_type: Corpus object type
     :param pred_feats: list of features to extract metadata for
     :param selector: function to select for Corpus objects to extract features from
     :return: dictionary mapping object id to a dictionary of predictive features
     """
-    obj_id_to_feats = {obj.id: extract_feats_from_obj(obj, pred_feats) for obj in corpus.iter_objs(obj_type, selector)}
+    obj_id_to_feats = {
+        obj.id: extract_feats_from_obj(obj, pred_feats)
+        for obj in corpus.iter_objs(obj_type, selector)
+    }
 
     return obj_id_to_feats
 
 
-def extract_feats(corpus: Corpus, obj_type: str, pred_feats: List[str],
-                  selector: Callable[[CorpusComponent], bool] = lambda x: True):
+def extract_feats(
+    corpus: Corpus,
+    obj_type: str,
+    pred_feats: List[str],
+    selector: Callable[[CorpusComponent], bool] = lambda x: True,
+):
     """
     Extract a matrix representation of Corpus objects' features from corpus
     :param corpus: target corpus
     :param obj_type: Corpus object type
     :param pred_feats: list of features to extract metadata for
     :param selector: function to select for Corpus objects to extract features from
     :return: matrix of Corpus objects' features
     """
     obj_id_to_feats = extract_feats_dict(corpus, obj_type, pred_feats, selector)
-    feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index')
+    feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient="index")
     return csr_matrix(feats_df.values)
 
 
-def extract_label_dict(corpus: Corpus, obj_type: str, labeller: Callable[[CorpusComponent], bool],
-                       selector: Callable[[CorpusComponent], bool] = lambda x: True):
+def extract_label_dict(
+    corpus: Corpus,
+    obj_type: str,
+    labeller: Callable[[CorpusComponent], bool],
+    selector: Callable[[CorpusComponent], bool] = lambda x: True,
+):
     """
     Generate dictionary mapping Corpus object id to label from corpus
     :param corpus: target corpus
     :param obj_type: Corpus object type
     :param labeller: function that takes a Corpus object as input and outputs its label
     :param selector: function to select for Corpus objects to extract features from
     :return: dictionary mapping Corpus object id to label
     """
     obj_id_to_label = dict()
     for obj in corpus.iter_objs(obj_type, selector):
-        obj_id_to_label[obj.id] = {'y': 1} if labeller(obj) else {'y': 0}
+        obj_id_to_label[obj.id] = {"y": 1} if labeller(obj) else {"y": 0}
 
     return obj_id_to_label
 
 
-def extract_feats_and_label(corpus: Corpus, obj_type: str, pred_feats: List[str],
-                            labeller: Callable[[CorpusComponent], bool],
-                            selector: Callable[[CorpusComponent], bool] = None):
+def extract_feats_and_label(
+    corpus: Corpus,
+    obj_type: str,
+    pred_feats: List[str],
+    labeller: Callable[[CorpusComponent], bool],
+    selector: Callable[[CorpusComponent], bool] = None,
+):
     """
     Extract matrix of predictive features and numpy array of labels from corpus
     :param corpus: target Corpus
     :param obj_type: Corpus object type
     :param pred_feats: list of features to extract metadata for
     :param labeller: function that takes a Corpus object as input and outputs its label
     :param selector: function to select for Corpus objects to extract features from
     :return: matrix of predictive features and numpy array of labels
     """
     obj_id_to_feats = extract_feats_dict(corpus, obj_type, pred_feats, selector)
     obj_id_to_label = extract_label_dict(corpus, obj_type, labeller, selector)
 
-    X_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index')
-    y_df = pd.DataFrame.from_dict(obj_id_to_label, orient='index')
+    X_df = pd.DataFrame.from_dict(obj_id_to_feats, orient="index")
+    y_df = pd.DataFrame.from_dict(obj_id_to_label, orient="index")
 
     X_y_df = pd.concat([X_df, y_df], axis=1, sort=False)
 
-    y = X_y_df['y']
-    X = X_y_df.drop(columns='y')
-    X = X.astype('float64')
+    y = X_y_df["y"]
+    X = X_y_df.drop(columns="y")
+    X = X.astype("float64")
 
     return csr_matrix(X.values), np.array(y)
 
 
 def extract_vector_feats_and_label(corpus, obj_type, vector_name, columns, labeller, selector):
     # if ((corpus is None) and (objs is None)) or ((corpus is not None) and (objs is not None)):
     #     raise ValueError("This function takes in either a Corpus or a list of speakers / utterances / conversations")
@@ -123,24 +142,24 @@
     :param clf: classifier model
     :param feature_names: list of feature names to get coefficients for
     :param coef_func: function for accessing the list of coefficients from the classifier model
     :return: DataFrame of features and coefficients, indexed by feature names
     """
     if coef_func is None:
         try:
-            coefs = clf.named_steps['logreg'].coef_[0].tolist()
+            coefs = clf.named_steps["logreg"].coef_[0].tolist()
         except AttributeError:
-            warn("Classifier is not a pipeline with a logistic regression component, so default coefficient getter function"
-                 " did not work. Choose a valid coef_func argument.")
+            warn(
+                "Classifier is not a pipeline with a logistic regression component, so default coefficient getter function"
+                " did not work. Choose a valid coef_func argument."
+            )
             return
     else:
         coefs = coef_func(clf)
 
     assert len(feature_names) == len(coefs)
     feats_coefs = sorted(list(zip(feature_names, coefs)), key=lambda x: x[1], reverse=True)
-    return pd.DataFrame(feats_coefs, columns=['feat_name', 'coef'])\
-                        .set_index('feat_name').sort_values('coef', ascending=False)
-
-
-
-
-
+    return (
+        pd.DataFrame(feats_coefs, columns=["feat_name", "coef"])
+        .set_index("feat_name")
+        .sort_values("coef", ascending=False)
+    )
```

### Comparing `convokit-2.5.3/convokit/classifier/vectorClassifier.py` & `convokit-3.0.0/convokit/classifier/vectorClassifier.py`

 * *Files 6% similar despite different names*

```diff
@@ -27,28 +27,48 @@
         labeller defines the y value of the object for fitting
     :param clf: a sklearn Classifier. By default, clf is a Pipeline with StandardScaler and LogisticRegression
     :param clf_attribute_name: the metadata attribute name to store the classifier prediction value under; default:
         "prediction"
     :param clf_prob_attribute_name: the metadata attribute name to store the classifier prediction score under;
         default: "pred_score"
     """
-    def __init__(self, obj_type: str, vector_name: str, columns: List[str] = None,
-                 labeller: Callable[[CorpusComponent], bool] = lambda x: True,
-                 clf=None, clf_attribute_name: str = "prediction", clf_prob_attribute_name: str = "pred_score"):
+
+    def __init__(
+        self,
+        obj_type: str,
+        vector_name: str,
+        columns: List[str] = None,
+        labeller: Callable[[CorpusComponent], bool] = lambda x: True,
+        clf=None,
+        clf_attribute_name: str = "prediction",
+        clf_prob_attribute_name: str = "pred_score",
+    ):
         if clf is None:
-            clf = Pipeline([("standardScaler", StandardScaler(with_mean=False)),
-                            ("logreg", LogisticRegression(solver='liblinear'))])
+            clf = Pipeline(
+                [
+                    ("standardScaler", StandardScaler(with_mean=False)),
+                    ("logreg", LogisticRegression(solver="liblinear")),
+                ]
+            )
             print("Initialized default classification model (standard scaled logistic regression).")
 
-        super().__init__(obj_type=obj_type, pred_feats=[], labeller=labeller,
-                         clf=clf, clf_attribute_name=clf_attribute_name, clf_prob_attribute_name=clf_prob_attribute_name)
+        super().__init__(
+            obj_type=obj_type,
+            pred_feats=[],
+            labeller=labeller,
+            clf=clf,
+            clf_attribute_name=clf_attribute_name,
+            clf_prob_attribute_name=clf_prob_attribute_name,
+        )
         self.vector_name = vector_name
         self.columns = columns
 
-    def fit(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True, y=None):
+    def fit(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True, y=None
+    ):
         """
         Fit the Transformer's internal classifier model on the vector matrix that represents one of
         the Corpus components, with an optional selector that selects for objects to be fit on.
 
         :param corpus: the target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False
             (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
@@ -64,15 +84,17 @@
         y = np.array(y)
         # print(corpus.get_vector_matrix(self.vector_name).matrix.shape)
         # print(X.shape)
         # print(y.shape)
         self.clf.fit(X, y)
         return self
 
-    def transform(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True) -> Corpus:
+    def transform(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ) -> Corpus:
         """
         Annotate the corpus components with the classifier prediction and prediction score, with an optional selector
         that selects for objects to be classified. Objects that are not selected will get a metadata value of 'None'
         instead of the classifier prediction.
 
         :param corpus: the target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False
@@ -106,47 +128,60 @@
         # """
         # Run classifier on list of Corpus component objects and annotate them with their predictions and
         # prediction scores.
         #
         # :param objs: list of Corpus objects
         # :return: list of annotated Corpus objects
         # """
-        raise NotImplementedError("VectorClassifier can only be run on corpora, not arbitrary lists of corpus "
-                                  "component objects.")
-
-    def fit_transform(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True) -> Corpus:
+        raise NotImplementedError(
+            "VectorClassifier can only be run on corpora, not arbitrary lists of corpus "
+            "component objects."
+        )
+
+    def fit_transform(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ) -> Corpus:
         """
         Runs the `fit()` and `transform()` steps in order, with the specified selector.
 
         :param corpus: the target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False
             (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
 
         :return: the target Corpus annotated
         """
         self.fit(corpus, selector=selector)
         return self.transform(corpus, selector=selector)
 
-    def summarize(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def summarize(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Generate a DataFrame indexed by object id with the classifier predictions and scores.
 
         :param corpus: the annotated Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False
             (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
         :return: a pandas DataFrame
         """
         objId_clf_prob = []
 
         for obj in corpus.iter_objs(self.obj_type, selector):
-            objId_clf_prob.append((obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name]))
-
-        return pd.DataFrame(list(objId_clf_prob),
-                            columns=['id', self.clf_attribute_name, self.clf_prob_attribute_name])\
-                            .set_index('id').sort_values(self.clf_prob_attribute_name, ascending=False)
+            objId_clf_prob.append(
+                (obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name])
+            )
+
+        return (
+            pd.DataFrame(
+                list(objId_clf_prob),
+                columns=["id", self.clf_attribute_name, self.clf_prob_attribute_name],
+            )
+            .set_index("id")
+            .sort_values(self.clf_prob_attribute_name, ascending=False)
+        )
 
     def summarize_objs(self, objs: List[CorpusComponent]):
         """
         Not implemented for VectorClassifier.
         """
         # Generate a pandas DataFrame (indexed by object id, with prediction and prediction score columns) of
         # classification results.
@@ -158,55 +193,66 @@
         # objId_clf_prob = []
         # for obj in objs:
         #     objId_clf_prob.append((obj.id, obj.meta[self.clf_attribute_name], obj.meta[self.clf_prob_attribute_name]))
         #
         # return pd.DataFrame(list(objId_clf_prob),
         #                     columns=['id', self.clf_attribute_name, self.clf_prob_attribute_name]).set_index('id').sort_values(
         #                     self.clf_prob_attribute_name)
-        raise NotImplementedError("VectorClassifier can only be run on corpora, not arbitrary lists of corpus "
-                                  "component objects.")
-
-    def evaluate_with_train_test_split(self, corpus: Corpus,
-                                       selector: Callable[[CorpusComponent], bool] = lambda x: True,
-                                       test_size: float = 0.2):
+        raise NotImplementedError(
+            "VectorClassifier can only be run on corpora, not arbitrary lists of corpus "
+            "component objects."
+        )
+
+    def evaluate_with_train_test_split(
+        self,
+        corpus: Corpus,
+        selector: Callable[[CorpusComponent], bool] = lambda x: True,
+        test_size: float = 0.2,
+    ):
         """
         Evaluate the performance of predictive features (Classifier.pred_feats) in predicting for the label,
         using a train-test split.
 
         Run either on a Corpus (with Classifier labeller, selector, obj_type settings) or a list of Corpus objects
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include /
             exclude). By default, the selector includes all objects of the specified type in the Corpus.
         :param test_size: size of test set
         :return: accuracy and confusion matrix
         """
-        X, y = extract_vector_feats_and_label(corpus, self.obj_type, self.vector_name, self.columns,
-                                              self.labeller, selector)
+        X, y = extract_vector_feats_and_label(
+            corpus, self.obj_type, self.vector_name, self.columns, self.labeller, selector
+        )
 
         print("Running a train-test-split evaluation...")
         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)
         self.clf.fit(X_train, y_train)
         preds = self.clf.predict(X_test)
         accuracy = np.mean(preds == y_test)
         print("Done.")
         return accuracy, confusion_matrix(y_true=y_test, y_pred=preds)
 
-    def evaluate_with_cv(self, corpus: Corpus, cv=KFold(n_splits=5, shuffle=True),
-                         selector: Callable[[CorpusComponent], bool] = lambda x: True):
+    def evaluate_with_cv(
+        self,
+        corpus: Corpus,
+        cv=KFold(n_splits=5, shuffle=True),
+        selector: Callable[[CorpusComponent], bool] = lambda x: True,
+    ):
         """
         Evaluate the performance of predictive features (Classifier.pred_feats) in predicting for the label,
         using cross-validation for data splitting.
 
         :param corpus: target Corpus
         :param cv: cross-validation model to use: KFold(n_splits=5, shuffle=True) by default.
         :param selector: if running on a Corpus, this is a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
 
         :return: cross-validated accuracy score
         """
 
-        X, y = extract_vector_feats_and_label(corpus, self.obj_type, self.vector_name,
-                                              self.columns, self.labeller, selector)
+        X, y = extract_vector_feats_and_label(
+            corpus, self.obj_type, self.vector_name, self.columns, self.labeller, selector
+        )
         print("Running a cross-validated evaluation...", end="")
         score = cross_val_score(self.clf, X, y, cv=cv)
         print("Done.")
         return score
```

### Comparing `convokit-2.5.3/convokit/coordination/coordination.py` & `convokit-3.0.0/convokit/coordination/coordination.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,60 +1,71 @@
-import pkg_resources
-from convokit.model import Corpus, Speaker, Utterance
 from collections import defaultdict
 from typing import Callable, Tuple, List, Dict, Optional, Collection, Union
-from .coordinationScore import CoordinationScore, CoordinationWordCategories
+import copy
 
+import pkg_resources
+
+from convokit.model import Corpus, Speaker, Utterance
 from convokit.transformer import Transformer
 from convokit.util import deprecation
+from .coordinationScore import CoordinationScore, CoordinationWordCategories
+
 
 class Coordination(Transformer):
     """Linguistic coordination is a measure of the propensity of a
     speaker to echo the language of another speaker in a
     conversation, as defined in "Echoes of Power: Language Effects
     and Power Differences in Social Interaction"
     (http://www.cs.cornell.edu/~cristian/Echoes_of_power.html)
-    
+
     This Transformer encapsulates computation of coordination-based features
     for a particular corpus.
 
     Coordination is a measure of power differences between speakers in a
     conversation, based on the propensity of a speaker to echo the same
     function words used by another speaker in a conversation. It is defined in
     Danescu-Niculescu-Mizil et al's "Echoes of Power: Language Effects and Power
     Differences in Social Interaction".
 
     This transformer contains various functions to measure coordination on
     different conversational scales. Calling `transform()` will annotate each
     speaker in the corpus with their coordination to all speakers they directly
     reply to. The `summarize()` function is a convenience method that computes
     aggregated coordination scores between two groups of speakers.
-    
+
     Note: labeling method is slightly different from that used in the paper --
     we no longer match words occurring in the middle of other words and that
     immediately follow an apostrophe. Notably, we no longer separately
     count the "all" in "y'all."
 
     :param coordination_attribute_name: metadata attribute name to store coordination scores during the `transform()` step.
     :param speaker_thresh: Thresholds based on minimum number of times the speaker uses each coordination marker. Speakers that do not meet the threshold are excluded from computation for a given marker.
     :param target_thresh: Thresholds based on minimum number of times the target uses each coordination marker. Targets that do not meet the threshold are excluded from computation for a given marker.
     :param utterances_thresh: Thresholds based on the minimum number of utterances for each speaker. Speakers that do not meet the threshold are excluded from computation for a given marker.
     :param speaker_thresh_indiv: Like `speaker_thresh` but only considers the utterances between a speaker and a single target; thresholds whether the utterances for a single target should be considered for a particular speaker.
     :param target_thresh_indiv: Like `target_thresh` but thresholds whether a single target's utterances should be considered for a particular speaker.
     :param utterances_thresh_indiv: Like `utterances_thresh` but thresholds whether a single target's utterances should be considered for a particular speaker.
     """
 
-    def __init__(self, coordination_attribute_name: str = "coord", 
-        speaker_thresh: int = 0, target_thresh: int = 3,
-        utterances_thresh: int = 0, speaker_thresh_indiv: int = 0,
-        target_thresh_indiv: int = 0, utterances_thresh_indiv: int = 0,
-        utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]] = None):
+    def __init__(
+        self,
+        coordination_attribute_name: str = "coord",
+        speaker_thresh: int = 0,
+        target_thresh: int = 3,
+        utterances_thresh: int = 0,
+        speaker_thresh_indiv: int = 0,
+        target_thresh_indiv: int = 0,
+        utterances_thresh_indiv: int = 0,
+        utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]] = None,
+    ):
         if utterance_thresh_func is not None:
-            deprecation("Coordination's utterance_thresh_func parameter",
-                "speaker, target and utterance threshold parameters")
+            deprecation(
+                "Coordination's utterance_thresh_func parameter",
+                "speaker, target and utterance threshold parameters",
+            )
         self.speaker_thresh = speaker_thresh
         self.target_thresh = target_thresh
         self.utterances_thresh = utterances_thresh
         self.speaker_thresh_indiv = speaker_thresh_indiv
         self.target_thresh_indiv = target_thresh_indiv
         self.utterances_thresh_indiv = utterances_thresh_indiv
         self.utterance_thresh_func = utterance_thresh_func
@@ -62,72 +73,94 @@
         self.precomputed = False
         self.coordination_attribute_name = coordination_attribute_name
 
     def fit(self, corpus: Corpus, y=None):
         """Learn coordination information for the given corpus."""
         self.corpus = corpus
 
-        #if not self.precomputed:
+        # if not self.precomputed:
         self._compute_liwc_reverse_dict()
         self._annot_liwc_cats(corpus)
         self.precomputed = True
 
     def precompute(self, corpus: Corpus):
         """Deprecated. Use fit() instead."""
         deprecation("Coordination's precompute function", "fit")
         self.fit(corpus)
 
     def transform(self, corpus: Corpus) -> Corpus:
         """Generate coordination scores for the corpus you called fit on.
-        
+
         Each speaker's coordination attribute will be a dictionary from targets
         to coordination scores between that speaker and target."""
         if corpus != self.corpus:
             raise Exception("Coordination: must fit and transform on same corpus")
         if not self.precomputed:
             raise Exception("Must fit before calling transform")
 
-        pair_scores = self.pairwise_scores(corpus, corpus.speaking_pairs(),
+        pair_scores = self.pairwise_scores(
+            corpus,
+            corpus.speaking_pairs(),
             speaker_thresh=self.speaker_thresh,
             target_thresh=self.target_thresh,
             utterances_thresh=self.utterances_thresh,
             speaker_thresh_indiv=self.speaker_thresh_indiv,
             target_thresh_indiv=self.target_thresh_indiv,
             utterances_thresh_indiv=self.utterances_thresh_indiv,
-            utterance_thresh_func=self.utterance_thresh_func)
+            utterance_thresh_func=self.utterance_thresh_func,
+        )
+
+        # Keep record of all score update for all (speakers, target) pairs to avoid redundant operations
+        todo = {}
 
         for (speaker, target), score in pair_scores.items():
             if self.coordination_attribute_name not in speaker.meta:
                 speaker.meta[self.coordination_attribute_name] = {}
-            speaker.meta[self.coordination_attribute_name][target.id] = score
+            key = (speaker, target.id)
+            todo.update({key: score})
 
+        for key, score in todo.items():
+            speaker = key[0]
+            target = key[1]
+            # For avoiding mutability for the sake of DB corpus
+            temp_dict = copy.deepcopy(speaker.meta[self.coordination_attribute_name])
+            temp_dict[target] = score
+            speaker.meta[self.coordination_attribute_name] = temp_dict
             assert isinstance(speaker, Speaker)
 
         return corpus
 
     def fit_transform(self, corpus: Corpus, y=None) -> Corpus:
         self.fit(corpus)
         return self.transform(corpus)
 
-    def summarize(self, corpus: Corpus,
-              speaker_selector: Callable[[Speaker], bool] = lambda obj: True,
-              target_selector: Callable[[Speaker], bool] = lambda obj: True,
-              focus: str = "speakers",
-              summary_report: bool = False,
-              speaker_thresh: Optional[int] = None,
-              target_thresh: Optional[int] = None,
-              utterances_thresh: Optional[int] = None,
-              speaker_thresh_indiv: Optional[int] = None,
-              target_thresh_indiv: Optional[int] = None,
-              utterances_thresh_indiv: Optional[int] = None,
-              utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]] = None,
-              split_by_attribs: Optional[List[str]] = None,
-              speaker_utterance_selector: Callable[[Tuple[Utterance, Utterance]], bool] = lambda utt1, utt2: True,
-              target_utterance_selector: Callable[[Tuple[Utterance, Utterance]], bool] = lambda utt1, utt2: True,
-              speaker_attribs: Optional[Dict] = None, target_attribs: Optional[Dict] = None) -> CoordinationScore:
+    def summarize(
+        self,
+        corpus: Corpus,
+        speaker_selector: Callable[[Speaker], bool] = lambda obj: True,
+        target_selector: Callable[[Speaker], bool] = lambda obj: True,
+        focus: str = "speakers",
+        summary_report: bool = False,
+        speaker_thresh: Optional[int] = None,
+        target_thresh: Optional[int] = None,
+        utterances_thresh: Optional[int] = None,
+        speaker_thresh_indiv: Optional[int] = None,
+        target_thresh_indiv: Optional[int] = None,
+        utterances_thresh_indiv: Optional[int] = None,
+        utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]] = None,
+        split_by_attribs: Optional[List[str]] = None,
+        speaker_utterance_selector: Callable[
+            [Tuple[Utterance, Utterance]], bool
+        ] = lambda utt1, utt2: True,
+        target_utterance_selector: Callable[
+            [Tuple[Utterance, Utterance]], bool
+        ] = lambda utt1, utt2: True,
+        speaker_attribs: Optional[Dict] = None,
+        target_attribs: Optional[Dict] = None,
+    ) -> CoordinationScore:
         """Computes a summary of the coordination scores by giving an
         aggregated score between two groups of speakers.
 
         The threshold parameters may be used to override the thresholds set in
         the constructor. If a threshold parameter is not explicitly set, it
         will take on the value provided in the constructor.
 
@@ -183,33 +216,37 @@
         aggregation methods.
         """
         if corpus != self.corpus:
             raise Exception("Coordination: must fit and score on same corpus")
         if not self.precomputed:
             raise Exception("Must fit before calling score")
 
-        if split_by_attribs is None: split_by_attribs = []
+        if split_by_attribs is None:
+            split_by_attribs = []
         if speaker_attribs is None:
             speaker_attribs = dict()
         else:
-            deprecation("Coordination's speaker_attribs parameter",
-                'speaker_utterance_selector')
+            deprecation("Coordination's speaker_attribs parameter", "speaker_utterance_selector")
             speaker_utterance_selector = lambda utt, _: (
-                Coordination._utterance_has_attribs(utt, speaker_attribs))
+                Coordination._utterance_has_attribs(utt, speaker_attribs)
+            )
         if target_attribs is None:
             target_attribs = dict()
         else:
-            deprecation("Coordination's target_attribs parameter",
-                'target_utterance_selector')
+            deprecation("Coordination's target_attribs parameter", "target_utterance_selector")
             target_utterance_selector = lambda _, utt: (
-                Coordination._utterance_has_attribs(utt, target_attribs))
+                Coordination._utterance_has_attribs(utt, target_attribs)
+            )
 
-        if speaker_thresh is None: speaker_thresh = self.speaker_thresh
-        if target_thresh is None: target_thresh = self.target_thresh
-        if utterances_thresh is None: utterances_thresh = self.utterances_thresh
+        if speaker_thresh is None:
+            speaker_thresh = self.speaker_thresh
+        if target_thresh is None:
+            target_thresh = self.target_thresh
+        if utterances_thresh is None:
+            utterances_thresh = self.utterances_thresh
         if speaker_thresh_indiv is None:
             speaker_thresh_indiv = self.speaker_thresh_indiv
         if target_thresh_indiv is None:
             target_thresh_indiv = self.target_thresh_indiv
         if utterances_thresh_indiv is None:
             utterances_thresh_indiv = self.utterances_thresh_indiv
 
@@ -221,28 +258,38 @@
             speaker = utt.speaker
             if speaker in speakers:
                 if utt.reply_to is not None:
                     reply_to = corpus.get_utterance(utt.reply_to)
                     target = reply_to.speaker
                     if target in group:
                         utterances.append(utt)
-        scores = self._scores_over_utterances(corpus, speakers, utterances,
-            speaker_thresh, target_thresh, utterances_thresh,
-            speaker_thresh_indiv, target_thresh_indiv,
-            utterances_thresh_indiv, utterance_thresh_func,
-            focus, split_by_attribs, speaker_utterance_selector,
-            target_utterance_selector)
+        scores = self._scores_over_utterances(
+            corpus,
+            speakers,
+            utterances,
+            speaker_thresh,
+            target_thresh,
+            utterances_thresh,
+            speaker_thresh_indiv,
+            target_thresh_indiv,
+            utterances_thresh_indiv,
+            utterance_thresh_func,
+            focus,
+            split_by_attribs,
+            speaker_utterance_selector,
+            target_utterance_selector,
+        )
 
         if summary_report:
             return self._summarize_score_report(scores)
         else:
             return scores
 
     def _summarize_score_report(self, scores: CoordinationScore):
-        marker_a1 = scores.averages_by_marker(strict_thresh=True)  
+        marker_a1 = scores.averages_by_marker(strict_thresh=True)
         marker = scores.averages_by_marker()
         agg1 = scores.aggregate(method=1)
         agg2 = scores.aggregate(method=2)
         agg3 = scores.aggregate(method=3)
         return {
             "marker_agg1": marker_a1,
             "marker_agg2": marker,
@@ -251,183 +298,213 @@
             "agg2": agg2,
             "agg3": agg3,
             "count_agg1": len([s for s in scores if len(scores[s]) == 8]),
             "count_agg2": len(scores),
             "count_agg3": len(scores),
         }
 
-    def pairwise_scores(self, corpus: Corpus,
-                        pairs: Collection[Tuple[Union[Speaker, str], Union[Speaker, str]]],
-                        speaker_thresh: int = 0, target_thresh: int = 3,
-                        utterances_thresh: int = 0, speaker_thresh_indiv: int = 0,
-                        target_thresh_indiv: int = 0, utterances_thresh_indiv: int = 0,
-                        utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]] = None)\
-            -> CoordinationScore:
+    def pairwise_scores(
+        self,
+        corpus: Corpus,
+        pairs: Collection[Tuple[Union[Speaker, str], Union[Speaker, str]]],
+        speaker_thresh: int = 0,
+        target_thresh: int = 3,
+        utterances_thresh: int = 0,
+        speaker_thresh_indiv: int = 0,
+        target_thresh_indiv: int = 0,
+        utterances_thresh_indiv: int = 0,
+        utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]] = None,
+    ) -> CoordinationScore:
         """Computes all pairwise coordination scores given a collection of
         (speaker, target) pairs.
-        
+
         :param corpus: Corpus to compute scores on
         :param pairs: collection of (speaker id, target id) pairs
         :type pairs: Collection
-        
+
         Also accepted: all threshold arguments accepted by :func:`score()`.
 
         :return: A :class:`CoordinationScore` object corresponding to the
             coordination scores for each (speaker, target) pair.
         """
         if corpus != self.corpus:
             raise Exception("Coordination: must fit and score on same corpus")
         if not self.precomputed:
             raise Exception("Must fit before calling score")
 
         pairs = set(pairs)
         any_speaker = next(iter(pairs))[0]
         if isinstance(any_speaker, str):
-            pairs_utts = corpus.directed_pairwise_exchanges(lambda x, y:
-                (x.id, y.id) in pairs, speaker_ids_only=True)
+            pairs_utts = corpus.directed_pairwise_exchanges(
+                lambda x, y: (x.id, y.id) in pairs, speaker_ids_only=True
+            )
         else:
-            pairs_utts = corpus.directed_pairwise_exchanges(lambda x, y:
-                (x, y) in pairs, speaker_ids_only=False)
+            pairs_utts = corpus.directed_pairwise_exchanges(
+                lambda x, y: (x, y) in pairs, speaker_ids_only=False
+            )
         all_scores = CoordinationScore()
         for (speaker, target), utterances in pairs_utts.items():
-            scores = self._scores_over_utterances(corpus, [speaker], utterances, speaker_thresh, target_thresh,
-                                                 utterances_thresh, speaker_thresh_indiv, target_thresh_indiv,
-                                                 utterances_thresh_indiv, utterance_thresh_func)
-            if len(scores) > 0: # scores.values() will be length 0 or 1
+            scores = self._scores_over_utterances(
+                corpus,
+                [speaker],
+                utterances,
+                speaker_thresh,
+                target_thresh,
+                utterances_thresh,
+                speaker_thresh_indiv,
+                target_thresh_indiv,
+                utterances_thresh_indiv,
+                utterance_thresh_func,
+            )
+            if len(scores) > 0:  # scores.values() will be length 0 or 1
                 all_scores[speaker, target] = list(scores.values())[0]
         return all_scores
 
     def score_report(self, corpus: Corpus, scores: CoordinationScore):
         """Deprecated. Use `summarize()` instead."""
-        deprecation("Coordination's score_report()",
-            "Coordination's summarize()")
+        deprecation("Coordination's score_report()", "Coordination's summarize()")
         if corpus != self.corpus:
             raise Exception("Coordination: must fit and score on same corpus")
         if not self.precomputed:
             raise Exception("Must fit before calling score")
 
-        marker_a1 = scores.averages_by_marker(strict_thresh=True)  
+        marker_a1 = scores.averages_by_marker(strict_thresh=True)
         marker = scores.averages_by_marker()
         agg1 = scores.aggregate(method=1)
         agg2 = scores.aggregate(method=2)
         agg3 = scores.aggregate(method=3)
         return marker_a1, marker, agg1, agg2, agg3
 
     # helper functions
     def _compute_liwc_reverse_dict(self) -> None:
-        with open(pkg_resources.resource_filename("convokit",
-            "data/coord-liwc-patterns.txt"), "r") as f:
+        with open(
+            pkg_resources.resource_filename("convokit", "data/coord-liwc-patterns.txt"), "r"
+        ) as f:
             all_words = []
             for line in f:
                 cat, pat = line.strip().split("\t")
-                #if cat == "auxverb": print(cat, pat)
+                # if cat == "auxverb": print(cat, pat)
                 # use "#" to mark word boundary
                 words = pat.replace("\\b", "#").split("|")
                 all_words += [(w[1:], cat) for w in words]
             self.liwc_trie = Coordination.make_trie(all_words)
 
     @staticmethod
     def make_trie(words) -> Dict:
         root = {}
         for word, cat in words:
             cur = root
             for c in word:
                 cur = cur.setdefault(c, {})
-            if "$" not in cur:   # use "$" as end-of-word symbol
+            if "$" not in cur:  # use "$" as end-of-word symbol
                 cur["$"] = {cat}
             else:
                 cur["$"].add(cat)
         return root
 
     def _annot_liwc_cats(self, corpus) -> None:
         # add liwc_categories field to each utterance
         word_chars = set("abcdefghijklmnopqrstuvwxyz0123456789_")
         for utt in corpus.iter_utterances():
             cats = set()
             last = None
             cur = None
             text = utt.text.lower() + " "
-            #if "'" in text: print(text)
+            # if "'" in text: print(text)
             for i, c in enumerate(text):
                 # slightly different from regex: won't match word after an
                 #   apostrophe unless the apostrophe starts the word
                 #   -- avoids false positives
                 if last not in word_chars and c in word_chars and (last != "'" or not cur):
                     cur = self.liwc_trie
                 if cur:
                     if c in cur and c != "#" and c != "$":
                         if c not in word_chars:
                             if "#" in cur and "$" in cur["#"]:
                                 cats |= cur["#"]["$"]  # finished current word
                         cur = cur[c]
-                    elif c not in word_chars and last in word_chars and \
-                        "#" in cur:
+                    elif c not in word_chars and last in word_chars and "#" in cur:
                         cur = cur["#"]
                     else:
                         cur = None
                 if cur and "$" in cur:
                     cats |= cur["$"]
                 last = c
             utt.meta["liwc-categories"] = cats
 
     @staticmethod
     def _annot_speaker(speaker: Speaker, utt: Utterance, split_by_attribs):
-        return (speaker, tuple([utt.meta[attrib] if attrib in utt.meta else None
-                             for attrib in split_by_attribs]))
+        return (
+            speaker,
+            tuple(
+                [utt.meta[attrib] if attrib in utt.meta else None for attrib in split_by_attribs]
+            ),
+        )
 
     @staticmethod
     def _utterance_has_attribs(utterance, desired_attribs) -> bool:
         for attrib, attrib_val in desired_attribs.items():
             if utterance.meta[attrib] != attrib_val:
                 return False
         return True
 
-    def _scores_over_utterances(self, corpus: Corpus, speakers: Collection[Union[Speaker, str]], utterances,
-                               speaker_thresh: int, target_thresh: int,
-                               utterances_thresh: int, speaker_thresh_indiv: int,
-                               target_thresh_indiv: int, utterances_thresh_indiv: int,
-                               utterance_thresh_func: Optional[Callable[[Tuple[Utterance, Utterance]], bool]]=None,
-                               focus: str="speakers",
-                               split_by_attribs: Optional[List[str]]=None,
-                               speaker_utterance_selector: Callable[[Tuple[Utterance, Utterance]], bool] = lambda utt1, utt2: True,
-                               target_utterance_selector: Callable[[Tuple[Utterance, Utterance]], bool] = lambda utt1, utt2: True
-                                   ) -> CoordinationScore:
+    def _scores_over_utterances(
+        self,
+        corpus: Corpus,
+        speakers: Collection[Union[Speaker, str]],
+        utterances,
+        speaker_thresh: int,
+        target_thresh: int,
+        utterances_thresh: int,
+        speaker_thresh_indiv: int,
+        target_thresh_indiv: int,
+        utterances_thresh_indiv: int,
+        utterance_thresh_func: Optional[Callable[[Utterance, Utterance], bool]] = None,
+        focus: str = "speakers",
+        split_by_attribs: Optional[List[str]] = None,
+        speaker_utterance_selector: Callable[
+            [Utterance, Utterance], bool
+        ] = lambda utt1, utt2: True,
+        target_utterance_selector: Callable[[Utterance, Utterance], bool] = lambda utt1, utt2: True,
+    ) -> CoordinationScore:
         assert not isinstance(speakers, str)
         assert focus == "speakers" or focus == "targets"
 
-        if split_by_attribs is None: split_by_attribs = []
+        if split_by_attribs is None:
+            split_by_attribs = []
 
         tally = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
         cond_tally = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
         cond_total = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
 
         n_utterances = defaultdict(lambda: defaultdict(int))
         targets = defaultdict(set)
         real_speakers = set()
         for utt2 in utterances:
             if corpus.has_utterance(utt2.reply_to):
                 speaker = utt2.speaker
                 utt1 = corpus.get_utterance(utt2.reply_to)
                 target = utt1.speaker
-                if speaker == target: continue
-                speaker, target = Coordination._annot_speaker(speaker, utt2, split_by_attribs), \
-                                  Coordination._annot_speaker(target, utt1, split_by_attribs)
+                if speaker == target:
+                    continue
+                speaker, target = Coordination._annot_speaker(
+                    speaker, utt2, split_by_attribs
+                ), Coordination._annot_speaker(target, utt1, split_by_attribs)
 
-                #speaker_has_attribs = Coordination._utterance_has_attribs(utt2, speaker_attribs)
-                #target_has_attribs = Coordination._utterance_has_attribs(utt1, target_attribs)
                 speaker_filter = speaker_utterance_selector(utt2, utt1)
                 target_filter = target_utterance_selector(utt2, utt1)
 
-                if not speaker_filter or not target_filter: continue
+                if not speaker_filter or not target_filter:
+                    continue
 
                 real_speakers.add(speaker)
 
-                if utterance_thresh_func is None or \
-                        utterance_thresh_func(utt2, utt1):
-                    if focus == "targets": speaker, target = target, speaker
+                if utterance_thresh_func is None or utterance_thresh_func(utt2, utt1):
+                    if focus == "targets":
+                        speaker, target = target, speaker
                     targets[speaker].add(target)
                     n_utterances[speaker][target] += 1
                     for cat in utt1.meta["liwc-categories"].union(utt2.meta["liwc-categories"]):
                         if cat in utt2.meta["liwc-categories"]:
                             tally[speaker][cat][target] += 1
                         if cat in utt1.meta["liwc-categories"]:
                             cond_total[speaker][cat][target] += 1
@@ -437,30 +514,37 @@
         out = CoordinationScore()
         if focus == "targets":
             speaker_thresh, target_thresh = target_thresh, speaker_thresh
             speaker_thresh_indiv, target_thresh_indiv = target_thresh_indiv, speaker_thresh_indiv
             real_speakers = list(targets.keys())
 
         for speaker in real_speakers:
-            if speaker[0] not in speakers and focus != "targets": continue
+            if speaker[0] not in speakers and focus != "targets":
+                continue
             coord_w = {}  # coordination score wrt a category
             for cat in CoordinationWordCategories:
                 threshed_cond_total = 0
                 threshed_cond_tally = 0
                 threshed_tally = 0
                 threshed_n_utterances = 0
                 for target in targets[speaker]:
-                    if tally[speaker][cat][target] >= speaker_thresh_indiv and \
-                            cond_total[speaker][cat][target] >= target_thresh_indiv and \
-                            n_utterances[speaker][target] >= utterances_thresh_indiv:
+                    if (
+                        tally[speaker][cat][target] >= speaker_thresh_indiv
+                        and cond_total[speaker][cat][target] >= target_thresh_indiv
+                        and n_utterances[speaker][target] >= utterances_thresh_indiv
+                    ):
                         threshed_cond_total += cond_total[speaker][cat][target]
                         threshed_cond_tally += cond_tally[speaker][cat][target]
                         threshed_tally += tally[speaker][cat][target]
                         threshed_n_utterances += n_utterances[speaker][target]
-                if threshed_cond_total >= max(target_thresh, 1) and \
-                    threshed_tally >= speaker_thresh and \
-                    threshed_n_utterances >= max(utterances_thresh, 1):
-                    coord_w[cat] = threshed_cond_tally / threshed_cond_total - \
-                            threshed_tally / threshed_n_utterances
+                if (
+                    threshed_cond_total >= max(target_thresh, 1)
+                    and threshed_tally >= speaker_thresh
+                    and threshed_n_utterances >= max(utterances_thresh, 1)
+                ):
+                    coord_w[cat] = (
+                        threshed_cond_tally / threshed_cond_total
+                        - threshed_tally / threshed_n_utterances
+                    )
             if len(coord_w) > 0:
                 out[speaker if split_by_attribs else speaker[0]] = coord_w
         return out
```

### Comparing `convokit-2.5.3/convokit/coordination/coordinationScore.py` & `convokit-3.0.0/convokit/coordination/coordinationScore.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,23 @@
-from convokit.model import Speaker
-from convokit.util import deprecation
 from collections import defaultdict
-from typing import Callable, Tuple, List, Dict, Optional, Collection, Hashable, Union
+from typing import Dict, Optional, Hashable, Union
+
+from convokit.model import Speaker
+
+CoordinationWordCategories = [
+    "article",
+    "auxverb",
+    "conj",
+    "adverb",
+    "ppron",
+    "ipron",
+    "preps",
+    "quant",
+]
 
-CoordinationWordCategories = ["article", "auxverb", "conj", "adverb",
-                              "ppron", "ipron", "preps", "quant"]
 
 class CoordinationScore(dict):
     """Encapsulates results of :func:`Coordination.score()` and
     :func:`Coordination.pairwise_scores()`.
 
     The simplest way to use it is as a dictionary mapping speakers to their
     scores:
@@ -26,46 +35,40 @@
     scores, the keys are tuples (speaker, target).
 
     There are also helper functions for filtering scores or getting aggregate
     scores (though these can be more conveniently accessed through
     Coordination's `summarize()` method, using the `summary_report=True`
     option).
     """
+
     def scores_for_marker(self, marker: str) -> Dict[Union[Speaker, Hashable], float]:
         """Return a dictionary from speakers to their scores for just the given
         marker.
 
         :param marker: The marker to return scores for.
         """
         return {speaker: scores[marker] for speaker, scores in self.items()}
 
-    def averages_by_user(self):
-        deprecation("averages_by_user()", "averages_by_speaker()")
-        return {speaker: sum(scores.values()) / len(scores)
-                for speaker, scores in self.items()}
-
-
     def averages_by_speaker(self) -> Dict[Union[Speaker, Hashable], float]:
         """Return a dictionary from speakers to the average of each speaker's
         marker scores."""
-        return {speaker: sum(scores.values()) / len(scores)
-                for speaker, scores in self.items()}
+        return {speaker: sum(scores.values()) / len(scores) for speaker, scores in self.items()}
 
-    def averages_by_marker(self, strict_thresh: bool=False) -> Dict[str, float]:
+    def averages_by_marker(self, strict_thresh: bool = False) -> Dict[str, float]:
         """Return a dictionary mapping markers to the average coordination score
         on that marker.
 
         :param strict_thresh: Whether to only include speakers with all 8 marker
             scores. This corresponds to Aggregate 1 in the Echoes paper (see
             top).
         """
         self.precompute_aggregates()
         return self.a1_avg_by_marker if strict_thresh else self.avg_by_marker
 
-    def aggregate(self, method: int=3) -> Optional[float]:
+    def aggregate(self, method: int = 3) -> Optional[float]:
         """Return the aggregate coordination score.
 
         :param method: Can be 1, 2 or 3, corresponding to which aggregate method
             to use:
 
             - aggregate 1: average scores only over speakers with a score for each
               coordination marker.
@@ -94,16 +97,17 @@
             for cat, score in scores.items():
                 scores_by_marker[cat].append(score)
                 if len(scores) == len(CoordinationWordCategories):
                     a1_scores_by_marker[cat].append(score)
         do_agg2 = False
         if len(scores_by_marker) == len(CoordinationWordCategories):
             do_agg2 = True
-            avg_score_by_marker = {cat: sum(scores) / len(scores)
-                                   for cat, scores in scores_by_marker.items()}
+            avg_score_by_marker = {
+                cat: sum(scores) / len(scores) for cat, scores in scores_by_marker.items()
+            }
         agg1s, agg2s, agg3s = [], [], []
         for speaker, scoredict in self.items():
             scores = list(scoredict.values())
             if len(scores) >= 1:
                 avg = sum(scores) / len(scores)
                 agg3s.append(avg)
                 if len(scores) == len(CoordinationWordCategories):
@@ -113,17 +117,17 @@
                         if cat not in scoredict:
                             scores.append(avg_score_by_marker[cat])
                     agg2s.append(sum(scores) / len(scores))
         agg1 = sum(agg1s) / len(agg1s) if agg1s else None
         agg2 = sum(agg2s) / len(agg2s) if agg2s else None
         agg3 = sum(agg3s) / len(agg3s) if agg3s else None
 
-        a1_avg_by_marker = {cat: sum(scores) / len(scores)
-                            for cat, scores in a1_scores_by_marker.items()}
-        avg_by_marker = {cat: sum(scores) / len(scores)
-                         for cat, scores in scores_by_marker.items()}
+        a1_avg_by_marker = {
+            cat: sum(scores) / len(scores) for cat, scores in a1_scores_by_marker.items()
+        }
+        avg_by_marker = {cat: sum(scores) / len(scores) for cat, scores in scores_by_marker.items()}
         self.precomputed_aggregates = True
         self.a1_avg_by_marker = a1_avg_by_marker
         self.avg_by_marker = avg_by_marker
         self.agg1 = agg1
         self.agg2 = agg2
         self.agg3 = agg3
```

### Comparing `convokit-2.5.3/convokit/data/coord-liwc-patterns.txt` & `convokit-3.0.0/convokit/data/coord-liwc-patterns.txt`

 * *Files identical despite different names*

### Comparing `convokit-2.5.3/convokit/data/liu-negative-words.txt` & `convokit-3.0.0/convokit/data/liu-negative-words.txt`

 * *Files identical despite different names*

### Comparing `convokit-2.5.3/convokit/data/liu-positive-words.txt` & `convokit-3.0.0/convokit/data/liu-positive-words.txt`

 * *Files identical despite different names*

### Comparing `convokit-2.5.3/convokit/expected_context_framework/col_normed_tfidf.py` & `convokit-3.0.0/convokit/expected_context_framework/col_normed_tfidf.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,56 +1,55 @@
 from sklearn.feature_extraction.text import TfidfVectorizer
 from sklearn.base import TransformerMixin
 from sklearn.preprocessing import Normalizer, normalize
 from scipy import sparse
-import numpy as np 
+import numpy as np
 import joblib
 import os
 import json
 
 from convokit.transformer import Transformer
 
+
 class ColNormedTfidfTransformer(Transformer):
     """
     Transformer that derives tf-idf reweighted representations of utterances,
-    which are normalized by column, i.e., per term. This may be helpful in deriving downstream representations that are less sensitive to relative term frequency; for instance, it could be used to derive input representations to `ExpectedContextModelWrapper`. 
+    which are normalized by column, i.e., per term. This may be helpful in deriving downstream representations that are less sensitive to relative term frequency; for instance, it could be used to derive input representations to `ExpectedContextModelWrapper`.
 
     :param input_field: the name of the attribute of utterances to use as input to fit. note that unless `token_pattern` is specified as an additional argument, this attribute must be a string consisting of whitespace-separated features.
     :param output_field: the name of the attribute to write to in the transform step.
     :param model: optional, an exisitng `ColNormedTfidfTransformer`
     :param kwargs: other keyword arguments used to initialize the underlying `TfidfVectorizer` from scikit-learn, see that documentation for details.
     """
-    def __init__(self, input_field, output_field='col_normed_tfidf',
-        model=None, **kwargs):
 
+    def __init__(self, input_field, output_field="col_normed_tfidf", model=None, **kwargs):
         if model is not None:
             self.tfidf_obj = model.tfidf_obj
         else:
             self.tfidf_obj = ColNormedTfidf(**kwargs)
         self.input_field = input_field
         self.output_field = output_field
-        if self.input_field == 'text':
+        if self.input_field == "text":
             self.text_func = lambda x: x.text
         else:
             self.text_func = lambda x: x.meta[self.input_field]
 
-
     def fit(self, corpus, y=None, selector=lambda x: True):
         """
         Fits a transformer over training data.
 
         :param corpus: Corpus
         :param selector: which utterances to fit the transformer over. a boolean function of the form filter(utterance) that defaults to True (i.e., all utterances).
         :return: None
         """
         docs = [self.text_func(ut) for ut in corpus.iter_utterances(selector=selector)]
         self.tfidf_obj.fit(docs)
         return self
-    
-    def transform(self, corpus, selector=lambda x: True): 
+
+    def transform(self, corpus, selector=lambda x: True):
         """
         Computes column-normalized tf-idf representations for utterances in a corpus, stored in the corpus as `<output_field>`. Also annotates each utterance with a metadata field, `<output_field>__n_feats`, indicating the number of terms in the vocabulary that utterance contains.
 
 
         :param corpus: Corpus
         :param selector: which utterances to transform
 
@@ -61,101 +60,103 @@
         for ut in corpus.iter_utterances(selector=selector):
             ids.append(ut.id)
             docs.append(self.text_func(ut))
             ut.add_vector(self.output_field)
         vects = self.tfidf_obj.transform(docs)
         column_names = self.tfidf_obj.get_feature_names()
         corpus.set_vector_matrix(self.output_field, matrix=vects, ids=ids, columns=column_names)
-        n_feats = np.array((vects>0).sum(axis=1)).flatten()
+        n_feats = np.array((vects > 0).sum(axis=1)).flatten()
         for id, n in zip(ids, n_feats):
-            corpus.get_utterance(id).meta[self.output_field + '__n_feats'] = int(n)
+            corpus.get_utterance(id).meta[self.output_field + "__n_feats"] = int(n)
         return corpus
 
     def transform_utterance(self, utt):
         """
-        Computes tf-idf representations for a single utterance. Representation is stored in the utterance as `<output_field>__vect`; 
+        Computes tf-idf representations for a single utterance. Representation is stored in the utterance as `<output_field>__vect`;
         number of vocabulary terms that utterance contains is stored as `<output_field>__n_feats`
 
         :param utt: Utterance
 
         :return: utterance, with representation and vocabulary count
         """
         docs = [self.text_func(utt)]
         vect_ = np.array(self.tfidf_obj.transform(docs))
-        n_feats = np.array((vect_>0).sum(axis=1)).flatten()
+        n_feats = np.array((vect_ > 0).sum(axis=1)).flatten()
         utt.meta[self.output_field] = [float(x) for x in vect_[0]]
-        utt.meta[self.output_field + '__n_feats'] = int(n_feats[0])
+        utt.meta[self.output_field + "__n_feats"] = int(n_feats[0])
         return utt
-    
+
     def fit_transform(self, corpus, y=None, selector=lambda x: True):
         self.fit(corpus, y, selector)
         return self.transform(corpus, selector)
-    
+
     def get_vocabulary(self):
         """
         :return: array of feature names
         """
         return self.tfidf_obj.get_feature_names()
-    
+
     def load(self, dirname):
         """
         Loads model from disk.
 
         :param dirname: directory to load from
         :return: None
         """
         self.tfidf_obj.load(dirname)
-    
+
     def dump(self, dirname):
         """
         Dumps model to disk.
 
         :param dirname: directory to write to
         :return: None
         """
         self.tfidf_obj.dump(dirname)
 
+
 class ColNormedTfidf(TransformerMixin):
 
     """
     Model that derives tf-idf reweighted representations of utterances,
     which are normalized by column. Can be used in ConvoKit through the `ColNormedTfidfTransformer` transformer; see documentation of that transformer for further details.
     """
-    
+
     def __init__(self, **kwargs):
-        if 'token_pattern' in kwargs:
+        if "token_pattern" in kwargs:
             self.tfidf_model = TfidfVectorizer(**kwargs)
         else:
-            self.tfidf_model = TfidfVectorizer(token_pattern=r'(?u)(\S+)',**kwargs)
-    
+            self.tfidf_model = TfidfVectorizer(token_pattern=r"(?u)(\S+)", **kwargs)
+
     def fit(self, X, y=None):
         tfidf_vects_raw = self.tfidf_model.fit_transform(X)
         self.col_norms = sparse.linalg.norm(tfidf_vects_raw, axis=0)
-    
+
     def transform(self, X):
         tfidf_vects_raw = self.tfidf_model.transform(X)
-        tfidf_vect = tfidf_vects_raw / self.col_norms 
+        tfidf_vect = tfidf_vects_raw / self.col_norms
         return tfidf_vect
-    
+
     def fit_transform(self, X, y=None):
         self.fit(X, y)
         return self.transform(X)
 
     def get_feature_names(self):
         return self.tfidf_model.get_feature_names()
-    
+
     def get_params(self, deep=True):
         return self.tfidf_model.get_params(deep=deep)
-    
+
     def set_params(self, **params):
         return self.tfidf_model.set_params(**params)
-    
+
     def load(self, dirname):
-        self.tfidf_model = joblib.load(os.path.join(dirname, 'tfidf_model.joblib'))
-        self.col_norms = np.load(os.path.join(dirname, 'tfidf_col_norms.npy'))
-    
+        self.tfidf_model = joblib.load(os.path.join(dirname, "tfidf_model.joblib"))
+        self.col_norms = np.load(os.path.join(dirname, "tfidf_col_norms.npy"))
+
     def dump(self, dirname):
         try:
             os.mkdir(dirname)
-        except: pass
-        np.save(os.path.join(dirname, 'tfidf_col_norms.npy'), self.col_norms)
-        joblib.dump(self.tfidf_model, os.path.join(dirname, 'tfidf_model.joblib'))  
+        except:
+            pass
+        np.save(os.path.join(dirname, "tfidf_col_norms.npy"), self.col_norms)
+        joblib.dump(self.tfidf_model, os.path.join(dirname, "tfidf_model.joblib"))
```

### Comparing `convokit-2.5.3/convokit/expected_context_framework/dual_context_wrapper.py` & `convokit-3.0.0/convokit/expected_context_framework/dual_context_wrapper.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,201 +2,240 @@
 import pandas as pd
 import numpy as np
 import json, os
 
 from convokit.expected_context_framework import ExpectedContextModelTransformer
 from convokit.transformer import Transformer
 
+
 class DualContextWrapper(Transformer):
     """
     Transformer that derives and compares characterizations of terms and utterances with respect to two different choices of conversational context. Designed in particular to contrast replies and predecessors, though other choices of context are also possible.
 
-    This is a wrapper that encompasses two instances of `ExpectedContextModelTransformer`, stored at the `ec_models` attribute. 
+    This is a wrapper that encompasses two instances of `ExpectedContextModelTransformer`, stored at the `ec_models` attribute.
     It computes two particular comparative term-level statistics, orientation and shift, stored as the `term_orientations` and `term_shifts` attributes.
     It also computes these statistics at the utterance level in the transform step.
 
     :param context_fields: list containing the names of the utterance-level attributes containing the IDs of the context-utterances used by each of the `ExpectedContextModelTransformer` instances.
     :param output_prefixes: list containing the name of the attributes and vectors that each `ExpectedContextModelTransformer` instances will write to in the transform step.
     :param vect_field: the name of the vectors to use as input vector representation for utterances, as stored in a corpus.
     :param context_vect_field: the name of the vectors to use as input vector representations for context-utterances, as stored in a corpus. by default, the transformer will use the same vector representations as utterances, specified in `vect_field`. if you expect that utterances and context-utterances will differ in some way (e.g., they come from speakers in a conversation who play clearly delineated roles), then it's a good idea to use a different input representation.
     :param wrapper_output_prefix: the metadata fields where the utterance-level orientation and shift statistics are stored. By default, these attributes are stored as `orn` and `shift` in the metadata; if `wrapper_output_prefix` is specified, then they are stored as `<wrapper_output_prefix>_orn` (orientation) and `<wrapper_output_prefix>_shift` (shift).
     :param n_svd_dims: the dimensionality of the representations to derive (via LSA/SVD).
     :param snip_first_dim: whether or not to remove the first dimension of the derived representations. by default this is set to `True`, since we've found that the first dimension tends to reflect term frequency, making the output less informative. Note that if `snip_first_dim=True` then in practice, we output `n_svd_dims-1`-dimensional representations.
     :param n_clusters: the number of clusters to infer.
     :param cluster_on: whether to cluster on utterance or term representations, (corresponding to values `'utts'` or `'terms'`). By default, we infer clusters based on representations of the utterances from the training data, and then assign term and context-utterance representations to the resultant clusters. In some cases (e.g., if utterances are highly unstructured and lengthy) it might be better to cluster term representations first.
     :param random_state: the random seed to use in the LSA step (which calls a randomized implementation of SVD)
     :param cluster_random_state: the random seed to use to infer clusters.
-    
+
     """
-    def __init__(self, context_fields, output_prefixes,
-                vect_field, context_vect_field=None, wrapper_output_prefix='',
-                n_svd_dims=25, snip_first_dim=True, n_clusters=8, cluster_on='utts',
-                random_state=None, cluster_random_state=None):
-        
+
+    def __init__(
+        self,
+        context_fields,
+        output_prefixes,
+        vect_field,
+        context_vect_field=None,
+        wrapper_output_prefix="",
+        n_svd_dims=25,
+        snip_first_dim=True,
+        n_clusters=8,
+        cluster_on="utts",
+        random_state=None,
+        cluster_random_state=None,
+    ):
         self.context_fields = context_fields
         self.output_prefixes = output_prefixes
         self.vect_field = vect_field
         self.context_vect_field = context_vect_field
         if self.context_vect_field is None:
             self.context_vect_field = vect_field
-        
+
         self.n_svd_dims = n_svd_dims
         self.snip_first_dim = snip_first_dim
         self.n_clusters = n_clusters
         self.cluster_on = cluster_on
         self.random_state = random_state
         self.cluster_random_state = cluster_random_state
         self.wrapper_output_prefix = wrapper_output_prefix
-        
+
         first_model = ExpectedContextModelTransformer(
-            context_field=self.context_fields[0], output_prefix=self.output_prefixes[0],
-            vect_field=self.vect_field, context_vect_field=self.context_vect_field,
-            n_svd_dims=self.n_svd_dims, snip_first_dim=self.snip_first_dim, n_clusters=self.n_clusters,
-            cluster_on=self.cluster_on, random_state=self.random_state, cluster_random_state=self.cluster_random_state)
+            context_field=self.context_fields[0],
+            output_prefix=self.output_prefixes[0],
+            vect_field=self.vect_field,
+            context_vect_field=self.context_vect_field,
+            n_svd_dims=self.n_svd_dims,
+            snip_first_dim=self.snip_first_dim,
+            n_clusters=self.n_clusters,
+            cluster_on=self.cluster_on,
+            random_state=self.random_state,
+            cluster_random_state=self.cluster_random_state,
+        )
         second_model = ExpectedContextModelTransformer(
-            context_field=self.context_fields[1], output_prefix=self.output_prefixes[1],
-            vect_field=self.vect_field, context_vect_field=self.context_vect_field,
-            n_svd_dims=self.n_svd_dims, snip_first_dim=self.snip_first_dim, n_clusters=self.n_clusters,
-            cluster_on=self.cluster_on, 
-            random_state=self.random_state, cluster_random_state=self.cluster_random_state)
+            context_field=self.context_fields[1],
+            output_prefix=self.output_prefixes[1],
+            vect_field=self.vect_field,
+            context_vect_field=self.context_vect_field,
+            n_svd_dims=self.n_svd_dims,
+            snip_first_dim=self.snip_first_dim,
+            n_clusters=self.n_clusters,
+            cluster_on=self.cluster_on,
+            random_state=self.random_state,
+            cluster_random_state=self.cluster_random_state,
+        )
         self.ec_models = [first_model, second_model]
-        
-        
-        
-        
+
     def fit(self, corpus, y=None, selector=lambda x: True, context_selector=lambda x: True):
         """
-        Fits a transformer over training data: fits the two `ExpectedContextModelTransformer` instances, and computes term-level orientation and shift. 
+        Fits a transformer over training data: fits the two `ExpectedContextModelTransformer` instances, and computes term-level orientation and shift.
 
         :param corpus: Corpus containing training data
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances will be considered in the fit step. defaults to using all utterances.
         :param context_selector: a boolean function of signature `filter(utterance)` that determines which context-utterances will be considered in the fit step. defaults to using all utterances.
         :return: None
         """
-    
+
         self.ec_models[0].fit(corpus, selector=selector, context_selector=context_selector)
         self.ec_models[1].ec_model.set_model(self.ec_models[0].ec_model)
-        
+
         self.ec_models[1].fit(corpus, selector=selector, context_selector=context_selector)
         self._compute_term_stats()
-    
+
     def transform(self, corpus, selector=lambda x: True):
         """
         Computes vector representations, ranges, and cluster assignments for utterances in a corpus, using the two `ExpectedContextModelTransformer` instances. Also computes utterance-level orientation and shift.
 
         :param corpus: Corpus
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances to transform. defaults to all utterances.
         :return: the Corpus, with per-utterance attributes.
         """
         self.ec_models[0].transform(corpus, selector=selector)
         self.ec_models[1].transform(corpus, selector=selector)
-        if self.wrapper_output_prefix == '':
-            orn_field = 'orn'
-            shift_field = 'shift'
+        if self.wrapper_output_prefix == "":
+            orn_field = "orn"
+            shift_field = "shift"
         else:
-            orn_field = self.wrapper_output_prefix + '_orn'
-            shift_field = self.wrapper_output_prefix + '_shift'
-        
+            orn_field = self.wrapper_output_prefix + "_orn"
+            shift_field = self.wrapper_output_prefix + "_shift"
+
         for ut in corpus.iter_utterances(selector=selector):
-            ut.meta[orn_field] = ut.meta[self.output_prefixes[0] + '_range'] - ut.meta[self.output_prefixes[1] + '_range']
-            
-        utt_shifts = paired_distances(corpus.get_vectors(self.output_prefixes[0] + '_repr'),
-                                     corpus.get_vectors(self.output_prefixes[1] + '_repr'))
-        for id, shift in zip(corpus.get_vector_matrix(self.output_prefixes[0] + '_repr').ids, utt_shifts):
+            ut.meta[orn_field] = (
+                ut.meta[self.output_prefixes[0] + "_range"]
+                - ut.meta[self.output_prefixes[1] + "_range"]
+            )
+
+        utt_shifts = paired_distances(
+            corpus.get_vectors(self.output_prefixes[0] + "_repr"),
+            corpus.get_vectors(self.output_prefixes[1] + "_repr"),
+        )
+        for id, shift in zip(
+            corpus.get_vector_matrix(self.output_prefixes[0] + "_repr").ids, utt_shifts
+        ):
             corpus.get_utterance(id).meta[shift_field] = shift
 
     def transform_utterance(self, utt):
         """
         Computes vector representations, ranges, and cluster assignments for an utterance, using the two `ExpectedContextModelTransformer` instances. Also computes utterance-level orientation and shift. Note that the utterance must contain the input representation as a metadata field, specified by what was passed into the constructor as the `vect_field` argument.
         Will write all of these characterizations (including vectors) to the utterance's metadata.
 
         :param utt: Utterance
         :return: the utterance, with per-utterance attributes.
         """
         utt = self.ec_models[0].transform_utterance(utt)
         utt = self.ec_models[1].transform_utterance(utt)
-        if self.wrapper_output_prefix == '':
-            orn_field = 'orn'
-            shift_field = 'shift'
+        if self.wrapper_output_prefix == "":
+            orn_field = "orn"
+            shift_field = "shift"
         else:
-            orn_field = self.wrapper_output_prefix + '_orn'
-            shift_field = self.wrapper_output_prefix + '_shift'
+            orn_field = self.wrapper_output_prefix + "_orn"
+            shift_field = self.wrapper_output_prefix + "_shift"
 
-        utt.meta[orn_field] = utt.meta[self.output_prefixes[0] + '_range'] \
-            - utt.meta[self.output_prefixes[1] + '_range']
-
-        utt.meta[shift_field] = float(paired_distances(
-                            np.array([utt.meta[self.output_prefixes[0] + '_repr']]),
-                            np.array([utt.meta[self.output_prefixes[1] + '_repr']])
-                        )[0])
+        utt.meta[orn_field] = (
+            utt.meta[self.output_prefixes[0] + "_range"]
+            - utt.meta[self.output_prefixes[1] + "_range"]
+        )
+
+        utt.meta[shift_field] = float(
+            paired_distances(
+                np.array([utt.meta[self.output_prefixes[0] + "_repr"]]),
+                np.array([utt.meta[self.output_prefixes[1] + "_repr"]]),
+            )[0]
+        )
         return utt
 
     def _compute_term_stats(self):
-        self.term_orientations = self.ec_models[0].get_term_ranges() - self.ec_models[1].get_term_ranges()
-        self.term_shifts = paired_distances(self.ec_models[0].get_term_reprs(), self.ec_models[1].get_term_reprs())
-        
+        self.term_orientations = (
+            self.ec_models[0].get_term_ranges() - self.ec_models[1].get_term_ranges()
+        )
+        self.term_shifts = paired_distances(
+            self.ec_models[0].get_term_reprs(), self.ec_models[1].get_term_reprs()
+        )
+
     def get_terms(self):
         """
         Gets the names of the terms for which the transformer has computed representations.
 
         :return: list of terms
         """
         return self.ec_models[0].get_terms()
-    
+
     def get_term_df(self):
         """
         Gets a Pandas dataframe containing term-level statistics computed by the transformer (shift, orientation) and its constituent `ExpectedContextModelTransformer` instances (ranges).
 
         :return: dataframe of term-level statistics
         """
-        return pd.DataFrame({'index': self.get_terms(),
-                       'orn': self.term_orientations,
-                       'shift': self.term_shifts,
-                        self.output_prefixes[0] + '_range': self.ec_models[0].get_term_ranges(),
-                        self.output_prefixes[1] + '_range': self.ec_models[1].get_term_ranges()})\
-                    .set_index('index')
+        return pd.DataFrame(
+            {
+                "index": self.get_terms(),
+                "orn": self.term_orientations,
+                "shift": self.term_shifts,
+                self.output_prefixes[0] + "_range": self.ec_models[0].get_term_ranges(),
+                self.output_prefixes[1] + "_range": self.ec_models[1].get_term_ranges(),
+            }
+        ).set_index("index")
 
     def summarize(self, k=10, max_chars=1000, corpus=None):
         """
         For each constituent ExpectedContextModelTransformer, prints inferred clusters and statistics about their sizes.
-        
+
         :param k: number of examples to print out.
         :param max_chars: maximum number of characters per utterance/context-utterance to print. Can be toggled to control the size of the output.
         :param corpus: optional, the corpus that the transformer was trained on. if set, will print example utterances and context-utterances as well as terms.
 
         :return: None
         """
-        print('MODEL', self.output_prefixes[0])
+        print("MODEL", self.output_prefixes[0])
         self.ec_models[0].summarize(k, max_chars, corpus)
         print()
-        print('MODEL', self.output_prefixes[1])
+        print("MODEL", self.output_prefixes[1])
         self.ec_models[1].summarize(k, max_chars, corpus)
-    
+
     def load(self, dirname, model_dirs=None):
         """
         Loads a model from disk.
 
         :param dirname: directory to read model from
         :param model_dirs: optional list containing the directories (relative to `dirname`) in which each `ExpectedContextModelTransformer` is stored. defaults to the `output_prefixes` argument passed at initialization.
         :return: None
         """
         if model_dirs is None:
             model_dirs = self.output_prefixes
         self.ec_models[0].load(os.path.join(dirname, model_dirs[0]))
         self.ec_models[1].load(os.path.join(dirname, model_dirs[1]))
         self._compute_term_stats()
-    
+
     def dump(self, dirname):
         """
         Writes a model to disk. Will store each `ExpectedContextModelTransformer` in a separate directory with names given by the `output_prefixes` argument passed at initialization.
 
         :param dirname: directory to write model to.
         :return: None
         """
         try:
             os.mkdir(dirname)
             os.mkdir(os.path.join(dirname, self.output_prefixes[0]))
             os.mkdir(os.path.join(dirname, self.output_prefixes[1]))
         except:
             pass
         self.ec_models[0].dump(os.path.join(dirname, self.output_prefixes[0]))
-        self.ec_models[1].dump(os.path.join(dirname, self.output_prefixes[1]))
+        self.ec_models[1].dump(os.path.join(dirname, self.output_prefixes[1]))
```

### Comparing `convokit-2.5.3/convokit/expected_context_framework/expected_context_model.py` & `convokit-3.0.0/convokit/expected_context_framework/expected_context_model.py`

 * *Files 11% similar despite different names*

```diff
@@ -10,44 +10,45 @@
 from sklearn.utils.extmath import randomized_svd
 from scipy import sparse
 import joblib
 import json
 
 from convokit.transformer import Transformer
 
+
 class ExpectedContextModelTransformer(Transformer):
     """
     Transformer that derives representations of terms and utterances in terms of their conversational context, i.e.,
     context-utterances that occur near an utterance, or utterances containing a term. Typically, the conversational
     context consists of immediate replies ("forwards context") or predecessors ("backwards context"), though
-    this can be specified by the user via the `context_field` argument. 
+    this can be specified by the user via the `context_field` argument.
 
     The underlying model in the transformer, implemented as the `ExpectedContextModel` class, is fitted given input training
     data consisting of pairs of utterances and context-utterances, represented as feature vectors (e.g., tf-idf reweighted
     term-document matrices), specified via the `vect_field` and `context_vect_field` arguments. This model is stored as the `ec_model` attribute of the transformer, and can be accessed as such.
     In the fit step, the model, which is based off of latent semantic analysis (LSA), computes the following:
 
     * representations of terms and utterances in the training data, with respect to the context, along with representations of the context (which are derived in the underlying LSA step). the dimensionality of these representations is specified via the `n_svd_dims` argument (see also the `snip_first_dim` and `random_state` arguments). these can be accessed via various `get` functions that the transformer provides.
     * a term-level statistic, "range", measuring the variation in context-utterances associated with a term. One interpretation of this statistic is that it quantifies the "strengths of our expectations" of what reply a term typically gets, or what predecessors it typically follows.
     * a clustering of utterance, term and context representations. The resultant clusters can help interpret the representations the model derives, by highlighting salient groupings that emerge. The number of clusters is specified via the `n_clusters` argument; the `print_clusters` function can be called to inspect this output. (see also the `cluster_on` and `cluster_random_state` arguments)
-    
 
-    
+
+
     An instance of the transformer can be initialized with an instance of another, fitted transformer, via the `model` argument. This ensures that both
     transformers derive representations that are comparable, i.e., can be interpreted as being part of the same vector space, with distances between
     representations that are well-defined. As an example of when this might be useful, we may wish to compare representations derived with respect
     to expected replies, with representations pertaining to expected predecessors.
 
-    The transfomer contains various functions to access term-level characterizations. In the transform step, it outputs 
+    The transfomer contains various functions to access term-level characterizations. In the transform step, it outputs
     vector representations of utterances, stored as `<output_prefix>_repr` in the corpus. It also outputs various attributes
     of utterances (names prefixed with `<output_prefix>_`), stored as metadata fields in each transformed utterance:
 
     * `range`: the range of the utterance
     * `clustering.cluster`: the name of the cluster the utterance has been assigned to
-    * `clustering.cluster_id_`: the numerical ID (0-# of clusters) of the cluster the utterance has been assigned to 
+    * `clustering.cluster_id_`: the numerical ID (0-# of clusters) of the cluster the utterance has been assigned to
     * `clustering.cluster_dist`: the distance between the utterance representation and the centroid of its cluster
 
     :param context_field: the name of an utterance-level attribute containing the ID of the corresponding context-utterance. in particular, to use immediate predecessors as context, set `context_field` to `'reply_to'`. as another example, to use immediate replies, provided that utterances contain an attribute `next_id` containing the ID of their reply, set `context_field` to `'next_id'`.
     :param output_prefix: the name of the attributes and vectors to write to in the transform step. the transformer outputs several fields, which will be prefixed with the given string.
     :param vect_field: the name of the vectors to use as input vector representation for utterances, as stored in a corpus.
     :param context_vect_field: the name of the vectors to use as input vector representations for context-utterances, as stored in a corpus. by default, the transformer will use the same vector representations as utterances, specified in `vect_field`. if you expect that utterances and context-utterances will differ in some way (e.g., they come from speakers in a conversation who play clearly delineated roles), then it's a good idea to use a different input representation.
     :param n_svd_dims: the dimensionality of the representations to derive (via LSA/SVD).
@@ -55,234 +56,256 @@
     :param n_clusters: the number of clusters to infer.
     :param cluster_on: whether to cluster on utterance or term representations, (corresponding to values `'utts'` or `'terms'`). By default, we infer clusters based on representations of the utterances from the training data, and then assign term and context-utterance representations to the resultant clusters. In some cases (e.g., if utterances are highly unstructured and lengthy) it might be better to cluster term representations first.
     :param model: an existing, fitted `ExpectedContextModelTransformer` object to initialize with (optional)
     :param random_state: the random seed to use in the LSA step (which calls a randomized implementation of SVD)
     :param cluster_random_state: the random seed to use to infer clusters.
 
     """
-    def __init__(self, context_field, output_prefix,
-                 vect_field, context_vect_field=None,
-                n_svd_dims=25, snip_first_dim=True, n_clusters=8, cluster_on='utts',
-                model=None, random_state=None, cluster_random_state=None):
+
+    def __init__(
+        self,
+        context_field,
+        output_prefix,
+        vect_field,
+        context_vect_field=None,
+        n_svd_dims=25,
+        snip_first_dim=True,
+        n_clusters=8,
+        cluster_on="utts",
+        model=None,
+        random_state=None,
+        cluster_random_state=None,
+    ):
         if model is not None:
             in_model = model.ec_model
         else:
             in_model = None
-        self.ec_model = ExpectedContextModel(model=in_model,
-            n_svd_dims=n_svd_dims, snip_first_dim=snip_first_dim, n_clusters=n_clusters, cluster_on=cluster_on,
-            random_state=random_state, cluster_random_state=cluster_random_state)
+        self.ec_model = ExpectedContextModel(
+            model=in_model,
+            n_svd_dims=n_svd_dims,
+            snip_first_dim=snip_first_dim,
+            n_clusters=n_clusters,
+            cluster_on=cluster_on,
+            random_state=random_state,
+            cluster_random_state=cluster_random_state,
+        )
         self.context_field = context_field
-        if context_field == 'reply_to':
+        if context_field == "reply_to":
             self.context_func = lambda x: x.reply_to
         else:
             self.context_func = lambda x: x.meta.get(context_field, None)
         self.output_prefix = output_prefix
         self.vect_field = vect_field
         self.context_vect_field = context_vect_field
         if self.context_vect_field is None:
             self.context_vect_field = vect_field
 
     ### fit functionality
 
     def fit(self, corpus, y=None, selector=lambda x: True, context_selector=lambda x: True):
         """
-        Fits an `ExpectedContextModelTransformer` transformer over training data: derives representations of terms, utterances and contexts, 
+        Fits an `ExpectedContextModelTransformer` transformer over training data: derives representations of terms, utterances and contexts,
         range statistics for terms, and a clustering of the resultant representations.
 
         :param corpus: Corpus containing training data
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances
             will be considered in the fit step. defaults to using all utterances.
         :param context_selector: a boolean function of signature `filter(utterance)` that determines which context-utterances
             will be considered in the fit step. defaults to using all utterances.
         :return: None
         """
 
         id_to_idx = corpus.get_vector_matrix(self.vect_field).ids_to_idx
         context_id_to_idx = corpus.get_vector_matrix(self.context_vect_field).ids_to_idx
-        
-        
+
         ids = []
         context_ids = []
         mapping_ids = []
         context_mapping_ids = []
         for ut in corpus.iter_utterances(selector=selector):
             ids.append(ut.id)
             context_id = self.context_func(ut)
             if context_id is not None:
                 try:
                     if context_selector(corpus.get_utterance(context_id)):
                         try:
                             mapping_ids.append(ut.id)
                             context_mapping_ids.append(context_id)
-                        except: continue
+                        except:
+                            continue
                 except:
                     continue
-                    
+
         for ut in corpus.iter_utterances(selector=context_selector):
             context_ids.append(ut.id)
 
         id_to_idx = {id: i for i, id in enumerate(ids)}
         context_id_to_idx = {id: i for i, id in enumerate(context_ids)}
         mapping_idxes = [id_to_idx[x] for x in mapping_ids]
         context_mapping_idxes = [context_id_to_idx[x] for x in context_mapping_ids]
-        
+
         utt_vects = corpus.get_vectors(self.vect_field, ids)
         context_utt_vects = corpus.get_vectors(self.context_vect_field, context_ids)
         mapping_table = np.vstack([mapping_idxes, context_mapping_idxes]).T
         self.mapping_table = mapping_table
         terms = corpus.get_vector_matrix(self.vect_field).columns
         context_terms = corpus.get_vector_matrix(self.context_vect_field).columns
-        self.ec_model.fit(utt_vects, context_utt_vects, mapping_table,
-                         terms, context_terms, utt_ids=ids, context_utt_ids=context_ids)
-            
+        self.ec_model.fit(
+            utt_vects,
+            context_utt_vects,
+            mapping_table,
+            terms,
+            context_terms,
+            utt_ids=ids,
+            context_utt_ids=context_ids,
+        )
+
     def _get_matrix(self, corpus, field, selector):
-        ids = [ut.id for ut in corpus.iter_utterances(selector=selector)
-              if field in ut.vectors]
+        ids = [ut.id for ut in corpus.iter_utterances(selector=selector) if field in ut.vectors]
         utt_vects = corpus.get_vectors(field, ids)
         return ids, utt_vects
-    
+
     def _add_vector(self, corpus, field, ids):
         for id in ids:
             corpus.get_utterance(id).add_vector(field)
-    
+
     ### transformers
 
     def transform(self, corpus, selector=lambda x: True):
         """
         Computes vector representations, ranges, and cluster assignments for utterances in a corpus.
 
         :param corpus: Corpus
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances
             to transform. defaults to all utterances.
         :return: the Corpus, with per-utterance representations, ranges and cluster assignments.
         """
         ids, utt_vects = self._get_matrix(corpus, self.vect_field, selector)
         utt_reprs = self.ec_model.transform(utt_vects)
-        corpus.set_vector_matrix(self.output_prefix + '_repr', matrix=utt_reprs,
-                                ids=ids)
-        self._add_vector(corpus, self.output_prefix + '_repr', ids)
+        corpus.set_vector_matrix(self.output_prefix + "_repr", matrix=utt_reprs, ids=ids)
+        self._add_vector(corpus, self.output_prefix + "_repr", ids)
         self.compute_utt_ranges(corpus, selector)
         self.compute_clusters(corpus, selector)
         return corpus
-    
+
     def transform_utterance(self, utt):
         """
         Computes vector representation, range, and cluster assignment for a single utterance. Note that the utterance must contain the input representation as a metadata field, specified by what was passed into the constructor as the `vect_field` argument.
         Will write all of these characterizations (including vectors) to the utterance's metadata; attribute names are prefixed with the `output_prefix` constructor argument.
 
         :param utt: Utterance
         :return: the utterance, with per-utterance representation, range and cluster assignments.
         """
 
         utt_vect = np.array([utt.meta[self.vect_field]])
         utt_repr = np.array(self.ec_model.transform(utt_vect))
-        utt.meta[self.output_prefix + '_repr'] = [float(x) for x in utt_repr[0]]
-        utt.meta[self.output_prefix + '_range'] = float(self.ec_model.compute_utt_ranges(utt_vect)[0])
+        utt.meta[self.output_prefix + "_repr"] = [float(x) for x in utt_repr[0]]
+        utt.meta[self.output_prefix + "_range"] = float(
+            self.ec_model.compute_utt_ranges(utt_vect)[0]
+        )
         cluster_df = self.ec_model.transform_clusters(utt_repr)
         for col in cluster_df.columns:
-            if col == 'cluster_dist':
-                utt.meta[self.output_prefix + '_clustering.' + col] = \
-                    float(cluster_df.iloc[0][col])
+            if col == "cluster_dist":
+                utt.meta[self.output_prefix + "_clustering." + col] = float(cluster_df.iloc[0][col])
             else:
-                utt.meta[self.output_prefix + '_clustering.' + col] = \
-                    cluster_df.iloc[0][col]
+                utt.meta[self.output_prefix + "_clustering." + col] = cluster_df.iloc[0][col]
         return utt
 
-
     def compute_utt_ranges(self, corpus, selector=lambda x: True):
         """
         Computes utterance ranges.
 
         :param corpus: Corpus
         :param selector: determines which utterances to compute ranges for.
 
         :return: the Corpus, with per-utterance ranges.
         """
         ids, utt_vects = self._get_matrix(corpus, self.vect_field, selector)
         ranges = self.ec_model.compute_utt_ranges(utt_vects)
         for id, r in zip(ids, ranges):
-            corpus.get_utterance(id).meta[self.output_prefix + '_range'] = r
+            corpus.get_utterance(id).meta[self.output_prefix + "_range"] = r
         return corpus
-    
+
     def transform_context_utts(self, corpus, selector=lambda x: True):
         """
-        Computes representations of context-utterances, along with cluster assignments. 
+        Computes representations of context-utterances, along with cluster assignments.
 
         :param corpus: Corpus
         :param selector: determines which utterances to compute representations for.
 
         :return: the Corpus, with per-utterance representations and cluster assignments.
         """
 
         ids, context_utt_vects = self._get_matrix(corpus, self.context_vect_field, selector)
         context_utt_reprs = self.ec_model.transform_context_utts(context_utt_vects)
-        corpus.set_vector_matrix(self.output_prefix + '_context_repr', matrix=context_utt_reprs,
-                                ids=ids)
-        self._add_vector(corpus, self.output_prefix + '_context_repr', ids)
+        corpus.set_vector_matrix(
+            self.output_prefix + "_context_repr", matrix=context_utt_reprs, ids=ids
+        )
+        self._add_vector(corpus, self.output_prefix + "_context_repr", ids)
         self.compute_clusters(corpus, selector, is_context=True)
         return corpus
-    
-    def fit_clusters(self, n_clusters='default', random_state='default'):
+
+    def fit_clusters(self, n_clusters="default", random_state="default"):
         """
         Infers a clustering of term or utterance representations (specified by the `cluster_on` argument used to initialize the transformer) on the training data originally used to fit the transformer. Can be called to infer a different number of clusters than what was initially specified.
 
         :param n_clusters: number of clusters to infer. defaults to the number of clusters specified when initializing the transformer.
         :param random_state: random seed used to infer clusters. defaults to the random seed used to initialize the transformer.
 
         :return: None
         """
-        if n_clusters=='default':
+        if n_clusters == "default":
             n_clusters = self.ec_model.n_clusters
-        if random_state == 'default':
+        if random_state == "default":
             random_state = self.ec_model.cluster_random_state
         self.ec_model.fit_clusters(n_clusters, random_state)
-    
+
     def compute_clusters(self, corpus, selector=lambda x: True, is_context=False):
         """
         Assigns utterances in a corpus, for which expected context representations have already been computed, to inferred clusters.
-        
+
         :param corpus: Corpus
         :param selector: determines which utterances to compute clusterings for
         :param is_context: whether to treat input data as utterances, or context-utterances
-        
+
         :return: a DataFrame containing cluster assignment information for each utterance.
         """
         if is_context:
-            ids, reprs = self._get_matrix(corpus, self.output_prefix + '_context_repr', selector)
+            ids, reprs = self._get_matrix(corpus, self.output_prefix + "_context_repr", selector)
         else:
-            ids, reprs = self._get_matrix(corpus, self.output_prefix + '_repr', selector)
+            ids, reprs = self._get_matrix(corpus, self.output_prefix + "_repr", selector)
         cluster_df = self.ec_model.transform_clusters(reprs, ids)
         if is_context:
-            cluster_field = self.output_prefix + '_context_clustering'
+            cluster_field = self.output_prefix + "_context_clustering"
         else:
-            cluster_field = self.output_prefix + '_clustering'
+            cluster_field = self.output_prefix + "_clustering"
         for id, entry in cluster_df.iterrows():
             for k, v in entry.to_dict().items():
-                corpus.get_utterance(id).meta[cluster_field + '.' + k] = v
+                corpus.get_utterance(id).meta[cluster_field + "." + k] = v
         return cluster_df
-    
+
     ### cluster management
 
     def set_cluster_names(self, cluster_names):
         """
         Assigns names to inferred clusters. May be called after inspecting the output of `print_clusters`.
 
         :param cluster_names: a list of names, where `cluster_names[i]` is the name of the cluster with `cluster_id_` `i`.
         :return: None
         """
         self.ec_model.set_cluster_names(cluster_names)
-    
+
     def get_cluster_names(self):
         """
         Returns the names of the inferred clusters.
 
         :return: list of cluster names where `cluster_names[i]` is the name of the cluster with `cluster_id_` `i`.
         """
         return self.ec_model.get_cluster_names()
-    
+
     def print_clusters(self, k=10, max_chars=1000, corpus=None):
         """
         Prints representative terms, utterances and context-utterances for each inferred type. Can be inspected to help interpret the transformer's output.
         By default, will only print out terms and context terms; if the corpus containing the training data is passed in, will output utterances
         and context-utterances as well.
 
         :param k: number of examples to print out.
@@ -290,73 +313,97 @@
         :param corpus: optional, the corpus that the transformer was trained on. if set, will print example utterances and context-utterances as well as terms.
 
         :return: None
         """
         n_clusters = self.ec_model.n_clusters
         cluster_obj = self.ec_model.clustering
         for i in range(n_clusters):
-            print('CLUSTER', i, self.ec_model.get_cluster_names()[i])
-            print('---')
-            print('terms')
-            term_subset = cluster_obj['terms'][cluster_obj['terms'].cluster_id_ == i].sort_values('cluster_dist').head(k)
-            print(term_subset[['cluster_dist']])
+            print("CLUSTER", i, self.ec_model.get_cluster_names()[i])
+            print("---")
+            print("terms")
+            term_subset = (
+                cluster_obj["terms"][cluster_obj["terms"].cluster_id_ == i]
+                .sort_values("cluster_dist")
+                .head(k)
+            )
+            print(term_subset[["cluster_dist"]])
             print()
-            print('context terms')
-            context_term_subset = cluster_obj['context_terms'][cluster_obj['context_terms'].cluster_id_ == i].sort_values('cluster_dist').head(k)
-            print(context_term_subset[['cluster_dist']])
+            print("context terms")
+            context_term_subset = (
+                cluster_obj["context_terms"][cluster_obj["context_terms"].cluster_id_ == i]
+                .sort_values("cluster_dist")
+                .head(k)
+            )
+            print(context_term_subset[["cluster_dist"]])
             print()
-            if corpus is None: continue
+            if corpus is None:
+                continue
             print()
-            print('utterances')
-            utt_subset = cluster_obj['utts'][cluster_obj['utts'].cluster_id_ == i].drop_duplicates('cluster_dist').sort_values('cluster_dist').head(k)
+            print("utterances")
+            utt_subset = (
+                cluster_obj["utts"][cluster_obj["utts"].cluster_id_ == i]
+                .drop_duplicates("cluster_dist")
+                .sort_values("cluster_dist")
+                .head(k)
+            )
             for id, row in utt_subset.iterrows():
-                print('>', id, '%.3f' % row.cluster_dist, corpus.get_utterance(id).text[:max_chars])
+                print(">", id, "%.3f" % row.cluster_dist, corpus.get_utterance(id).text[:max_chars])
             print()
-            print('context-utterances')
-            context_utt_subset = cluster_obj['context_utts'][cluster_obj['context_utts'].cluster_id_ == i].drop_duplicates('cluster_dist').sort_values('cluster_dist').head(k)
+            print("context-utterances")
+            context_utt_subset = (
+                cluster_obj["context_utts"][cluster_obj["context_utts"].cluster_id_ == i]
+                .drop_duplicates("cluster_dist")
+                .sort_values("cluster_dist")
+                .head(k)
+            )
             for id, row in context_utt_subset.iterrows():
-                print('>>', id, '%.3f' % row.cluster_dist, corpus.get_utterance(id).text[:max_chars])
-            print('\n====\n')
-    
+                print(
+                    ">>", id, "%.3f" % row.cluster_dist, corpus.get_utterance(id).text[:max_chars]
+                )
+            print("\n====\n")
+
     def print_cluster_stats(self):
         """
         Returns a Pandas dataframe containing the % of terms, context terms, and training utterances/context-utterances that have been assigned to each cluster.
 
         :return: dataframe containing cluster statistics
         """
         cluster_obj = self.ec_model.clustering
-        return pd.concat([
-            cluster_obj[k].cluster.value_counts(normalize=True).rename(k).sort_index()
-            for k in ['utts', 'terms', 'context_utts', 'context_terms']
-        ], axis=1)
+        return pd.concat(
+            [
+                cluster_obj[k].cluster.value_counts(normalize=True).rename(k).sort_index()
+                for k in ["utts", "terms", "context_utts", "context_terms"]
+            ],
+            axis=1,
+        )
 
     def summarize(self, k=10, max_chars=1000, corpus=None):
         """
         Wrapper function to print inferred clusters and statistics about their sizes.
 
         :param k: number of examples to print out.
         :param max_chars: maximum number of characters per utterance/context-utterance to print. Can be toggled to control the size of the output.
         :param corpus: optional, the corpus that the transformer was trained on. if set, will print example utterances and context-utterances as well as terms.
 
         :return: None
         """
-        print('STATS')
+        print("STATS")
         print(self.print_cluster_stats())
-        print('\nCLUSTERS')
-        self.print_clusters(k=k, max_chars=max_chars,  corpus=corpus)
-    
+        print("\nCLUSTERS")
+        self.print_clusters(k=k, max_chars=max_chars, corpus=corpus)
+
     ### getters for representations from training data
 
     def get_terms(self):
         """
         Gets the names of the terms for which the transformer has computed representations.
 
         :return: list of terms
         """
-        return self.ec_model.terms 
+        return self.ec_model.terms
 
     def get_term_ranges(self):
         """
         Gets the range statistics of terms.
 
         :return: list of term ranges. order corresponds to the ordering of terms returned via `get_terms()`.
         """
@@ -406,321 +453,381 @@
         """
         Loads a model from disk.
 
         :param dirname: directory to read model from
         :return: None
         """
         self.ec_model.load(dirname)
-    
+
     def dump(self, dirname):
         """
         Writes a model to disk.
 
         :param dirname: directory to write model to.
         :return: None
         """
         self.ec_model.dump(dirname)
 
+
 class ExpectedContextModel:
     """
     Model that derives representations of terms and utterances in terms of their conversational context, i.e.,
     context-utterances that occur near an utterance, or utterances containing a term. Typically, the conversational
     context consists of immediate replies ("forwards context") or predecessors ("backwards context"), though
     this can be specified by the user. Can be used in ConvoKit through the `ExpectedContextModelTransformer` transformer;
     see documentation of that transformer for further details.
     """
 
-    def __init__(self, n_svd_dims=25, snip_first_dim=True, n_clusters=8,
-                     context_U=None, context_V=None, context_s=None,
-                     model=None,
-                     context_terms=None, cluster_on='utts',
-                     random_state=None, cluster_random_state=None):
-        
+    def __init__(
+        self,
+        n_svd_dims=25,
+        snip_first_dim=True,
+        n_clusters=8,
+        context_U=None,
+        context_V=None,
+        context_s=None,
+        model=None,
+        context_terms=None,
+        cluster_on="utts",
+        random_state=None,
+        cluster_random_state=None,
+    ):
         self.n_svd_dims = n_svd_dims
         self.snip_first_dim = snip_first_dim
         self.random_state = random_state
         self.n_clusters = n_clusters
         self.cluster_random_state = cluster_random_state
         self.cluster_on = cluster_on
-        
+
         if (context_U is None) and (model is None):
             self.fitted_context = False
-        elif (model is not None):
+        elif model is not None:
             self.set_model(model)
             # self.fitted_context = True
             # self.n_svd_dims = model.n_svd_dims
             # self.context_U = model.context_U
             # self.train_context_reprs = self._snip(self.context_U, self.snip_first_dim)
             # self.context_V = model.context_V
             # self.context_term_reprs = self._snip(self.context_V, self.snip_first_dim)
             # self.context_s = model.context_s
             # self.context_terms = self._get_default_ids(model.context_terms, len(self.context_V))
-        elif (context_U is not None):
+        elif context_U is not None:
             self.fitted_context = True
             self.n_svd_dims = context_U.shape[1]
             self.context_U = context_U
             self.train_context_reprs = self._snip(self.context_U, self.snip_first_dim)
-            
+
             self.context_V = context_V
             self.context_term_reprs = self._snip(self.context_V, self.snip_first_dim)
-            
+
             self.context_s = context_s
             self.context_terms = self._get_default_ids(context_terms, len(self.context_V))
 
-        self.terms = None 
+        self.terms = None
         self.clustering = {}
 
     def set_model(self, model):
         self.fitted_context = True
         self.n_svd_dims = model.n_svd_dims
         self.context_U = model.context_U
         self.train_context_reprs = self._snip(self.context_U, self.snip_first_dim)
         self.context_V = model.context_V
         self.context_term_reprs = self._snip(self.context_V, self.snip_first_dim)
         self.context_s = model.context_s
         self.context_terms = self._get_default_ids(model.context_terms, len(self.context_V))
-            
-    def fit_context_utts(self, context_utt_vects, 
-                    context_terms=None):
-        self.context_U, self.context_s, self.context_V = \
-            randomized_svd(context_utt_vects, n_components=self.n_svd_dims,
-                          random_state=self.random_state)
+
+    def fit_context_utts(self, context_utt_vects, context_terms=None):
+        self.context_U, self.context_s, self.context_V = randomized_svd(
+            context_utt_vects, n_components=self.n_svd_dims, random_state=self.random_state
+        )
         self.train_context_reprs = self._snip(self.context_U, self.snip_first_dim)
-        
+
         self.context_V = self.context_V.T
         self.context_term_reprs = self._snip(self.context_V, self.snip_first_dim)
-        
+
         self.context_terms = self._get_default_ids(context_terms, len(self.context_V))
         self.fitted_context = True
-                                                
-    def fit(self, utt_vects, context_utt_vects, utt_context_pairs,
-            terms=None, context_terms=None,
-            refit_context=False, fit_clusters=True, n_clusters=None, cluster_random_state=None,
-           utt_ids=None, context_utt_ids=None):
+
+    def fit(
+        self,
+        utt_vects,
+        context_utt_vects,
+        utt_context_pairs,
+        terms=None,
+        context_terms=None,
+        refit_context=False,
+        fit_clusters=True,
+        n_clusters=None,
+        cluster_random_state=None,
+        utt_ids=None,
+        context_utt_ids=None,
+    ):
         if (not self.fitted_context) or refit_context:
             self.fit_context_utts(context_utt_vects, context_terms)
-        
+
         self.terms = self._get_default_ids(terms, utt_vects.shape[1])
-        
-        utt_vect_subset = utt_vects[utt_context_pairs[:,0]]
-        context_repr_subset = self.context_U[utt_context_pairs[:,1]]
+
+        utt_vect_subset = utt_vects[utt_context_pairs[:, 0]]
+        context_repr_subset = self.context_U[utt_context_pairs[:, 1]]
         self.term_reprs_full = utt_vect_subset.T * context_repr_subset / self.context_s
         self.term_reprs = self._snip(self.term_reprs_full, snip_first_dim=self.snip_first_dim)
         self.train_utt_reprs = self.transform(utt_vects)
 
         full_dists = cosine_distances(
-                self.term_reprs,
-                self._snip(context_repr_subset, snip_first_dim=self.snip_first_dim)
-            )
-        weights = normalize(np.array(utt_vect_subset > 0), norm='l1', axis=0)
+            self.term_reprs, self._snip(context_repr_subset, snip_first_dim=self.snip_first_dim)
+        )
+        weights = normalize(np.array(utt_vect_subset > 0), norm="l1", axis=0)
         clipped_dists = np.clip(full_dists, None, 1)
         self.term_ranges = (clipped_dists * weights.T).sum(axis=1)
         if fit_clusters:
             if self.n_clusters is None:
                 self.n_clusters = n_clusters
             if self.cluster_random_state is None:
                 self.cluster_random_state = cluster_random_state
-            self.fit_clusters(self.n_clusters, self.cluster_random_state,
-                             utt_ids=utt_ids, context_utt_ids=context_utt_ids)
-        
+            self.fit_clusters(
+                self.n_clusters,
+                self.cluster_random_state,
+                utt_ids=utt_ids,
+                context_utt_ids=context_utt_ids,
+            )
+
     def transform(self, utt_vects):
         return self._snip(utt_vects * self.term_reprs_full / self.context_s, self.snip_first_dim)
-        
+
     def compute_utt_ranges(self, utt_vects):
-        return np.dot(normalize(utt_vects, norm='l1'), self.term_ranges)
-    
+        return np.dot(normalize(utt_vects, norm="l1"), self.term_ranges)
+
     def transform_context_utts(self, context_utt_vects):
-        return self._snip(context_utt_vects * self.context_V / self.context_s, self.snip_first_dim)  
-    
-    def fit_clusters(self, n_clusters='default', random_state='default', utt_ids=None, context_utt_ids=None):
-        if n_clusters == 'default':
+        return self._snip(context_utt_vects * self.context_V / self.context_s, self.snip_first_dim)
+
+    def fit_clusters(
+        self, n_clusters="default", random_state="default", utt_ids=None, context_utt_ids=None
+    ):
+        if n_clusters == "default":
             n_clusters = self.n_clusters
-        if random_state == 'default':
+        if random_state == "default":
             random_state = self.cluster_random_state
         km_obj = ClusterWrapper(n_clusters=n_clusters, random_state=random_state)
-        if self.cluster_on == 'terms':
+        if self.cluster_on == "terms":
             km_obj.fit(self.term_reprs)
-        elif self.cluster_on == 'utts':
+        elif self.cluster_on == "utts":
             km_obj.fit(self.train_utt_reprs)
-        self.clustering['km_obj'] = km_obj
-        self.clustering['utts'] = km_obj.transform(self.train_utt_reprs, utt_ids)
-        self.clustering['terms'] = km_obj.transform(self.term_reprs, self.terms)
-        self.clustering['context_utts'] = km_obj.transform(self.train_context_reprs, context_utt_ids)
-        self.clustering['context_terms'] = km_obj.transform(self.context_term_reprs, self.context_terms)
-    
+        self.clustering["km_obj"] = km_obj
+        self.clustering["utts"] = km_obj.transform(self.train_utt_reprs, utt_ids)
+        self.clustering["terms"] = km_obj.transform(self.term_reprs, self.terms)
+        self.clustering["context_utts"] = km_obj.transform(
+            self.train_context_reprs, context_utt_ids
+        )
+        self.clustering["context_terms"] = km_obj.transform(
+            self.context_term_reprs, self.context_terms
+        )
+
     def transform_clusters(self, reprs, ids=None):
-        return self.clustering['km_obj'].transform(reprs, ids)
-    
+        return self.clustering["km_obj"].transform(reprs, ids)
+
     def set_cluster_names(self, cluster_names):
         cluster_names = np.array(cluster_names)
-        self.clustering['km_obj'].set_cluster_names(cluster_names)
-        for k in ['utts','terms','context_utts','context_terms']:
-            self.clustering[k]['cluster'] = cluster_names[self.clustering[k].cluster_id_]
+        self.clustering["km_obj"].set_cluster_names(cluster_names)
+        for k in ["utts", "terms", "context_utts", "context_terms"]:
+            self.clustering[k]["cluster"] = cluster_names[self.clustering[k].cluster_id_]
 
     def get_cluster_names(self):
-        return self.clustering['km_obj'].cluster_names
+        return self.clustering["km_obj"].cluster_names
 
     def print_clusters(self, k=10, max_chars=1000, text_df=None):
         n_clusters = self.n_clusters
         cluster_obj = self.clustering
         cluster_names = self.get_cluster_names()
         for i in range(n_clusters):
-            print('CLUSTER', i, cluster_names[i])
-            print('---')
-            print('terms')
-            term_subset = cluster_obj['terms'][cluster_obj['terms'].cluster_id_ == i].sort_values('cluster_dist').head(k)
-            print(term_subset[['cluster_dist']])
+            print("CLUSTER", i, cluster_names[i])
+            print("---")
+            print("terms")
+            term_subset = (
+                cluster_obj["terms"][cluster_obj["terms"].cluster_id_ == i]
+                .sort_values("cluster_dist")
+                .head(k)
+            )
+            print(term_subset[["cluster_dist"]])
             print()
-            print('context terms')
-            context_term_subset = cluster_obj['context_terms'][cluster_obj['context_terms'].cluster_id_ == i].sort_values('cluster_dist').head(k)
-            print(context_term_subset[['cluster_dist']])
+            print("context terms")
+            context_term_subset = (
+                cluster_obj["context_terms"][cluster_obj["context_terms"].cluster_id_ == i]
+                .sort_values("cluster_dist")
+                .head(k)
+            )
+            print(context_term_subset[["cluster_dist"]])
             print()
-            if text_df is None: continue
+            if text_df is None:
+                continue
             print()
-            print('utterances')
-            utt_subset = cluster_obj['utts'][cluster_obj['utts'].cluster_id_ == i].drop_duplicates('cluster_dist').sort_values('cluster_dist').head(k)
+            print("utterances")
+            utt_subset = (
+                cluster_obj["utts"][cluster_obj["utts"].cluster_id_ == i]
+                .drop_duplicates("cluster_dist")
+                .sort_values("cluster_dist")
+                .head(k)
+            )
             for id, row in utt_subset.iterrows():
-                print('>', id, '%.3f' % row.cluster_dist, text_df.loc[id].text[:max_chars])
+                print(">", id, "%.3f" % row.cluster_dist, text_df.loc[id].text[:max_chars])
             print()
-            print('context-utterances')
-            context_utt_subset = cluster_obj['context_utts'][cluster_obj['context_utts'].cluster_id_ == i].drop_duplicates('cluster_dist').sort_values('cluster_dist').head(k)
+            print("context-utterances")
+            context_utt_subset = (
+                cluster_obj["context_utts"][cluster_obj["context_utts"].cluster_id_ == i]
+                .drop_duplicates("cluster_dist")
+                .sort_values("cluster_dist")
+                .head(k)
+            )
             for id, row in context_utt_subset.iterrows():
-                print('>>', id, '%.3f' % row.cluster_dist, text_df.loc[id].text[:max_chars])
-            print('\n====\n')
+                print(">>", id, "%.3f" % row.cluster_dist, text_df.loc[id].text[:max_chars])
+            print("\n====\n")
 
     def print_cluster_stats(self):
         cluster_obj = self.clustering
-        return pd.concat([
-            cluster_obj[k].cluster.value_counts(normalize=True).rename(k).sort_index()
-            for k in ['utts', 'terms', 'context_utts', 'context_terms']
-        ], axis=1)
-    
+        return pd.concat(
+            [
+                cluster_obj[k].cluster.value_counts(normalize=True).rename(k).sort_index()
+                for k in ["utts", "terms", "context_utts", "context_terms"]
+            ],
+            axis=1,
+        )
+
     def load(self, dirname):
-        with open(os.path.join(dirname, 'meta.json')) as f:
+        with open(os.path.join(dirname, "meta.json")) as f:
             meta_dict = json.load(f)
-        self.n_svd_dims = meta_dict['n_svd_dims']
-        self.random_state = meta_dict['random_state']
-        self.snip_first_dim = meta_dict['snip_first_dim']
-        self.cluster_on = meta_dict['cluster_on']
-        
-        self.context_U = np.load(os.path.join(dirname, 'context_U.npy'))
+        self.n_svd_dims = meta_dict["n_svd_dims"]
+        self.random_state = meta_dict["random_state"]
+        self.snip_first_dim = meta_dict["snip_first_dim"]
+        self.cluster_on = meta_dict["cluster_on"]
+
+        self.context_U = np.load(os.path.join(dirname, "context_U.npy"))
         self.train_context_reprs = self._snip(self.context_U, self.snip_first_dim)
-        self.context_V = np.load(os.path.join(dirname, 'context_V.npy'))
+        self.context_V = np.load(os.path.join(dirname, "context_V.npy"))
         self.context_term_reprs = self._snip(self.context_V, self.snip_first_dim)
-        self.context_s = np.load(os.path.join(dirname, 'context_s.npy'))
-        self.context_terms = np.load(os.path.join(dirname, 'context_terms.npy'))
-        self.terms = np.load(os.path.join(dirname, 'terms.npy'))
-        self.term_reprs_full = np.matrix(np.load(os.path.join(dirname, 'term_reprs.npy')))
+        self.context_s = np.load(os.path.join(dirname, "context_s.npy"))
+        self.context_terms = np.load(os.path.join(dirname, "context_terms.npy"))
+        self.terms = np.load(os.path.join(dirname, "terms.npy"))
+        self.term_reprs_full = np.matrix(np.load(os.path.join(dirname, "term_reprs.npy")))
         self.term_reprs = self._snip(self.term_reprs_full, self.snip_first_dim)
-        self.term_ranges = np.load(os.path.join(dirname, 'term_ranges.npy'))
-        self.train_utt_reprs = np.load(os.path.join(dirname, 'train_utt_reprs.npy'))
-        
+        self.term_ranges = np.load(os.path.join(dirname, "term_ranges.npy"))
+        self.train_utt_reprs = np.load(os.path.join(dirname, "train_utt_reprs.npy"))
+
         try:
             km_obj = ClusterWrapper(self.n_clusters)
             km_obj.load(dirname)
-            self.clustering['km_obj'] = km_obj
-            for k in ['utts','terms','context_utts','context_terms']:
-                self.clustering[k] = pd.read_csv(os.path.join(dirname, 'clustering_%s.tsv' % k),
-                                                sep='\t', index_col=0)
+            self.clustering["km_obj"] = km_obj
+            for k in ["utts", "terms", "context_utts", "context_terms"]:
+                self.clustering[k] = pd.read_csv(
+                    os.path.join(dirname, "clustering_%s.tsv" % k), sep="\t", index_col=0
+                )
         except Exception as e:
             pass
-    
+
     def dump(self, dirname, dump_clustering=True):
         try:
             os.mkdir(dirname)
-        except: 
+        except:
             pass
-        with open(os.path.join(dirname, 'meta.json'), 'w') as f:
-            json.dump({'n_svd_dims': self.n_svd_dims, 
-                      'random_state': self.random_state,
-                      'snip_first_dim': self.snip_first_dim,
-                      'cluster_on': self.cluster_on}, f)
-        for name, obj in [('context_U', self.context_U),
-                         ('context_V', self.context_V),
-                         ('context_s', self.context_s),
-                         ('context_terms', self.context_terms),
-                         ('terms',  self.terms),
-                         ('term_reprs', self.term_reprs_full),
-                         ('term_ranges', self.term_ranges),
-                         ('train_utt_reprs', self.train_utt_reprs)]:
-            np.save(os.path.join(dirname, name + '.npy'), obj)
+        with open(os.path.join(dirname, "meta.json"), "w") as f:
+            json.dump(
+                {
+                    "n_svd_dims": self.n_svd_dims,
+                    "random_state": self.random_state,
+                    "snip_first_dim": self.snip_first_dim,
+                    "cluster_on": self.cluster_on,
+                },
+                f,
+            )
+        for name, obj in [
+            ("context_U", self.context_U),
+            ("context_V", self.context_V),
+            ("context_s", self.context_s),
+            ("context_terms", self.context_terms),
+            ("terms", self.terms),
+            ("term_reprs", self.term_reprs_full),
+            ("term_ranges", self.term_ranges),
+            ("train_utt_reprs", self.train_utt_reprs),
+        ]:
+            np.save(os.path.join(dirname, name + ".npy"), obj)
         if dump_clustering and (len(self.clustering) > 0):
-            self.clustering['km_obj'].dump(dirname)
-            for k in ['utts','terms','context_utts','context_terms']:
-                self.clustering[k].to_csv(os.path.join(dirname, 'clustering_%s.tsv' % k), sep='\t')
-    
+            self.clustering["km_obj"].dump(dirname)
+            for k in ["utts", "terms", "context_utts", "context_terms"]:
+                self.clustering[k].to_csv(os.path.join(dirname, "clustering_%s.tsv" % k), sep="\t")
+
     def _get_default_ids(self, ids, n):
         if ids is None:
             return np.arange(n)
-        else: return ids
+        else:
+            return ids
 
     def _snip(self, vects, snip_first_dim=True, dim=None):
         if dim is None:
             dim = vects.shape[1]
-        return normalize(vects[:,int(snip_first_dim):dim])
+        return normalize(vects[:, int(snip_first_dim) : dim])
+
 
 class ClusterWrapper:
     """
     Wrapper that performs K-Means clustering. Handles model loading and dumping,
-    formats clustering output as dataframes for convenience, and keeps track of 
+    formats clustering output as dataframes for convenience, and keeps track of
     names that an end-user can assign to clusters.
     """
+
     def __init__(self, n_clusters, cluster_names=None, random_state=None):
-        
         self.n_clusters = n_clusters
         self.random_state = random_state
-        
+
         self.cluster_names = np.arange(n_clusters)
         if cluster_names is not None:
             self.cluster_names = cluster_names
         self.km_model = KMeans(n_clusters=n_clusters, random_state=random_state)
         self.km_df = None
-    
+
     def fit(self, vects, ids=None):
-        
         self.km_model.fit(vects)
         self.km_df = self.transform(vects, ids)
-        
+
     def set_cluster_names(self, names):
         self.cluster_names = np.array(names)
         if self.km_df is not None:
-            self.km_df['cluster'] = self.cluster_names[self.km_df.cluster_id_]
-    
+            self.km_df["cluster"] = self.cluster_names[self.km_df.cluster_id_]
+
     def transform(self, vects, ids=None):
         if ids is None:
             ids = np.arange(len(vects))
-        km_df = self._get_km_assignment_df(self.km_model,
-                     vects, ids, self.cluster_names)
+        km_df = self._get_km_assignment_df(self.km_model, vects, ids, self.cluster_names)
         return km_df
-    
+
     def _get_km_assignment_df(self, km, vects, ids, cluster_names):
         dists = km.transform(vects)
         min_dist = dists[np.arange(len(dists)), dists.argmin(axis=1)]
         cluster_assigns = km.predict(vects)
         cluster_assign_names = cluster_names[cluster_assigns]
-        df = pd.DataFrame({'index': ids,  
-                          'cluster_id_': cluster_assigns,
-                          'cluster': cluster_assign_names,
-                          'cluster_dist': min_dist}).set_index('index')
+        df = pd.DataFrame(
+            {
+                "index": ids,
+                "cluster_id_": cluster_assigns,
+                "cluster": cluster_assign_names,
+                "cluster_dist": min_dist,
+            }
+        ).set_index("index")
         return df
-    
+
     def load(self, dirname):
-        with open(os.path.join(dirname, 'cluster_meta.json')) as f:
+        with open(os.path.join(dirname, "cluster_meta.json")) as f:
             meta_dict = json.load(f)
-        self.n_clusters = meta_dict['n_clusters']
-        self.random_state = meta_dict['random_state']
-        
-        self.km_df = pd.read_csv(os.path.join(dirname, 'cluster_km_df.tsv'),
-                                sep='\t', index_col=0)
-        self.cluster_names = np.load(os.path.join(dirname, 'cluster_names.npy'))
-        self.km_model = joblib.load(os.path.join(dirname, 'km_model.joblib'))
-    
+        self.n_clusters = meta_dict["n_clusters"]
+        self.random_state = meta_dict["random_state"]
+
+        self.km_df = pd.read_csv(os.path.join(dirname, "cluster_km_df.tsv"), sep="\t", index_col=0)
+        self.cluster_names = np.load(os.path.join(dirname, "cluster_names.npy"))
+        self.km_model = joblib.load(os.path.join(dirname, "km_model.joblib"))
+
     def dump(self, dirname):
         try:
             os.mkdir(dirname)
-        except: pass
-        with open(os.path.join(dirname, 'cluster_meta.json'), 'w') as f:
-            json.dump({'n_clusters': self.n_clusters,
-                      'random_state': self.random_state}, f)
-        self.km_df.to_csv(os.path.join(dirname, 'cluster_km_df.tsv'), sep='\t')
-        np.save(os.path.join(dirname, 'cluster_names.npy'), self.cluster_names)
-        joblib.dump(self.km_model, os.path.join(dirname, 'km_model.joblib'))
+        except:
+            pass
+        with open(os.path.join(dirname, "cluster_meta.json"), "w") as f:
+            json.dump({"n_clusters": self.n_clusters, "random_state": self.random_state}, f)
+        self.km_df.to_csv(os.path.join(dirname, "cluster_km_df.tsv"), sep="\t")
+        np.save(os.path.join(dirname, "cluster_names.npy"), self.cluster_names)
+        joblib.dump(self.km_model, os.path.join(dirname, "km_model.joblib"))
```

### Comparing `convokit-2.5.3/convokit/expected_context_framework/expected_context_model_pipeline.py` & `convokit-3.0.0/convokit/expected_context_framework/expected_context_model_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,26 +1,31 @@
-from convokit.expected_context_framework import ColNormedTfidfTransformer, ExpectedContextModelTransformer, DualContextWrapper
+from convokit.expected_context_framework import (
+    ColNormedTfidfTransformer,
+    ExpectedContextModelTransformer,
+    DualContextWrapper,
+)
 
 from convokit.transformer import Transformer
 from convokit.convokitPipeline import ConvokitPipeline
 from convokit.text_processing import TextProcessor
 from convokit import Utterance, Speaker
 
 import os
 
+
 class ExpectedContextModelPipeline(Transformer):
     """
     Wrapper class implementing a pipeline that derives characterizations of terms and utterances in terms of their conversational context. The pipeline handles the following steps:
 
     * processing input text (via a pipeline supplied by the user in the `text_pipe` argument);
     * transforming text to input representation (via `ColNormedTfidfTransformer`);
     * deriving characterizations (via `ExpectedContextModelTransformer`)
 
     The `ColNormedTfidfTransformer` components are stored as the `tfidf_model` and `context_tfidf_model` attributes of the class; the `ExpectedContextModelTransformer` is stored as the `ec_model` attribute.
-    
+
     For further details, see the `ColNormedTfidfTransformer` and `ExpectedContextModelTransformer` classes.
 
     :param context_field: the name of an utterance-level attribute containing the ID of the corresponding context-utterance. in particular, to use immediate predecessors as context, set `context_field` to `'reply_to'`. as another example, to use immediate replies, provided that utterances contain an attribute `next_id` containing the ID of their reply, set `context_field` to `'next_id'`.
     :param output_prefix: the name of the attributes and vectors to write to in the transform step. the transformer outputs several fields, which will be prefixed with the given string.
     :param text_field: the  name of the utterance-level attribute containing the text to use as input.
     :param context_text_field: the  name of the utterance-level attribute containing the text to use as input for context-utterances. by default, is equivalent to `text_field`.
     :param text_pipe: a `convokitPipeline` object used to compute the contents of `text_field`. defaults to populating the `text_field` attribute of each utterance utt with `utt.text`.
@@ -35,157 +40,175 @@
     :param n_clusters: the number of clusters to infer.
     :param cluster_on: whether to cluster on utterance or term representations, (corresponding to values `'utts'` or `'terms'`). By default, we infer clusters based on representations of the utterances from the training data, and then assign term and context-utterance representations to the resultant clusters. In some cases (e.g., if utterances are highly unstructured and lengthy) it might be better to cluster term representations first.
     :param ec_model: an existing, fitted `ExpectedContextModelPipeline` object to initialize with (optional)
     :param random_state: the random seed to use in the LSA step (which calls a randomized implementation of SVD)
     :param cluster_random_state: the random seed to use to infer clusters.
 
     """
-    def __init__(self, 
-        context_field, output_prefix, 
-        text_field, context_text_field=None,
-        text_pipe=None, context_text_pipe=None,
-        tfidf_params={}, context_tfidf_params=None, share_tfidf_models=True,
-        min_terms=0, context_min_terms=None,
-        n_svd_dims=25, snip_first_dim=True, n_clusters=8, cluster_on='utts',
-        ec_model=None,
-        random_state=None, cluster_random_state=None):
 
+    def __init__(
+        self,
+        context_field,
+        output_prefix,
+        text_field,
+        context_text_field=None,
+        text_pipe=None,
+        context_text_pipe=None,
+        tfidf_params={},
+        context_tfidf_params=None,
+        share_tfidf_models=True,
+        min_terms=0,
+        context_min_terms=None,
+        n_svd_dims=25,
+        snip_first_dim=True,
+        n_clusters=8,
+        cluster_on="utts",
+        ec_model=None,
+        random_state=None,
+        cluster_random_state=None,
+    ):
         self.context_field = context_field
         self.output_prefix = output_prefix
-        
-        self.vect_field = 'col_normed_tfidf'
+
+        self.vect_field = "col_normed_tfidf"
         self.share_tfidf_models = share_tfidf_models
-        
+
         if share_tfidf_models:
             self.context_vect_field = self.vect_field
         else:
-            self.context_vect_field = 'context_col_normed_tfidf'
-        
-        
+            self.context_vect_field = "context_col_normed_tfidf"
+
         self.text_field = text_field
         if context_text_field is None:
             self.context_text_field = text_field
         else:
             self.context_text_field = context_text_field
-        
+
         if text_pipe is None:
-            self.text_pipe = ConvokitPipeline([
-                ('text_pipe', TextProcessor(output_field=self.text_field,
-                               proc_fn=lambda x: x))
-            ])
+            self.text_pipe = ConvokitPipeline(
+                [("text_pipe", TextProcessor(output_field=self.text_field, proc_fn=lambda x: x))]
+            )
         else:
             self.text_pipe = text_pipe
-        
+
         if context_text_pipe is None:
             self.context_text_pipe = self.text_pipe
         else:
             self.context_text_pipe = context_text_pipe
-        
+
         self.tfidf_params = tfidf_params
         if context_tfidf_params is None:
             self.context_tfidf_params = tfidf_params
         else:
             self.context_tfidf_params = context_tfidf_params
-        
+
         self.min_terms = min_terms
         if context_min_terms is None:
             self.context_min_terms = min_terms
         else:
             self.context_min_terms = context_min_terms
-        
+
         if ec_model is not None:
             in_model = ec_model.ec_model
         else:
             in_model = None
         self.ec_model = ExpectedContextModelTransformer(
-            context_field=context_field, output_prefix=output_prefix,
+            context_field=context_field,
+            output_prefix=output_prefix,
             vect_field=self.vect_field,
             context_vect_field=self.context_vect_field,
             model=in_model,
-            n_svd_dims=n_svd_dims, snip_first_dim=snip_first_dim, n_clusters=n_clusters, cluster_on=cluster_on,
-            random_state=random_state, cluster_random_state=cluster_random_state)
-        
-        
+            n_svd_dims=n_svd_dims,
+            snip_first_dim=snip_first_dim,
+            n_clusters=n_clusters,
+            cluster_on=cluster_on,
+            random_state=random_state,
+            cluster_random_state=cluster_random_state,
+        )
+
         self.tfidf_model = ColNormedTfidfTransformer(
-            input_field=self.text_field,
-            output_field=self.vect_field, **self.tfidf_params
+            input_field=self.text_field, output_field=self.vect_field, **self.tfidf_params
         )
         if not share_tfidf_models:
             self.context_tfidf_model = ColNormedTfidfTransformer(
                 input_field=self.context_text_field,
                 output_field=self.context_vect_field,
                 **self.context_tfidf_params
             )
         else:
             self.context_tfidf_model = self.tfidf_model
-        
-        
+
     def fit(self, corpus, y=None, selector=lambda x: True, context_selector=lambda x: True):
         """
-        Fits an `ExpectedContextModelPipeline` over training data: derives input and latent representations of terms, utterances and contexts, 
+        Fits an `ExpectedContextModelPipeline` over training data: derives input and latent representations of terms, utterances and contexts,
         range statistics for terms, and a clustering of the resultant representations.
 
         :param corpus: Corpus containing training data
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances will be considered in the fit step. defaults to using all utterances, subject to `min_terms` parameter passed at initialization.
         :param context_selector: a boolean function of signature `filter(utterance)` that determines which context-utterances will be considered in the fit step. defaults to using all utterances, subject to `context_min_terms` parameter passed at initialization.
         :return: None
         """
 
         self.text_pipe.fit_transform(corpus)
         if not self.share_tfidf_models:
             self.context_text_pipe.fit_transform(corpus)
         self.tfidf_model.fit_transform(corpus, selector=selector)
         if not self.share_tfidf_models:
             self.context_tfidf_model.fit_transform(corpus, selector=context_selector)
-        self.ec_model.fit(corpus, 
+        self.ec_model.fit(
+            corpus,
             selector=lambda x: selector(x)
-             and (x.meta.get(self.vect_field + '__n_feats',0) >= self.min_terms),
+            and (x.meta.get(self.vect_field + "__n_feats", 0) >= self.min_terms),
             context_selector=lambda x: context_selector(x)
-             and (x.meta.get(self.context_vect_field + '__n_feats',0) >= self.context_min_terms))
-    
+            and (x.meta.get(self.context_vect_field + "__n_feats", 0) >= self.context_min_terms),
+        )
+
     def transform(self, corpus, y=None, selector=lambda x: True):
         """
         Computes vector representations, ranges, and cluster assignments for utterances in a corpus.
 
         :param corpus: Corpus
-        :param selector: a boolean function of signature `filter(utterance)` that determines which utterances to transform. 
+        :param selector: a boolean function of signature `filter(utterance)` that determines which utterances to transform.
         :return: the Corpus, with per-utterance representations, ranges and cluster assignments.
         """
         _ = self.text_pipe.transform(corpus)
         _ = self.tfidf_model.transform(corpus, selector=selector)
-        _ = self.ec_model.transform(corpus, selector=lambda x: selector(x)
-             and (x.meta.get(self.vect_field + '__n_feats',0) >= self.min_terms))
+        _ = self.ec_model.transform(
+            corpus,
+            selector=lambda x: selector(x)
+            and (x.meta.get(self.vect_field + "__n_feats", 0) >= self.min_terms),
+        )
         return corpus
-    
+
     def transform_utterance(self, utt):
         """
-        Computes vector representation, range, and cluster assignment for a single utterance, which can be a ConvoKit Utterance or a string. 
+        Computes vector representation, range, and cluster assignment for a single utterance, which can be a ConvoKit Utterance or a string.
         Will return an Utterance object a nd write all of these characterizations (including vectors) to the utterance's metadata; attribute names are prefixed with the `output_prefix` constructor argument.
 
         :param utt: Utterance or string
         :return: the utterance, with per-utterance representation, range and cluster assignments.
         """
         if isinstance(utt, str):
-            utt = Utterance(text=utt, speaker=Speaker()) 
+            utt = Utterance(text=utt, speaker=Speaker())
         self.text_pipe.transform_utterance(utt)
         self.tfidf_model.transform_utterance(utt)
         return self.ec_model.transform_utterance(utt)
-    
+
     def summarize(self, k=10, max_chars=1000, corpus=None):
         """
         Prints inferred clusters and statistics about their sizes.
 
         :param k: number of examples to print out.
         :param max_chars: maximum number of characters per utterance/context-utterance to print. Can be toggled to control the size of the output.
         :param corpus: optional, the corpus that the transformer was trained on. if set, will print example utterances and context-utterances as well as terms.
 
         :return: None
         """
         self.ec_model.summarize(k, max_chars, corpus)
-    
+
     def set_cluster_names(self, names):
         """
         Assigns names to inferred clusters. May be called after inspecting the output of `print_clusters`.
 
         :param cluster_names: a list of names, where `cluster_names[i]` is the name of the cluster with `cluster_id_` `i`.
         :return: None
         """
@@ -202,59 +225,60 @@
     def get_terms(self):
         """
         Gets the names of the terms for which the transformer has computed representations.
 
         :return: list of terms
         """
         return self.ec_model.get_terms()
-    
+
     def load(self, dirname, model_dirs=None):
         """
         Loads a model from disk.
 
         :param dirname: directory to read model from
         :param model_dirs: optional list containing the directories (relative to `dirname`) in which each component is stored. the order of the list is as follows: [the `ExpectedContextModelTransformer`, the utterance `ColNormedTfidfTransformer`, the context-utterance `ColNormedTfidfTransformer` (if `share_tfidf_models` is set to `False` at initialization)]. defaults to `['ec_model', 'tfidf_model', 'context_tfidf_model']`.
         :return: None
         """
         if model_dirs is None:
-            model_dirs = ['ec_model', 'tfidf_model', 'context_tfidf_model']
-        
+            model_dirs = ["ec_model", "tfidf_model", "context_tfidf_model"]
+
         self.tfidf_model.load(os.path.join(dirname, model_dirs[1]))
         if not self.share_tfidf_models:
             self.context_tfidf_model.load(os.path.join(dirname, model_dirs[2]))
         else:
             self.context_tfidf_model = self.tfidf_model
         self.ec_model.load(os.path.join(dirname, model_dirs[0]))
-        
+
     def dump(self, dirname):
         """
         Writes a model to disk.
 
         :param dirname: directory to write model to.
         :return: None
         """
         try:
             os.mkdir(dirname)
         except:
             pass
-        self.tfidf_model.dump(os.path.join(dirname, 'tfidf_model'))
+        self.tfidf_model.dump(os.path.join(dirname, "tfidf_model"))
         if not self.share_tfidf_models:
-            self.context_tfidf_model.dump(os.path.join(dirname, 'context_tfidf_model'))
-        self.ec_model.dump(os.path.join(dirname, 'ec_model'))
-        
+            self.context_tfidf_model.dump(os.path.join(dirname, "context_tfidf_model"))
+        self.ec_model.dump(os.path.join(dirname, "ec_model"))
+
+
 class DualContextPipeline(Transformer):
     """
     Wrapper class implementing a pipeline that derives characterizations of terms and utterances in terms of two choices of conversational context. The pipeline handles the following steps:
 
     * processing input text (via a pipeline supplied by the user in the `text_pipe` argument);
     * transforming text to input representation (via `ColNormedTfidfTransformer`);
     * deriving characterizations (via `DualContextWrapper`)
 
     The `ColNormedTfidfTransformer` components are stored as the `tfidf_model` and `context_tfidf_model` attributes of the class; the `DualContextWrapper` is stored as the `dualmodel` attribute.
-    
+
     For further details, see the `ColNormedTfidfTransformer` and `DualContextWrapper` classes.
 
     :param context_field: the name of an utterance-level attribute containing the ID of the corresponding context-utterance. in particular, to use immediate predecessors as context, set `context_field` to `'reply_to'`. as another example, to use immediate replies, provided that utterances contain an attribute `next_id` containing the ID of their reply, set `context_field` to `'next_id'`.
     :param output_prefixes: list containing the name of the attributes and vectors that the `DualContextWrapper` component will write to in the transform step.
     :param text_field: the  name of the utterance-level attribute containing the text to use as input.
     :param context_text_field: the  name of the utterance-level attribute containing the text to use as input for context-utterances. by default, is equivalent to `text_field`.
     :param wrapper_output_prefix: the metadata fields where the utterance-level orientation and shift statistics are stored. By default, these attributes are stored as `orn` and `shift` in the metadata; if `wrapper_output_prefix` is specified, then they are stored as `<wrapper_output_prefix>_orn` (orientation) and `<wrapper_output_prefix>_shift` (shift).
@@ -269,90 +293,101 @@
     :param snip_first_dim: whether or not to remove the first dimension of the derived representations. by default this is set to `True`, since we've found that the first dimension tends to reflect term frequency, making the output less informative. Note that if `snip_first_dim=True` then in practice, we output `n_svd_dims-1`-dimensional representations.
     :param n_clusters: the number of clusters to infer.
     :param cluster_on: whether to cluster on utterance or term representations, (corresponding to values `'utts'` or `'terms'`). By default, we infer clusters based on representations of the utterances from the training data, and then assign term and context-utterance representations to the resultant clusters. In some cases (e.g., if utterances are highly unstructured and lengthy) it might  be better to cluster term representations first.
     :param random_state: the random seed to use in the LSA step (which calls a randomized implementation of SVD)
     :param cluster_random_state: the random seed to use to infer clusters.
 
     """
-    def __init__(self, 
-        context_fields, output_prefixes, 
-        text_field, context_text_field=None,
-        wrapper_output_prefix='',
-        text_pipe=None, context_text_pipe=None,
-        tfidf_params={}, context_tfidf_params=None, share_tfidf_models=True,
-        min_terms=0, context_min_terms=None,
-        n_svd_dims=25, snip_first_dim=True, n_clusters=8, cluster_on='utts',
-        random_state=None, cluster_random_state=None):
 
-        
-        self.vect_field = 'col_normed_tfidf'
+    def __init__(
+        self,
+        context_fields,
+        output_prefixes,
+        text_field,
+        context_text_field=None,
+        wrapper_output_prefix="",
+        text_pipe=None,
+        context_text_pipe=None,
+        tfidf_params={},
+        context_tfidf_params=None,
+        share_tfidf_models=True,
+        min_terms=0,
+        context_min_terms=None,
+        n_svd_dims=25,
+        snip_first_dim=True,
+        n_clusters=8,
+        cluster_on="utts",
+        random_state=None,
+        cluster_random_state=None,
+    ):
+        self.vect_field = "col_normed_tfidf"
         self.share_tfidf_models = share_tfidf_models
-        
+
         if share_tfidf_models:
             self.context_vect_field = self.vect_field
         else:
-            self.context_vect_field = 'context_col_normed_tfidf'
-        
-        
+            self.context_vect_field = "context_col_normed_tfidf"
+
         self.text_field = text_field
         if context_text_field is None:
             self.context_text_field = text_field
         else:
             self.context_text_field = context_text_field
-        
+
         if text_pipe is None:
-            self.text_pipe = ConvokitPipeline([
-                ('text_pipe', TextProcessor(output_field=self.text_field,
-                               proc_fn=lambda x: x))
-            ])
+            self.text_pipe = ConvokitPipeline(
+                [("text_pipe", TextProcessor(output_field=self.text_field, proc_fn=lambda x: x))]
+            )
         self.text_pipe = text_pipe
         self.text_pipe.steps[-1][1].output_field = self.text_field
-        
+
         if context_text_pipe is None:
             self.context_text_pipe = self.text_pipe
         else:
             self.context_text_pipe = context_text_pipe
             self.context_text_pipe.steps[-1][1].output_field = self.context_text_field
-        
+
         self.tfidf_params = tfidf_params
         if context_tfidf_params is None:
             self.context_tfidf_params = tfidf_params
         else:
             self.context_tfidf_params = context_tfidf_params
-        
+
         self.min_terms = min_terms
         if context_min_terms is None:
             self.context_min_terms = min_terms
         else:
             self.context_min_terms = context_min_terms
-        
-        
+
         self.dualmodel = DualContextWrapper(
-            context_fields=context_fields, output_prefixes=output_prefixes,
+            context_fields=context_fields,
+            output_prefixes=output_prefixes,
             vect_field=self.vect_field,
             context_vect_field=self.context_vect_field,
             wrapper_output_prefix=wrapper_output_prefix,
-            n_svd_dims=n_svd_dims, snip_first_dim=snip_first_dim, n_clusters=n_clusters, cluster_on=cluster_on,
-            random_state=random_state, cluster_random_state=cluster_random_state)
-        
-        
+            n_svd_dims=n_svd_dims,
+            snip_first_dim=snip_first_dim,
+            n_clusters=n_clusters,
+            cluster_on=cluster_on,
+            random_state=random_state,
+            cluster_random_state=cluster_random_state,
+        )
+
         self.tfidf_model = ColNormedTfidfTransformer(
-            input_field=self.text_field,
-            output_field=self.vect_field, **self.tfidf_params
+            input_field=self.text_field, output_field=self.vect_field, **self.tfidf_params
         )
         if not share_tfidf_models:
             self.context_tfidf_model = ColNormedTfidfTransformer(
                 input_field=self.context_text_field,
                 output_field=self.context_vect_field,
                 **self.context_tfidf_params
             )
         else:
             self.context_tfidf_model = self.tfidf_model
-        
-        
+
     def fit(self, corpus, y=None, selector=lambda x: True, context_selector=lambda x: True):
         """
         Fits the model over training data.
 
         :param corpus: Corpus containing training data
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances will be considered in the fit step. defaults to using all utterances, subject to `min_terms` parameter passed at initialization.
         :param context_selector: a boolean function of signature `filter(utterance)` that determines which context-utterances will be considered in the fit step. defaults to using all utterances, subject to `context_min_terms` parameter passed at initialization.
@@ -360,49 +395,53 @@
         """
         self.text_pipe.fit_transform(corpus)
         if not self.share_tfidf_models:
             self.context_text_pipe.fit_transform(corpus)
         self.tfidf_model.fit_transform(corpus, selector=selector)
         if not self.share_tfidf_models:
             self.context_tfidf_model.fit_transform(corpus, selector=context_selector)
-        self.dualmodel.fit(corpus, 
+        self.dualmodel.fit(
+            corpus,
             selector=lambda x: selector(x)
-             and (x.meta.get(self.vect_field + '__n_feats',0) >= self.min_terms),
+            and (x.meta.get(self.vect_field + "__n_feats", 0) >= self.min_terms),
             context_selector=lambda x: context_selector(x)
-             and (x.meta.get(self.context_vect_field + '__n_feats',0) >= self.context_min_terms))
-    
+            and (x.meta.get(self.context_vect_field + "__n_feats", 0) >= self.context_min_terms),
+        )
+
     def transform(self, corpus, y=None, selector=lambda x: True):
         """
-        Computes vector representations, and statistics for utterances in a corpus, using the `DualContextWrapper` component. 
+        Computes vector representations, and statistics for utterances in a corpus, using the `DualContextWrapper` component.
 
         :param corpus: Corpus
         :param selector: a boolean function of signature `filter(utterance)` that determines which utterances to transform. defaults to all utterances.
         :return: the Corpus, with per-utterance attributes.
         """
         _ = self.text_pipe.transform(corpus)
         _ = self.tfidf_model.transform(corpus, selector=selector)
-        _ = self.dualmodel.transform(corpus, 
-            selector=lambda x: selector(x) 
-            and (x.meta.get(self.vect_field + '__n_feats',0) >= self.min_terms))
+        _ = self.dualmodel.transform(
+            corpus,
+            selector=lambda x: selector(x)
+            and (x.meta.get(self.vect_field + "__n_feats", 0) >= self.min_terms),
+        )
         return corpus
-    
+
     def transform_utterance(self, utt):
         """
-        Computes representations and statistics for a single utterance, which can be a ConvoKit Utterance or a string. 
+        Computes representations and statistics for a single utterance, which can be a ConvoKit Utterance or a string.
         Will return an Utterance object a nd write all of these characterizations (including vectors) to the utterance's metadata; attribute names are prefixed with the `output_prefix` constructor argument.
 
         :param utt: Utterance or string
         :return: the utterance, with per-utterance representation, range and cluster assignments.
         """
         if isinstance(utt, str):
-            utt = Utterance(text=utt, speaker=Speaker()) 
+            utt = Utterance(text=utt, speaker=Speaker())
         self.text_pipe.transform_utterance(utt)
         self.tfidf_model.transform_utterance(utt)
         return self.dualmodel.transform_utterance(utt)
-    
+
     def summarize(self, k=10, max_chars=1000, corpus=None):
         """
         Prints inferred clusters and statistics about their sizes, for each component in the underlying `DualContextWrapper`.
 
         :param k: number of examples to print out.
         :param max_chars: maximum number of characters per utterance/context-utterance to print. Can be toggled to control the size of the output.
         :param corpus: optional, the corpus that the transformer was trained on. if set, will print example utterances and context-utterances as well as terms.
@@ -432,31 +471,31 @@
         Loads a model from disk.
 
         :param dirname: directory to read model from
         :param model_dirs: optional list containing the directories (relative to `dirname`) in which each component is stored. the order of the list is as follows: [the `DualContextWrapper` components, the utterance `ColNormedTfidfTransformer`, the context-utterance `ColNormedTfidfTransformer` (if `share_tfidf_models` is set to `False` at initialization)]. defaults to `[output_prefixes[0], output_prefixes[1], 'tfidf_model', 'context_tfidf_model']` where `output_prefixes` is passed at initialization.
         :return: None
         """
         if model_dirs is None:
-            model_dirs = self.dualmodel.output_prefixes + ['tfidf_model', 'context_tfidf_model']
-        
+            model_dirs = self.dualmodel.output_prefixes + ["tfidf_model", "context_tfidf_model"]
+
         self.tfidf_model.load(os.path.join(dirname, model_dirs[2]))
         if not self.share_tfidf_models:
             self.context_tfidf_model.load(os.path.join(dirname, model_dirs[3]))
         else:
             self.context_tfidf_model = self.tfidf_model
         self.dualmodel.load(dirname, model_dirs[:2])
-    
+
     def dump(self, dirname):
         """
         Writes a model to disk.
 
         :param dirname: directory to write model to.
         :return: None
         """
         self.dualmodel.dump(dirname)
         try:
-            os.mkdir(os.path.join(dirname, 'tfidf_model'))
+            os.mkdir(os.path.join(dirname, "tfidf_model"))
         except:
             pass
-        self.tfidf_model.dump(os.path.join(dirname, 'tfidf_model'))
+        self.tfidf_model.dump(os.path.join(dirname, "tfidf_model"))
         if not self.share_tfidf_models:
-            self.context_tfidf_model.dump(os.path.join(dirname, 'context_tfidf_model'))
+            self.context_tfidf_model.dump(os.path.join(dirname, "context_tfidf_model"))
```

### Comparing `convokit-2.5.3/convokit/fighting_words/fightingWords.py` & `convokit-3.0.0/convokit/fighting_words/fightingWords.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,37 +1,41 @@
+import warnings
+from collections import defaultdict
+from typing import List, Callable, Tuple
+
 import numpy as np
+import pandas as pd
+from cleantext import clean
+from matplotlib import pyplot as plt
 from sklearn.feature_extraction.text import CountVectorizer as CV
+
 from convokit import Transformer
 from convokit.model import Corpus, CorpusComponent
-from typing import List, Callable, Tuple
-from matplotlib import pyplot as plt
-import pandas as pd
-from cleantext import clean
-from collections import defaultdict
 
-clean_str = lambda s: clean(s,
-                            fix_unicode=True,               # fix various unicode errors
-                            to_ascii=True,                  # transliterate to closest ASCII representation
-                            lower=True,                     # lowercase text
-                            no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them
-                            no_urls=True,                  # replace all URLs with a special token
-                            no_emails=True,                # replace all email addresses with a special token
-                            no_phone_numbers=True,         # replace all phone numbers with a special token
-                            no_numbers=False,               # replace all numbers with a special token
-                            no_digits=False,                # replace all digits with a special token
-                            no_currency_symbols=True,      # replace all currency symbols with a special token
-                            no_punct=False,                 # fully remove punctuation
-                            replace_with_url="<URL>",
-                            replace_with_email="<EMAIL>",
-                            replace_with_phone_number="<PHONE>",
-                            replace_with_number="<NUMBER>",
-                            replace_with_digit="0",
-                            replace_with_currency_symbol="<CUR>",
-                            lang="en"
-                            )
+clean_str = lambda s: clean(
+    s,
+    fix_unicode=True,  # fix various unicode errors
+    to_ascii=True,  # transliterate to closest ASCII representation
+    lower=True,  # lowercase text
+    no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them
+    no_urls=True,  # replace all URLs with a special token
+    no_emails=True,  # replace all email addresses with a special token
+    no_phone_numbers=True,  # replace all phone numbers with a special token
+    no_numbers=False,  # replace all numbers with a special token
+    no_digits=False,  # replace all digits with a special token
+    no_currency_symbols=True,  # replace all currency symbols with a special token
+    no_punct=False,  # fully remove punctuation
+    replace_with_url="<URL>",
+    replace_with_email="<EMAIL>",
+    replace_with_phone_number="<PHONE>",
+    replace_with_number="<NUMBER>",
+    replace_with_digit="0",
+    replace_with_currency_symbol="<CUR>",
+    lang="en",
+)
 
 
 class FightingWords(Transformer):
     """
     Based on Monroe et al.'s "Fightin’ Words: Lexical Feature Selection and Evaluation for Identifying the Content of
     Political Conflict"
 
@@ -61,52 +65,70 @@
         Default is 'fighting_words_class1'.
     :param class2_attribute_name: metadata attribute name to store class2 ngrams under during the `transform()` step.
         Default is 'fighting_words_class2'.
 
     :ivar cv: modifiable countvectorizer
 
     """
-    def __init__(self, obj_type="utterance", text_func=None, cv=None, ngram_range=None, prior=0.1,
-                 class1_attribute_name='fighting_words_class1', class2_attribute_name='fighting_words_class2'):
+
+    def __init__(
+        self,
+        obj_type="utterance",
+        text_func=None,
+        cv=None,
+        ngram_range=None,
+        prior=0.1,
+        class1_attribute_name="fighting_words_class1",
+        class2_attribute_name="fighting_words_class2",
+    ):
         assert obj_type in ["speaker", "utterance", "conversation"]
         self.obj_type = obj_type
 
         if text_func is None:
-            if obj_type == 'utterance':
+            if obj_type == "utterance":
                 self.text_func = lambda utt: FightingWords.clean_text(utt.text)
-            elif obj_type == 'conversation':
-                self.text_func = lambda convo: \
-                    FightingWords.clean_text(' '.join([utt.text for utt in convo.iter_utterances()]))
+            elif obj_type == "conversation":
+                self.text_func = lambda convo: FightingWords.clean_text(
+                    " ".join([utt.text for utt in convo.iter_utterances()])
+                )
             else:
-                self.text_func = lambda spkr: \
-                    FightingWords.clean_text(' '.join([utt.text for utt in spkr.iter_utterances()]))
+                self.text_func = lambda spkr: FightingWords.clean_text(
+                    " ".join([utt.text for utt in spkr.iter_utterances()])
+                )
         else:
             self.text_func = text_func
 
         self.ngram_range = ngram_range
         self.prior = prior
         self.cv = cv
         self.ngram_zscores = None
         self._count_matrix = None
         if self.cv is None and type(self.prior) is not float:
-            raise ValueError("If using a non-uniform prior, you must pass a count vectorizer with "
-                             "the vocabulary parameter set.")
+            raise ValueError(
+                "If using a non-uniform prior, you must pass a count vectorizer with "
+                "the vocabulary parameter set."
+            )
         if self.cv is None:
             print("Initializing default CountVectorizer", end=" ")
             if self.ngram_range is None:
                 self.ngram_range = (1, 3)
             print("with ngram_range {}...".format(self.ngram_range), end=" ")
-            self.cv = CV(decode_error='ignore', min_df=10, max_df=.5, ngram_range=self.ngram_range,
-                         binary=False, max_features=15000)
+            self.cv = CV(
+                decode_error="ignore",
+                min_df=10,
+                max_df=0.5,
+                ngram_range=self.ngram_range,
+                binary=False,
+                max_features=15000,
+            )
             print("Done.")
 
         self.class1_attribute_name = class1_attribute_name
         self.class2_attribute_name = class2_attribute_name
 
-
     @staticmethod
     def clean_text(in_string):
         """
         Cleans the text using Python clean-text package: fixes unicode, transliterates all characters to closest ASCII, lowercases text, removes line breaks and punctuation, replaces (urls, emails, phone numbers, numbers, currency) with corresponding <TOKEN>
 
         :param in_string: input string
         :return: cleaned string
@@ -121,105 +143,130 @@
         Returns:
         - A dict of length |Vocab| with (n-gram, zscore) pairs.
         """
 
         class1 = [self.text_func(obj) for obj in class1]
         class2 = [self.text_func(obj) for obj in class2]
 
-        counts_mat = self.cv.fit_transform(class1+class2).toarray()
+        counts_mat = self.cv.fit_transform(class1 + class2).toarray()
         # Now sum over languages...
         vocab_size = len(self.cv.vocabulary_)
         print("Vocab size is {}".format(vocab_size))
         if type(self.prior) is float:
             priors = np.array([self.prior for _ in range(vocab_size)])
         else:
             priors = self.prior
         z_scores = np.empty(priors.shape[0])
         count_matrix = np.empty([2, vocab_size], dtype=np.float32)
-        count_matrix[0, :] = np.sum(counts_mat[:len(class1), :], axis=0)
-        count_matrix[1, :] = np.sum(counts_mat[len(class1):, :], axis=0)
+        count_matrix[0, :] = np.sum(counts_mat[: len(class1), :], axis=0)
+        count_matrix[1, :] = np.sum(counts_mat[len(class1) :, :], axis=0)
         self._count_matrix = count_matrix
         a0 = np.sum(priors)
-        n1 = 1.*np.sum(count_matrix[0, :])
-        n2 = 1.*np.sum(count_matrix[1, :])
+        n1 = 1.0 * np.sum(count_matrix[0, :])
+        n2 = 1.0 * np.sum(count_matrix[1, :])
         print("Comparing language...")
         for i in range(vocab_size):
-            #compute delta
-            term1 = np.log((count_matrix[0, i] + priors[i])/(n1 + a0 - count_matrix[0, i] - priors[i]))
-            term2 = np.log((count_matrix[1, i] + priors[i])/(n2 + a0 - count_matrix[1, i] - priors[i]))
+            # compute delta
+            term1 = np.log(
+                (count_matrix[0, i] + priors[i]) / (n1 + a0 - count_matrix[0, i] - priors[i])
+            )
+            term2 = np.log(
+                (count_matrix[1, i] + priors[i]) / (n2 + a0 - count_matrix[1, i] - priors[i])
+            )
             delta = term1 - term2
-            #compute variance on delta
-            var = 1./(count_matrix[0, i] + priors[i]) + 1./(count_matrix[1, i] + priors[i])
-            #store final score
-            z_scores[i] = delta/np.sqrt(var)
+            # compute variance on delta
+            var = 1.0 / (count_matrix[0, i] + priors[i]) + 1.0 / (count_matrix[1, i] + priors[i])
+            # store final score
+            z_scores[i] = delta / np.sqrt(var)
         index_to_term = {v: k for k, v in self.cv.vocabulary_.items()}
         sorted_indices = np.argsort(z_scores)
         return {index_to_term[i]: z_scores[i] for i in sorted_indices}
 
-    def fit(self, corpus: Corpus, class1_func: Callable[[CorpusComponent], bool],
-            class2_func: Callable[[CorpusComponent], bool], y=None,
-            selector: Callable[[CorpusComponent], bool] = lambda utt: True):
+    def fit(
+        self,
+        corpus: Corpus,
+        class1_func: Callable[[CorpusComponent], bool],
+        class2_func: Callable[[CorpusComponent], bool],
+        y=None,
+        selector: Callable[[CorpusComponent], bool] = lambda utt: True,
+    ):
         """
         Learn the fighting words from a corpus, with an optional selector that selects for corpus components prior to
-            grouping the corpus components into class1 / class2.
+            grouping the corpus components into `class1` / `class2`.
+
+        A warning will be printed if there are components that appear in both `class1` and `class2`, as FightingWords
+            is typically used for disjoint sets of texts.
 
         :param corpus: target Corpus
         :param class1_func: selector function for identifying corpus components that belong to class 1
         :param class2_func: selector function for identifying corpus components that belong to class 2
         :param selector: a (lambda) function that takes a CorpusComponent and returns True/False; this selects for
             Corpus components that should be considered in this fitting step
         :return: fitted FightingWords Transformer
 
         """
         class1, class2 = [], []
         for obj in corpus.iter_objs(self.obj_type, selector):
             if class1_func(obj):
                 class1.append(obj)
-            elif class2_func(obj):
+            if class2_func(obj):
                 class2.append(obj)
 
         if len(class1) == 0:
             raise ValueError("class1_func returned 0 valid corpus components.")
         if len(class2) == 0:
             raise ValueError("class2_func returned 0 valid corpus components.")
 
-        print("class1_func returned {} valid corpus components. "
-              "class2_func returned {} valid corpus components.".format(len(class1), len(class2)))
+        overlaps_found = set([obj.id for obj in class1]) & set([obj.id for obj in class2])
+        if len(overlaps_found):
+            warnings.warn(
+                "There are components that appear in both classes. "
+                "Note that FightingWords is typically used to compare two disjoint sets of texts."
+            )
+
+        print(
+            f"class1_func returned {len(class1)} valid corpus components. "
+            f"class2_func returned {len(class2)} valid corpus components."
+        )
 
         self.ngram_zscores = self._bayes_compare_language(class1, class2)
         print("ngram zscores computed.")
         return self
 
-    def get_ngram_zscores(self, class1_name='class1', class2_name='class2'):
+    def get_ngram_zscores(self, class1_name="class1", class2_name="class2"):
         """
         Get a DataFrame of ngrams and their corresponding zscores and class labels.
 
         :param class1_name: readable name for objects in class1
         :param class2_name: readable name for objects in class2
         :return: a DataFrame of ngrams with zscores and classes, indexed by the ngrams
         """
 
         if self.ngram_zscores is None:
             raise ValueError("fit() must be run on a corpus first.")
-        df = pd.DataFrame(list(self.ngram_zscores.items()), columns=['ngram', 'z-score']).set_index('ngram')
-        df['class'] = (df['z-score'] >= 0).apply(lambda x: [class2_name, class1_name][int(x)])
+        df = pd.DataFrame(list(self.ngram_zscores.items()), columns=["ngram", "z-score"]).set_index(
+            "ngram"
+        )
+        df["class"] = (df["z-score"] >= 0).apply(lambda x: [class2_name, class1_name][int(x)])
         return df
 
     def get_top_k_ngrams(self, top_k: int = 10) -> Tuple[List[str], List[str]]:
         """
         Returns the (ordered) top k ngrams for both classes.
 
         :param top_k: by default, k = 10
         :return: two ordered lists of ngrams (with descending z-score): first list is for class 1,
             second list is for class 2.
         """
         if self.ngram_zscores is None:
             raise ValueError("fit() must be run on a corpus first.")
 
-        ngram_zscores_list = list(zip(self.get_ngram_zscores().index, self.get_ngram_zscores()['z-score']))
+        ngram_zscores_list = list(
+            zip(self.get_ngram_zscores().index, self.get_ngram_zscores()["z-score"])
+        )
         top_k_class1 = list(reversed([x[0] for x in ngram_zscores_list[-top_k:]]))
         top_k_class2 = [x[0] for x in ngram_zscores_list[:top_k]]
         return top_k_class1, top_k_class2
 
     def get_ngrams_past_threshold(self, threshold: float = 1.0) -> Tuple[List[str], List[str]]:
         """
         Returns the (ordered) ngrams that have absolute z-scores that exceed a specified threshold, for both classes
@@ -236,16 +283,20 @@
         for ngram, zscore in self.ngram_zscores.items():
             if zscore > threshold:
                 class1_ngrams.append(ngram)
             elif zscore < -threshold:
                 class2_ngrams.append(ngram)
         return class1_ngrams[::-1], class2_ngrams
 
-    def transform(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True,
-                  config=None) -> Corpus:
+    def transform(
+        self,
+        corpus: Corpus,
+        selector: Callable[[CorpusComponent], bool] = lambda x: True,
+        config=None,
+    ) -> Corpus:
         """
         Annotates the corpus component objects with the lists of fighting words that the object contains.
 
         The relevant fighting words to use are specified by the config parameter. By default, the annotation method
         is to annotate the corpus components with the top 10 fighting words of each class.
 
         Lists are stored under the metadata attributes defined when initializing the FightingWords Transformer.
@@ -256,36 +307,45 @@
         :param config: a dictionary of configuration parameters for setting which fighting words are significant enough
             to annotate. The dictionary should hold the keys: annot_method ('top_k' or 'threshold'), and either
             'threshold' (a float for the min absolute z-score to be considered significant) or 'top_k' (an int to set
             the value of k). By default, config is {'annot_method': 'top_k', 'top_k': 10}.
 
         :return: annotated corpus
         """
-        config = {'top_k': 10, 'annot_method': 'top_k'} if config is None else config
+        config = {"top_k": 10, "annot_method": "top_k"} if config is None else config
 
-        class1_ngrams, class2_ngrams = self.get_top_k_ngrams(top_k=config['top_k']) if \
-            config['annot_method'] == "top_k" else self.get_ngrams_past_threshold(threshold=config['threshold'])
-
-        for obj in corpus.iter_objs(self.obj_type): # improve the efficiency of this; tricky because ngrams #TODO
+        class1_ngrams, class2_ngrams = (
+            self.get_top_k_ngrams(top_k=config["top_k"])
+            if config["annot_method"] == "top_k"
+            else self.get_ngrams_past_threshold(threshold=config["threshold"])
+        )
+
+        for obj in corpus.iter_objs(
+            self.obj_type
+        ):  # improve the efficiency of this; tricky because ngrams #TODO
             if selector(obj):
                 obj_text = self.text_func(obj)
-                obj.meta[self.class1_attribute_name] = [ngram for ngram in class1_ngrams if ngram in obj_text]
-                obj.meta[self.class2_attribute_name] = [ngram for ngram in class2_ngrams if ngram in obj_text]
+                obj.meta[self.class1_attribute_name] = [
+                    ngram for ngram in class1_ngrams if ngram in obj_text
+                ]
+                obj.meta[self.class2_attribute_name] = [
+                    ngram for ngram in class2_ngrams if ngram in obj_text
+                ]
             else:
                 obj.meta[self.class1_attribute_name] = None
                 obj.meta[self.class2_attribute_name] = None
 
         return corpus
 
     def get_zscore(self, ngram):
         """
         Get z-score of a given ngram.
 
         :param ngram: ngram of interest
-        :return: z-score value, None if zgram not in vocabulary
+        :return: z-score value, None if ngram not in vocabulary
         """
         if self.ngram_zscores is None:
             raise ValueError("fit() must be run on a corpus first.")
         return self.ngram_zscores.get(ngram, None)
 
     def get_class(self, ngram):
         """
@@ -294,36 +354,41 @@
         :param ngram: ngram of interest
         :return: "class1" if the ngram has non-negative z-score, "class2" if ngram has positive z-score, None if
             ngram not in vocabulary
         """
         if self.ngram_zscores is None:
             raise ValueError("fit() must be run on a corpus first.")
         zscore = self.ngram_zscores.get(ngram, None)
-        if zscore is None: return zscore
+        if zscore is None:
+            return zscore
         if zscore >= 0:
             return "class1"
         else:
             return "class2"
 
-    def summarize(self, corpus: Corpus, plot: bool = False, class1_name='class1', class2_name='class2'):
+    def summarize(
+        self, corpus: Corpus, plot: bool = False, class1_name="class1", class2_name="class2"
+    ):
         """
         Returns a DataFrame of ngram with zscores and classes, and optionally plots the fighting words distribution.
         FightingWords Transformer must be fitted prior to running this.
 
         :param corpus: corpus to learn fighting words from if not already fitted
         :param plot: if True, generates a plot for the fighting words distribution
         :param class1_name: descriptive name for class1 corpus component objects
         :param class2_name: descriptive name for class2 corpus component objects
         :return: DataFrame of ngrams with zscores and classes, indexed by the ngrams (plot is optionally generated)
         """
         if plot:
             self.plot_fighting_words(class1_name=class1_name, class2_name=class2_name)
         return self.get_ngram_zscores(class1_name=class1_name, class2_name=class2_name)
 
-    def plot_fighting_words(self, max_label_size=15, class1_name='class1', class2_name='class2', config=None):
+    def plot_fighting_words(
+        self, max_label_size=15, class1_name="class1", class2_name="class2", config=None
+    ):
         """
         Plots the distribution of fighting words.
 
         Adapted from Xanda Schofield's https://gist.github.com/xandaschofield/3c4070b2f232b185ce6a09e47b4e7473
 
         Specifically, the weighted log-odds ratio is plotted against frequency of word within topic.
 
@@ -337,75 +402,75 @@
         :param class2_name: descriptive name for class2 corpus component objects
         :param config: a dictionary of configuration parameters for setting which fighting words are significant enough
             to annotate. The dictionary should hold the keys: annot_method ('top_k' or 'threshold'), and either
             'threshold' (a float for the min absolute z-score to be considered significant) or 'top_k' (an int to set
             the value of k). By default, config is {'annot_method': 'top_k', 'top_k': 10}.
         :return: None (plot is generated)
         """
-        config = {'top_k': 10, 'annot_method': 'top_k'} if config is None else config
+        config = {"top_k": 10, "annot_method": "top_k"} if config is None else config
 
         if self.ngram_zscores is None:
             raise ValueError("fit() must be run on a corpus first.")
 
         x_vals = self._count_matrix.sum(axis=0)
-        y_vals = list(self.get_ngram_zscores()['z-score'])
+        y_vals = list(self.get_ngram_zscores()["z-score"])
         sizes = abs(np.array(y_vals))
         scale_factor = max_label_size / max(sizes)
         sizes *= scale_factor
-        neg_color, pos_color, insig_color = ('orange', 'purple', 'grey')
+        neg_color, pos_color, insig_color = ("orange", "purple", "grey")
         annots = []
 
-        class1_sig_ngrams, class2_sig_ngrams = self.get_top_k_ngrams(top_k=config['top_k']) \
-            if config['annot_method'] == "top_k" else self.get_ngrams_past_threshold(threshold=config['threshold'])
+        class1_sig_ngrams, class2_sig_ngrams = (
+            self.get_top_k_ngrams(top_k=config["top_k"])
+            if config["annot_method"] == "top_k"
+            else self.get_ngrams_past_threshold(threshold=config["threshold"])
+        )
         class1_sig_ngrams = set(class1_sig_ngrams)
         class2_sig_ngrams = set(class2_sig_ngrams)
 
         terms = list(self.get_ngram_zscores().index)
 
         class1, class2, class_insig = defaultdict(list), defaultdict(list), defaultdict(list)
 
         for i in range(len(terms)):
             if terms[i] in class1_sig_ngrams:
-                class1['x'].append(x_vals[i])
-                class1['y'].append(y_vals[i])
-                class1['size'].append(sizes[i])
+                class1["x"].append(x_vals[i])
+                class1["y"].append(y_vals[i])
+                class1["size"].append(sizes[i])
                 annots.append(terms[i])
             elif terms[i] in class2_sig_ngrams:
-                class2['x'].append(x_vals[i])
-                class2['y'].append(y_vals[i])
-                class2['size'].append(sizes[i])
+                class2["x"].append(x_vals[i])
+                class2["y"].append(y_vals[i])
+                class2["size"].append(sizes[i])
                 annots.append(terms[i])
             else:
-                class_insig['x'].append(x_vals[i])
-                class_insig['y'].append(y_vals[i])
-                class_insig['size'].append(sizes[i])
+                class_insig["x"].append(x_vals[i])
+                class_insig["y"].append(y_vals[i])
+                class_insig["size"].append(sizes[i])
                 annots.append(None)
 
-
         fig, ax = plt.subplots(figsize=(9, 6), dpi=200)
 
-        ax.scatter(class1['x'], class1['y'], c=pos_color, s=class1['size'], label=class1_name)
-        ax.scatter(class2['x'], class2['y'], c=neg_color, s=class2['size'], label=class2_name)
-        ax.scatter(class_insig['x'], class_insig['y'], c=insig_color, s=class_insig['size'])
+        ax.scatter(class1["x"], class1["y"], c=pos_color, s=class1["size"], label=class1_name)
+        ax.scatter(class2["x"], class2["y"], c=neg_color, s=class2["size"], label=class2_name)
+        ax.scatter(class_insig["x"], class_insig["y"], c=insig_color, s=class_insig["size"])
 
         for i, annot in enumerate(annots):
             if annot is not None:
                 ax.annotate(annot, (x_vals[i], y_vals[i]))
 
         ax.legend()
-        ax.set_xscale('log')
+        ax.set_xscale("log")
         ax.set_title("Weighted log-odds ratio vs. Frequency of word within class")
         plt.show()
 
     def get_model(self):
         """
         Get the FightingWords CountVectorizer model
         """
         return self.cv
 
     def set_model(self, cv):
         """
         Set the FightingWords CountVectorizer model
         """
         self.cv = cv
-
-
```

### Comparing `convokit-2.5.3/convokit/forecaster/CRAFT/CRAFTNN.py` & `convokit-3.0.0/convokit/forecaster/CRAFT/CRAFTNN.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,71 +1,88 @@
 try:
     import torch
 except (ModuleNotFoundError, ImportError) as e:
-    raise ModuleNotFoundError("torch is not currently installed. Run 'pip install convokit[craft]' if you would like to use the CRAFT model.")
+    raise ModuleNotFoundError(
+        "torch is not currently installed. Run 'pip install convokit[craft]' if you would like to use the CRAFT model."
+    )
 
 from torch import nn
 import os
 from urllib.request import urlretrieve
 from .CRAFTUtil import CONSTANTS
 
+
 class EncoderRNN(nn.Module):
     """
     This module represents the utterance encoder component of CRAFT,
     responsible for creating vector representations of utterances
     """
+
     def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):
         super(EncoderRNN, self).__init__()
         self.n_layers = n_layers
         self.hidden_size = hidden_size
         self.embedding = embedding
 
         # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'
         #   because our input size is a word embedding with number of features == hidden_size
-        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,
-                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)
+        self.gru = nn.GRU(
+            hidden_size,
+            hidden_size,
+            n_layers,
+            dropout=(0 if n_layers == 1 else dropout),
+            bidirectional=True,
+        )
 
     def forward(self, input_seq, input_lengths, hidden=None):
         # Convert word indexes to embeddings
         embedded = self.embedding(input_seq)
         # Pack padded batch of sequences for RNN module
         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)
         # Forward pass through GRU
         outputs, hidden = self.gru(packed, hidden)
         # Unpack padding
         outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)
         # Sum bidirectional GRU outputs
-        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]
+        outputs = outputs[:, :, : self.hidden_size] + outputs[:, :, self.hidden_size :]
         # Return output and final hidden state
         return outputs, hidden
 
+
 class ContextEncoderRNN(nn.Module):
     """This module represents the context encoder component of CRAFT, responsible for creating an order-sensitive vector representation of conversation context"""
+
     def __init__(self, hidden_size, n_layers=1, dropout=0):
         super(ContextEncoderRNN, self).__init__()
         self.n_layers = n_layers
         self.hidden_size = hidden_size
 
         # only unidirectional GRU for context encoding
-        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,
-                          dropout=(0 if n_layers == 1 else dropout), bidirectional=False)
+        self.gru = nn.GRU(
+            hidden_size,
+            hidden_size,
+            n_layers,
+            dropout=(0 if n_layers == 1 else dropout),
+            bidirectional=False,
+        )
 
     def forward(self, input_seq, input_lengths, hidden=None):
         # Pack padded batch of sequences for RNN module
         packed = torch.nn.utils.rnn.pack_padded_sequence(input_seq, input_lengths)
         # Forward pass through GRU
         outputs, hidden = self.gru(packed, hidden)
         # Unpack padding
         outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)
         # return output and final hidden state
         return outputs, hidden
 
 
 class SingleTargetClf(nn.Module):
     """This module represents the CRAFT classifier head, which takes the context encoding and uses it to make a forecast"""
+
     def __init__(self, hidden_size, dropout=0.1):
         super(SingleTargetClf, self).__init__()
 
         self.hidden_size = hidden_size
 
         # initialize classifier
         self.layer1 = nn.Linear(hidden_size, hidden_size)
@@ -82,54 +99,72 @@
         # (batch_size) -> (1, batch_size, 1)
         lengths = encoder_input_lengths.unsqueeze(0).unsqueeze(2)
         # Then we expand it accordingly
         # (1, batch_size, 1) -> (1, batch_size, hidden_size)
         lengths = lengths.expand((1, -1, encoder_outputs.size(2)))
 
         # take only the last state of the encoder for each batch
-        last_outputs = torch.gather(encoder_outputs, 0, lengths-1).squeeze(dim=0)
+        last_outputs = torch.gather(encoder_outputs, 0, lengths - 1).squeeze(dim=0)
         # forward pass through hidden layers
         layer1_out = self.layer1_act(self.layer1(self.dropout(last_outputs)))
         layer2_out = self.layer2_act(self.layer2(self.dropout(layer1_out)))
         # compute and return logits
         logits = self.clf(self.dropout(layer2_out)).squeeze(dim=1)
         return logits
 
 
 class Predictor(nn.Module):
     """This helper module encapsulates the CRAFT pipeline, defining the logic of passing an input through each consecutive sub-module."""
+
     def __init__(self, encoder, context_encoder, classifier):
         super(Predictor, self).__init__()
         self.encoder = encoder
         self.context_encoder = context_encoder
         self.classifier = classifier
 
-    def forward(self, input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length):
+    def forward(
+        self,
+        input_batch,
+        dialog_lengths,
+        dialog_lengths_list,
+        utt_lengths,
+        batch_indices,
+        dialog_indices,
+        batch_size,
+        max_length,
+    ):
         # Forward input through encoder model
         _, utt_encoder_hidden = self.encoder(input_batch, utt_lengths)
 
         # Convert utterance encoder final states to batched dialogs for use by context encoder
-        context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)
+        context_encoder_input = makeContextEncoderInput(
+            utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices
+        )
 
         # Forward pass through context encoder
-        context_encoder_outputs, context_encoder_hidden = self.context_encoder(context_encoder_input, dialog_lengths)
+        context_encoder_outputs, context_encoder_hidden = self.context_encoder(
+            context_encoder_input, dialog_lengths
+        )
 
         # Forward pass through classifier to get prediction logits
         logits = self.classifier(context_encoder_outputs, dialog_lengths)
 
         # Apply sigmoid activation
         predictions = torch.sigmoid(logits)
         return predictions
 
-def makeContextEncoderInput(utt_encoder_hidden, dialog_lengths, batch_size, batch_indices, dialog_indices):
+
+def makeContextEncoderInput(
+    utt_encoder_hidden, dialog_lengths, batch_size, batch_indices, dialog_indices
+):
     """The utterance encoder takes in utterances in combined batches, with no knowledge of which ones go where in which conversation.
-       Its output is therefore also unordered. We correct this by using the information computed during tensor conversion to regroup
-       the utterance vectors into their proper conversational order."""
+    Its output is therefore also unordered. We correct this by using the information computed during tensor conversion to regroup
+    the utterance vectors into their proper conversational order."""
     # first, sum the forward and backward encoder states
-    utt_encoder_summed = utt_encoder_hidden[-2,:,:] + utt_encoder_hidden[-1,:,:]
+    utt_encoder_summed = utt_encoder_hidden[-2, :, :] + utt_encoder_hidden[-1, :, :]
     # we now have hidden state of shape [utterance_batch_size, hidden_size]
     # split it into a list of [hidden_size,] x utterance_batch_size
     last_states = [t.squeeze() for t in utt_encoder_summed.split(1, dim=0)]
 
     # create a placeholder list of tensors to group the states by source dialog
     states_dialog_batched = [[None for _ in range(dialog_lengths[i])] for i in range(batch_size)]
 
@@ -140,57 +175,67 @@
     # stack each dialog into a tensor of shape [dialog_length, hidden_size]
     states_dialog_batched = [torch.stack(d) for d in states_dialog_batched]
 
     # finally, condense all the dialog tensors into a single zero-padded tensor
     # of shape [max_dialog_length, batch_size, hidden_size]
     return torch.nn.utils.rnn.pad_sequence(states_dialog_batched)
 
-def initialize_model(custom_model_path, voc, device, device_type: str, hidden_size, encoder_n_layers, dropout,
-                     context_encoder_n_layers):
+
+def initialize_model(
+    custom_model_path,
+    voc,
+    device,
+    device_type: str,
+    hidden_size,
+    encoder_n_layers,
+    dropout,
+    context_encoder_n_layers,
+):
     print("Loading saved parameters...")
     if custom_model_path is None:
         if not os.path.isfile("model.tar"):
             print("\tDownloading trained CRAFT...")
-            urlretrieve(CONSTANTS['MODEL_URL'], "model.tar")
+            urlretrieve(CONSTANTS["MODEL_URL"], "model.tar")
             print("\t...Done!")
         custom_model_path = "model.tar"
     # If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.
     # To do so, replace the previous line with the following:
-    if device_type == 'cpu':
-        checkpoint = torch.load(custom_model_path, map_location=torch.device('cpu'))
-    elif device_type == 'cuda':
+    if device_type == "cpu":
+        checkpoint = torch.load(custom_model_path, map_location=torch.device("cpu"))
+    elif device_type == "cuda":
         checkpoint = torch.load(custom_model_path)
-    encoder_sd = checkpoint['en']
-    context_sd = checkpoint['ctx']
-    if 'atk_clf' in checkpoint:
-        attack_clf_sd = checkpoint['atk_clf']
+    encoder_sd = checkpoint["en"]
+    context_sd = checkpoint["ctx"]
+    if "atk_clf" in checkpoint:
+        attack_clf_sd = checkpoint["atk_clf"]
 
-    embedding_sd = checkpoint['embedding']
-    voc.__dict__ = checkpoint['voc_dict']
+    embedding_sd = checkpoint["embedding"]
+    voc.__dict__ = checkpoint["voc_dict"]
 
-    print('Building encoders, decoder, and classifier...')
+    print("Building encoders, decoder, and classifier...")
     # Initialize word embeddings
     embedding = nn.Embedding(voc.num_words, hidden_size)
     embedding.load_state_dict(embedding_sd)
     # Initialize utterance and context encoders
     encoder: EncoderRNN = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)
-    context_encoder: ContextEncoderRNN = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)
+    context_encoder: ContextEncoderRNN = ContextEncoderRNN(
+        hidden_size, context_encoder_n_layers, dropout
+    )
     encoder.load_state_dict(encoder_sd)
     context_encoder.load_state_dict(context_sd)
     # Initialize classifier
     attack_clf: SingleTargetClf = SingleTargetClf(hidden_size, dropout)
-    if 'atk_clf' in checkpoint:
+    if "atk_clf" in checkpoint:
         attack_clf.load_state_dict(attack_clf_sd)
     # Use appropriate device
     encoder = encoder.to(device)
     context_encoder = context_encoder.to(device)
     attack_clf = attack_clf.to(device)
-    print('Models built and ready to go!')
+    print("Models built and ready to go!")
 
     # Set dropout layers to eval mode
     encoder.eval()
     context_encoder.eval()
     attack_clf.eval()
 
     # Initialize the pipeline
     return Predictor(encoder, context_encoder, attack_clf)
-
```

### Comparing `convokit-2.5.3/convokit/forecaster/CRAFT/CRAFTUtil.py` & `convokit-3.0.0/convokit/forecaster/CRAFT/CRAFTUtil.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,52 +1,63 @@
 import requests
 import unicodedata
 import nltk
 import random
 import itertools
+
 try:
     import torch
 except (ModuleNotFoundError, ImportError) as e:
-    raise ModuleNotFoundError("torch is not currently installed. Run 'pip install convokit[craft]' if you would like to use the CRAFT model.")
+    raise ModuleNotFoundError(
+        "torch is not currently installed. Run 'pip install convokit[craft]' if you would like to use the CRAFT model."
+    )
 
 from typing import List, Tuple
 
-CONSTANTS = {'PAD_token': 0,
-             'SOS_token': 1,
-             'EOS_token': 2,
-             'UNK_token': 3,
-             'WORD2INDEX_URL': "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/word2index.json",
-             'INDEX2WORD_URL': "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/index2word.json",
-             'MODEL_URL': "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/craft_full.tar",
-             }
+CONSTANTS = {
+    "PAD_token": 0,
+    "SOS_token": 1,
+    "EOS_token": 2,
+    "UNK_token": 3,
+    "WORD2INDEX_URL": "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/word2index.json",
+    "INDEX2WORD_URL": "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/index2word.json",
+    "MODEL_URL": "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/craft_full.tar",
+}
 
 # Default word tokens
 PAD_token = 0  # Used for padding short sentences
 SOS_token = 1  # Start-of-sentence token
 EOS_token = 2  # End-of-sentence token
 UNK_token = 3  # Unknown word token
 
 # model download paths
 WORD2INDEX_URL = "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/word2index.json"
 INDEX2WORD_URL = "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/index2word.json"
 MODEL_URL = "http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/craft_full.tar"
 
+
 class Voc:
     """A class for representing the vocabulary used by a CRAFT model"""
 
     def __init__(self, name, word2index=None, index2word=None):
         self.name = name
-        self.trimmed = False if not word2index else True # if a precomputed vocab is specified assume the speaker wants to use it as-is
+        self.trimmed = (
+            False if not word2index else True
+        )  # if a precomputed vocab is specified assume the speaker wants to use it as-is
         self.word2index = word2index if word2index else {"UNK": UNK_token}
         self.word2count = {}
-        self.index2word = index2word if index2word else {PAD_token: "PAD", SOS_token: "SOS", EOS_token: "EOS", UNK_token: "UNK"}
+        self.index2word = (
+            index2word
+            if index2word
+            else {PAD_token: "PAD", SOS_token: "SOS", EOS_token: "EOS", UNK_token: "UNK"}
+        )
         self.num_words = 4 if not index2word else len(index2word)  # Count SOS, EOS, PAD, UNK
 
     def addSentence(self, sentence):
-        for word in sentence.split(' '):
+        for word in sentence.split(" "):
             self.addWord(word)
 
     def addWord(self, word):
         if word not in self.word2index:
             self.word2index[word] = self.num_words
             self.word2count[word] = 1
             self.index2word[self.num_words] = word
@@ -62,118 +73,131 @@
 
         keep_words = []
 
         for k, v in self.word2count.items():
             if v >= min_count:
                 keep_words.append(k)
 
-        print('keep_words {} / {} = {:.4f}'.format(
-            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)
-        ))
+        print(
+            "keep_words {} / {} = {:.4f}".format(
+                len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)
+            )
+        )
 
         # Reinitialize dictionaries
         self.word2index = {"UNK": UNK_token}
         self.word2count = {}
         self.index2word = {PAD_token: "PAD", SOS_token: "SOS", EOS_token: "EOS", UNK_token: "UNK"}
-        self.num_words = 4 # Count default tokens
+        self.num_words = 4  # Count default tokens
 
         for word in keep_words:
             self.addWord(word)
 
+
 # Create a Voc object from precomputed data structures
 def loadPrecomputedVoc(corpus_name, word2index_url, index2word_url):
     # load the word-to-index lookup map
     r = requests.get(word2index_url)
     word2index = r.json()
     # load the index-to-word lookup map
     r = requests.get(index2word_url)
     index2word = r.json()
     return Voc(corpus_name, word2index, index2word)
 
+
 # Helper functions for preprocessing and tokenizing text
 
+
 # Turn a Unicode string to plain ASCII, thanks to
 # https://stackoverflow.com/a/518232/2809427
 def unicodeToAscii(s):
-    return ''.join(
-        c for c in unicodedata.normalize('NFD', s)
-        if unicodedata.category(c) != 'Mn'
-    )
+    return "".join(c for c in unicodedata.normalize("NFD", s) if unicodedata.category(c) != "Mn")
+
 
 # Tokenize the string using NLTK
 def craft_tokenize(voc, text):
-    tokenizer = nltk.tokenize.RegexpTokenizer(pattern=r'\w+|[^\w\s]')
+    tokenizer = nltk.tokenize.RegexpTokenizer(pattern=r"\w+|[^\w\s]")
     # simplify the problem space by considering only ASCII data
     cleaned_text = unicodeToAscii(text.lower())
 
     # if the resulting string is empty, nothing else to do
     if not cleaned_text.strip():
         return []
 
     tokens = tokenizer.tokenize(cleaned_text)
     for i in range(len(tokens)):
         if tokens[i] not in voc.word2index:
             tokens[i] = "UNK"
     return tokens
 
+
 # Helper functions for turning dialog and text sequences into tensors, and manipulating those tensors
 
+
 def indexesFromSentence(voc, sentence):
     return [voc.word2index[word] for word in sentence] + [EOS_token]
 
+
 def zeroPadding(l, fillvalue=PAD_token):
     return list(itertools.zip_longest(*l, fillvalue=fillvalue))
 
+
 def binaryMatrix(l):
     m = []
     for i, seq in enumerate(l):
         m.append([])
         for token in seq:
             if token == PAD_token:
                 m[i].append(0)
             else:
                 m[i].append(1)
     return m
 
+
 # Takes a batch of dialogs (lists of lists of tokens) and converts it into a
 # batch of utterances (lists of tokens) sorted by length, while keeping track of
 # the information needed to reconstruct the original batch of dialogs
 def dialogBatch2UtteranceBatch(dialog_batch):
-    utt_tuples = [] # will store tuples of (utterance, original position in batch, original position in dialog)
+    utt_tuples = (
+        []
+    )  # will store tuples of (utterance, original position in batch, original position in dialog)
     for batch_idx in range(len(dialog_batch)):
         dialog = dialog_batch[batch_idx]
         for dialog_idx in range(len(dialog)):
             utterance = dialog[dialog_idx]
             utt_tuples.append((utterance, batch_idx, dialog_idx))
     # sort the utterances in descending order of length, to remain consistent with pytorch padding requirements
     utt_tuples.sort(key=lambda x: len(x[0]), reverse=True)
     # return the utterances, original batch indices, and original dialog indices as separate lists
     utt_batch = [u[0] for u in utt_tuples]
     batch_indices = [u[1] for u in utt_tuples]
     dialog_indices = [u[2] for u in utt_tuples]
     return utt_batch, batch_indices, dialog_indices
 
+
 # Returns padded input sequence tensor and lengths
 def inputVar(l, voc):
     indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]
     lengths = torch.tensor([len(indexes) for indexes in indexes_batch])
     padList = zeroPadding(indexes_batch)
     padVar = torch.LongTensor(padList)
     return padVar, lengths
 
+
 # Returns padded target sequence tensor, padding mask, and max target length
 def outputVar(l, voc):
     indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]
     max_target_len = max([len(indexes) for indexes in indexes_batch])
     padList = zeroPadding(indexes_batch)
     mask = binaryMatrix(padList)
     mask = torch.ByteTensor(mask)
     padVar = torch.LongTensor(padList)
     return padVar, mask, max_target_len
 
+
 # Returns all items for a given batch of pairs
 def batch2TrainData(voc, pair_batch: List[Tuple], already_sorted=False):
     if not already_sorted:
         pair_batch.sort(key=lambda x: len(x[0]), reverse=True)
     input_batch, output_batch, label_batch, id_batch = [], [], [], []
     for pair in pair_batch:
         input_batch.append(pair[0])
@@ -184,31 +208,41 @@
         else:
             id_batch.append(None)
     dialog_lengths = torch.tensor([len(x) for x in input_batch])
     input_utterances, batch_indices, dialog_indices = dialogBatch2UtteranceBatch(input_batch)
     inp, utt_lengths = inputVar(input_utterances, voc)
     output, mask, max_target_len = outputVar(output_batch, voc)
     label_batch = torch.FloatTensor(label_batch) if label_batch[0] is not None else None
-    return inp, dialog_lengths, utt_lengths, batch_indices, dialog_indices, \
-           label_batch, id_batch, output, mask, max_target_len
+    return (
+        inp,
+        dialog_lengths,
+        utt_lengths,
+        batch_indices,
+        dialog_indices,
+        label_batch,
+        id_batch,
+        output,
+        mask,
+        max_target_len,
+    )
+
 
 def batchIterator(voc, source_data, batch_size, shuffle=True):
     cur_idx = 0
     if shuffle:
         random.shuffle(source_data)
     while True:
         if cur_idx >= len(source_data):
             cur_idx = 0
             if shuffle:
                 random.shuffle(source_data)
-        batch = source_data[cur_idx:(cur_idx+batch_size)]
+        batch = source_data[cur_idx : (cur_idx + batch_size)]
         # the true batch size may be smaller than the given batch size if there is not enough data left
         true_batch_size = len(batch)
         # ensure that the dialogs in this batch are sorted by length, as expected by the padding module
         batch.sort(key=lambda x: len(x[0]), reverse=True)
         # for analysis purposes, get the source dialogs and labels associated with this batch
         batch_dialogs = [x[0] for x in batch]
         # convert batch to tensors
         batch_tensors = batch2TrainData(voc, batch, already_sorted=True)
         yield (batch_tensors, batch_dialogs, true_batch_size)
         cur_idx += batch_size
-
```

### Comparing `convokit-2.5.3/convokit/forecaster/CRAFTModel.py` & `convokit-3.0.0/convokit/forecaster/CRAFTModel.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,43 +1,46 @@
 try:
     import torch
 except (ModuleNotFoundError, ImportError) as e:
-    raise ModuleNotFoundError("torch is not currently installed. Run 'pip install convokit[craft]' if you would like to use the CRAFT model.")
+    raise ModuleNotFoundError(
+        "torch is not currently installed. Run 'pip install convokit[craft]' if you would like to use the CRAFT model."
+    )
 
 import pandas as pd
 from convokit.forecaster.CRAFT.CRAFTUtil import loadPrecomputedVoc, batchIterator, CONSTANTS
 from .CRAFT.CRAFTNN import initialize_model, makeContextEncoderInput, Predictor
 from .forecasterModel import ForecasterModel
 import numpy as np
 import torch.nn.functional as F
 from torch import optim
 from sklearn.model_selection import train_test_split
 from typing import Dict
 import os
 
 default_options = {
-    'hidden_size': 500,
-    'encoder_n_layers': 2,
-    'context_encoder_n_layers': 2,
-    'decoder_n_layers': 2,
-    'dropout': 0.1,
-    'batch_size': 64,
-    'clip': 50.0,
-    'learning_rate': 1e-5,
-    'print_every': 10,
-    'train_epochs': 30,
-    'validation_size': 0.2,
-    'max_length': 80,
-    'trained_model_output_filepath': "finetuned_model.tar"
+    "hidden_size": 500,
+    "encoder_n_layers": 2,
+    "context_encoder_n_layers": 2,
+    "decoder_n_layers": 2,
+    "dropout": 0.1,
+    "batch_size": 64,
+    "clip": 50.0,
+    "learning_rate": 1e-5,
+    "print_every": 10,
+    "train_epochs": 30,
+    "validation_size": 0.2,
+    "max_length": 80,
+    "trained_model_output_filepath": "finetuned_model.tar",
 }
 
 # To understand the separation of concerns for the CRAFT files:
 # CRAFT/craftNN.py contains the class implementations needed to initialize the CRAFT Neural Network model
 # CRAFT/craftUtil.py contains utility methods for manipulating the data for it to be passed to the CRAFT model
 
+
 class CRAFTModel(ForecasterModel):
     """
     CRAFTModel is one of the Forecaster models that can be used with the Forecaster Transformer.
 
     By default, CRAFTModel will be initialized with default options
 
     - hidden_size: 500
@@ -56,33 +59,39 @@
     :param device_type: 'cpu' or 'cuda', default: 'cpu'
     :param model_path: filepath to CRAFT model if loading a custom CRAFT model
     :param options: configuration options for the neural network: uses default options otherwise.
     :param forecast_attribute_name: name of DataFrame column containing predictions, default: "prediction"
     :param forecast_prob_attribute_name: name of DataFrame column containing prediction scores, default: "score"
     """
 
-    def __init__(self, device_type: str = 'cpu',
-                 model_path: str = None,
-                 options: Dict = None,
-                 forecast_attribute_name: str = "prediction",
-                 forecast_feat_name=None,
-                 forecast_prob_attribute_name: str = "pred_score",
-                 forecast_prob_feat_name=None):
-
-        super().__init__(forecast_attribute_name=forecast_attribute_name,
-                         forecast_feat_name=forecast_feat_name,
-                         forecast_prob_attribute_name=forecast_prob_attribute_name,
-                         forecast_prob_feat_name=forecast_prob_feat_name)
-        assert device_type in ['cuda', 'cpu']
+    def __init__(
+        self,
+        device_type: str = "cpu",
+        model_path: str = None,
+        options: Dict = None,
+        forecast_attribute_name: str = "prediction",
+        forecast_feat_name=None,
+        forecast_prob_attribute_name: str = "pred_score",
+        forecast_prob_feat_name=None,
+    ):
+        super().__init__(
+            forecast_attribute_name=forecast_attribute_name,
+            forecast_feat_name=forecast_feat_name,
+            forecast_prob_attribute_name=forecast_prob_attribute_name,
+            forecast_prob_feat_name=forecast_prob_feat_name,
+        )
+        assert device_type in ["cuda", "cpu"]
         # device: controls GPU usage: 'cuda' to enable GPU, 'cpu' to run on CPU only.
         self.device = torch.device(device_type)
         self.device_type = device_type
         # voc: the vocabulary object (convokit.forecaster.craftUtil.Voc) used by predictor.
         # Used to convert text data into numerical input for CRAFT.
-        self.voc = loadPrecomputedVoc("wikiconv", CONSTANTS['WORD2INDEX_URL'], CONSTANTS['INDEX2WORD_URL'])
+        self.voc = loadPrecomputedVoc(
+            "wikiconv", CONSTANTS["WORD2INDEX_URL"], CONSTANTS["INDEX2WORD_URL"]
+        )
 
         if options is None:
             self.options = default_options
         else:
             for k, v in default_options.items():
                 if k not in options:
                     options[k] = v
@@ -90,23 +99,36 @@
         print("Initializing CRAFT model with options:")
         print(self.options)
 
         if model_path is not None:
             if not os.path.isfile(model_path) or not model_path.endswith(".tar"):
                 print("Could not find CRAFT model tar file at: {}".format(model_path))
                 model_path = None
-        self.predictor: Predictor = initialize_model(model_path, self.voc, self.device, self.device_type,
-                                                     self.options['hidden_size'],
-                                                     self.options['encoder_n_layers'],
-                                                     self.options['dropout'],
-                                                     self.options['context_encoder_n_layers'])
-
-
-    def _evaluate_batch(self, predictor, input_batch, dialog_lengths,
-                        dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, true_batch_size):
+        self.predictor: Predictor = initialize_model(
+            model_path,
+            self.voc,
+            self.device,
+            self.device_type,
+            self.options["hidden_size"],
+            self.options["encoder_n_layers"],
+            self.options["dropout"],
+            self.options["context_encoder_n_layers"],
+        )
+
+    def _evaluate_batch(
+        self,
+        predictor,
+        input_batch,
+        dialog_lengths,
+        dialog_lengths_list,
+        utt_lengths,
+        batch_indices,
+        dialog_indices,
+        true_batch_size,
+    ):
         """
         Helper for _evaluate_dataset. Runs CRAFT evaluation on a single batch; _evaluate_dataset calls this helper iteratively to get results for the entire dataset.
 
         :param predictor: the trained CRAFT model to use, provided as a PyTorch Model instance.
         :param input_batch: the batch to run CRAFT on (produced by convokit.forecaster.craftUtil.batchIterator, formatted as a batch of utterances)
         :param dialog_lengths: how many comments are in each conversation in this batch, as a PyTorch Tensor
         :param dialog_lengths_list: same as dialog_lengths, but as a Python List
@@ -118,64 +140,109 @@
         :return: per-utterance scores and binarized predictions.
         """
         # Set device options
         input_batch = input_batch.to(self.device)
         dialog_lengths = dialog_lengths.to(self.device)
         utt_lengths = utt_lengths.to(self.device)
         # Predict future attack using predictor
-        scores = predictor(input_batch, dialog_lengths, dialog_lengths_list, utt_lengths,
-                           batch_indices, dialog_indices, true_batch_size, self.options['max_length'])
+        scores = predictor(
+            input_batch,
+            dialog_lengths,
+            dialog_lengths_list,
+            utt_lengths,
+            batch_indices,
+            dialog_indices,
+            true_batch_size,
+            self.options["max_length"],
+        )
         predictions = (scores > 0.5).float()
         return predictions, scores
 
     def _evaluate_dataset(self, predictor, dataset):
         """
         Run a trained CRAFT model over an entire dataset in a batched fashion.
 
         :param predictor: the trained CRAFT model to use, provided as a PyTorch Model instance.
         :param dataset: the dataset to evaluate on, formatted as a list of (context, reply, id_of_reply) tuples.
         :return: a DataFrame, indexed by utterance ID, of CRAFT scores for each utterance, and the corresponding binary prediction.
         """
         # create a batch iterator for the given data
-        batch_iterator = batchIterator(self.voc, dataset, self.options['batch_size'], shuffle=False)
+        batch_iterator = batchIterator(self.voc, dataset, self.options["batch_size"], shuffle=False)
         # find out how many iterations we will need to cover the whole dataset
-        n_iters = len(dataset) // self.options['batch_size'] + int(len(dataset) % self.options['batch_size'] > 0)
+        n_iters = len(dataset) // self.options["batch_size"] + int(
+            len(dataset) % self.options["batch_size"] > 0
+        )
         output_df = {
             "id": [],
             self.forecast_attribute_name: [],
-            self.forecast_prob_attribute_name: []
+            self.forecast_prob_attribute_name: [],
         }
-        for iteration in range(1, n_iters+1):
+        for iteration in range(1, n_iters + 1):
             batch, batch_dialogs, true_batch_size = next(batch_iterator)
             # Extract fields from batch
-            input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, \
-                labels, batch_ids, target_variable, mask, max_target_len = batch
+            (
+                input_variable,
+                dialog_lengths,
+                utt_lengths,
+                batch_indices,
+                dialog_indices,
+                labels,
+                batch_ids,
+                target_variable,
+                mask,
+                max_target_len,
+            ) = batch
             dialog_lengths_list = [len(x) for x in batch_dialogs]
             # run the model
-            predictions, scores = self._evaluate_batch(predictor, input_variable, dialog_lengths, dialog_lengths_list, utt_lengths,
-                                                       batch_indices, dialog_indices, true_batch_size)
+            predictions, scores = self._evaluate_batch(
+                predictor,
+                input_variable,
+                dialog_lengths,
+                dialog_lengths_list,
+                utt_lengths,
+                batch_indices,
+                dialog_indices,
+                true_batch_size,
+            )
 
             # format the output as a dataframe (which we can later re-join with the corpus)
             for i in range(true_batch_size):
                 utt_id = batch_ids[i]
                 pred = predictions[i].item()
                 score = scores[i].item()
                 output_df["id"].append(utt_id)
                 output_df[self.forecast_attribute_name].append(pred)
                 output_df[self.forecast_prob_attribute_name].append(score)
 
-            print("Iteration: {}; Percent complete: {:.1f}%".format(iteration, iteration / n_iters * 100))
+            print(
+                "Iteration: {}; Percent complete: {:.1f}%".format(
+                    iteration, iteration / n_iters * 100
+                )
+            )
 
         return pd.DataFrame(output_df).set_index("id")
 
-    def _train_NN(self, input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments
-              encoder, context_encoder, attack_clf,                                                                    # network arguments
-              encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments
-              batch_size, clip):                                                                # misc arguments
-
+    def _train_NN(
+        self,
+        input_variable,
+        dialog_lengths,
+        dialog_lengths_list,
+        utt_lengths,
+        batch_indices,
+        dialog_indices,
+        labels,  # input/output arguments
+        encoder,
+        context_encoder,
+        attack_clf,  # network arguments
+        encoder_optimizer,
+        context_encoder_optimizer,
+        attack_clf_optimizer,  # optimization arguments
+        batch_size,
+        clip,
+    ):  # misc arguments
         # Zero gradients
         encoder_optimizer.zero_grad()
         context_encoder_optimizer.zero_grad()
         attack_clf_optimizer.zero_grad()
 
         # Set device options
         input_variable = input_variable.to(self.device)
@@ -183,15 +250,17 @@
         utt_lengths = utt_lengths.to(self.device)
         labels = labels.to(self.device)
 
         # Forward pass through utterance encoder
         _, utt_encoder_hidden = encoder(input_variable, utt_lengths)
 
         # Convert utterance encoder final states to batched dialogs for use by context encoder
-        context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)
+        context_encoder_input = makeContextEncoderInput(
+            utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices
+        )
 
         # Forward pass through context encoder
         context_encoder_outputs, _ = context_encoder(context_encoder_input, dialog_lengths)
 
         # Forward pass through classifier to get prediction logits
         logits = attack_clf(context_encoder_outputs, dialog_lengths)
 
@@ -211,72 +280,132 @@
         context_encoder_optimizer.step()
         attack_clf_optimizer.step()
 
         return loss.item()
 
     def _validate(self, predictor, dataset):
         # create a batch iterator for the given data
-        batch_iterator = batchIterator(self.voc, dataset, self.options['batch_size'], shuffle=False)
+        batch_iterator = batchIterator(self.voc, dataset, self.options["batch_size"], shuffle=False)
         # find out how many iterations we will need to cover the whole dataset
-        n_iters = len(dataset) // self.options['batch_size'] + int(len(dataset) % self.options['batch_size'] > 0)
+        n_iters = len(dataset) // self.options["batch_size"] + int(
+            len(dataset) % self.options["batch_size"] > 0
+        )
         # containers for full prediction results so we can compute accuracy at the end
         all_preds = []
         all_labels = []
-        for iteration in range(1, n_iters+1):
+        for iteration in range(1, n_iters + 1):
             batch, batch_dialogs, true_batch_size = next(batch_iterator)
             # Extract fields from batch
-            input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, \
-                batch_labels, batch_ids, target_variable, mask, max_target_len = batch
+            (
+                input_variable,
+                dialog_lengths,
+                utt_lengths,
+                batch_indices,
+                dialog_indices,
+                batch_labels,
+                batch_ids,
+                target_variable,
+                mask,
+                max_target_len,
+            ) = batch
             dialog_lengths_list = [len(x) for x in batch_dialogs]
             # run the model
-            predictions, scores = self._evaluate_batch(predictor, input_variable, dialog_lengths, dialog_lengths_list,
-                                                       utt_lengths, batch_indices, dialog_indices,
-                                                       true_batch_size)
+            predictions, scores = self._evaluate_batch(
+                predictor,
+                input_variable,
+                dialog_lengths,
+                dialog_lengths_list,
+                utt_lengths,
+                batch_indices,
+                dialog_indices,
+                true_batch_size,
+            )
             # aggregate results for computing accuracy at the end
             all_preds += [p.item() for p in predictions]
             all_labels += [l.item() for l in batch_labels]
-            print("Iteration: {}; Percent complete: {:.1f}%".format(iteration, iteration / n_iters * 100))
+            print(
+                "Iteration: {}; Percent complete: {:.1f}%".format(
+                    iteration, iteration / n_iters * 100
+                )
+            )
 
         # compute and return the accuracy
         return (np.asarray(all_preds) == np.asarray(all_labels)).mean()
 
-    def _train_iters(self, train_pairs, val_pairs, encoder, context_encoder, attack_clf,
-                     encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,
-                     n_iteration, validate_every):
-
+    def _train_iters(
+        self,
+        train_pairs,
+        val_pairs,
+        encoder,
+        context_encoder,
+        attack_clf,
+        encoder_optimizer,
+        context_encoder_optimizer,
+        attack_clf_optimizer,
+        embedding,
+        n_iteration,
+        validate_every,
+    ):
         # create a batch iterator for training data
-        batch_iterator = batchIterator(self.voc, train_pairs, self.options['batch_size'])
+        batch_iterator = batchIterator(self.voc, train_pairs, self.options["batch_size"])
 
         # Initializations
-        print('Initializing ...')
+        print("Initializing ...")
         start_iteration = 1
         print_loss = 0
 
         # Training loop
         print("Training...")
         # keep track of best validation accuracy - only save when we have a model that beats the current best
         best_acc = 0
         for iteration in range(start_iteration, n_iteration + 1):
             training_batch, training_dialogs, true_batch_size = next(batch_iterator)
             # Extract fields from batch
-            input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, \
-            labels, batch_ids, target_variable, mask, max_target_len = training_batch
+            (
+                input_variable,
+                dialog_lengths,
+                utt_lengths,
+                batch_indices,
+                dialog_indices,
+                labels,
+                batch_ids,
+                target_variable,
+                mask,
+                max_target_len,
+            ) = training_batch
             dialog_lengths_list = [len(x) for x in training_dialogs]
 
             # Run a training iteration with batch
-            loss = self._train_NN(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments
-                         encoder, context_encoder, attack_clf,                                                                    # network arguments
-                         encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments
-                         true_batch_size, self.options['clip'])                                                                                   # misc arguments
+            loss = self._train_NN(
+                input_variable,
+                dialog_lengths,
+                dialog_lengths_list,
+                utt_lengths,
+                batch_indices,
+                dialog_indices,
+                labels,  # input/output arguments
+                encoder,
+                context_encoder,
+                attack_clf,  # network arguments
+                encoder_optimizer,
+                context_encoder_optimizer,
+                attack_clf_optimizer,  # optimization arguments
+                true_batch_size,
+                self.options["clip"],
+            )  # misc arguments
             print_loss += loss
 
             # Print progress
-            if iteration % self.options['print_every'] == 0:
-                print_loss_avg = print_loss / self.options['print_every']
-                print("Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}".format(iteration, iteration / n_iteration * 100, print_loss_avg))
+            if iteration % self.options["print_every"] == 0:
+                print_loss_avg = print_loss / self.options["print_every"]
+                print(
+                    "Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}".format(
+                        iteration, iteration / n_iteration * 100, print_loss_avg
+                    )
+                )
                 print_loss = 0
 
             # Evaluate on validation set
             if iteration % validate_every == 0:
                 print("Validating!")
                 # put the network components into evaluation mode
                 encoder.eval()
@@ -287,63 +416,87 @@
                 accuracy = self._validate(predictor, val_pairs)
                 print("Validation set accuracy: {:.2f}%".format(accuracy * 100))
 
                 # keep track of our best model so far
                 if accuracy > best_acc:
                     print("Validation accuracy better than current best; saving model...")
                     best_acc = accuracy
-                    torch.save({
-                        'iteration': iteration,
-                        'en': encoder.state_dict(),
-                        'ctx': context_encoder.state_dict(),
-                        'atk_clf': attack_clf.state_dict(),
-                        'en_opt': encoder_optimizer.state_dict(),
-                        'ctx_opt': context_encoder_optimizer.state_dict(),
-                        'atk_clf_opt': attack_clf_optimizer.state_dict(),
-                        'loss': loss,
-                        'voc_dict': self.voc.__dict__,
-                        'embedding': embedding.state_dict()
-                    }, self.options['trained_model_output_filepath'])
+                    torch.save(
+                        {
+                            "iteration": iteration,
+                            "en": encoder.state_dict(),
+                            "ctx": context_encoder.state_dict(),
+                            "atk_clf": attack_clf.state_dict(),
+                            "en_opt": encoder_optimizer.state_dict(),
+                            "ctx_opt": context_encoder_optimizer.state_dict(),
+                            "atk_clf_opt": attack_clf_optimizer.state_dict(),
+                            "loss": loss,
+                            "voc_dict": self.voc.__dict__,
+                            "embedding": embedding.state_dict(),
+                        },
+                        self.options["trained_model_output_filepath"],
+                    )
 
                 # put the network components back into training mode
                 encoder.train()
                 context_encoder.train()
                 attack_clf.train()
 
     def train(self, id_to_context_reply_label):
         ids = list(id_to_context_reply_label)
-        train_pair_ids, val_pair_ids = train_test_split(ids, test_size=self.options['validation_size'])
+        train_pair_ids, val_pair_ids = train_test_split(
+            ids, test_size=self.options["validation_size"]
+        )
         train_pairs = [id_to_context_reply_label[pair_id] for pair_id in train_pair_ids]
         val_pairs = [id_to_context_reply_label[pair_id] for pair_id in val_pair_ids]
         # Compute the number of training iterations we will need in order to achieve the number of epochs specified in the settings at the start of the notebook
-        n_iter_per_epoch = len(train_pairs) // self.options['batch_size'] + int(len(train_pairs) % self.options['batch_size'] == 1)
-        n_iteration = n_iter_per_epoch * self.options['train_epochs']
+        n_iter_per_epoch = len(train_pairs) // self.options["batch_size"] + int(
+            len(train_pairs) % self.options["batch_size"] == 1
+        )
+        n_iteration = n_iter_per_epoch * self.options["train_epochs"]
 
         # Put dropout layers in train mode
         self.predictor.encoder.train()
         self.predictor.context_encoder.train()
         self.predictor.classifier.train()
 
         # Initialize optimizers
-        print('Building optimizers...')
-        encoder_optimizer = optim.Adam(self.predictor.encoder.parameters(), lr=self.options['learning_rate'])
-        context_encoder_optimizer = optim.Adam(self.predictor.context_encoder.parameters(),
-                                               lr=self.options['learning_rate'])
-        attack_clf_optimizer = optim.Adam(self.predictor.classifier.parameters(), lr=self.options['learning_rate'])
+        print("Building optimizers...")
+        encoder_optimizer = optim.Adam(
+            self.predictor.encoder.parameters(), lr=self.options["learning_rate"]
+        )
+        context_encoder_optimizer = optim.Adam(
+            self.predictor.context_encoder.parameters(), lr=self.options["learning_rate"]
+        )
+        attack_clf_optimizer = optim.Adam(
+            self.predictor.classifier.parameters(), lr=self.options["learning_rate"]
+        )
 
         # Run training iterations, validating after every epoch
         print("Starting Training!")
         print("Will train for {} iterations".format(n_iteration))
-        self._train_iters(train_pairs, val_pairs, self.predictor.encoder, self.predictor.context_encoder,
-                          self.predictor.classifier, encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,
-                          self.predictor.encoder.embedding, n_iteration, n_iter_per_epoch)
-
+        self._train_iters(
+            train_pairs,
+            val_pairs,
+            self.predictor.encoder,
+            self.predictor.context_encoder,
+            self.predictor.classifier,
+            encoder_optimizer,
+            context_encoder_optimizer,
+            attack_clf_optimizer,
+            self.predictor.encoder.embedding,
+            n_iteration,
+            n_iter_per_epoch,
+        )
 
     def forecast(self, id_to_context_reply_label):
         """
         Compute forecasts and forecast scores for the given dictionary of utterance id to (context, reply) pairs. Return the values in a DataFrame.
 
         :param id_to_context_reply_label: dict mapping utterance id to (context, reply, label)
         :return: a pandas DataFrame
         """
-        dataset = [(context, reply, label, id_) for id_, (context, reply, label) in id_to_context_reply_label.items()]
+        dataset = [
+            (context, reply, label, id_)
+            for id_, (context, reply, label) in id_to_context_reply_label.items()
+        ]
         return self._evaluate_dataset(self.predictor, dataset)
```

### Comparing `convokit-2.5.3/convokit/forecaster/cumulativeBoW.py` & `convokit-3.0.0/convokit/forecaster/cumulativeBoW.py`

 * *Files 16% similar despite different names*

```diff
@@ -2,65 +2,94 @@
 from sklearn.feature_extraction.text import CountVectorizer as CV
 from sklearn.pipeline import Pipeline
 from sklearn.preprocessing import StandardScaler
 from sklearn.linear_model import LogisticRegression
 from typing import List
 import pandas as pd
 
+
 class CumulativeBoW(ForecasterModel):
     """
     A cumulative bag-of-words forecasting model.
 
     :param vectorizer: optional vectorizer; default CV (min_df=10, max_df=0.5, ngram_range=(1,1), max_features=15000)
     :param clf_model: optional classifier model; default standard-scaled logistic regression
     :param use_tokens: if using default vectorizer, set this to true if input is already tokenized
     :param forecast_attribute_name: name for DataFrame column containing predictions, default: "prediction"
     :param forecast_prob_attribute_name: name for column containing prediction scores, default: "score"
     """
-    def __init__(self, vectorizer=None, clf_model=None, use_tokens=False,
-                 forecast_attribute_name: str = "prediction", forecast_prob_attribute_name: str = "score"):
 
-        super().__init__(forecast_attribute_name=forecast_attribute_name, forecast_prob_attribute_name=forecast_prob_attribute_name)
+    def __init__(
+        self,
+        vectorizer=None,
+        clf_model=None,
+        use_tokens=False,
+        forecast_attribute_name: str = "prediction",
+        forecast_prob_attribute_name: str = "score",
+    ):
+        super().__init__(
+            forecast_attribute_name=forecast_attribute_name,
+            forecast_prob_attribute_name=forecast_prob_attribute_name,
+        )
         if vectorizer is None:
             print("Initializing default unigram CountVectorizer...")
             if use_tokens:
-                self.vectorizer = CV(decode_error='ignore', min_df=10, max_df=.5, ngram_range=(1, 1), binary=False,
-                                     max_features=15000, tokenizer=lambda x: x, preprocessor=lambda x: x)
+                self.vectorizer = CV(
+                    decode_error="ignore",
+                    min_df=10,
+                    max_df=0.5,
+                    ngram_range=(1, 1),
+                    binary=False,
+                    max_features=15000,
+                    tokenizer=lambda x: x,
+                    preprocessor=lambda x: x,
+                )
             else:
-                self.vectorizer = CV(decode_error='ignore', min_df=10, max_df=.5,
-                                     ngram_range=(1, 1), binary=False, max_features=15000)
+                self.vectorizer = CV(
+                    decode_error="ignore",
+                    min_df=10,
+                    max_df=0.5,
+                    ngram_range=(1, 1),
+                    binary=False,
+                    max_features=15000,
+                )
         else:
             self.vectorizer = vectorizer
 
         if clf_model is None:
             print("Initializing default classification model (standard scaled logistic regression)")
-            self.clf_model = Pipeline([("standardScaler", StandardScaler(with_mean=False)),
-                                   ("logreg", LogisticRegression(solver='liblinear'))])  
+            self.clf_model = Pipeline(
+                [
+                    ("standardScaler", StandardScaler(with_mean=False)),
+                    ("logreg", LogisticRegression(solver="liblinear")),
+                ]
+            )
         else:
             self.clf_model = clf_model
 
-            
     @staticmethod
     def _combine_contexts(id_to_context_others):
         """
         Combines the context part of the dictionary into a single entity (list or string) - this mutates the dictionary
 
         :param id_to_context_others: dictionary of utterance id to (context, reply, label)
         :return: input dictionary with context as a single entity (list or string)
         """
         for comment_id, (context, *others) in id_to_context_others.items():
             if isinstance(context[0], str):
-                context_all = ' '.join(utt_text for utt_text in context)
+                context_all = " ".join(utt_text for utt_text in context)
             elif isinstance(context, List):
                 context_all = []
                 for utt_tokens in context:
                     context_all.extend(utt_tokens)
             else:
-                raise TypeError("Context utterances are of an invalid type. "
-                                "The utterance should be either a List of tokens or a string.")
+                raise TypeError(
+                    "Context utterances are of an invalid type. "
+                    "The utterance should be either a List of tokens or a string."
+                )
             context = context_all
             id_to_context_others[comment_id] = (context, *others)
         return id_to_context_others
 
     def train(self, id_to_context_reply_label):
         CumulativeBoW._combine_contexts(id_to_context_reply_label)
         contexts = [context for id_, (context, reply, label) in id_to_context_reply_label.items()]
@@ -77,11 +106,11 @@
             raise ValueError("Forecaster model has not been fitted yet.")
 
         CumulativeBoW._combine_contexts(id_to_context_reply_label)
         contexts = [context for id_, (context, reply, label) in id_to_context_reply_label.items()]
         X = self.vectorizer.transform(contexts)
         ids = [id_ for id_, _ in id_to_context_reply_label.items()]
         preds, pred_probs = self.clf_model.predict(X), self.clf_model.predict_proba(X)[:, 1]
-        return pd.DataFrame(data=list(zip(ids, preds, pred_probs)),
-                            columns=["id", self.forecast_attribute_name, self.forecast_prob_attribute_name]).set_index('id')
-
-
+        return pd.DataFrame(
+            data=list(zip(ids, preds, pred_probs)),
+            columns=["id", self.forecast_attribute_name, self.forecast_prob_attribute_name],
+        ).set_index("id")
```

### Comparing `convokit-2.5.3/convokit/forecaster/forecaster.py` & `convokit-3.0.0/convokit/forecaster/forecaster.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,168 +1,225 @@
 from convokit.model import Corpus, Conversation, Utterance
 from typing import Callable, Optional
 from convokit import Transformer
 from .cumulativeBoW import CumulativeBoW
 from .forecasterModel import ForecasterModel
 import pandas as pd
 
+
 class Forecaster(Transformer):
     """
     Implements basic Forecaster behavior.
 
     :param forecaster_model: ForecasterModel to use, e.g. cumulativeBoW or CRAFT
     :param forecast_mode: 'future' or 'past'. 'future' (the default behavior) annotates each utterance with a forecast score using all context up to and including that utterance (i.e., a prediction of the future state of the conversation after this utterance). 'past' annotates each utterance with a forecast score using all context prior to that utterance (i.e., what the model believed this utterance would look like prior to actually seeing it)
     :param convo_structure: conversations in expected corpus are 'branched' or 'linear', default: "branched"
     :param text_func: optional function for extracting the text of the utterance, default: uses utterance's text attribute
     :param label_func: callable function for getting the utterance's forecast label (True or False); only used in training
     :param use_last_only: if forecast_mode is 'past' and use_last_only is True, for each dialog, use only the context-reply pair where the reply is the last utterance in the dialog
     :param skip_broken_convos: if True and convo_structure is 'branched', exclude all conversations that have broken reply-to structures, default: True
     :param forecast_attribute_name: metadata feature name to use in annotation for forecast result, default: "forecast"
     :param forecast_prob_attribute_name: metadata feature name to use in annotation for forecast result probability, default: "forecast_prob"
     """
-    def __init__(self, forecaster_model: ForecasterModel = None,
-                 forecast_mode: str = "future",
-                 convo_structure: str = "branched",
-                 text_func=lambda utt: utt.text,
-                 label_func: Callable[[Utterance], bool] = lambda utt: True,
-                 use_last_only: bool = False,
-                 skip_broken_convos: bool = True,
-                 forecast_attribute_name: str = "forecast",
-                 forecast_prob_attribute_name: str = "forecast_prob"
-                 ):
 
+    def __init__(
+        self,
+        forecaster_model: ForecasterModel = None,
+        forecast_mode: str = "future",
+        convo_structure: str = "branched",
+        text_func=lambda utt: utt.text,
+        label_func: Callable[[Utterance], bool] = lambda utt: True,
+        use_last_only: bool = False,
+        skip_broken_convos: bool = True,
+        forecast_attribute_name: str = "forecast",
+        forecast_prob_attribute_name: str = "forecast_prob",
+    ):
         assert convo_structure in ["branched", "linear"]
         self.convo_structure = convo_structure
 
         if forecaster_model is None:
-            print("No model passed to Forecaster. Initializing default forecaster model: Cumulative Bag-of-words...")
-            self.forecaster_model = CumulativeBoW(forecast_attribute_name=forecast_attribute_name,
-                                                  forecast_prob_attribute_name=forecast_prob_attribute_name)
+            print(
+                "No model passed to Forecaster. Initializing default forecaster model: Cumulative Bag-of-words..."
+            )
+            self.forecaster_model = CumulativeBoW(
+                forecast_attribute_name=forecast_attribute_name,
+                forecast_prob_attribute_name=forecast_prob_attribute_name,
+            )
         else:
             self.forecaster_model = forecaster_model
         self.forecast_mode = forecast_mode
         self.label_func = label_func
         self.text_func = text_func
         self.use_last_only = use_last_only
         self.skip_broken_convos = skip_broken_convos
         self.forecast_attribute_name = forecast_attribute_name
         self.forecast_prob_attribute_name = forecast_prob_attribute_name
 
-    def _get_context_reply_label_dict(self, corpus: Corpus, convo_selector, utt_excluder, include_label=True):
+    def _get_context_reply_label_dict(
+        self, corpus: Corpus, convo_selector, utt_excluder, include_label=True
+    ):
         """
         Returns a dict mapping reply id to (context, reply, label).
 
         If self.forecast_mode == 'future': return a dict mapping the leaf utt id to the path from root utt to leaf utt
         """
         dialogs = []
         if self.convo_structure == "branched":
             for convo in corpus.iter_conversations(convo_selector):
                 try:
                     for path in convo.get_root_to_leaf_paths():
                         path = [utt for utt in path if not utt_excluder(utt)]
-                        if len(path) == 1: continue
+                        if len(path) == 1:
+                            continue
                         dialogs.append(path)
                 except ValueError as e:
                     if not self.skip_broken_convos:
                         raise e
 
         elif self.convo_structure == "linear":
             for convo in corpus.iter_conversations(convo_selector):
-                utts = convo.get_chronological_utterance_list(selector=lambda x: not utt_excluder(x))
-                if len(utts) == 1: continue
+                utts = convo.get_chronological_utterance_list(
+                    selector=lambda x: not utt_excluder(x)
+                )
+                if len(utts) == 1:
+                    continue
                 dialogs.append(utts)
 
         id_to_context_reply_label = dict()
 
         # this flag determines whether the dictionary entry for each utterance ID should include that
         # utterance in the context (True corresponds to "future" behavior). This needs to be always
         # False when include_label = True, since include_label assumes that the label comes from the
         # utterance after the last utterance in the context. This override logic won't affect
         # forecast_mode however, since that argument only applies to transform() while include_label
         # is only True when called from fit()
-        include_current = (self.forecast_mode == 'future') and (not include_label)
+        include_current = (self.forecast_mode == "future") and (not include_label)
 
         for dialog in dialogs:
             if self.use_last_only:
                 reply = self.text_func(dialog[-1])
-                context = [self.text_func(utt) for utt in (dialog if include_current else dialog[:-1])]
+                context = [
+                    self.text_func(utt) for utt in (dialog if include_current else dialog[:-1])
+                ]
                 label = self.label_func(dialog[-1]) if include_label else None
                 id_to_context_reply_label[dialog[-1].id] = (context, reply, label)
             else:
                 for idx in range(0 if include_current else 1, len(dialog)):
                     reply = self.text_func(dialog[idx])
                     label = self.label_func(dialog[idx]) if include_label else None
                     reply_id = dialog[idx].id
-                    context = [self.text_func(utt) for utt in (dialog[:(idx+1)] if include_current else dialog[:idx])]
-                    id_to_context_reply_label[reply_id] = (context, reply, label) if include_label else (context, reply, None)
+                    context = [
+                        self.text_func(utt)
+                        for utt in (dialog[: (idx + 1)] if include_current else dialog[:idx])
+                    ]
+                    id_to_context_reply_label[reply_id] = (
+                        (context, reply, label) if include_label else (context, reply, None)
+                    )
 
         return id_to_context_reply_label
 
-    def fit(self, corpus: Corpus, y=None,
-            selector: Callable[[Conversation], bool] = lambda convo: True,
-            ignore_utterances: Callable[[Utterance], bool] = lambda utt: False):
+    def fit(
+        self,
+        corpus: Corpus,
+        y=None,
+        selector: Callable[[Conversation], bool] = lambda convo: True,
+        ignore_utterances: Callable[[Utterance], bool] = lambda utt: False,
+    ):
         """
         Train the ForecasterModel on the given corpus.
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Conversation and returns a bool: True if the Conversation is to be included in the fitting step. By default, includes all Conversations.
         :param ignore_utterances: a (lambda) function that takes an Utterance and returns a bool: True if the Utterance should be excluded from the Conversation in the fitting step. By default, all Utterances are included.
         :return: fitted Forecaster Transformer
         """
-        id_to_context_reply_label = self._get_context_reply_label_dict(corpus, selector, ignore_utterances, include_label=True)
+        id_to_context_reply_label = self._get_context_reply_label_dict(
+            corpus, selector, ignore_utterances, include_label=True
+        )
         self.forecaster_model.train(id_to_context_reply_label)
 
-    def transform(self, corpus: Corpus,
-                  selector: Callable[[Conversation], bool] = lambda convo: True,
-                  ignore_utterances: Callable[[Utterance], bool] = lambda utt: False) -> Corpus:
+    def transform(
+        self,
+        corpus: Corpus,
+        selector: Callable[[Conversation], bool] = lambda convo: True,
+        ignore_utterances: Callable[[Utterance], bool] = lambda utt: False,
+    ) -> Corpus:
         """
         Annotate the corpus utterances with forecast and forecast score information
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Conversation and returns a bool: True if the Conversation is to be included in the transformation step. By default, includes all Conversations.
         :param ignore_utterances: a (lambda) function that takes an Utterance and returns a bool: True if the Utterance should be excluded from the Conversation in the transformation step. By default, all Utterances are included.
         :return: annotated Corpus
         """
-        id_to_context_reply_label = self._get_context_reply_label_dict(corpus, selector, ignore_utterances, include_label=False)
+        id_to_context_reply_label = self._get_context_reply_label_dict(
+            corpus, selector, ignore_utterances, include_label=False
+        )
         forecast_df = self.forecaster_model.forecast(id_to_context_reply_label)
 
         for utt in corpus.iter_utterances():
             if utt.id in forecast_df.index:
-                utt.add_meta(self.forecast_attribute_name, forecast_df.loc[utt.id][self.forecast_attribute_name])
-                utt.add_meta(self.forecast_prob_attribute_name, forecast_df.loc[utt.id][self.forecast_prob_attribute_name])
+                utt.add_meta(
+                    self.forecast_attribute_name,
+                    forecast_df.loc[utt.id][self.forecast_attribute_name],
+                )
+                utt.add_meta(
+                    self.forecast_prob_attribute_name,
+                    forecast_df.loc[utt.id][self.forecast_prob_attribute_name],
+                )
             else:
                 utt.add_meta(self.forecast_attribute_name, None)
                 utt.add_meta(self.forecast_prob_attribute_name, None)
 
         return corpus
 
-    def fit_transform(self, corpus: Corpus, y=None, selector: Callable[[Conversation], bool] = lambda convo: True,
-                      ignore_utterances: Callable[[Utterance], bool] = lambda utt: False) -> Corpus:
+    def fit_transform(
+        self,
+        corpus: Corpus,
+        y=None,
+        selector: Callable[[Conversation], bool] = lambda convo: True,
+        ignore_utterances: Callable[[Utterance], bool] = lambda utt: False,
+    ) -> Corpus:
         self.fit(corpus, selector=selector, ignore_utterances=ignore_utterances)
         return self.transform(corpus, selector=selector, ignore_utterances=ignore_utterances)
 
-    def summarize(self, corpus: Corpus,
-                  selector: Callable[[Conversation], bool] = lambda convo: True,
-                  ignore_utterances: Callable[[Utterance], bool] = lambda utt: False,
-                  exclude_na=True):
+    def summarize(
+        self,
+        corpus: Corpus,
+        selector: Callable[[Conversation], bool] = lambda convo: True,
+        ignore_utterances: Callable[[Utterance], bool] = lambda utt: False,
+        exclude_na=True,
+    ):
         """
         Returns a DataFrame of utterances and their forecasts (and forecast probabilities)
 
         :param corpus: target Corpus
         :param exclude_na: whether to drop NaN results
         :param selector: a (lambda) function that takes a Conversation and returns a bool: True if the Conversation is to be included in the summary step. By default, includes all Conversations.
         :param ignore_utterances: a (lambda) function that takes an Utterance and returns a bool: True if the Utterance should be excluded from the Conversation in the summary step. By default, all Utterances are included.
         :return: a pandas DataFrame
         """
         utt_forecast_prob = []
         for convo in corpus.iter_conversations(selector):
             for utt in convo.iter_utterances(lambda x: not ignore_utterances(x)):
-                utt_forecast_prob.append((utt.id, utt.meta[self.forecast_attribute_name], utt.meta[self.forecast_prob_attribute_name]))
-        forecast_df = pd.DataFrame(utt_forecast_prob, columns=["utt_id", self.forecast_attribute_name, self.forecast_prob_attribute_name]) \
-            .set_index('utt_id').sort_values(self.forecast_prob_attribute_name, ascending=False)
+                utt_forecast_prob.append(
+                    (
+                        utt.id,
+                        utt.meta[self.forecast_attribute_name],
+                        utt.meta[self.forecast_prob_attribute_name],
+                    )
+                )
+        forecast_df = (
+            pd.DataFrame(
+                utt_forecast_prob,
+                columns=["utt_id", self.forecast_attribute_name, self.forecast_prob_attribute_name],
+            )
+            .set_index("utt_id")
+            .sort_values(self.forecast_prob_attribute_name, ascending=False)
+        )
         if exclude_na:
             forecast_df = forecast_df.dropna()
         return forecast_df
 
     def get_model(self):
         """
         Get the forecaster model object
```

### Comparing `convokit-2.5.3/convokit/hyperconvo/communityEmbedder.py` & `convokit-3.0.0/convokit/hyperconvo/communityEmbedder.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,15 +18,17 @@
     :param community_key: Key in "meta" dictionary of each utterance
             whose corresponding value we'll use as the community label for that
             utterance (see threadEmbedder)
     :param n_components: Number of dimensions to embed communities into
     :param method: Embedding method; "svd", "tsne" or "none"
     """
 
-    def __init__(self, community_key: Optional[str]=None, n_components: int=2, method: str="none"):
+    def __init__(
+        self, community_key: Optional[str] = None, n_components: int = 2, method: str = "none"
+    ):
         self.community_key = community_key
         self.n_components = n_components
         self.method = method
 
     def transform(self, corpus: Corpus) -> Corpus:
         """
         Same as fit_transform()
@@ -40,20 +42,24 @@
         :param corpus: the Corpus to use
 
         :return: Modifies and returns Corpus with new meta key: "communityEmbedder", value: Dict,
                 containing "pts": an array with rows corresponding to embedded communities,
                 and "labels": an array whose ith entry is the community of the ith row of X.
         """
         if self.community_key is None:
-            raise RuntimeError("Must specify community_key to retrieve label information from utterance")
+            raise RuntimeError(
+                "Must specify community_key to retrieve label information from utterance"
+            )
 
         corpus_meta = corpus.get_meta()
         if "threadEmbedder" not in corpus_meta:
-            raise RuntimeError("Missing threadEmbedder metadata: "
-                               "threadEmbedder.fit_transform() must be run on the Corpus first")
+            raise RuntimeError(
+                "Missing threadEmbedder metadata: "
+                "threadEmbedder.fit_transform() must be run on the Corpus first"
+            )
 
         thread_embed_data = corpus_meta["threadEmbedder"]
 
         X_mid = thread_embed_data["X"]
         roots = thread_embed_data["roots"]
 
         if self.method.lower() == "svd":
@@ -66,21 +72,20 @@
             raise Exception("Invalid embed_communities embedding method")
 
         if f is not None:
             X_embedded = f(n_components=self.n_components).fit_transform(X_mid)
         else:
             X_embedded = X_mid
 
-        labels = [corpus.get_utterance(root).meta[self.community_key]
-                  for root in roots]
+        labels = [corpus.get_utterance(root).meta[self.community_key] for root in roots]
         # label_counts = Counter(labels)
         subs = defaultdict(list)
         for x, label in zip(X_embedded, labels):
             subs[label].append(x / np.linalg.norm(x))
 
         labels, subs = zip(*subs.items())
         pts = [np.mean(sub, axis=0) for sub in subs]
 
         retval = {"pts": pts, "labels": labels}
         corpus.add_meta("communityEmbedder", retval)
 
-        return corpus
+        return corpus
```

### Comparing `convokit-2.5.3/convokit/hyperconvo/hyperconvo.py` & `convokit-3.0.0/convokit/hyperconvo/hyperconvo.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,39 +1,43 @@
+from typing import Dict, Optional, Callable
+
 import numpy as np
-import scipy.stats
 import pandas as pd
+import scipy.stats
 from scipy.sparse import csr_matrix
-from typing import Dict, Optional, Callable
 
-from convokit.util import deprecation
-from convokit.transformer import Transformer
 from convokit.model import Corpus, Conversation
+from convokit.transformer import Transformer
 from .hypergraph import Hypergraph
 
+
 def degree_stat_funcs(nan_val):
     # int wrapping is to convert from np.int64 to int, since np.int64 is not JSON-serializable
     return {
-    "max": lambda l: int(np.max(l)),
-    "argmax": lambda l: int(np.argmax(l)),
-    "norm.max": lambda l: np.max(l) / np.sum(l) if np.sum(l) > 0 else 0,
-    "2nd-largest": lambda l: int(np.partition(l, -2)[-2]) if len(l) > 1 else nan_val,
-    "2nd-argmax": lambda l: int((-l).argsort()[1]) if len(l) > 1 else nan_val,
-    "norm.2nd-largest": lambda l: np.partition(l, -2)[-2] / np.sum(l) if (len(l) > 1 and np.sum(l) > 0) else nan_val,
-    "mean": np.mean,
-    "mean-nonzero": lambda l: np.mean(l[l != 0]) if len(l[l != 0]) > 0 else 0,
-    "prop-nonzero": lambda l: np.mean(l != 0),
-    "prop-multiple": lambda l: np.mean(l[l != 0] > 1) if len(l[l !=0] > 1) > 0 else 0,
-    "entropy": lambda l: scipy.stats.entropy(l) if np.sum(l) > 0 else nan_val,
-    "2nd-largest / max": lambda l: np.partition(l, -2)[-2] / np.max(l) if (len(l) > 1 and np.sum(l) > 0) else nan_val
-}
-
-motif_stat_funcs = {
-    "is-present": lambda l: len(l) > 0,
-    "count": len
-}
+        "max": lambda l: int(np.max(l)),
+        "argmax": lambda l: int(np.argmax(l)),
+        "norm.max": lambda l: np.max(l) / np.sum(l) if np.sum(l) > 0 else 0,
+        "2nd-largest": lambda l: int(np.partition(l, -2)[-2]) if len(l) > 1 else nan_val,
+        "2nd-argmax": lambda l: int((-l).argsort()[1]) if len(l) > 1 else nan_val,
+        "norm.2nd-largest": lambda l: np.partition(l, -2)[-2] / np.sum(l)
+        if (len(l) > 1 and np.sum(l) > 0)
+        else nan_val,
+        "mean": np.mean,
+        "mean-nonzero": lambda l: np.mean(l[l != 0]) if len(l[l != 0]) > 0 else 0,
+        "prop-nonzero": lambda l: np.mean(l != 0),
+        "prop-multiple": lambda l: np.mean(l[l != 0] > 1) if len(l[l != 0] > 1) > 0 else 0,
+        "entropy": lambda l: scipy.stats.entropy(l) if np.sum(l) > 0 else nan_val,
+        "2nd-largest / max": lambda l: np.partition(l, -2)[-2] / np.max(l)
+        if (len(l) > 1 and np.sum(l) > 0)
+        else nan_val,
+    }
+
+
+motif_stat_funcs = {"is-present": lambda l: len(l) > 0, "count": len}
+
 
 class HyperConvo(Transformer):
     """
     Encapsulates computation of hypergraph features for a particular
     corpus.
 
     fit_transform() retrieves features from the corpus conversational
@@ -58,39 +62,48 @@
 
     :param prefix_len: Use the first [prefix_len] utterances of each conversation to construct the hypergraph
     :param min_convo_len: Only consider conversations of at least this length
     :param vector_name: feature name to store hyperconvo features under
     :param invalid_val: value to use for invalid hyperconvo features, default is np.nan
     """
 
-    def __init__(self, prefix_len: int = 10, min_convo_len: int = 10, vector_name: str = "hyperconvo", feat_name=None,
-                 invalid_val: float = np.nan):
+    def __init__(
+        self,
+        prefix_len: int = 10,
+        min_convo_len: int = 10,
+        vector_name: str = "hyperconvo",
+        invalid_val: float = np.nan,
+    ):
         self.prefix_len = prefix_len
         self.min_convo_len = min_convo_len
-        self.vector_name = vector_name if feat_name is None else feat_name
-        if feat_name is not None: deprecation("HyperConvo's feat_name parameter", "vector_name")
-
+        self.vector_name = vector_name
         self.invalid_val = invalid_val
 
-    def transform(self, corpus: Corpus, selector: Optional[Callable[[Conversation], bool]] = lambda convo: True) -> Corpus:
+    def transform(
+        self,
+        corpus: Corpus,
+        selector: Optional[Callable[[Conversation], bool]] = lambda convo: True,
+    ) -> Corpus:
         """
         Retrieves features from the Corpus Conversations using retrieve_feats() and annotates Conversations with this feature set
 
         :param corpus: Corpus object to retrieve feature information from
         :param selector: a (lambda) function that takes a Conversation and returns True / False; function selects
             conversations to be annotated with hypergraph features. By default, all conversations will be annotated.
         :return: corpus with conversations having a new meta field with the specified feature name  containing the stats generated by retrieve_feats().
         """
 
         convo_id_to_feats = self.retrieve_feats(corpus, selector)
         df = pd.DataFrame(convo_id_to_feats).T
-        corpus.set_vector_matrix(name=self.vector_name,
-                                 ids=list(df.index),
-                                 columns=list(df.columns),
-                                 matrix=csr_matrix(df.values.astype('float64')))
+        corpus.set_vector_matrix(
+            name=self.vector_name,
+            ids=list(df.index),
+            columns=list(df.columns),
+            matrix=csr_matrix(df.values.astype("float64")),
+        )
 
         for convo in corpus.iter_conversations(selector):
             convo.add_vector(self.vector_name)
         return corpus
 
     @staticmethod
     def _node_type_name(b: bool) -> str:
@@ -114,30 +127,39 @@
         :param exclude_id: id of utterance to exclude from Hypergraph construction
         :return: A stats dictionary, i.e. a dictionary of feature names to feature values. For degree-related features specifically.
         """
 
         stats = {}
         for from_hyper in [False, True]:
             for to_hyper in [False, True]:
-                if not from_hyper and to_hyper: continue # skip c->C
+                if not from_hyper and to_hyper:
+                    continue  # skip c->C
                 if from_hyper:
                     outdegrees = np.array(graph.outdegrees(from_hyper, to_hyper))
                 indegrees = np.array(graph.indegrees(from_hyper, to_hyper))
 
                 for stat, stat_func in degree_stat_funcs(self.invalid_val).items():
                     if from_hyper:
-                        stats["{}[outdegree over {}->{} {}responses]".format(stat,
-                                                                     HyperConvo._node_type_name(from_hyper),
-                                                                     HyperConvo._node_type_name(to_hyper),
-                                                                     name_ext)] = stat_func(outdegrees)
-
-                    stats["{}[indegree over {}->{} {}responses]".format(stat,
-                                                                        HyperConvo._node_type_name(from_hyper),
-                                                                        HyperConvo._node_type_name(to_hyper),
-                                                                        name_ext)] = stat_func(indegrees)
+                        stats[
+                            "{}[outdegree over {}->{} {}responses]".format(
+                                stat,
+                                HyperConvo._node_type_name(from_hyper),
+                                HyperConvo._node_type_name(to_hyper),
+                                name_ext,
+                            )
+                        ] = stat_func(outdegrees)
+
+                    stats[
+                        "{}[indegree over {}->{} {}responses]".format(
+                            stat,
+                            HyperConvo._node_type_name(from_hyper),
+                            HyperConvo._node_type_name(to_hyper),
+                            name_ext,
+                        )
+                    ] = stat_func(indegrees)
         return stats
 
     @staticmethod
     def _motif_feats(graph: Hypergraph = None, name_ext: str = "") -> Dict:
         """
         Helper method for retrieve_feats().
         Generate statistics on degree-related features in a Hypergraph (G), or a Hypergraph
@@ -152,21 +174,24 @@
         """
         stats = {}
         for motif, motif_func in [
             ("reciprocity motif", graph.reciprocity_motifs),
             ("external reciprocity motif", graph.external_reciprocity_motifs),
             ("dyadic interaction motif", graph.dyadic_interaction_motifs),
             ("incoming triads", graph.incoming_triad_motifs),
-            ("outgoing triads", graph.outgoing_triad_motifs)]:
+            ("outgoing triads", graph.outgoing_triad_motifs),
+        ]:
             motifs = motif_func()
             for stat, stat_func in motif_stat_funcs.items():
                 stats["{}[{}{}]".format(stat, motif, name_ext)] = stat_func(motifs)
         return stats
 
-    def retrieve_feats(self, corpus: Corpus, selector: Callable[[Conversation], bool] = lambda convo: True) -> Dict[str, Dict]:
+    def retrieve_feats(
+        self, corpus: Corpus, selector: Callable[[Conversation], bool] = lambda convo: True
+    ) -> Dict[str, Dict]:
         """
         Retrieve all hypergraph features for a given corpus (viewed as a set of conversation threads).
 
         See init() for further documentation.
 
         :param corpus: target Corpus
         :param selector: (lambda) function selecting the Conversations that features should be computed for.
@@ -175,19 +200,23 @@
             features specifically.
         """
 
         threads_stats = dict()
 
         for convo in corpus.iter_conversations(selector):
             ordered_utts = convo.get_chronological_utterance_list()
-            if len(ordered_utts) < self.min_convo_len: continue
-            utts = ordered_utts[:self.prefix_len]
+            if len(ordered_utts) < self.min_convo_len:
+                continue
+            utts = ordered_utts[: self.prefix_len]
             stats = {}
             G = Hypergraph.init_from_utterances(utterances=utts)
-            G_mid = Hypergraph.init_from_utterances(utterances=utts[1:]) # exclude root
-            for k, v in self._degree_feats(graph=G).items(): stats[k] = v
-            for k, v in HyperConvo._motif_feats(graph=G).items(): stats[k] = v
-            for k, v in self._degree_feats(graph=G_mid, name_ext="mid-thread ").items(): stats[k] = v
-            for k, v in HyperConvo._motif_feats(graph=G_mid, name_ext=" over mid-thread").items(): stats[k] = v
+            G_mid = Hypergraph.init_from_utterances(utterances=utts[1:])  # exclude root
+            for k, v in self._degree_feats(graph=G).items():
+                stats[k] = v
+            for k, v in HyperConvo._motif_feats(graph=G).items():
+                stats[k] = v
+            for k, v in self._degree_feats(graph=G_mid, name_ext="mid-thread ").items():
+                stats[k] = v
+            for k, v in HyperConvo._motif_feats(graph=G_mid, name_ext=" over mid-thread").items():
+                stats[k] = v
             threads_stats[convo.id] = stats
         return threads_stats
-
```

### Comparing `convokit-2.5.3/convokit/hyperconvo/hypergraph.py` & `convokit-3.0.0/convokit/hyperconvo/hypergraph.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,29 +1,31 @@
 from typing import Tuple, List, Dict, Collection
 from collections import defaultdict
 from convokit import Utterance, Speaker
 import itertools
 
+
 class Hypergraph:
     """
     Represents a hypergraph, consisting of nodes, directed edges,
     hypernodes (each of which is a set of nodes) and hyperedges (directed edges
     from hypernodes to hypernodes). Contains functionality to extract motifs
     from hypergraphs (Fig 2 of
     http://www.cs.cornell.edu/~cristian/Patterns_of_participant_interactions.html)
     """
+
     def __init__(self):
         # public
         self.nodes: Dict[str, Utterance] = dict()
         self.hypernodes = dict()
         self.speakers = dict()
 
         # private
         self.adj_out = dict()  # out edges for each (hyper)node
-        self.adj_in = dict()   # in edges for each (hyper)node
+        self.adj_in = dict()  # in edges for each (hyper)node
 
     @staticmethod
     def init_from_utterances(utterances: List[Utterance]):
         utt_dict = {utt.id: utt for utt in utterances}
         utt_to_speaker_id = {utt.id: utt.speaker.id for utt in utterances}
         hypergraph = Hypergraph()
         speaker_to_utt_ids = dict()
@@ -36,16 +38,21 @@
             if utt.speaker not in speaker_to_utt_ids:
                 speaker_to_utt_ids[utt.speaker] = set()
             speaker_to_utt_ids[utt.speaker].add(utt.id)
 
             if utt.reply_to is not None and utt.reply_to in utt_dict:
                 reply_edges.append((utt.id, utt.reply_to))
                 speaker_to_reply_tos[utt.speaker.id].append(utt.reply_to)
-                speaker_target_pairs.append([utt.speaker.id, utt_dict[utt.reply_to].speaker.id,
-                                             {'utt': utt, 'target_speaker': utt_to_speaker_id[utt.reply_to]}])
+                speaker_target_pairs.append(
+                    [
+                        utt.speaker.id,
+                        utt_dict[utt.reply_to].speaker.id,
+                        {"utt": utt, "target_speaker": utt_to_speaker_id[utt.reply_to]},
+                    ]
+                )
             hypergraph.add_node(utt)
 
         # hypernodes (speakers)
         for speaker, utt_ids in speaker_to_utt_ids.items():
             hypergraph.add_hypernode(speaker, utt_ids)
 
         # reply edges (utt to utt)
@@ -80,52 +87,48 @@
         assert v in self.nodes or v in self.hypernodes
         # if u in self.hypernodes and v in self.hypernodes:
         #     assert info is not N
         if v not in self.adj_out[u]:
             self.adj_out[u][v] = []
         if u not in self.adj_in[v]:
             self.adj_in[v][u] = []
-        if info is None: info = dict()
+        if info is None:
+            info = dict()
         self.adj_out[u][v].append(info)
         self.adj_in[v][u].append(info)
 
     def edges(self) -> Dict[Tuple[str, str], List]:
-        return dict(((u, v), lst) for u, d in self.adj_out.items()
-                    for v, lst in d.items())
+        return dict(((u, v), lst) for u, d in self.adj_out.items() for v, lst in d.items())
 
     def outgoing_nodes(self, u: str) -> Dict[str, List]:
         assert u in self.adj_out
-        return dict((v, lst) for v, lst in self.adj_out[u].items()
-                    if v in self.nodes)
+        return dict((v, lst) for v, lst in self.adj_out[u].items() if v in self.nodes)
 
     def outgoing_hypernodes(self, u) -> Dict[str, List]:
         assert u in self.adj_out
-        return dict((v, lst) for v, lst in self.adj_out[u].items()
-                    if v in self.hypernodes)
+        return dict((v, lst) for v, lst in self.adj_out[u].items() if v in self.hypernodes)
 
     def incoming_nodes(self, v: str) -> Dict[str, List]:
         assert v in self.adj_in
-        return dict((u, lst) for u, lst in self.adj_in[v].items() if u in
-                    self.nodes)
+        return dict((u, lst) for u, lst in self.adj_in[v].items() if u in self.nodes)
 
     def incoming_hypernodes(self, v: str) -> Dict[str, List]:
         assert v in self.adj_in
-        return dict((u, lst) for u, lst in self.adj_in[v].items() if u in
-                    self.hypernodes)
+        return dict((u, lst) for u, lst in self.adj_in[v].items() if u in self.hypernodes)
 
-    def outdegrees(self, from_hyper: bool=False, to_hyper: bool=False) -> List[int]:
+    def outdegrees(self, from_hyper: bool = False, to_hyper: bool = False) -> List[int]:
         retval = []
         from_nodes = self.hypernodes if from_hyper else self.nodes
         to_nodes = self.hypernodes if to_hyper else self.nodes
 
         for node in from_nodes:
             retval.append(sum([1 for v, l in self.adj_out[node].items() if v in to_nodes]))
         return retval
 
-    def indegrees(self, from_hyper: bool=False, to_hyper: bool=False) -> List[int]:
+    def indegrees(self, from_hyper: bool = False, to_hyper: bool = False) -> List[int]:
         retval = []
         from_nodes = self.hypernodes if from_hyper else self.nodes
         to_nodes = self.hypernodes if to_hyper else self.nodes
 
         for node in to_nodes:
             retval.append(sum([1 for u, l in self.adj_in[node].items() if u in from_nodes]))
         return retval
@@ -133,33 +136,38 @@
     def reciprocity_motifs(self) -> List[Tuple]:
         """
         :return: List of tuples of form (C1, c1, c2, C1->c2, c2->c1) as in paper
         """
         motifs = []
         for C1, c1_nodes in self.hypernodes.items():
             for c1 in c1_nodes:
-                motifs += [(C1, c1, c2, e1, e2) for c2 in self.adj_in[c1] if
-                           c2 in self.nodes and c2 in self.adj_out[C1]
-                           for e1 in self.adj_out[C1][c2] # only 1 such e1
-                           for e2 in self.adj_out[c2][c1]] # only 1 such e2
+                motifs += [
+                    (C1, c1, c2, e1, e2)
+                    for c2 in self.adj_in[c1]
+                    if c2 in self.nodes and c2 in self.adj_out[C1]
+                    for e1 in self.adj_out[C1][c2]  # only 1 such e1
+                    for e2 in self.adj_out[c2][c1]
+                ]  # only 1 such e2
         return motifs
 
     def external_reciprocity_motifs(self) -> List[Tuple]:
         """
         :return: List of tuples of form (C3, c2, c1, C3->c2, c2->c1) as in paper
         """
         motifs = []
         for C3 in self.hypernodes:
             for c2 in self.adj_out[C3]:
                 if c2 in self.nodes:
-                    motifs += [(C3, c2, c1, e1, e2) for c1 in
-                               set(self.adj_out[c2].keys()) - self.hypernodes[C3]
-                               if c1 in self.nodes
-                               for e1 in self.adj_out[C3][c2]  # there should be only 1 such e1
-                               for e2 in self.adj_out[c2][c1]] # there should only be 1 such e2
+                    motifs += [
+                        (C3, c2, c1, e1, e2)
+                        for c1 in set(self.adj_out[c2].keys()) - self.hypernodes[C3]
+                        if c1 in self.nodes
+                        for e1 in self.adj_out[C3][c2]  # there should be only 1 such e1
+                        for e2 in self.adj_out[c2][c1]
+                    ]  # there should only be 1 such e2
         return motifs
 
     def dyadic_interaction_motifs(self) -> List[Tuple]:
         """
         :return: List of tuples of form (C1, C2, C1->C2, C2->C1) as in paper
         """
 
@@ -185,8 +193,8 @@
         :return: List of tuples of form (C1, C2, C3, C1->C2, C1->C3) as in paper
         """
         motifs = []
         for C1 in self.hypernodes:
             outgoing = [C for C in self.adj_out[C1].keys() if C not in self.nodes]
             for C2, C3 in itertools.combinations(outgoing, 2):
                 motifs += [(C1, C2, C3, self.adj_out[C1][C2], self.adj_out[C1][C3])]
-        return motifs
+        return motifs
```

### Comparing `convokit-2.5.3/convokit/hyperconvo/threadEmbedder.py` & `convokit-3.0.0/convokit/hyperconvo/threadEmbedder.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,16 +16,21 @@
 
     :param n_components: Number of dimensions to embed threads into
     :param method: Embedding method; "svd", "tsne" or "none"
     :param norm_method: Normalization method; "standard" or "none"
     :param return_components: if True, returns the components from embedding
     """
 
-    def __init__(self, n_components: int=7, method: str="svd",
-                 norm_method: str="standard", return_components: bool=False):
+    def __init__(
+        self,
+        n_components: int = 7,
+        method: str = "svd",
+        norm_method: str = "standard",
+        return_components: bool = False,
+    ):
         self.n_components = n_components
         self.method = method
         self.norm_method = norm_method
         self.return_components = return_components
 
     def transform(self, corpus: Corpus) -> Corpus:
         """
@@ -42,27 +47,33 @@
              to embedded threads, "roots": an array whose ith entry is the
              thread root id of the ith row of X. If return_components is True,
              then the Dict contains a third key "components": the SVD components array
         """
         convos = corpus.iter_conversations()
         sample_convo_meta = next(iter(convos))
         if "hyperconvo" not in sample_convo_meta:
-            raise RuntimeError("Missing thread statistics: HyperConvo.fit_transform() must be run on the Corpus first")
+            raise RuntimeError(
+                "Missing thread statistics: HyperConvo.fit_transform() must be run on the Corpus first"
+            )
 
         thread_stats = dict()
 
         for convo in convos:
             thread_stats.update(convo.meta["hyperconvo"])
 
         X = []
         roots = []
         for root, feats in thread_stats.items():
             roots.append(root)
-            row = np.array([v[1] if not (np.isnan(v[1]) or np.isinf(v[1])) else
-                            0 for v in sorted(feats.items())])
+            row = np.array(
+                [
+                    v[1] if not (np.isnan(v[1]) or np.isinf(v[1])) else 0
+                    for v in sorted(feats.items())
+                ]
+            )
             X.append(row)
         X = np.array(X)
 
         if self.norm_method.lower() == "standard":
             X = StandardScaler().fit_transform(X)
         elif self.norm_method.lower() == "none":
             pass
@@ -76,11 +87,12 @@
         else:
             raise Exception("Invalid embed_feats embedding method")
 
         emb = f(n_components=self.n_components)
         X_mid = emb.fit_transform(X) / emb.singular_values_
 
         retval = {"X": X_mid, "roots": roots}
-        if self.return_components: retval["components"] = emb.components_
+        if self.return_components:
+            retval["components"] = emb.components_
 
         corpus.add_meta("threadEmbedder", retval)
         return corpus
```

### Comparing `convokit-2.5.3/convokit/model/conversation.py` & `convokit-3.0.0/convokit/model/conversation.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+from collections import defaultdict
 from typing import Dict, List, Callable, Generator, Optional
-from .utterance import Utterance
-from .speaker import Speaker
-from convokit.util import deprecation, warn
+
+from convokit.util import warn
 from .corpusComponent import CorpusComponent
-from collections import defaultdict
-from .utteranceNode import UtteranceNode
 from .corpusUtil import *
+from .speaker import Speaker
+from .utterance import Utterance
+from .utteranceNode import UtteranceNode
 
 
 class Conversation(CorpusComponent):
     """
     Represents a discrete subset of utterances in the dataset, connected by a reply-to chain.
 
     :param owner: The Corpus that this Conversation belongs to
@@ -18,17 +19,21 @@
     :param meta: Table of initial values for conversation-level metadata
 
     :ivar id: the ID of the Conversation
     :ivar meta: A dictionary-like view object providing read-write access to
         conversation-level metadata.
     """
 
-    def __init__(self, owner, id: Optional[str] = None,
-                 utterances: Optional[List[str]] = None,
-                 meta: Optional[Dict] = None):
+    def __init__(
+        self,
+        owner,
+        id: Optional[str] = None,
+        utterances: Optional[List[str]] = None,
+        meta: Optional[Dict] = None,
+    ):
         super().__init__(obj_type="conversation", owner=owner, id=id, meta=meta)
         self._owner = owner
         self._utterance_ids: List[str] = utterances
         self._speaker_ids = None
         self.tree: Optional[UtteranceNode] = None
 
     def _add_utterance(self, utt: Utterance):
@@ -52,59 +57,44 @@
 
         :return: the Utterance with the given ID
         """
         # delegate to the owner Corpus since Conversation does not itself own
         # any Utterances
         return self._owner.get_utterance(ut_id)
 
-    def iter_utterances(self, selector: Callable[[Utterance], bool] = lambda utt: True) -> \
-            Generator[Utterance, None, None]:
+    def iter_utterances(
+        self, selector: Callable[[Utterance], bool] = lambda utt: True
+    ) -> Generator[Utterance, None, None]:
         """
         Get utterances in the Corpus, with an optional selector that filters for Utterances that should be included.
 
         :param selector: a (lambda) function that takes an Utterance and returns True or False (i.e. include / exclude).
-			By default, the selector includes all Utterances in the Conversation.
-		:return: a generator of Utterances
+                        By default, the selector includes all Utterances in the Conversation.
+                :return: a generator of Utterances
         """
         for ut_id in self._utterance_ids:
             utt = self._owner.get_utterance(ut_id)
             if selector(utt):
                 yield utt
 
-    def get_utterances_dataframe(self, selector: Callable[[Utterance], bool] = lambda utt: True,
-                                 exclude_meta: bool = False):
+    def get_utterances_dataframe(
+        self, selector: Callable[[Utterance], bool] = lambda utt: True, exclude_meta: bool = False
+    ):
         """
         Get a DataFrame of the Utterances in the Conversation with fields and metadata attributes.
-		Set an optional selector that filters for Utterances that should be included.
-		Edits to the DataFrame do not change the corpus in any way.
+                Set an optional selector that filters for Utterances that should be included.
+                Edits to the DataFrame do not change the corpus in any way.
 
         :param selector: a (lambda) function that takes an Utterance and returns True or False (i.e. include / exclude).
-			By default, the selector includes all Utterances in the Conversation.
+                        By default, the selector includes all Utterances in the Conversation.
         :param exclude_meta: whether to exclude metadata
         :return: a pandas DataFrame
         """
         return get_utterances_dataframe(self, selector, exclude_meta)
 
-    def get_usernames(self) -> List[str]:
-        """Produces a list of names of all speakers in the Conversation, which can
-        be used in calls to get_speaker() to retrieve specific speakers. Provides no
-        ordering guarantees for the list.
-
-        :return: a list of usernames
-        """
-        deprecation("get_usernames()", "get_speaker_ids()")
-        if self._speaker_ids is None:
-            # first call to get_usernames or iter_speakers; precompute cached list
-            # of usernames
-            self._speaker_ids = set()
-            for ut_id in self._utterance_ids:
-                ut = self._owner.get_utterance(ut_id)
-                self._speaker_ids.add(ut.speaker.name)
-        return list(self._speaker_ids)
-
     def get_speaker_ids(self) -> List[str]:
         """
         Produces a list of ids of all speakers in the Conversation, which can be used in calls to get_speaker()
         to retrieve specific speakers. Provides no ordering guarantees for the list.
 
         :return: a list of speaker ids
         """
@@ -123,66 +113,65 @@
 
         :return: the Speaker with the given speaker_id
         """
         # delegate to the owner Corpus since Conversation does not itself own
         # any Utterances
         return self._owner.get_speaker(speaker_id)
 
-    def get_user(self, speaker_id: str):
-        deprecation("get_user()", "get_speaker()")
-        return self.get_speaker(speaker_id)
-
-    def iter_speakers(self, selector: Callable[[Speaker], bool] = lambda speaker: True) -> Generator[Speaker, None, None]:
+    def iter_speakers(
+        self, selector: Callable[[Speaker], bool] = lambda speaker: True
+    ) -> Generator[Speaker, None, None]:
         """
         Get Speakers that have participated in the Conversation, with an optional selector that filters for Speakers
         that should be included.
 
-		:param selector: a (lambda) function that takes a Speaker and returns True or False (i.e. include / exclude).
-			By default, the selector includes all Speakers in the Conversation.
-		:return: a generator of Speakers
+                :param selector: a (lambda) function that takes a Speaker and returns True or False (i.e. include / exclude).
+                        By default, the selector includes all Speakers in the Conversation.
+                :return: a generator of Speakers
         """
         if self._speaker_ids is None:
             # first call to get_ids or iter_speakers; precompute cached list of speaker ids
             self._speaker_ids = set()
             for ut_id in self._utterance_ids:
                 ut = self._owner.get_utterance(ut_id)
                 self._speaker_ids.add(ut.speaker.id)
         for speaker_id in self._speaker_ids:
             speaker = self._owner.get_speaker(speaker_id)
             if selector(speaker):
                 yield speaker
 
-    def get_speakers_dataframe(self, selector: Optional[Callable[[Speaker], bool]] = lambda utt: True,
-                               exclude_meta: bool = False):
+    def get_speakers_dataframe(
+        self,
+        selector: Optional[Callable[[Speaker], bool]] = lambda utt: True,
+        exclude_meta: bool = False,
+    ):
         """
         Get a DataFrame of the Speakers that have participated in the Conversation with fields and metadata attributes,
         with an optional selector that filters Speakers that should be included.
         Edits to the DataFrame do not change the corpus in any way.
 
-		:param exclude_meta: whether to exclude metadata
-		:param selector: selector: a (lambda) function that takes a Speaker and returns True or False
-			(i.e. include / exclude). By default, the selector includes all Speakers in the Conversation.
-		:return: a pandas DataFrame
-		"""
+                :param exclude_meta: whether to exclude metadata
+                :param selector: selector: a (lambda) function that takes a Speaker and returns True or False
+                        (i.e. include / exclude). By default, the selector includes all Speakers in the Conversation.
+                :return: a pandas DataFrame
+        """
         return get_speakers_dataframe(self, selector, exclude_meta)
 
-    def iter_users(self, selector=lambda speaker: True):
-        deprecation("iter_users()", "iter_speakers()")
-        return self.iter_speakers(selector)
-
     def print_conversation_stats(self):
         """
         Helper function for printing the number of Utterances and Spekaers in the Conversation.
 
         :return: None (prints output)
         """
         print("Number of Utterances: {}".format(len(list(self.iter_utterances()))))
         print("Number of Speakers: {}".format(len(list(self.iter_speakers()))))
 
-    def get_chronological_speaker_list(self, selector: Callable[[Speaker], bool] = lambda speaker: True):
+    def get_chronological_speaker_list(
+        self, selector: Callable[[Speaker], bool] = lambda speaker: True
+    ):
         """
         Get the speakers in the conversation sorted in chronological order (speakers may appear more than once)
 
         :param selector: (lambda) function for which speakers should be included; all speakers are included by default
         :return: list of speakers for each chronological utterance
         """
         try:
@@ -194,68 +183,83 @@
     def check_integrity(self, verbose: bool = True) -> bool:
         """
         Check the integrity of this Conversation; i.e. do the constituent utterances form a complete reply-to chain?
 
         :param verbose: whether to print errors indicating the problems with the Conversation
         :return: True if the conversation structure is complete else False
         """
-        if verbose: print("Checking reply-to chain of Conversation", self.id)
+        if verbose:
+            print("Checking reply-to chain of Conversation", self.id)
         utt_reply_tos = {utt.id: utt.reply_to for utt in self.iter_utterances()}
         target_utt_ids = set(list(utt_reply_tos.values()))
         speaker_utt_ids = set(list(utt_reply_tos.keys()))
-        root_utt_id = target_utt_ids - speaker_utt_ids # There should only be 1 root_utt_id: None
+        root_utt_id = target_utt_ids - speaker_utt_ids  # There should only be 1 root_utt_id: None
 
         if len(root_utt_id) != 1:
             if verbose:
                 for utt_id in root_utt_id:
                     if utt_id is not None:
                         warn("ERROR: Missing utterance {}".format(utt_id))
             return False
         else:
             root_id = list(root_utt_id)[0]
             if root_id is not None:
-                if verbose: warn("ERROR: Missing utterance {}".format(root_id))
+                if verbose:
+                    warn("ERROR: Missing utterance {}".format(root_id))
                 return False
 
         # sanity check
         utts_replying_to_none = 0
         for utt in self.iter_utterances():
             if utt.reply_to is None:
                 utts_replying_to_none += 1
 
         if utts_replying_to_none > 1:
-            if verbose: warn("ERROR: Found more than one Utterance replying to None.")
+            if verbose:
+                warn("ERROR: Found more than one Utterance replying to None.")
             return False
 
-        circular = [utt_id for utt_id, utt_reply_to in utt_reply_tos.items() if utt_id == utt_reply_to]
+        circular = [
+            utt_id for utt_id, utt_reply_to in utt_reply_tos.items() if utt_id == utt_reply_to
+        ]
         if len(circular) > 0:
-            if verbose: warn("ERROR: Found utterances with .reply_to pointing to themselves: {}".format(circular))
+            if verbose:
+                warn(
+                    "ERROR: Found utterances with .reply_to pointing to themselves: {}".format(
+                        circular
+                    )
+                )
             return False
 
-        if verbose: print("No issues found.\n")
+        if verbose:
+            print("No issues found.\n")
         return True
 
     def initialize_tree_structure(self):
         if not self.check_integrity(verbose=False):
-            raise ValueError("Conversation {} reply-to chain does not form a valid tree.".format(self.id))
+            raise ValueError(
+                "Conversation {} reply-to chain does not form a valid tree.".format(self.id)
+            )
 
         root_node_id = None
         # Find root node
         for utt in self.iter_utterances():
             if utt.reply_to is None:
                 root_node_id = utt.id
 
         parent_to_children_ids = defaultdict(list)
         for utt in self.iter_utterances():
             parent_to_children_ids[utt.reply_to].append(utt.id)
 
         wrapped_utts = {utt.id: UtteranceNode(utt) for utt in self.iter_utterances()}
 
         for parent_id, wrapped_utt in wrapped_utts.items():
-            wrapped_utt.set_children([wrapped_utts[child_id] for child_id in parent_to_children_ids[parent_id]])
+            wrapped_utt.set_children(
+                [wrapped_utts[child_id] for child_id in parent_to_children_ids[parent_id]]
+            )
 
         self.tree = wrapped_utts[root_node_id]
 
     def traverse(self, traversal_type: str, as_utterance: bool = True):
         """
         Traverse through the Conversation tree structure in a breadth-first search ('bfs'), depth-first search (dfs),
         pre-order ('preorder'), or post-order ('postorder') way.
@@ -263,35 +267,41 @@
         :param traversal_type: dfs, bfs, preorder, or postorder
         :param as_utterance: whether the iterator should yield the utterance (True) or the utterance node (False)
         :return: an iterator of the utterances or utterance nodes
         """
         if self.tree is None:
             self.initialize_tree_structure()
             if self.tree is None:
-                raise ValueError("Failed to traverse because Conversation reply-to chain does not form a valid tree.")
-
-        traversals = {'bfs': self.tree.bfs_traversal,
-                      'dfs': self.tree.dfs_traversal,
-                      'preorder': self.tree.pre_order,
-                      'postorder': self.tree.post_order}
+                raise ValueError(
+                    "Failed to traverse because Conversation reply-to chain does not form a valid tree."
+                )
+
+        traversals = {
+            "bfs": self.tree.bfs_traversal,
+            "dfs": self.tree.dfs_traversal,
+            "preorder": self.tree.pre_order,
+            "postorder": self.tree.post_order,
+        }
 
         for utt_node in traversals[traversal_type]():
             yield utt_node.utt if as_utterance else utt_node
 
     def get_subtree(self, root_utt_id):
         """
         Get the utterance node of the specified input id
 
         :param root_utt_id: id of the root node that the subtree starts from
         :return: UtteranceNode object
         """
         if self.tree is None:
             self.initialize_tree_structure()
             if self.tree is None:
-                raise ValueError("Failed to traverse because Conversation reply-to chain does not form a valid tree.")
+                raise ValueError(
+                    "Failed to traverse because Conversation reply-to chain does not form a valid tree."
+                )
 
         for utt_node in self.tree.bfs_traversal():
             if utt_node.utt.id == root_utt_id:
                 return utt_node
 
     def get_longest_paths(self) -> List[List[Utterance]]:
         """
@@ -300,90 +310,119 @@
         exists, a list containing a single list of Utterances is returned.
 
         :return: a list of lists of Utterances
         """
         if self.tree is None:
             self.initialize_tree_structure()
             if self.tree is None:
-                raise ValueError("Failed to traverse because Conversation reply-to chain does not form a valid tree.")
+                raise ValueError(
+                    "Failed to traverse because Conversation reply-to chain does not form a valid tree."
+                )
 
         paths = self.get_root_to_leaf_paths()
         max_len = max(len(path) for path in paths)
 
         return [p for p in paths if len(p) == max_len]
 
-    def _print_convo_helper(self, root: str, indent: int, reply_to_dict: Dict[str, str],
-                            utt_info_func: Callable[[Utterance], str],
-                            limit=None) -> None:
+    def _print_convo_helper(
+        self,
+        root: str,
+        indent: int,
+        reply_to_dict: Dict[str, str],
+        utt_info_func: Callable[[Utterance], str],
+        limit=None,
+    ) -> None:
         """
         Helper function for print_conversation_structure()
         """
         if limit is not None:
-            if self.get_utterance(root).meta['order'] > limit:
+            if self.get_utterance(root).meta["order"] > limit:
                 return
-        print(" "*indent + utt_info_func(self.get_utterance(root)))
+        print(" " * indent + utt_info_func(self.get_utterance(root)))
         children_utt_ids = [k for k, v in reply_to_dict.items() if v == root]
         for child_utt_id in children_utt_ids:
-            self._print_convo_helper(root=child_utt_id, indent=indent+4,
-                                     reply_to_dict=reply_to_dict, utt_info_func=utt_info_func, limit=limit)
-
-    def print_conversation_structure(self, utt_info_func: Callable[[Utterance], str] = lambda utt: utt.speaker.id, limit: int = None) -> None:
+            self._print_convo_helper(
+                root=child_utt_id,
+                indent=indent + 4,
+                reply_to_dict=reply_to_dict,
+                utt_info_func=utt_info_func,
+                limit=limit,
+            )
+
+    def print_conversation_structure(
+        self,
+        utt_info_func: Callable[[Utterance], str] = lambda utt: utt.speaker.id,
+        limit: int = None,
+    ) -> None:
         """
         Prints an indented representation of utterances in the Conversation with conversation reply-to structure
         determining the indented level. The details of each utterance to be printed can be configured.
 
         If limit is set to a value other than None, this will annotate utterances with an 'order' metadata indicating
         their temporal order in the conversation, where the first utterance in the conversation is annotated with 1.
 
         :param utt_info_func: callable function taking an utterance as input and returning a string of the desired
             utterance information. By default, this is a lambda function returning the utterance's speaker's id
         :param limit: maximum number of utterances to print out. if k, this includes the first k utterances.
         :return: None. Prints to stdout.
         """
         if not self.check_integrity(verbose=False):
-            raise ValueError("Could not print conversation structure: The utterance reply-to chain is broken. "
-                             "Try check_integrity() to diagnose the problem.")
+            raise ValueError(
+                "Could not print conversation structure: The utterance reply-to chain is broken. "
+                "Try check_integrity() to diagnose the problem."
+            )
 
         if limit is not None:
             assert isinstance(limit, int)
             for idx, utt in enumerate(self.get_chronological_utterance_list()):
-                utt.meta['order'] = idx + 1
+                utt.meta["order"] = idx + 1
 
         root_utt_id = [utt for utt in self.iter_utterances() if utt.reply_to is None][0].id
         reply_to_dict = {utt.id: utt.reply_to for utt in self.iter_utterances()}
 
-        self._print_convo_helper(root=root_utt_id, indent=0, reply_to_dict=reply_to_dict,
-                                 utt_info_func=utt_info_func, limit=limit)
+        self._print_convo_helper(
+            root=root_utt_id,
+            indent=0,
+            reply_to_dict=reply_to_dict,
+            utt_info_func=utt_info_func,
+            limit=limit,
+        )
 
     def get_utterances_dataframe(self, selector=lambda utt: True, exclude_meta: bool = False):
         """
-		Get a DataFrame of the Utterances in the COnversation with fields and metadata attributes.
-		Set an optional selector that filters Utterances that should be included.
-		Edits to the DataFrame do not change the corpus in any way.
-
-		:param exclude_meta: whether to exclude metadata
-		:param selector: a (lambda) function that takes a Utterance and returns True or False (i.e. include / exclude).
-			By default, the selector includes all Utterances in the Conversation.
-		:return: a pandas DataFrame
-		"""
+        Get a DataFrame of the Utterances in the COnversation with fields and metadata attributes.
+        Set an optional selector that filters Utterances that should be included.
+        Edits to the DataFrame do not change the corpus in any way.
+
+        :param exclude_meta: whether to exclude metadata
+        :param selector: a (lambda) function that takes a Utterance and returns True or False (i.e. include / exclude).
+                By default, the selector includes all Utterances in the Conversation.
+        :return: a pandas DataFrame
+        """
         return get_utterances_dataframe(self, selector, exclude_meta)
 
-    def get_chronological_utterance_list(self, selector: Callable[[Utterance], bool] = lambda utt: True):
+    def get_chronological_utterance_list(
+        self, selector: Callable[[Utterance], bool] = lambda utt: True
+    ):
         """
         Get the utterances in the conversation sorted in increasing order of timestamp
 
         :param selector: function for which utterances should be included; all utterances are included by default
         :return: list of utterances, sorted by timestamp
         """
         try:
-            return sorted([utt for utt in self.iter_utterances(selector)], key=lambda utt: utt.timestamp)
+            return sorted(
+                [utt for utt in self.iter_utterances(selector)], key=lambda utt: utt.timestamp
+            )
         except TypeError as e:
             raise ValueError(str(e) + "\nUtterance timestamps may not have been set correctly.")
 
-    def _get_path_from_leaf_to_root(self, leaf_utt: Utterance, root_utt: Utterance) -> List[Utterance]:
+    def _get_path_from_leaf_to_root(
+        self, leaf_utt: Utterance, root_utt: Utterance
+    ) -> List[Utterance]:
         """
         Helper function for get_root_to_leaf_paths, which returns the path for a given leaf_utt and root_utt
         """
         if leaf_utt == root_utt:
             return [leaf_utt]
         path = [leaf_utt]
         root_id = root_utt.id
@@ -397,33 +436,43 @@
         """
         Get the paths (stored as a list of lists of utterances) from the root to each of the leaves
         in the conversational tree
 
         :return: List of lists of Utterances
         """
         if not self.check_integrity(verbose=False):
-            raise ValueError("Conversation failed integrity check. "
-                             "It is either missing an utterance in the reply-to chain and/or has multiple root nodes. "
-                             "Run check_integrity() to diagnose issues.")
+            raise ValueError(
+                "Conversation failed integrity check. "
+                "It is either missing an utterance in the reply-to chain and/or has multiple root nodes. "
+                "Run check_integrity() to diagnose issues."
+            )
 
         utt_reply_tos = {utt.id: utt.reply_to for utt in self.iter_utterances()}
         target_utt_ids = set(list(utt_reply_tos.values()))
         speaker_utt_ids = set(list(utt_reply_tos.keys()))
-        root_utt_id = target_utt_ids - speaker_utt_ids # There should only be 1 root_utt_id: None
+        root_utt_id = target_utt_ids - speaker_utt_ids  # There should only be 1 root_utt_id: None
         assert len(root_utt_id) == 1
         root_utt = [utt for utt in self.iter_utterances() if utt.reply_to is None][0]
         leaf_utt_ids = speaker_utt_ids - target_utt_ids
 
-        paths = [self._get_path_from_leaf_to_root(self.get_utterance(leaf_utt_id), root_utt)
-                 for leaf_utt_id in leaf_utt_ids]
+        paths = [
+            self._get_path_from_leaf_to_root(self.get_utterance(leaf_utt_id), root_utt)
+            for leaf_utt_id in leaf_utt_ids
+        ]
         return paths
 
+    @staticmethod
+    def generate_default_conversation_id(utterance_id):
+        return f"__default_conversation__{utterance_id}"
+
     def __hash__(self):
         return super().__hash__()
 
     def __eq__(self, other):
         if not isinstance(other, Conversation):
             return False
         return self.id == other.id and set(self._utterance_ids) == set(other._utterance_ids)
 
     def __str__(self):
-        return "Conversation('id': {}, 'utterances': {}, 'meta': {})".format(repr(self.id), self._utterance_ids, self.meta)
+        return "Conversation('id': {}, 'utterances': {}, 'meta': {})".format(
+            repr(self.id), self._utterance_ids, self.meta
+        )
```

### Comparing `convokit-2.5.3/convokit/model/convoKitIndex.py` & `convokit-3.0.0/convokit/model/convoKitIndex.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,67 +1,84 @@
 from typing import Optional, Dict, List
 
 
 class ConvoKitIndex:
-    def __init__(self, owner, utterances_index: Optional[Dict[str, List[str]]] = None,
-                 speakers_index: Optional[Dict[str, List[str]]] = None,
-                 conversations_index: Optional[Dict[str, List[str]]] = None,
-                 overall_index: Optional[Dict[str, List[str]]] = None,
-                 vectors: Optional[List[str]] = None,
-                 version: Optional[int] = 0):
+    def __init__(
+        self,
+        owner,
+        utterances_index: Optional[Dict[str, List[str]]] = None,
+        speakers_index: Optional[Dict[str, List[str]]] = None,
+        conversations_index: Optional[Dict[str, List[str]]] = None,
+        overall_index: Optional[Dict[str, List[str]]] = None,
+        vectors: Optional[List[str]] = None,
+        version: Optional[int] = 0,
+    ):
         self.owner = owner
         self.utterances_index = utterances_index if utterances_index is not None else {}
         self.speakers_index = speakers_index if speakers_index is not None else {}
         self.conversations_index = conversations_index if conversations_index is not None else {}
         self.overall_index = overall_index if overall_index is not None else {}
-        self.indices = {'utterance': self.utterances_index,
-                        'conversation': self.conversations_index,
-                        'speaker': self.speakers_index,
-                        'corpus': self.overall_index}
+        self.indices = {
+            "utterance": self.utterances_index,
+            "conversation": self.conversations_index,
+            "speaker": self.speakers_index,
+            "corpus": self.overall_index,
+        }
         self.vectors = set(vectors) if vectors is not None else set()
         self.version = version
-        self.type_check = True # toggle-able to enable/disable type checks on metadata additions
-        self.lock_metadata_deletion = {'utterance': True,
-                                       'conversation': True,
-                                       'speaker': True}
+        self.type_check = True  # toggle-able to enable/disable type checks on metadata additions
+        self.lock_metadata_deletion = {"utterance": True, "conversation": True, "speaker": True}
+
+    def create_new_index(self, obj_type: str, key: str):
+        """
+        Create a new entry in the obj_type index with a blank type list,
+        representing an "Any" type which might be later refined.
+
+        :param obj_type: utterance, conversation, or speaker
+        :param key: string
+        :param class_type: class type
+        """
+        if key not in self.indices[obj_type]:
+            self.indices[obj_type][key] = []
 
     def update_index(self, obj_type: str, key: str, class_type: str):
         """
         Append the class_type to the index
 
         :param obj_type: utterance, conversation, or speaker
         :param key: string
         :param class_type: class type
         :return: None
         """
         assert type(key) == str
-        assert 'class' in class_type or class_type == 'bin'
+        assert "class" in class_type or class_type == "bin"
         if key not in self.indices[obj_type]:
             self.indices[obj_type][key] = []
         self.indices[obj_type][key].append(class_type)
 
     def set_index(self, obj_type: str, key: str, class_type: str):
         """
         Set the class_type of the index as [`class_type`].
 
         :param obj_type: utterance, conversation, or speaker
         :param key: string
         :param class_type: class type
         :return: None
         """
         assert type(key) == str
-        assert 'class' in class_type or class_type == 'bin'
+        assert "class" in class_type or class_type == "bin"
         self.indices[obj_type][key] = [class_type]
 
     def get_index(self, obj_type: str):
         return self.indices[obj_type]
 
     def del_from_index(self, obj_type: str, key: str):
         assert type(key) == str
-        if key not in self.indices[obj_type]: return
+        if key not in self.indices[obj_type]:
+            return
         del self.indices[obj_type][key]
         #
         # corpus = self.owner
         # for corpus_obj in corpus.iter_objs(obj_type):
         #     if key in corpus_obj.meta:
         #         del corpus_obj.meta[key]
 
@@ -73,15 +90,15 @@
 
     def update_from_dict(self, meta_index: Dict):
         self.conversations_index.update(meta_index["conversations-index"])
         self.utterances_index.update(meta_index["utterances-index"])
         speaker_index = "speakers-index" if "speakers-index" in meta_index else "users-index"
         self.speakers_index.update(meta_index[speaker_index])
         self.overall_index.update(meta_index["overall-index"])
-        self.vectors = set(meta_index.get('vectors', set()))
+        self.vectors = set(meta_index.get("vectors", set()))
         for index in self.indices.values():
             for k, v in index.items():
                 if isinstance(v, str):
                     index[k] = [v]
 
         self.version = meta_index["version"]
 
@@ -89,22 +106,22 @@
         retval = dict()
         retval["utterances-index"] = self.utterances_index
         retval["speakers-index"] = self.speakers_index
         retval["conversations-index"] = self.conversations_index
         retval["overall-index"] = self.overall_index
 
         if force_version is None:
-            retval['version'] = self.version + 1
+            retval["version"] = self.version + 1
         else:
-            retval['version'] = force_version
+            retval["version"] = force_version
 
         if exclude_vectors is not None:
-            retval['vectors'] = list(self.vectors - set(exclude_vectors))
+            retval["vectors"] = list(self.vectors - set(exclude_vectors))
         else:
-            retval['vectors'] = list(self.vectors)
+            retval["vectors"] = list(self.vectors)
 
         return retval
 
     def enable_type_check(self):
         self.type_check = True
 
     def disable_type_check(self):
```

### Comparing `convokit-2.5.3/convokit/model/convoKitMatrix.py` & `convokit-3.0.0/convokit/model/convoKitMatrix.py`

 * *Files 4% similar despite different names*

```diff
@@ -22,15 +22,17 @@
     :ivar matrix: the matrix data
     :ivar ids: ids corresponding to rows
     :ivar columns: names corresponding to columns
     :ivar ids_to_idx: a mapping from id to the row index
     :ivar cols_to_idx: a mapping from column name to the column index
     """
 
-    def __init__(self, name, matrix, ids: Optional[List[str]] = None, columns: Optional[List[str]] = None):
+    def __init__(
+        self, name, matrix, ids: Optional[List[str]] = None, columns: Optional[List[str]] = None
+    ):
         self.name = name
         self._matrix = matrix
         self._sparse = isinstance(self._matrix, scipy.sparse.csr.csr_matrix)
         self.ids = np.arange(matrix.shape[0]) if ids is None else ids
         self.columns = np.arange(matrix.shape[1]) if columns is None else columns
         self.ids_to_idx = {id: idx for idx, id in enumerate(self.ids)}
         self.cols_to_idx = {col: idx for idx, col in enumerate(self.columns)}
@@ -46,31 +48,40 @@
             self._matrix = value
             self._sparse = isinstance(value, scipy.sparse.csr.csr_matrix)
         else:
             raise ValueError("Matrix must be a numpy ndarray or a scipy csr_matrix.")
 
     @matrix.deleter
     def matrix(self):
-        warn("ConvoKitMatrix's internal matrix cannot be deleted. Use Corpus.delete_vector_matrix() instead.")
+        warn(
+            "ConvoKitMatrix's internal matrix cannot be deleted. Use Corpus.delete_vector_matrix() instead."
+        )
 
     def _initialization_checks(self):
         try:
             self.matrix.shape
         except AttributeError:
             raise AttributeError("Input matrix is not a numpy or scipy matrix.")
 
         try:
             assert len(self.ids) == self.matrix.shape[0]
             if self.columns is not None:
                 assert len(self.columns) == self.matrix.shape[1]
         except AssertionError:
-            raise ValueError("Input matrix dimensions {} do not match "
-                             "length of ids and/or columns".format(self.matrix.shape))
-
-    def get_vectors(self, ids: Optional[List[str]] = None, columns: Optional[List[str]] = None, as_dataframe: bool=False):
+            raise ValueError(
+                "Input matrix dimensions {} do not match "
+                "length of ids and/or columns".format(self.matrix.shape)
+            )
+
+    def get_vectors(
+        self,
+        ids: Optional[List[str]] = None,
+        columns: Optional[List[str]] = None,
+        as_dataframe: bool = False,
+    ):
         """
 
         :param ids: optional list of object ids to get vectors for; all by default
         :param columns: optional list of named columns of the vector to include; all by default
         :param as_dataframe: whether to return the vector as a dataframe (True) or in its raw array form (False). False
             by default.
         :return: a vector matrix (either np.ndarray or csr_matrix) or a pandas dataframe
@@ -85,15 +96,17 @@
             return self.matrix[id_indices][:, col_indices]
         else:
             mat = self.matrix.toarray() if issparse(self.matrix) else self.matrix
             return pd.DataFrame(mat[id_indices][:, col_indices], index=ids, columns=cols)
 
     def to_dict(self):
         if self.columns is None:
-            raise ValueError("Matrix columns are missing. Update matrix.columns with a list of column names.")
+            raise ValueError(
+                "Matrix columns are missing. Update matrix.columns with a list of column names."
+            )
         d = dict()
         for id, idx in self.ids_to_idx.items():
             row = self.matrix[idx]
             d[id] = {self.columns[i]: v for i, v in enumerate(row)}
         return d
 
     def to_dataframe(self) -> pd.DataFrame:
@@ -111,15 +124,15 @@
     def from_file(filepath):
         """
         Initialize a ConvoKitMatrix from a file of form "vector.[name].p".
 
         :param filepath:
         :return:
         """
-        with open(filepath, 'rb') as f:
+        with open(filepath, "rb") as f:
             retval: ConvoKitMatrix = pickle.load(f)
             if not retval._sparse:
                 retval.matrix = retval.matrix.toarray()
             return retval
 
     @staticmethod
     def from_dir(dirpath, matrix_name):
@@ -127,15 +140,15 @@
         Initialize a ConvoKitMatrix of the specified `matrix_name` from a specified directory `dirpath`.
 
         :param dirpath: path to Corpus directory
         :param matrix_name: name of vector matrix
         :return: the initialized ConvoKitMatrix
         """
         try:
-            with open(os.path.join(dirpath, 'vectors.{}.p'.format(matrix_name)), 'rb') as f:
+            with open(os.path.join(dirpath, "vectors.{}.p".format(matrix_name)), "rb") as f:
                 retval: ConvoKitMatrix = pickle.load(f)
                 if not retval._sparse:
                     retval.matrix = retval.matrix.toarray()
                 return retval
         except FileNotFoundError:
             warn("Could not find vector with name: {} at {}.".format(matrix_name, dirpath))
             return None
@@ -146,39 +159,41 @@
 
         :param dirpath: directory path to Corpus
         :return: None
         """
         if not issparse(self.matrix):
             temp = self.matrix
             self.matrix = csr_matrix(self.matrix)
-            with open(os.path.join(dirpath, 'vectors.{}.p'.format(self.name)), 'wb') as f:
+            with open(os.path.join(dirpath, "vectors.{}.p".format(self.name)), "wb") as f:
                 pickle.dump(self, f)
             self.matrix = temp
         else:
-            with open(os.path.join(dirpath, 'vectors.{}.p'.format(self.name)), 'wb') as f:
+            with open(os.path.join(dirpath, "vectors.{}.p".format(self.name)), "wb") as f:
                 pickle.dump(self, f)
 
     def subset(self, ids: Optional[List[str]] = None, columns: Optional[List[str]] = None):
         """
         Get a (subset) copy of the ConvoKitMatrix object according to specified subset of ids and columns
         :param ids: list of ids to be included in the subset; all by default
         :param columns: list of columns to be included in the subset; all by default
         :return: a new ConvoKitMatrix object with the subset of
         """
         ids = ids if ids is not None else self.ids
         columns = columns if columns is not None else self.columns
 
         submatrix = self.to_dataframe().loc[ids][columns]
-        return ConvoKitMatrix(name=self.name,
-                              matrix=csr_matrix(submatrix.values.astype('float64')),
-                              ids=ids,
-                              columns=columns)
+        return ConvoKitMatrix(
+            name=self.name,
+            matrix=csr_matrix(submatrix.values.astype("float64")),
+            ids=ids,
+            columns=columns,
+        )
 
     @staticmethod
-    def hstack(name: str, matrices: List['ConvoKitMatrix']):
+    def hstack(name: str, matrices: List["ConvoKitMatrix"]):
         """
         Combines multiple ConvoKitMatrices into a single ConvoKitMatrix by stacking them horizontally (i.e. each
         constituent matrix must have the same ids).
 
         :param name: name of new matrix
         :param matrices: constituent ConvoKiMatrices
         :return: a new ConvoKitMatrix
@@ -188,15 +203,15 @@
         columns = []
         for m in matrices:
             columns.extend(m.columns)
 
         return ConvoKitMatrix(name=name, matrix=stacked, ids=matrices[0].ids, columns=columns)
 
     @staticmethod
-    def vstack(name: str, matrices: List['ConvoKitMatrix']):
+    def vstack(name: str, matrices: List["ConvoKitMatrix"]):
         """
         Combines multiple ConvoKitMatrices into a single ConvoKitMatrix by stacking them horizontally (i.e. each
         constituent matrix must have the same columns).
 
         :param name: name of new matrix
         :param matrices: constituent ConvoKiMatrices
         :return: a new ConvoKitMatrix
```

### Comparing `convokit-2.5.3/convokit/model/corpus.py` & `convokit-3.0.0/convokit/model/corpus.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,26 +1,30 @@
+import random
+import shutil
+from typing import Collection, Callable, Set, Generator, Tuple, ValuesView, Union
+
 from pandas import DataFrame
 from tqdm import tqdm
-from typing import List, Collection, Callable, Set, Generator, Tuple, Optional, ValuesView, Union
-from .corpusHelper import *
-from convokit.util import deprecation, warn
-from .corpusUtil import *
-from .convoKitIndex import ConvoKitIndex
-import random
-from .convoKitMeta import ConvoKitMeta
+
+from convokit.convokitConfig import ConvoKitConfig
+from convokit.util import create_safe_id
 from .convoKitMatrix import ConvoKitMatrix
-import shutil
+from .corpusUtil import *
+from .corpus_helpers import *
+from .backendMapper import BackendMapper
 
 
 class Corpus:
     """
     Represents a dataset, which can be loaded from a folder or constructed from a list of utterances.
 
     :param filename: Path to a folder containing a Corpus or to an utterances.jsonl / utterances.json file to load
     :param utterances: list of utterances to initialize Corpus from
+    :param db_collection_prefix: if a db backend is used, this determines how the database will be named. If not specified, a random name will be used.
+    :param db_host: if specified, and a db backend is used, connect to the database at this URL. If not specified, will default to the db_host in the ConvoKit global configuration file.
     :param preload_vectors: list of names of vectors to be preloaded from directory; by default,
         no vectors are loaded but can be loaded any time after corpus initialization (i.e. vectors are lazy-loaded).
     :param utterance_start_index: if loading from directory and the corpus folder contains utterances.jsonl, specify the
         line number (zero-indexed) to begin parsing utterances from
     :param utterance_end_index: if loading from directory and the corpus folder contains utterances.jsonl, specify the
         line number (zero-indexed) of the last utterance to be parsed.
     :param merge_lines: whether to merge adjacent lines from same speaker if multiple consecutive utterances belong to
@@ -30,154 +34,247 @@
     :param exclude_speaker_meta: speaker metadata to be ignored
     :param exclude_overall_meta: overall metadata to be ignored
     :param disable_type_check: whether to do type checking when loading the Corpus from a directory.
         Type-checking ensures that the ConvoKitIndex is initialized correctly. However, it may be unnecessary if the
         index.json is already accurate and disabling it will allow for a faster corpus load. This parameter is set to
         True by default, i.e. type-checking is not carried out.
 
+    :param backend: specify the backend type, either “mem” or “db”, default to “mem”.
+    :param backend_mapper: (advanced usage only) if provided, use this as the BackendMapper instance instead of initializing a new one.
+
     :ivar meta_index: index of Corpus metadata
     :ivar vectors: the vectors stored in the Corpus
     :ivar corpus_dirpath: path to the directory the corpus was loaded from
     """
 
-    def __init__(self, filename: Optional[str] = None, utterances: Optional[List[Utterance]] = None,
-                 preload_vectors: List[str] = None, utterance_start_index: int = None,
-                 utterance_end_index: int = None, merge_lines: bool = False,
-                 exclude_utterance_meta: Optional[List[str]] = None,
-                 exclude_conversation_meta: Optional[List[str]] = None,
-                 exclude_speaker_meta: Optional[List[str]] = None,
-                 exclude_overall_meta: Optional[List[str]] = None,
-                 disable_type_check=True):
-
-        if filename is None:
-            self.corpus_dirpath = None
-        elif os.path.isdir(filename):
-            self.corpus_dirpath = filename
-        else:
-            self.corpus_dirpath = os.path.dirname(filename)
+    def __init__(
+        self,
+        filename: Optional[str] = None,
+        utterances: Optional[List[Utterance]] = None,
+        db_collection_prefix: Optional[str] = None,
+        db_host: Optional[str] = None,
+        preload_vectors: List[str] = None,
+        utterance_start_index: int = None,
+        utterance_end_index: int = None,
+        merge_lines: bool = False,
+        exclude_utterance_meta: Optional[List[str]] = None,
+        exclude_conversation_meta: Optional[List[str]] = None,
+        exclude_speaker_meta: Optional[List[str]] = None,
+        exclude_overall_meta: Optional[List[str]] = None,
+        disable_type_check=True,
+        backend: Optional[str] = None,
+        backend_mapper: Optional[BackendMapper] = None,
+    ):
+        self.config = ConvoKitConfig()
+        self.corpus_dirpath = get_corpus_dirpath(filename)
+
+        # configure corpus ID (optional for mem mode, required for DB mode)
+        if backend is None:
+            backend = self.config.default_backend
+        if db_collection_prefix is None and filename is None and backend == "db":
+            db_collection_prefix = create_safe_id()
+            warn(
+                "You are in DB mode, but no collection prefix was specified and no filename was given from which to infer one."
+                "Will use a randomly generated unique prefix " + db_collection_prefix
+            )
+        self.id = get_corpus_id(db_collection_prefix, filename, backend)
+        self.backend = backend
+        self.backend_mapper = initialize_backend(self, backend_mapper, backend, db_host)
 
         self.meta_index = ConvoKitIndex(self)
-        self.meta = ConvoKitMeta(self.meta_index, 'corpus')
+        self.meta = ConvoKitMeta(self, self.meta_index, "corpus")
 
-        # private storage
+        # private backend
         self._vector_matrices = dict()
 
         convos_data = defaultdict(dict)
-        if exclude_utterance_meta is None: exclude_utterance_meta = []
-        if exclude_conversation_meta is None: exclude_conversation_meta = []
-        if exclude_speaker_meta is None: exclude_speaker_meta = []
-        if exclude_overall_meta is None: exclude_overall_meta = []
-
-        # Construct corpus from file or directory
-        if filename is not None:
-            if disable_type_check: self.meta_index.disable_type_check()
-            if os.path.isdir(filename):
-                utterances = load_uttinfo_from_dir(filename, utterance_start_index,
-                                                   utterance_end_index, exclude_utterance_meta)
-
-                speakers_data = load_speakers_data_from_dir(filename, exclude_speaker_meta)
-                convos_data = load_convos_data_from_dir(filename, exclude_conversation_meta)
-                load_corpus_meta_from_dir(filename, self.meta, exclude_overall_meta)
-
-                with open(os.path.join(filename, "index.json"), "r") as f:
-                    idx_dict = json.load(f)
-                    self.meta_index.update_from_dict(idx_dict)
-
-                # load all processed text information, but don't load actual text.
-                # also checks if the index file exists.
-                # try:
-                #     with open(os.path.join(filename, "processed_text.index.json"), "r") as f:
-                #         self.processed_text = {k: {} for k in json.load(f)}
-                # except:
-                #     pass
-
-                # unpack binary data for utterances
-                unpack_binary_data_for_utts(utterances, filename, self.meta_index.utterances_index,
-                                            exclude_utterance_meta, KeyMeta)
-                # unpack binary data for speakers
-                unpack_binary_data(filename, speakers_data, self.meta_index.speakers_index, "speaker",
-                                   exclude_speaker_meta)
-
-                # unpack binary data for conversations
-                unpack_binary_data(filename, convos_data, self.meta_index.conversations_index, "convo",
-                                   exclude_conversation_meta)
-
-                # unpack binary data for overall corpus
-                unpack_binary_data(filename, self.meta, self.meta_index.overall_index, "overall", exclude_overall_meta)
-
-            else:
-                speakers_data = defaultdict(dict)
-                convos_data = defaultdict(dict)
-                utterances = load_from_utterance_file(filename, utterance_start_index, utterance_end_index)
-
-            self.utterances = dict()
-            self.speakers = dict()
-
-            initialize_speakers_and_utterances_objects(self, self.utterances, utterances, self.speakers, speakers_data)
+        if exclude_utterance_meta is None:
+            exclude_utterance_meta = []
+        if exclude_conversation_meta is None:
+            exclude_conversation_meta = []
+        if exclude_speaker_meta is None:
+            exclude_speaker_meta = []
+        if exclude_overall_meta is None:
+            exclude_overall_meta = []
+
+        if filename is not None and backend == "db":
+            # JSON-to-DB construction mode uses a specialized code branch, which
+            # optimizes for this use case by using direct batch insertions into the
+            # DB rather than going through the BackendMapper, hence improving
+            # efficiency.
+
+            with open(os.path.join(filename, "index.json"), "r") as f:
+                idx_dict = json.load(f)
+                self.meta_index.update_from_dict(idx_dict)
+
+            # populate the DB with the contents of the source file
+            ids_in_db = populate_db_from_file(
+                filename,
+                self.backend_mapper.db,
+                self.id,
+                self.meta_index,
+                utterance_start_index,
+                utterance_end_index,
+                exclude_utterance_meta,
+                exclude_conversation_meta,
+                exclude_speaker_meta,
+                exclude_overall_meta,
+            )
+
+            # with the BackendMapper's DB now populated, initialize the corresponding
+            # CorpusComponent instances.
+            init_corpus_from_backend_manager(self, ids_in_db)
 
             self.meta_index.enable_type_check()
-
             # load preload_vectors
             if preload_vectors is not None:
                 for vector_name in preload_vectors:
                     matrix = ConvoKitMatrix.from_dir(self.corpus_dirpath, vector_name)
                     if matrix is not None:
                         self._vector_matrices[vector_name] = matrix
 
-        elif utterances is not None:  # Construct corpus from utterances list
-            self.speakers = {u.speaker.id: u.speaker for u in utterances}
-            self.utterances = {u.id: u for u in utterances}
-            for _, speaker in self.speakers.items():
-                speaker.owner = self
-            for _, utt in self.utterances.items():
-                utt.owner = self
-
-        if merge_lines:
-            self.utterances = merge_utterance_lines(self.utterances)
-
-        if disable_type_check: self.meta_index.disable_type_check()
-        self.conversations = initialize_conversations(self, self.utterances, convos_data)
-        self.meta_index.enable_type_check()
-        self.update_speakers_data()
+            if merge_lines:
+                self.utterances = merge_utterance_lines(self.utterances)
+        else:
+            # Construct corpus from file or directory
+            if filename is not None:
+                if disable_type_check:
+                    self.meta_index.disable_type_check()
+                if os.path.isdir(filename):
+                    utterances = load_utterance_info_from_dir(
+                        filename, utterance_start_index, utterance_end_index, exclude_utterance_meta
+                    )
+
+                    speakers_data = load_speakers_data_from_dir(filename, exclude_speaker_meta)
+                    convos_data = load_convos_data_from_dir(filename, exclude_conversation_meta)
+                    load_corpus_meta_from_dir(filename, self.meta, exclude_overall_meta)
+
+                    with open(os.path.join(filename, "index.json"), "r") as f:
+                        idx_dict = json.load(f)
+                        self.meta_index.update_from_dict(idx_dict)
+
+                    # unpack all binary data
+                    unpack_all_binary_data(
+                        filename=filename,
+                        meta_index=self.meta_index,
+                        meta=self.meta,
+                        utterances=utterances,
+                        speakers_data=speakers_data,
+                        convos_data=convos_data,
+                        exclude_utterance_meta=exclude_utterance_meta,
+                        exclude_speaker_meta=exclude_speaker_meta,
+                        exclude_conversation_meta=exclude_conversation_meta,
+                        exclude_overall_meta=exclude_overall_meta,
+                    )
+
+                else:
+                    speakers_data = defaultdict(dict)
+                    convos_data = defaultdict(dict)
+                    utterances = load_from_utterance_file(
+                        filename, utterance_start_index, utterance_end_index
+                    )
+
+                self.utterances = dict()
+                self.speakers = dict()
+
+                initialize_speakers_and_utterances_objects(self, utterances, speakers_data)
+
+                self.meta_index.enable_type_check()
+
+                # load preload_vectors
+                if preload_vectors is not None:
+                    for vector_name in preload_vectors:
+                        matrix = ConvoKitMatrix.from_dir(self.corpus_dirpath, vector_name)
+                        if matrix is not None:
+                            self._vector_matrices[vector_name] = matrix
+
+            elif utterances is not None:  # Construct corpus from utterances list
+                self.speakers = {utt.speaker.id: utt.speaker for utt in utterances}
+                self.utterances = {utt.id: utt for utt in utterances}
+                for speaker in self.speakers.values():
+                    speaker.owner = self
+                for utt in self.utterances.values():
+                    utt.owner = self
+
+            if merge_lines:
+                self.utterances = merge_utterance_lines(self.utterances)
+
+            if disable_type_check:
+                self.meta_index.disable_type_check()
+            # if corpus is nonempty (check for self.utterances), construct the conversation
+            # data from the utterance list
+            if hasattr(self, "utterances"):
+                self.conversations = initialize_conversations(
+                    self, convos_data, fill_missing_convo_ids=True
+                )
+                self.meta_index.enable_type_check()
+                self.update_speakers_data()
+
+    @classmethod
+    def reconnect_to_db(cls, db_collection_prefix: str, db_host: Optional[str] = None):
+        """
+        Factory method for a Corpus instance backed by an already-existing database (e.g.,
+        one that was created in a previous run of a Python script or interactive session).
+
+        This can be used to reconnect to existing Corpus data that you still want to use
+        without having to reload the data from the source file; this can happen for example
+        if your script crashed in the middle of working with the Corpus and you want to
+        resume where you left off.
+        """
+        # create a blank Corpus that will hold the data
+        result = cls(db_collection_prefix=db_collection_prefix, db_host=db_host, backend="db")
+        # through the constructor, the blank Corpus' BackendMapper is now connected
+        # to the DB. Next use the DB contents to populate the corpus components.
+        init_corpus_from_backend_manager(result)
+
+        return result
 
     @property
     def vectors(self):
         return self.meta_index.vectors
 
     @vectors.setter
     def vectors(self, new_vectors):
-        if not isinstance(new_vectors, type(['stringlist'])):
-            raise ValueError("The preload_vectors being set should be a list of strings, "
-                             "where each string is the name of a vector matrix.")
+        if not isinstance(new_vectors, type(["stringlist"])):
+            raise ValueError(
+                "The preload_vectors being set should be a list of strings, "
+                "where each string is the name of a vector matrix."
+            )
         self.meta_index.vectors = new_vectors
 
-    def dump(self, name: str, base_path: Optional[str] = None,
-             exclude_vectors: List[str] = None,
-             force_version: int = None,
-             overwrite_existing_corpus: bool = False,
-             fields_to_skip=None) -> None:
+    def dump(
+        self,
+        name: str,
+        base_path: Optional[str] = None,
+        exclude_vectors: List[str] = None,
+        force_version: int = None,
+        overwrite_existing_corpus: bool = False,
+        fields_to_skip=None,
+    ) -> None:
         """
         Dumps the corpus and its metadata to disk. Optionally, set `force_version` to a desired integer version number,
         otherwise the version number is automatically incremented.
 
         :param name: name of corpus
         :param base_path: base directory to save corpus in (None to save to a default directory)
         :param exclude_vectors: list of names of vector matrices to exclude from the dumping step. By default; all
             vector matrices that belong to the Corpus (whether loaded or not) are dumped.
         :param force_version: version number to set for the dumped corpus
-        :param overwrite_existing_corpus: if True, save to the path you loaded the corpus from, overriding the original corpus. 
+        :param overwrite_existing_corpus: if True, save to the path you loaded the corpus from, overriding the original corpus.
         :param fields_to_skip: a dictionary of {object type: list of metadata attributes to omit when writing to disk}. object types can be one of "speaker", "utterance", "conversation", "corpus".
         """
         if fields_to_skip is None:
             fields_to_skip = dict()
         dir_name = name
         if base_path is not None and overwrite_existing_corpus:
             raise ValueError("Not allowed to specify both base_path and overwrite_existing_corpus!")
         if overwrite_existing_corpus and self.corpus_dirpath is None:
-            raise ValueError("Cannot use save to existing path on Corpus generated from utterance list!")
+            raise ValueError(
+                "Cannot use save to existing path on Corpus generated from utterance list!"
+            )
         if not overwrite_existing_corpus:
             if base_path is None:
                 base_path = os.path.expanduser("~/.convokit/")
                 if not os.path.exists(base_path):
                     os.mkdir(base_path)
                 base_path = os.path.join(base_path, "saved-corpora/")
                 if not os.path.exists(base_path):
@@ -186,44 +283,58 @@
         else:
             dir_name = os.path.join(self.corpus_dirpath)
 
         if not os.path.exists(dir_name):
             os.mkdir(dir_name)
 
         # dump speakers, conversations, utterances
-        dump_corpus_component(self, dir_name, "speakers.json", "speaker", "speaker", exclude_vectors, fields_to_skip)
-        dump_corpus_component(self, dir_name, "conversations.json", "conversation", "convo",
-                              exclude_vectors, fields_to_skip)
+        dump_corpus_component(
+            self, dir_name, "speakers.json", "speaker", "speaker", exclude_vectors, fields_to_skip
+        )
+        dump_corpus_component(
+            self,
+            dir_name,
+            "conversations.json",
+            "conversation",
+            "convo",
+            exclude_vectors,
+            fields_to_skip,
+        )
         dump_utterances(self, dir_name, exclude_vectors, fields_to_skip)
 
         # dump corpus
         with open(os.path.join(dir_name, "corpus.json"), "w") as f:
             d_bin = defaultdict(list)
-            meta_up = dump_helper_bin(self.meta, d_bin, fields_to_skip.get('corpus', None))
+            meta_up = dump_helper_bin(self.meta, d_bin, fields_to_skip.get("corpus", None))
 
             json.dump(meta_up, f)
             for name, l_bin in d_bin.items():
                 with open(os.path.join(dir_name, name + "-overall-bin.p"), "wb") as f_pk:
                     pickle.dump(l_bin, f_pk)
 
         # dump index
         with open(os.path.join(dir_name, "index.json"), "w") as f:
-            json.dump(self.meta_index.to_dict(exclude_vectors=exclude_vectors, force_version=force_version), f)
+            json.dump(
+                self.meta_index.to_dict(
+                    exclude_vectors=exclude_vectors, force_version=force_version
+                ),
+                f,
+            )
 
         # dump vectors
         if exclude_vectors is not None:
             vectors_to_dump = [v for v in self.vectors if v not in set(exclude_vectors)]
         else:
             vectors_to_dump = self.vectors
         for vector_name in vectors_to_dump:
             if vector_name in self._vector_matrices:
                 self._vector_matrices[vector_name].dump(dir_name)
             else:
-                src = os.path.join(self.corpus_dirpath, 'vectors.{}.p'.format(vector_name))
-                dest = os.path.join(dir_name, 'vectors.{}.p'.format(vector_name))
+                src = os.path.join(self.corpus_dirpath, "vectors.{}.p".format(vector_name))
+                dest = os.path.join(dir_name, "vectors.{}.p".format(vector_name))
                 shutil.copy(src, dest)
 
     # with open(os.path.join(dir_name, "processed_text.index.json"), "w") as f:
     #     json.dump(list(self.processed_text.keys()), f)
 
     def get_utterance(self, utt_id: str) -> Utterance:
         """
@@ -248,18 +359,14 @@
         Gets Speaker of the specified id from the corpus
 
         :param speaker_id: id of Speaker
         :return: Speaker
         """
         return self.speakers[speaker_id]
 
-    def get_user(self, user_id: str) -> Speaker:
-        deprecation("get_user()", "get_speaker()")
-        return self.get_speaker(user_id)
-
     def get_object(self, obj_type: str, oid: str):
         """
         General Corpus object getter. Gets Speaker / Utterance / Conversation of specified id from the Corpus
 
         :param obj_type: "speaker", "utterance", or "conversation"
         :param oid: object id
         :return: Corpus object of specified object type with specified object id
@@ -295,18 +402,14 @@
         Checks if a Speaker of the specified id exists in the Corpus
 
         :param speaker_id: id of Speaker
         :return: True if Speaker of specified id is present, False otherwise
         """
         return speaker_id in self.speakers
 
-    def has_user(self, speaker_id):
-        deprecation("has_user()", "has_speaker()")
-        return self.has_speaker(speaker_id)
-
     def random_utterance(self) -> Utterance:
         """
         Get a random Utterance from the Corpus
 
         :return: a random Utterance
         """
         return random.choice(list(self.utterances.values()))
@@ -323,243 +426,277 @@
         """
         Get a random Speaker from the Corpus
 
         :return: a random Speaker
         """
         return random.choice(list(self.speakers.values()))
 
-    def random_user(self) -> Speaker:
-        deprecation("random_user()", "random_speaker()")
-        return self.random_speaker()
-
-    def iter_utterances(self, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True) -> \
-            Generator[Utterance, None, None]:
+    def iter_utterances(
+        self, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True
+    ) -> Generator[Utterance, None, None]:
         """
         Get utterances in the Corpus, with an optional selector that filters for Utterances that should be included.
 
         :param selector: a (lambda) function that takes an Utterance and returns True or False (i.e. include / exclude).
             By default, the selector includes all Utterances in the Corpus.
         :return: a generator of Utterances
         """
         for v in self.utterances.values():
             if selector(v):
                 yield v
 
-    def get_utterances_dataframe(self, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True,
-                                 exclude_meta: bool = False):
+    def get_utterances_dataframe(
+        self,
+        selector: Optional[Callable[[Utterance], bool]] = lambda utt: True,
+        exclude_meta: bool = False,
+    ):
         """
         Get a DataFrame of the utterances with fields and metadata attributes, with an optional selector that filters
         utterances that should be included. Edits to the DataFrame do not change the corpus in any way.
 
         :param exclude_meta: whether to exclude metadata
         :param selector: a (lambda) function that takes a Utterance and returns True or False (i.e. include / exclude).
             By default, the selector includes all Utterances in the Corpus.
         :return: a pandas DataFrame
         """
         return get_utterances_dataframe(self, selector, exclude_meta)
 
-    def iter_conversations(self, selector: Optional[Callable[[Conversation], bool]] = lambda convo: True) -> Generator[
-                           Conversation, None, None]:
+    def iter_conversations(
+        self, selector: Optional[Callable[[Conversation], bool]] = lambda convo: True
+    ) -> Generator[Conversation, None, None]:
         """
         Get conversations in the Corpus, with an optional selector that filters for Conversations that should be included
 
         :param selector: a (lambda) function that takes a Conversation and returns True or False (i.e. include / exclude).
             By default, the selector includes all Conversations in the Corpus.
         :return: a generator of Conversations
         """
         for v in self.conversations.values():
             if selector(v):
                 yield v
 
-    def get_conversations_dataframe(self, selector: Optional[Callable[[Conversation], bool]] = lambda convo: True,
-                                    exclude_meta: bool = False):
+    def get_conversations_dataframe(
+        self,
+        selector: Optional[Callable[[Conversation], bool]] = lambda convo: True,
+        exclude_meta: bool = False,
+    ):
         """
         Get a DataFrame of the conversations with fields and metadata attributes, with an optional selector that filters
         for conversations that should be included. Edits to the DataFrame do not change the corpus in any way.
 
         :param exclude_meta: whether to exclude metadata
         :param selector: a (lambda) function that takes a Conversation and returns True or False (i.e. include / exclude).
             By default, the selector includes all Conversations in the Corpus.
         :return: a pandas DataFrame
         """
         return get_conversations_dataframe(self, selector, exclude_meta)
 
-    def iter_speakers(self, selector: Optional[Callable[[Speaker], bool]] = lambda speaker: True) -> \
-            Generator[Speaker, None, None]:
+    def iter_speakers(
+        self, selector: Optional[Callable[[Speaker], bool]] = lambda speaker: True
+    ) -> Generator[Speaker, None, None]:
         """
         Get Speakers in the Corpus, with an optional selector that filters for Speakers that should be included
 
         :param selector: a (lambda) function that takes a Speaker and returns True or False (i.e. include / exclude).
             By default, the selector includes all Speakers in the Corpus.
         :return: a generator of Speakers
         """
 
         for speaker in self.speakers.values():
             if selector(speaker):
                 yield speaker
 
-    def get_speakers_dataframe(self, selector: Optional[Callable[[Speaker], bool]] = lambda utt: True,
-                               exclude_meta: bool = False):
+    def get_speakers_dataframe(
+        self,
+        selector: Optional[Callable[[Speaker], bool]] = lambda utt: True,
+        exclude_meta: bool = False,
+    ):
         """
         Get a DataFrame of the Speakers with fields and metadata attributes, with an optional selector that filters
         Speakers that should be included. Edits to the DataFrame do not change the corpus in any way.
 
         :param exclude_meta: whether to exclude metadata
         :param selector: selector: a (lambda) function that takes a Speaker and returns True or False
             (i.e. include / exclude). By default, the selector includes all Speakers in the Corpus.
         :return: a pandas DataFrame
         """
         return get_speakers_dataframe(self, selector, exclude_meta)
 
-    def iter_users(self, selector=lambda speaker: True):
-        deprecation("iter_users()", "iter_speakers()")
-        return self.iter_speakers(selector)
-
-    def iter_objs(self, obj_type: str,
-                  selector: Callable[[Union[Speaker, Utterance, Conversation]], bool] = lambda obj: True):
+    def iter_objs(
+        self,
+        obj_type: str,
+        selector: Callable[[Union[Speaker, Utterance, Conversation]], bool] = lambda obj: True,
+    ):
         """
         Get Corpus objects of specified type from the Corpus, with an optional selector that filters for Corpus object that should be included
 
         :param obj_type: "speaker", "utterance", or "conversation"
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude).
             By default, the selector includes all objects of the specified type in the Corpus.
         :return: a generator of Speakers
         """
 
         assert obj_type in ["speaker", "utterance", "conversation"]
-        obj_iters = {"conversation": self.iter_conversations,
-                     "speaker": self.iter_speakers,
-                     "utterance": self.iter_utterances}
+        obj_iters = {
+            "conversation": self.iter_conversations,
+            "speaker": self.iter_speakers,
+            "utterance": self.iter_utterances,
+        }
 
         return obj_iters[obj_type](selector)
 
-    def get_utterance_ids(self, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True) -> List[str]:
+    def get_utterance_ids(
+        self, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True
+    ) -> List[str]:
         """
         Get a list of ids of Utterances in the Corpus, with an optional selector that filters for Utterances that should be included
 
         :param selector: a (lambda) function that takes an Utterance and returns True or False (i.e. include / exclude).
             By default, the selector includes all Utterances in the Corpus.
         :return: list of Utterance ids
         """
         return [utt.id for utt in self.iter_utterances(selector)]
 
-    def get_conversation_ids(self, selector: Optional[Callable[[Conversation], bool]] = lambda convo: True) -> List[
-        str]:
+    def get_conversation_ids(
+        self, selector: Optional[Callable[[Conversation], bool]] = lambda convo: True
+    ) -> List[str]:
         """
         Get a list of ids of Conversations in the Corpus, with an optional selector that filters for Conversations that should be included
 
         :param selector: a (lambda) function that takes a Conversation and returns True or False (i.e. include / exclude).
             By default, the selector includes all Conversations in the Corpus.
         :return: list of Conversation ids
         """
         return [convo.id for convo in self.iter_conversations(selector)]
 
-    def get_speaker_ids(self, selector: Optional[Callable[[Speaker], bool]] = lambda speaker: True) -> List[
-        str]:
+    def get_speaker_ids(
+        self, selector: Optional[Callable[[Speaker], bool]] = lambda speaker: True
+    ) -> List[str]:
         """
         Get a list of ids of Speakers in the Corpus, with an optional selector that filters for Speakers that should be included
 
         :param selector: a (lambda) function that takes a Speaker and returns True or False (i.e. include / exclude).
             By default, the selector includes all Speakers in the Corpus.
         :return: list of Speaker ids
         """
         return [speaker.id for speaker in self.iter_speakers(selector)]
 
-    def get_object_ids(self, obj_type: str,
-                       selector: Callable[[Union[Speaker, Utterance, Conversation]], bool] = lambda obj: True):
+    def get_object_ids(
+        self,
+        obj_type: str,
+        selector: Callable[[Union[Speaker, Utterance, Conversation]], bool] = lambda obj: True,
+    ):
         """
         Get a list of ids of Corpus objects of the specified type in the Corpus, with an optional selector that filters for objects that should be included
 
         :param obj_type: "speaker", "utterance", or "conversation"
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude).
             By default, the selector includes all objects of the specified type in the Corpus.
         :return: list of Corpus object ids
         """
         assert obj_type in ["speaker", "utterance", "conversation"]
         return [obj.id for obj in self.iter_objs(obj_type, selector)]
 
-    def get_usernames(self, selector: Optional[Callable[[Speaker], bool]] = lambda user: True) -> Set[str]:
-        """Get names of speakers in the dataset.
-
-        This function will be deprecated and replaced by get_speaker_ids()
-
-        :param selector: optional function that takes in a
-            `Speaker` and returns True to include the speaker's name in the
-            resulting list, or False otherwise.
-
-        :return: Set containing all speaker names selected by the selector
-            function, or all speaker names in the dataset if no selector function
-            was used.
-
-        """
-        deprecation("get_usernames()", "get_speaker_ids()")
-        return set([u.id for u in self.iter_speakers(selector)])
-
     def filter_conversations_by(self, selector: Callable[[Conversation], bool]):
         """
         Mutate the corpus by filtering for a subset of Conversations within the Corpus.
 
         :param selector: function for selecting which Conversations to keep
         :return: the mutated Corpus
         """
 
-        self.conversations = {convo_id: convo for convo_id, convo in self.conversations.items() if selector(convo)}
-        utt_ids = set([utt for convo in self.conversations.values() for utt in convo.get_utterance_ids()])
+        self.conversations = {
+            convo_id: convo for convo_id, convo in self.conversations.items() if selector(convo)
+        }
+        utt_ids = set(
+            [utt for convo in self.conversations.values() for utt in convo.get_utterance_ids()]
+        )
         self.utterances = {utt.id: utt for utt in self.utterances.values() if utt.id in utt_ids}
         speaker_ids = set([utt.speaker.id for utt in self.utterances.values()])
-        self.speakers = {speaker.id: speaker for speaker in self.speakers.values() if speaker.id in speaker_ids}
+        self.speakers = {
+            speaker.id: speaker for speaker in self.speakers.values() if speaker.id in speaker_ids
+        }
         self.update_speakers_data()
         self.reinitialize_index()
+
+        # clear all backend entries corresponding to filtered-out components
+        meta_ids = [self.meta.backend_key]
+        for utt in self.iter_utterances():
+            meta_ids.append(utt.meta.backend_key)
+        for convo in self.iter_conversations():
+            meta_ids.append(convo.meta.backend_key)
+        for speaker in self.iter_speakers():
+            meta_ids.append(speaker.meta.backend_key)
+        self.backend_mapper.purge_obsolete_entries(
+            self.get_utterance_ids(), self.get_conversation_ids(), self.get_speaker_ids(), meta_ids
+        )
+
         return self
 
-    def filter_utterances_by(self, selector: Callable[[Utterance], bool]):
+    @staticmethod
+    def filter_utterances(source_corpus: "Corpus", selector: Callable[[Utterance], bool]):
         """
-        Returns a new corpus that includes only a subset of Utterances within this Corpus. This filtering provides no
+        Returns a new corpus that includes only a subset of Utterances from the source Corpus. This filtering provides no
         guarantees with regard to maintaining conversational integrity and should be used with care.
 
-        Vectors are not preserved.
+        Vectors are not preserved. The source corpus will be invalidated and will no longer be usable.
 
+        :param source_corpus: the Corpus to subset from
         :param selector: function for selecting which
         :return: a new Corpus with a subset of the Utterances
         """
-        utts = list(self.iter_utterances(selector))
+        utts = list(source_corpus.iter_utterances(selector))
         new_corpus = Corpus(utterances=utts)
         for convo in new_corpus.iter_conversations():
-            convo.meta.update(self.get_conversation(convo.id).meta)
+            convo.meta.update(source_corpus.get_conversation(convo.id).meta)
+
+        # original Corpus is invalidated and no longer usable; clear all data from
+        # its now-orphaned BackendMapper to avoid having duplicates in memory
+        source_corpus.backend_mapper.clear_all_data()
+
         return new_corpus
 
-    def reindex_conversations(self, new_convo_roots: List[str], preserve_corpus_meta: bool = True,
-                              preserve_convo_meta: bool = True, verbose=True) -> 'Corpus':
+    @staticmethod
+    def reindex_conversations(
+        source_corpus: "Corpus",
+        new_convo_roots: List[str],
+        preserve_corpus_meta: bool = True,
+        preserve_convo_meta: bool = True,
+        verbose=True,
+    ) -> "Corpus":
         """
-        Generates a new Corpus from current Corpus with specified list of utterance ids to use as conversation ids.
+        Generates a new Corpus from source Corpus with specified list of utterance ids to use as conversation ids.
 
         The subtrees denoted by these utterance ids should be distinct and should not overlap, otherwise there may be unexpected behavior.
 
-        Vectors are not preserved. The original Corpus will be mutated.
+        Vectors are not preserved. The source Corpus will be invalidated and no longer usable.
 
+        :param source_corpus: the Corpus containing the original data to select from
         :param new_convo_roots: List of utterance ids to use as conversation ids
         :param preserve_corpus_meta: set as True to copy original Corpus metadata to new Corpus
         :param preserve_convo_meta: set as True to copy original Conversation metadata to new Conversation metadata
             (For each new conversation, use the metadata of the conversation that the utterance belonged to.)
         :param verbose: whether to print a warning when
         :return: new Corpus with reindexed Conversations
-        """""
+        """ ""
         new_convo_roots = set(new_convo_roots)
-        for convo in self.iter_conversations():
+        for convo in source_corpus.iter_conversations():
             try:
                 convo.initialize_tree_structure()
             except ValueError as e:
                 if verbose:
                     warn(str(e))
 
         new_corpus_utts = []
         original_utt_to_convo_id = dict()
 
         for utt_id in new_convo_roots:
-            orig_convo = self.get_conversation(self.get_utterance(utt_id).conversation_id)
+            orig_convo = source_corpus.get_conversation(
+                source_corpus.get_utterance(utt_id).conversation_id
+            )
             original_utt_to_convo_id[utt_id] = orig_convo.id
             try:
                 subtree = orig_convo.get_subtree(utt_id)
                 new_root_utt = subtree.utt
                 new_root_utt.reply_to = None
                 subtree_utts = [node.utt for node in subtree.bfs_traversal()]
                 for utt in subtree_utts:
@@ -567,84 +704,111 @@
                 new_corpus_utts.extend(subtree_utts)
             except ValueError:
                 continue
 
         new_corpus = Corpus(utterances=new_corpus_utts)
 
         if preserve_corpus_meta:
-            new_corpus.meta.update(self.meta)
+            new_corpus.meta.update(source_corpus.meta)
 
         if preserve_convo_meta:
             for convo in new_corpus.iter_conversations():
-                convo.meta['original_convo_meta'] = self.get_conversation(original_utt_to_convo_id[convo.id]).meta
-                convo.meta['original_convo_id'] = original_utt_to_convo_id[convo.id]
+                convo.meta["original_convo_meta"] = source_corpus.get_conversation(
+                    original_utt_to_convo_id[convo.id]
+                ).meta.to_dict()
+                convo.meta["original_convo_id"] = original_utt_to_convo_id[convo.id]
         if verbose:
-            missing_convo_roots = list(set(new_convo_roots) - set(new_corpus.get_conversation_ids()))
+            missing_convo_roots = list(
+                set(new_convo_roots) - set(new_corpus.get_conversation_ids())
+            )
             if len(missing_convo_roots) > 0:
                 warn("Failed to find some of the specified new convo roots:\n")
                 print(missing_convo_roots)
 
+        # original Corpus is invalidated and no longer usable; clear all data from
+        # its now-orphaned BackendMapper to avoid having duplicates in memory
+        source_corpus.backend_mapper.clear_all_data()
+
         return new_corpus
 
     def get_meta(self) -> Dict:
         return self.meta
 
     def add_meta(self, key: str, value) -> None:
         self.meta[key] = value
 
-    def speaking_pairs(self, selector: Optional[Callable[[Speaker, Speaker], bool]] = lambda speaker1, speaker2: True,
-                       speaker_ids_only: bool = False) -> Set[Tuple[str, str]]:
+    def speaking_pairs(
+        self,
+        selector: Optional[Callable[[Speaker, Speaker], bool]] = lambda speaker1, speaker2: True,
+        speaker_ids_only: bool = False,
+    ) -> Set[Tuple[str, str]]:
         """
         Get all directed speaking pairs (a, b) of speakers such that a replies to b at least once in the dataset.
 
         :param selector: optional function that takes in a Speaker and a replied-to Speaker and returns True to include
             the pair in the result, or False otherwise.
         :param speaker_ids_only: if True, return just pairs of speaker names rather than speaker objects.
         :type speaker_ids_only: bool
 
         :return: Set containing all speaking pairs selected by the selector function, or all speaking pairs in the
             dataset if no selector function was used.
         """
         pairs = set()
         for utt2 in self.iter_utterances():
-            if utt2.speaker is not None and utt2.reply_to is not None and self.has_utterance(utt2.reply_to):
+            if (
+                utt2.speaker is not None
+                and utt2.reply_to is not None
+                and self.has_utterance(utt2.reply_to)
+            ):
                 utt1 = self.get_utterance(utt2.reply_to)
                 if utt1.speaker is not None:
                     if selector(utt2.speaker, utt1.speaker):
-                        pairs.add((utt2.speaker.id, utt1.speaker.id) if
-                                  speaker_ids_only else (utt2.speaker, utt1.speaker))
+                        pairs.add(
+                            (utt2.speaker.id, utt1.speaker.id)
+                            if speaker_ids_only
+                            else (utt2.speaker, utt1.speaker)
+                        )
         return pairs
 
-    def directed_pairwise_exchanges(self, selector: Optional[Callable[[Speaker, Speaker], bool]] = lambda speaker1, speaker2: True,
-                                    speaker_ids_only: bool = False) -> Dict[Tuple, List[Utterance]]:
+    def directed_pairwise_exchanges(
+        self,
+        selector: Optional[Callable[[Speaker, Speaker], bool]] = lambda speaker1, speaker2: True,
+        speaker_ids_only: bool = False,
+    ) -> Dict[Tuple, List[Utterance]]:
         """
         Get all directed pairwise exchanges in the dataset.
 
-        :param selector: optional function that takes in a speaking speaker and a replied-to speaker and 
+        :param selector: optional function that takes in a speaking speaker and a replied-to speaker and
             returns True to include the pair in the result, or False otherwise.
         :param speaker_ids_only: if True, index conversations
             by speaker ids rather than Speaker objects.
         :type speaker_ids_only: bool
 
         :return: Dictionary mapping (speaker, target) tuples to a list of
             utterances given by the speaker in reply to the target.
         """
         pairs = defaultdict(list)
         for u2 in self.iter_utterances():
             if u2.speaker is not None and u2.reply_to is not None:
                 u1 = self.get_utterance(u2.reply_to)
                 if u1.speaker is not None:
                     if selector(u2.speaker, u1.speaker):
-                        key = (u2.speaker.id, u1.speaker.id) if speaker_ids_only else (u2.speaker, u1.speaker)
+                        key = (
+                            (u2.speaker.id, u1.speaker.id)
+                            if speaker_ids_only
+                            else (u2.speaker, u1.speaker)
+                        )
                         pairs[key].append(u2)
 
         return pairs
 
     @staticmethod
-    def _merge_utterances(utts1: List[Utterance], utts2: List[Utterance], warnings: bool) -> ValuesView[Utterance]:
+    def _merge_utterances(
+        utts1: List[Utterance], utts2: List[Utterance], warnings: bool
+    ) -> ValuesView[Utterance]:
         """
         Helper function for merge().
 
         Combine two collections of utterances into a single dictionary of Utterance id -> Utterance.
 
         If metadata of utterances in the two collections share the same key, but different values,
         the second collections' utterance metadata will be used.
@@ -672,62 +836,73 @@
             if utt.id in seen_utts:
                 prev_utt = seen_utts[utt.id]
                 if prev_utt == utt:
                     # other utterance metadata is ignored if data is not matched
                     for key, val in utt.meta.items():
                         if key in prev_utt.meta and prev_utt.meta[key] != val:
                             if warnings:
-                                warn("Found conflicting values for Utterance {} for metadata key: {}. "
-                                     "Overwriting with other corpus's Utterance metadata.".format(repr(utt.id),
-                                                                                                  repr(key)))
+                                warn(
+                                    "Found conflicting values for Utterance {} for metadata key: {}. "
+                                    "Overwriting with other corpus's Utterance metadata.".format(
+                                        repr(utt.id), repr(key)
+                                    )
+                                )
                         prev_utt.meta[key] = val
                 else:
                     if warnings:
-                        warn("Utterances with same id do not share the same data:\n" +
-                             str(prev_utt) + "\n" +
-                             str(utt) + "\n" +
-                             "Ignoring second corpus's utterance."
-                             )
+                        warn(
+                            "Utterances with same id do not share the same data:\n"
+                            + str(prev_utt)
+                            + "\n"
+                            + str(utt)
+                            + "\n"
+                            + "Ignoring second corpus's utterance."
+                        )
             else:
                 seen_utts[utt.id] = utt
 
         return seen_utts.values()
 
     @staticmethod
-    def _collect_speaker_data(utt_sets: Collection[Collection[Utterance]]) -> Tuple[
-        Dict[str, Dict[str, str]], Dict[str, Dict[str, bool]]]:
+    def _collect_speaker_data(
+        utt_sets: Collection[Collection[Utterance]],
+    ) -> Tuple[Dict[str, Speaker], Dict[str, Dict[str, str]], Dict[str, Dict[str, bool]]]:
         """
         Helper function for merge().
 
         Iterates through the input set of utterances, to collect Speaker data and metadata.
 
         Collect Speaker metadata in another Dictionary indexed by Speaker ID
 
         Track if conflicting speaker metadata is found in another dictionary
 
         :param utt_sets: Collections of collections of Utterances to extract Speakers from
         :return: speaker metadata and the corresponding tracker
         """
         # Collect SPEAKER data and metadata
+        speakers_data = {}
         speakers_meta = defaultdict(lambda: defaultdict(str))
         speakers_meta_conflict = defaultdict(lambda: defaultdict(bool))
         for utt_set in utt_sets:
             for utt in utt_set:
+                if utt.speaker.id not in speakers_data:
+                    speakers_data[utt.speaker.id] = utt.speaker
                 for meta_key, meta_val in utt.speaker.meta.items():
                     curr = speakers_meta[utt.speaker][meta_key]
                     if curr != meta_val:
                         if curr != "":
                             speakers_meta_conflict[utt.speaker][meta_key] = True
                         speakers_meta[utt.speaker][meta_key] = meta_val
 
-        return speakers_meta, speakers_meta_conflict
+        return speakers_data, speakers_meta, speakers_meta_conflict
 
     @staticmethod
-    def _update_corpus_speaker_data(new_corpus, speakers_meta: Dict, speakers_meta_conflict: Dict,
-                                    warnings: bool) -> None:
+    def _update_corpus_speaker_data(
+        new_corpus, speakers_meta: Dict, speakers_meta_conflict: Dict, warnings: bool
+    ) -> None:
         """
         Helper function for merge().
 
         Update new_corpus's Speakers' data (utterance and conversation lists) and metadata
 
         Prints a warning if multiple values are found for any speaker's metadata key; latest speaker metadata is used
 
@@ -736,16 +911,18 @@
         :return: None (mutates the new_corpus's Speakers)
         """
         # Update SPEAKER data and metadata with merged versions
         for speaker in new_corpus.iter_speakers():
             for meta_key, meta_val in speakers_meta[speaker].items():
                 if speakers_meta_conflict[speaker][meta_key]:
                     if warnings:
-                        warn("Multiple values found for {} for metadata key: {}. "
-                             "Taking the latest one found".format(speaker, repr(meta_key)))
+                        warn(
+                            "Multiple values found for {} for metadata key: {}. "
+                            "Taking the latest one found".format(speaker, repr(meta_key))
+                        )
                 speaker.meta[meta_key] = meta_val
 
     def _reinitialize_index_helper(self, new_index, obj_type):
         """
         Helper for reinitializing the index of the different Corpus object types
         :param new_index: new ConvoKitIndex object
         :param obj_type: utterance, speaker, or conversation
@@ -766,76 +943,104 @@
         new_index = ConvoKitIndex(self)
 
         self._reinitialize_index_helper(new_index, "utterance")
         self._reinitialize_index_helper(new_index, "speaker")
         self._reinitialize_index_helper(new_index, "conversation")
 
         for key, value in self.meta.items():  # overall
-            new_index.update_index('corpus', key, str(type(value)))
+            new_index.update_index("corpus", key, str(type(value)))
 
         new_index.version = old_index.version
         self.meta_index = new_index
 
-    def merge(self, other_corpus, warnings: bool = True):
+    @staticmethod
+    def merge(primary: "Corpus", secondary: "Corpus", warnings: bool = True):
         """
-        Merges this corpus with another corpus.
+        Merges two corpora (one primary and one secondary), creating a new Corpus with their combined data.
 
-        Utterances with the same id must share the same data, otherwise the other corpus utterance data & metadata
+        Utterances with the same id must share the same data. In case of conflicts,
+        the primary Corpus will take precedence and the conflicting Utterance from secondary
         will be ignored. A warning is printed when this happens.
 
-        If metadata of this corpus (or its conversations / utterances) shares a key with the metadata of the
-        other corpus, the other corpus's metadata (or its conversations / utterances) values will be used. A warning
+        If metadata of the primary Corpus (or its conversations / utterances) shares a key with the metadata of the
+        secondary Corpus, the secondary's metadata (or its conversations / utterances) values will be used. A warning
         is printed when this happens.
 
-        May mutate original and other corpus in the process.
+        Will invalidate primary and secondary in the process.
 
-        (Updates internal ConvoKit Index to match post-merge state and uses this Corpus's version number.)
+        The resulting Corpus will inherit the primary Corpus's id and version number.
 
-        :param other_corpus: Corpus
+        :param primary: the primary Corpus
+        :param secondary: the secondary Corpus
         :param warnings: print warnings when data conflicts are encountered
         :return: new Corpus constructed from combined lists of utterances
         """
-        utts1 = list(self.iter_utterances())
-        utts2 = list(other_corpus.iter_utterances())
-        combined_utts = self._merge_utterances(utts1, utts2, warnings=warnings)
-        new_corpus = Corpus(utterances=list(combined_utts))
+        utts1 = list(primary.iter_utterances())
+        utts2 = list(secondary.iter_utterances())
+        combined_utts = list(primary._merge_utterances(utts1, utts2, warnings=warnings))
         # Note that we collect Speakers from the utt sets directly instead of the combined utts, otherwise
         # differences in Speaker meta will not be registered for duplicate Utterances (because utts would be discarded
         # during merging)
-        speakers_meta, speakers_meta_conflict = self._collect_speaker_data([utts1, utts2])
-        Corpus._update_corpus_speaker_data(new_corpus, speakers_meta, speakers_meta_conflict, warnings=warnings)
+        combined_speakers, speakers_meta, speakers_meta_conflict = primary._collect_speaker_data(
+            [utts1, utts2]
+        )
+        # Ensure that all attributions of an Utterance to the same speaker ID actually
+        # map to the same Speaker instance. Otherwise, you can end up with two
+        # Utterances that appear to have the same author but actually point to two
+        # identical-but-distinct Speaker objects, which can result in unintuivie
+        # behavior down the line.
+        for utt in combined_utts:
+            intended_speaker = combined_speakers[utt.speaker.id]
+            if not (utt.speaker is intended_speaker):
+                utt.speaker = intended_speaker
+        new_corpus = Corpus(utterances=combined_utts)
+        Corpus._update_corpus_speaker_data(
+            new_corpus, speakers_meta, speakers_meta_conflict, warnings=warnings
+        )
 
         # Merge CORPUS metadata
-        new_corpus.meta = self.meta
-        for key, val in other_corpus.meta.items():
+        new_corpus.meta.reinitialize_from(primary.meta)
+        for key, val in secondary.meta.items():
             if key in new_corpus.meta and new_corpus.meta[key] != val:
                 if warnings:
-                    warn("Found conflicting values for Corpus metadata key: {}. "
-                         "Overwriting with other Corpus's metadata.".format(repr(key)))
+                    warn(
+                        "Found conflicting values for primary Corpus metadata key: {}. "
+                        "Overwriting with secondary Corpus's metadata.".format(repr(key))
+                    )
             new_corpus.meta[key] = val
 
         # Merge CONVERSATION metadata
-        convos1 = self.iter_conversations()
-        convos2 = other_corpus.iter_conversations()
+        convos1 = primary.iter_conversations()
+        convos2 = secondary.iter_conversations()
 
         for convo in convos1:
-            new_corpus.get_conversation(convo.id).meta = convo.meta
+            new_corpus.get_conversation(convo.id).meta.reinitialize_from(convo.meta)
 
         for convo in convos2:
             for key, val in convo.meta.items():
                 curr_meta = new_corpus.get_conversation(convo.id).meta
                 if key in curr_meta and curr_meta[key] != val:
                     if warnings:
-                        warn("Found conflicting values for Conversation {} for metadata key: {}. "
-                             "Overwriting with other corpus's Conversation metadata.".format(repr(convo.id), repr(key)))
+                        warn(
+                            "Found conflicting values for Conversation {} for metadata key: {}. "
+                            "Overwriting with secondary corpus's Conversation metadata.".format(
+                                repr(convo.id), repr(key)
+                            )
+                        )
                 curr_meta[key] = val
 
         new_corpus.update_speakers_data()
         new_corpus.reinitialize_index()
 
+        # source corpora are now invalidated and all needed data has been copied
+        # into the new merged corpus; clear the source corpora's backend mapper to
+        # prevent having duplicates in memory
+        primary.backend_mapper.clear_all_data()
+        secondary.backend_mapper.clear_all_data()
+
         return new_corpus
 
     def add_utterances(self, utterances=List[Utterance], warnings: bool = False, with_checks=True):
         """
         Add utterances to the Corpus.
 
         If the corpus has utterances that share an id with an utterance in the input utterance list,
@@ -846,50 +1051,78 @@
 
         :param utterances: Utterances to be added to the Corpus
         :param warnings: set to True for warnings to be printed
         :param with_checks: set to True if checks on utterance and metadata overlaps are desired. Set to False if newly added utterances are guaranteed to be new and share the same set of metadata keys.
         :return: a Corpus with the utterances from this Corpus and the input utterances combined
         """
         if with_checks:
-            helper_corpus = Corpus(utterances=utterances)
-            return self.merge(helper_corpus, warnings=warnings)
-        else:
-            new_speakers = {u.speaker.id: u.speaker for u in utterances}
-            new_utterances = {u.id: u for u in utterances}
-            for speaker in new_speakers.values():
-                speaker.owner = self
-            for utt in new_utterances.values():
-                utt.owner = self
-
-            # update corpus speakers
-            for new_speaker_id, new_speaker in new_speakers.items():
-                if new_speaker_id not in self.speakers:
-                    self.speakers[new_speaker_id] = new_speaker
-
-            # update corpus utterances + (link speaker -> utt)
-            for new_utt_id, new_utt in new_utterances.items():
-                if new_utt_id not in self.utterances:
-                    self.utterances[new_utt_id] = new_utt
-                    self.speakers[new_utt.speaker.id]._add_utterance(new_utt)
-
-            # update corpus conversations + (link convo <-> utt)
-            new_convos = defaultdict(list)
-            for utt in new_utterances.values():
-                if utt.conversation_id in self.conversations:
+            # leverage the merge method's _merge_utterances method to run the checks
+            # (but then run a subsequent filtering operation since we aren't actually doing a merge)
+            added_utt_ids = {utt.id for utt in utterances}
+            combined_utts = self._merge_utterances(
+                list(self.iter_utterances()), utterances, warnings
+            )
+            combined_speakers, speakers_meta, speakers_meta_conflict = self._collect_speaker_data(
+                [list(self.iter_utterances()), utterances]
+            )
+            utterances = [utt for utt in combined_utts if utt.id in added_utt_ids]
+            for utt in utterances:
+                intended_speaker = combined_speakers[utt.speaker.id]
+                if not (utt.speaker is intended_speaker):
+                    utt.speaker = intended_speaker
+
+        new_speakers = {u.speaker.id: u.speaker for u in utterances}
+        new_utterances = {u.id: u for u in utterances}
+        for speaker in new_speakers.values():
+            speaker.owner = self
+        for utt in new_utterances.values():
+            utt.owner = self
+
+        # update corpus speakers
+        for new_speaker_id, new_speaker in new_speakers.items():
+            if new_speaker_id not in self.speakers:
+                self.speakers[new_speaker_id] = new_speaker
+
+        # update corpus utterances + (link speaker -> utt)
+        for new_utt_id, new_utt in new_utterances.items():
+            if new_utt_id not in self.utterances:
+                self.utterances[new_utt_id] = new_utt
+                self.speakers[new_utt.speaker.id]._add_utterance(new_utt)
+
+        # add convo ids if new utts are missing convo ids
+        fill_missing_conversation_ids(self.utterances)
+
+        # update corpus conversations + (link convo <-> utt)
+        new_convos = defaultdict(list)
+        convo_id_to_root_utt_id = dict()
+        for utt in new_utterances.values():
+            if utt.conversation_id in self.conversations:
+                if (not with_checks) or (
+                    utt.id not in self.conversations[utt.conversation_id].get_utterance_ids()
+                ):
                     self.conversations[utt.conversation_id]._add_utterance(utt)
-                else:
-                    new_convos[utt.conversation_id].append(utt.id)
-            for convo_id, convo_utts in new_convos.items():
-                new_convo = Conversation(owner=self, id=convo_id,
-                                         utterances=convo_utts,
-                                         meta=None)
-                self.conversations[convo_id] = new_convo
-                # (link speaker -> convo)
-                new_convo_speaker = self.speakers[new_convo.get_utterance(convo_id).speaker.id]
-                new_convo_speaker._add_conversation(new_convo)
+            else:
+                new_convos[utt.conversation_id].append(utt.id)
+            if utt.reply_to is None:
+                convo_id_to_root_utt_id[utt.conversation_id] = utt.id
+
+        for convo_id, convo_utts in new_convos.items():
+            new_convo = Conversation(owner=self, id=convo_id, utterances=convo_utts, meta=None)
+            self.conversations[convo_id] = new_convo
+            # (link speaker -> convo)
+            convo_root_utt_id = convo_id_to_root_utt_id[convo_id]
+            convo_root_utt = new_convo.get_utterance(convo_root_utt_id)
+            new_convo_speaker = self.speakers[convo_root_utt.speaker.id]
+            new_convo_speaker._add_conversation(new_convo)
+
+        # update speaker metadata (only in cases of conflict)
+        if with_checks:
+            Corpus._update_corpus_speaker_data(
+                self, speakers_meta, speakers_meta_conflict, warnings
+            )
 
         return self
 
     def update_speakers_data(self) -> None:
         """
         Updates the conversation and utterance lists of every Speaker in the Corpus
 
@@ -932,15 +1165,17 @@
         self.meta_index.lock_metadata_deletion[obj_type] = False
         for obj in self.iter_objs(obj_type):
             if attribute in obj.meta:
                 del obj.meta[attribute]
         self.meta_index.del_from_index(obj_type, attribute)
         self.meta_index.lock_metadata_deletion[obj_type] = True
 
-    def set_vector_matrix(self, name: str, matrix, ids: List[str]=None, columns: List[str] = None):
+    def set_vector_matrix(
+        self, name: str, matrix, ids: List[str] = None, columns: List[str] = None
+    ):
         """
         Adds a vector matrix to the Corpus, where the matrix is an array of vector representations of some
         set of Corpus components (i.e. Utterances, Conversations, Speakers).
 
         A ConvoKitMatrix object is initialized from the arguments and stored in the Corpus.
 
         :param name: descriptive name for the matrix
@@ -948,28 +1183,36 @@
         :param ids: optional list of Corpus component object ids, where each id corresponds to each row of the matrix
         :param columns: optional list of names for the columns of the matrix
         :return: None
         """
 
         matrix = ConvoKitMatrix(name=name, matrix=matrix, ids=ids, columns=columns)
         if name in self.meta_index.vectors:
-            warn('Vector matrix "{}" already exists. Overwriting it with newly set vector matrix.'.format(name))
+            warn(
+                'Vector matrix "{}" already exists. Overwriting it with newly set vector matrix.'.format(
+                    name
+                )
+            )
         self.meta_index.add_vector(name)
         self._vector_matrices[name] = matrix
 
     def append_vector_matrix(self, matrix: ConvoKitMatrix):
         """
         Adds an already constructed ConvoKitMatrix to the Corpus.
 
         :param matrix: a ConvoKitMatrix object
         :return: None
         """
         if matrix.name in self.meta_index.vectors:
-            warn('Vector matrix "{}" already exists. '
-                 "Overwriting it with newly appended vector matrix that has name: '{}'.".format(matrix.name, matrix.name))
+            warn(
+                'Vector matrix "{}" already exists. '
+                "Overwriting it with newly appended vector matrix that has name: '{}'.".format(
+                    matrix.name, matrix.name
+                )
+            )
         self.meta_index.add_vector(matrix.name)
         self._vector_matrices[matrix.name] = matrix
 
     def get_vector_matrix(self, name):
         """
         Gets the ConvoKitMatrix stored in the corpus as `name`.
         Returns None if no such matrix exists.
@@ -980,43 +1223,49 @@
         # This is the lazy load step
         if name in self.vectors and name not in self._vector_matrices:
             matrix = ConvoKitMatrix.from_dir(self.corpus_dirpath, name)
             if matrix is not None:
                 self._vector_matrices[name] = matrix
         return self._vector_matrices[name]
 
-    def get_vectors(self, name, ids: Optional[List[str]] = None, columns: Optional[List[str]] = None,
-                    as_dataframe: bool = False):
+    def get_vectors(
+        self,
+        name,
+        ids: Optional[List[str]] = None,
+        columns: Optional[List[str]] = None,
+        as_dataframe: bool = False,
+    ):
         """
         Get the vectors for some corpus component objects.
 
         :param name: name of the vector matrix
         :param ids: optional list of object ids to get vectors for; all by default
         :param columns: optional list of named columns of the vector to include; all by default
         :param as_dataframe: whether to return the vector as a dataframe (True) or in its raw array form (False). False
             by default.
         :return: a vector matrix (either np.ndarray or csr_matrix) or a pandas dataframe
         """
-        return self.get_vector_matrix(name).get_vectors(ids=ids, columns=columns, as_dataframe=as_dataframe)
+        return self.get_vector_matrix(name).get_vectors(
+            ids=ids, columns=columns, as_dataframe=as_dataframe
+        )
 
     def delete_vector_matrix(self, name):
         """
         Deletes the vector matrix stored under `name`.
 
         :param name: name of the vector mtrix
         :return: None
         """
         self.meta_index.vectors.remove(name)
         if name in self._vector_matrices:
             del self._vector_matrices[name]
 
     def dump_vectors(self, name, dir_name=None):
-
         if (self.corpus_dirpath is None) and (dir_name is None):
-            raise ValueError('Must specify a directory to read from.')
+            raise ValueError("Must specify a directory to read from.")
         if dir_name is None:
             dir_name = self.corpus_dirpath
 
         self.get_vector_matrix(name).dump(dir_name)
 
     def load_info(self, obj_type, fields=None, dir_name=None):
         """
@@ -1033,33 +1282,32 @@
         :param dir_name: the directory to read attributes from. by default, or if set to None, will read from the directory that the Corpus was loaded from.
         :return: None
         """
         if fields is None:
             fields = []
 
         if (self.corpus_dirpath is None) and (dir_name is None):
-            raise ValueError('Must specify a directory to read from.')
+            raise ValueError("Must specify a directory to read from.")
         if dir_name is None:
             dir_name = self.corpus_dirpath
 
         if len(fields) == 0:
-            fields = [x.replace('info.', '').replace('.jsonl', '') for x in os.listdir(dir_name)
-                      if x.startswith('info')]
+            fields = [
+                x.replace("info.", "").replace(".jsonl", "")
+                for x in os.listdir(dir_name)
+                if x.startswith("info")
+            ]
 
         for field in fields:
             # self.aux_info[field] = self.load_jsonlist_to_dict(
             #     os.path.join(dir_name, 'feat.%s.jsonl' % field))
-            getter = lambda oid: self.get_object(obj_type, oid)
-            entries = load_jsonlist_to_dict(os.path.join(dir_name, 'info.%s.jsonl' % field))
-            for k, v in entries.items():
-                try:
-                    obj = getter(k)
-                    obj.set_info(field, v)
-                except:
-                    continue
+            if self.backend == "mem":
+                load_info_to_mem(self, dir_name, obj_type, field)
+            elif self.backend == "db":
+                load_info_to_db(self, dir_name, obj_type, field)
 
     def dump_info(self, obj_type, fields, dir_name=None):
         """
         writes attributes of objects in a corpus to disk.
         This function, along with load_info, supports cases where a particular attribute is to be stored separately from the other corpus files, for organization or efficiency. These attributes will not be read when the corpus is initialized; rather, they can be loaded on-demand using this function.
 
         For each attribute with name <NAME>, will write to a file called info.<NAME>.jsonl, where rows are json-serialized dictionaries structured as {"id": id of object, "value": value of attribute}.
@@ -1067,120 +1315,82 @@
         :param obj_type: type of object the attribute is associated with. can be one of "utterance", "speaker", "conversation".
         :param fields: a list of names of attributes to write to disk.
         :param dir_name: the directory to write attributes to. by default, or if set to None, will read from the directory that the Corpus was loaded from.
         :return: None
         """
 
         if (self.corpus_dirpath is None) and (dir_name is None):
-            raise ValueError('must specify a directory to write to')
+            raise ValueError("must specify a directory to write to")
 
         if dir_name is None:
             dir_name = self.corpus_dirpath
         # if len(fields) == 0:
         #     fields = self.aux_info.keys()
         for field in fields:
             # if field not in self.aux_info:
             #     raise ValueError("field %s not in index" % field)
             iterator = self.iter_objs(obj_type)
             entries = {obj.id: obj.retrieve_meta(field) for obj in iterator}
             # self.dump_jsonlist_from_dict(self.aux_info[field],
             #     os.path.join(dir_name, 'feat.%s.jsonl' % field))
-            dump_jsonlist_from_dict(entries, os.path.join(dir_name, 'info.%s.jsonl' % field))
-
-    # def load_vector_reprs(self, field, dir_name=None):
-    #     """
-    #     reads vector representations of Corpus objects from disk.
-    #
-    #     Will read matrices from a file called vect_info.<field>.npy and corresponding object IDs from a file called vect_info.<field>.keys,
-    #
-    #     :param field: the name of the representation
-    #     :param dir_name: the directory to read from; by default, or if set to None, will read from the directory that the Corpus was loaded from.
-    #     :return: None
-    #     """
-    #
-    #     if (self.corpus_dirpath is None) and (dir_name is None):
-    #         raise ValueError('must specify a directory to read from')
-    #     if dir_name is None:
-    #         dir_name = self.corpus_dirpath
-    #
-    #     self._vector_matrices[field] = self._load_vectors(
-    #         os.path.join(dir_name, 'vect_info.' + field)
-    #     )
-    #
-    # def dump_vector_reprs(self, field, dir_name=None):
-    #     """
-    #     writes vector representations of Corpus objects to disk.
-    #
-    #     Will write matrices to a file called vect_info.<field>.npy and corresponding object IDs to a file called vect_info.<field>.keys,
-    #
-    #     :param field: the name of the representation to write to disk
-    #     :param dir_name: the directory to write to. by default, or if set to None, will read from the directory that the Corpus was loaded from.
-    #     :return: None
-    #     """
-    #
-    #     if (self.corpus_dirpath is None) and (dir_name is None):
-    #         raise ValueError('must specify a directory to write to')
-    #
-    #     if dir_name is None:
-    #         dir_name = self.corpus_dirpath
-    #
-    #     self._dump_vectors(self._vector_matrices[field], os.path.join(dir_name, 'vect_info.' + field))
+            dump_jsonlist_from_dict(entries, os.path.join(dir_name, "info.%s.jsonl" % field))
 
     def get_attribute_table(self, obj_type, attrs):
         """
         returns a DataFrame, indexed by the IDs of objects of `obj_type`, containing attributes of these objects.
 
         :param obj_type: the type of object to get attributes for. can be `'utterance'`, `'speaker'` or `'conversation'`.
         :param attrs: a list of names of attributes to get.
         :return: a Pandas DataFrame of attributes.
         """
         iterator = self.iter_objs(obj_type)
 
         table_entries = []
         for obj in iterator:
             entry = dict()
-            entry['id'] = obj.id
+            entry["id"] = obj.id
             for attr in attrs:
                 entry[attr] = obj.retrieve_meta(attr)
             table_entries.append(entry)
-        return pd.DataFrame(table_entries).set_index('id')
+        return pd.DataFrame(table_entries).set_index("id")
 
     def set_speaker_convo_info(self, speaker_id, convo_id, key, value):
         """
         assigns speaker-conversation attribute `key` with `value` to speaker `speaker_id` in conversation `convo_id`.
 
         :param speaker_id: speaker
         :param convo_id: conversation
         :param key: name of attribute
         :param value: value of attribute
         :return: None
         """
 
         speaker = self.get_speaker(speaker_id)
-        if 'conversations' not in speaker.meta:
-            speaker.meta['conversations'] = {}
-        if convo_id not in speaker.meta['conversations']:
-            speaker.meta['conversations'][convo_id] = {}
-        speaker.meta['conversations'][convo_id][key] = value
+        speaker_convos = speaker.meta.get("conversations", {})
+        if convo_id not in speaker_convos:
+            speaker_convos[convo_id] = {}
+        speaker_convos[convo_id][key] = value
+        speaker.meta["conversations"] = speaker_convos
 
     def get_speaker_convo_info(self, speaker_id, convo_id, key=None):
         """
         retreives speaker-conversation attribute `key` for `speaker_id` in conversation `convo_id`.
 
         :param speaker_id: speaker
         :param convo_id: conversation
         :param key: name of attribute. if None, will return all attributes for that speaker-conversation.
         :return: attribute value
         """
 
         speaker = self.get_speaker(speaker_id)
-        if 'conversations' not in speaker.meta: return None
+        if "conversations" not in speaker.meta:
+            return None
         if key is None:
-            return speaker.meta['conversations'].get(convo_id, {})
-        return speaker.meta['conversations'].get(convo_id, {}).get(key)
+            return speaker.meta["conversations"].get(convo_id, {})
+        return speaker.meta["conversations"].get(convo_id, {}).get(key)
 
     def organize_speaker_convo_history(self, utterance_filter=None):
         """
         For each speaker, pre-computes a list of all of their utterances, organized by the conversation they participated in. Annotates speaker with the following:
             * `n_convos`: number of conversations
             * `start_time`: time of first utterance, across all conversations
             * `conversations`: a dictionary keyed by conversation id, where entries consist of:
@@ -1196,60 +1406,75 @@
         if utterance_filter is None:
             utterance_filter = lambda x: True
         else:
             utterance_filter = utterance_filter
 
         speaker_to_convo_utts = defaultdict(lambda: defaultdict(list))
         for utterance in self.iter_utterances():
-            if not utterance_filter(utterance): continue
+            if not utterance_filter(utterance):
+                continue
 
             speaker_to_convo_utts[utterance.speaker.id][utterance.conversation_id].append(
-                (utterance.id, utterance.timestamp))
+                (utterance.id, utterance.timestamp)
+            )
         for speaker, convo_utts in speaker_to_convo_utts.items():
             for convo, utts in convo_utts.items():
                 sorted_utts = sorted(utts, key=lambda x: (x[1], x[0]))
-                self.set_speaker_convo_info(speaker, convo, 'utterance_ids', [x[0] for x in sorted_utts])
-                self.set_speaker_convo_info(speaker, convo, 'start_time', sorted_utts[0][1])
-                self.set_speaker_convo_info(speaker, convo, 'n_utterances', len(sorted_utts))
+                self.set_speaker_convo_info(
+                    speaker, convo, "utterance_ids", [x[0] for x in sorted_utts]
+                )
+                self.set_speaker_convo_info(speaker, convo, "start_time", sorted_utts[0][1])
+                self.set_speaker_convo_info(speaker, convo, "n_utterances", len(sorted_utts))
         for speaker in self.iter_speakers():
             try:
-                speaker.set_info('n_convos', len(speaker.retrieve_meta('conversations')))
+                speaker.add_meta("n_convos", len(speaker.retrieve_meta("conversations")))
             except:
                 continue
 
-            sorted_convos = sorted(speaker.retrieve_meta('conversations').items(),
-                                   key=lambda x: (x[1]['start_time'], x[1]['utterance_ids'][0]))
-            speaker.set_info('start_time', sorted_convos[0][1]['start_time'])
+            sorted_convos = sorted(
+                speaker.retrieve_meta("conversations").items(),
+                key=lambda x: (x[1]["start_time"], x[1]["utterance_ids"][0]),
+            )
+            speaker.add_meta("start_time", sorted_convos[0][1]["start_time"])
             for idx, (convo_id, _) in enumerate(sorted_convos):
-                self.set_speaker_convo_info(speaker.id, convo_id, 'idx', idx)
+                self.set_speaker_convo_info(speaker.id, convo_id, "idx", idx)
 
     def get_speaker_convo_attribute_table(self, attrs):
         """
         Returns a table where each row lists a (speaker, convo) level aggregate for each attribute in attrs.
 
         :param attrs: list of (speaker, convo) attribute names
         :return: DataFrame containing all speaker,convo attributes.
         """
 
         table_entries = []
         for speaker in self.iter_speakers():
-            if 'conversations' not in speaker.meta: continue
-            for convo_id, convo_dict in speaker.meta['conversations'].items():
-                entry = {'id': '%s__%s' % (speaker.id, convo_id),
-                         'speaker': speaker.id, 'convo_id': convo_id,
-                         'convo_idx': convo_dict['idx']}
+            if "conversations" not in speaker.meta:
+                continue
+            for convo_id, convo_dict in speaker.meta["conversations"].items():
+                entry = {
+                    "id": "%s__%s" % (speaker.id, convo_id),
+                    "speaker": speaker.id,
+                    "convo_id": convo_id,
+                    "convo_idx": convo_dict["idx"],
+                }
 
                 for attr in attrs:
                     entry[attr] = convo_dict.get(attr, None)
                 table_entries.append(entry)
-        return pd.DataFrame(table_entries).set_index('id')
+        return pd.DataFrame(table_entries).set_index("id")
 
-    def get_full_attribute_table(self, speaker_convo_attrs, speaker_attrs=None, convo_attrs=None,
-                                 speaker_suffix='__speaker',
-                                 convo_suffix='__convo'):
+    def get_full_attribute_table(
+        self,
+        speaker_convo_attrs,
+        speaker_attrs=None,
+        convo_attrs=None,
+        speaker_suffix="__speaker",
+        convo_suffix="__convo",
+    ):
         """
         Returns a table where each row lists a (speaker, convo) level aggregate for each attribute in attrs,
         along with speaker-level and conversation-level attributes; by default these attributes are suffixed with
         '__speaker' and '__convo' respectively.
 
         :param speaker_convo_attrs: list of (speaker, convo) attribute names
         :param speaker_attrs: list of speaker attribute names
@@ -1260,34 +1485,37 @@
         """
         if speaker_attrs is None:
             speaker_attrs = []
         if convo_attrs is None:
             convo_attrs = []
 
         uc_df = self.get_speaker_convo_attribute_table(speaker_convo_attrs)
-        u_df = self.get_attribute_table('speaker', speaker_attrs)
+        u_df = self.get_attribute_table("speaker", speaker_attrs)
         u_df.columns = [x + speaker_suffix for x in u_df.columns]
-        c_df = self.get_attribute_table('conversation', convo_attrs)
+        c_df = self.get_attribute_table("conversation", convo_attrs)
         c_df.columns = [x + convo_suffix for x in c_df.columns]
-        return uc_df.join(u_df, on='speaker').join(c_df, on='convo_id')
+        return uc_df.join(u_df, on="speaker").join(c_df, on="convo_id")
 
     def update_metadata_from_df(self, obj_type, df):
-        assert obj_type in ['utterance', 'speaker', 'conversation']
+        assert obj_type in ["utterance", "speaker", "conversation"]
         meta_cols = extract_meta_from_df(df)
-        df.columns = [col.replace('meta.', '') for col in df.columns]
-        df = df.set_index('id')
+        df.columns = [col.replace("meta.", "") for col in df.columns]
+        df = df.set_index("id")
         for obj in self.iter_objs(obj_type):
             obj_meta = df.loc[obj.id][meta_cols].to_dict() if meta_cols else None
             if obj_meta is not None:
                 obj.meta.update(obj_meta)
         return self
 
     @staticmethod
-    def from_pandas(utterances_df: DataFrame, speakers_df: Optional[DataFrame] = None,
-                    conversations_df: Optional[DataFrame] = None) -> 'Corpus':
+    def from_pandas(
+        utterances_df: DataFrame,
+        speakers_df: Optional[DataFrame] = None,
+        conversations_df: Optional[DataFrame] = None,
+    ) -> "Corpus":
         """
         Generates a Corpus from utterances, speakers, and conversations dataframes.
         For each dataframe, if the 'id' column is absent, the dataframe index will be used as the id.
         Metadata should be denoted with a 'meta.<key>' column in the dataframe. For example, if an utterance is to have
         a metadata key 'score', then the 'meta.score' column must be present in dataframe.
 
         `speakers_df` and `conversations_df` are optional, as their IDs can be inferred from `utterances_df`, and so
@@ -1300,49 +1528,65 @@
         metadata keys in the dataframe if it would be inconvenient.
 
         :param utterances_df: utterances data in a pandas Dataframe, all primary data fields expected, with metadata optional
         :param speakers_df: (optional) speakers data in a pandas Dataframe
         :param conversations_df: (optional) conversations data in a pandas Dataframe
         :return: Corpus constructed from the dataframe(s)
         """
-        columns = ['speaker', 'id', 'timestamp', 'conversation_id', 'reply_to', 'text']
-
-        for (df_type, df) in [('utterances', utterances_df), ('conversations', conversations_df),
-                              ('speakers', speakers_df)]:
-            if df is None: continue
-            if 'id' not in df.columns:
-                print(f'ID column is not present in {df_type} dataframe, generated ID column from dataframe index...')
-                df['id'] = df.index
+        columns = ["speaker", "id", "timestamp", "conversation_id", "reply_to", "text"]
 
-        #checking if dataframes contain their respective required columns
-        assert pd.Series(columns).isin(utterances_df.columns).all(), "Utterances dataframe must contain all primary data fields"
+        for df_type, df in [
+            ("utterances", utterances_df),
+            ("conversations", conversations_df),
+            ("speakers", speakers_df),
+        ]:
+            if df is None:
+                continue
+            if "id" not in df.columns:
+                print(
+                    f"ID column is not present in {df_type} dataframe, generated ID column from dataframe index..."
+                )
+                df["id"] = df.index
+
+        # checking if dataframes contain their respective required columns
+        assert (
+            pd.Series(columns).isin(utterances_df.columns).all()
+        ), "Utterances dataframe must contain all primary data fields"
 
         utterance_meta_cols = extract_meta_from_df(utterances_df)
 
         utterance_list = []
         for index, row in tqdm(utterances_df.iterrows()):
             if utterance_meta_cols:
                 metadata = {}
                 for meta_col in utterance_meta_cols:
-                    metadata[meta_col] = row['meta.' + meta_col]
-            else: 
+                    metadata[meta_col] = row["meta." + meta_col]
+            else:
                 metadata = None
 
             # adding utterance in utterance list
-            reply_to = None if row['reply_to'] == "None" else row['reply_to']
-            utterance_list.append(Utterance(id=str(row['id']), speaker=Speaker(id=str(row['speaker'])),
-                                            conversation_id=str(row['conversation_id']), reply_to=reply_to,
-                                            timestamp=row['timestamp'], text=row['text'],
-                                            meta=metadata))
+            reply_to = None if row["reply_to"] == "None" else row["reply_to"]
+            utterance_list.append(
+                Utterance(
+                    id=str(row["id"]),
+                    speaker=Speaker(id=str(row["speaker"])),
+                    conversation_id=str(row["conversation_id"]),
+                    reply_to=reply_to,
+                    timestamp=row["timestamp"],
+                    text=row["text"],
+                    meta=metadata,
+                )
+            )
 
         # initializing corpus using utterance_list
         corpus = Corpus(utterances=utterance_list)
         if speakers_df is not None:
-            corpus.update_metadata_from_df('speaker', speakers_df)
+            corpus.update_metadata_from_df("speaker", speakers_df)
         if conversations_df is not None:
-            corpus.update_metadata_from_df('conversation', conversations_df)
+            corpus.update_metadata_from_df("conversation", conversations_df)
 
         return corpus
 
+
 # def __repr__(self):
 # def __eq__(self, other):
 #     return True
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `convokit-2.5.3/convokit/model/speaker.py` & `convokit-3.0.0/convokit/model/speaker.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from functools import total_ordering
-from typing import Dict, List, Optional, Callable
-from convokit.util import deprecation
+from typing import Dict, List, Optional
+
 from .corpusComponent import CorpusComponent
 from .corpusUtil import *
 
 
 @total_ordering
 class Speaker(CorpusComponent):
     """
@@ -19,17 +19,23 @@
     :type meta: dict
 
     :ivar id: id of the speaker.
     :ivar meta: A dictionary-like view object providing read-write access to
         speaker-level metadata.
     """
 
-    def __init__(self, owner=None, id: str = None, name: str = None, utts=None, convos = None, meta: Optional[Dict] = None):
-        name_var = id if id is not None else name # to be deprecated
-        super().__init__(obj_type="speaker", owner=owner, id=name_var, meta=meta)
+    def __init__(
+        self,
+        owner=None,
+        id: str = None,
+        utts=None,
+        convos=None,
+        meta: Optional[Dict] = None,
+    ):
+        super().__init__(obj_type="speaker", owner=owner, id=id, meta=meta)
         self.utterances = utts if utts is not None else dict()
         self.conversations = convos if convos is not None else dict()
         # self._split_attribs = set()
         # self._update_uid()
 
     # def identify_by_attribs(self, attribs: Collection) -> None:
     #     """Identify a speaker by a list of attributes. Sets which speaker info
@@ -43,83 +49,74 @@
     #     :param attribs: Collection of attribute names.
     #     :type attribs: Collection
     #     """
     #
     #     self._split_attribs = set(attribs)
     #     # self._update_uid()
 
-    def _get_name(self):
-        deprecation("speaker.name", "speaker.id")
-        return self._id
-
-    def _set_name(self, value: str):
-        deprecation("speaker.name", "speaker.id")
-        self._id = value
-        # self._update_uid()
-
-    name = property(_get_name, _set_name)
-
     def _add_utterance(self, utt):
         self.utterances[utt.id] = utt
 
     def _add_conversation(self, convo):
         self.conversations[convo.id] = convo
 
-    def get_utterance(self, ut_id: str): #-> Utterance:
+    def get_utterance(self, ut_id: str):  # -> Utterance:
         """
         Get the Utterance with the specified Utterance id
 
         :param ut_id: The id of the Utterance
         :return: An Utterance object
         """
         return self.utterances[ut_id]
 
-    def iter_utterances(self, selector=lambda utt: True): #-> Generator[Utterance, None, None]:
+    def iter_utterances(self, selector=lambda utt: True):  # -> Generator[Utterance, None, None]:
         """
         Get utterances made by the Speaker, with an optional selector that selects for Utterances that
         should be included.
 
-		:param selector: a (lambda) function that takes an Utterance and returns True or False (i.e. include / exclude).
-			By default, the selector includes all Utterances in the Corpus.
+                :param selector: a (lambda) function that takes an Utterance and returns True or False (i.e. include / exclude).
+                        By default, the selector includes all Utterances in the Corpus.
         :return: An iterator of the Utterances made by the speaker
         """
         for v in self.utterances.values():
             if selector(v):
                 yield v
 
     def get_utterances_dataframe(self, selector=lambda utt: True, exclude_meta: bool = False):
         """
-		Get a DataFrame of the Utterances made by the Speaker with fields and metadata attributes.
-		Set an optional selector that filters for Utterances that should be included.
-		Edits to the DataFrame do not change the corpus in any way.
-
-		:param exclude_meta: whether to exclude metadata
-		:param selector: a (lambda) function that takes a Utterance and returns True or False (i.e. include / exclude).
-			By default, the selector includes all Utterances in the Corpus.
-		:return: a pandas DataFrame
-		"""
+        Get a DataFrame of the Utterances made by the Speaker with fields and metadata attributes.
+        Set an optional selector that filters for Utterances that should be included.
+        Edits to the DataFrame do not change the corpus in any way.
+
+        :param exclude_meta: whether to exclude metadata
+        :param selector: a (lambda) function that takes a Utterance and returns True or False (i.e. include / exclude).
+                By default, the selector includes all Utterances in the Corpus.
+        :return: a pandas DataFrame
+        """
         return get_utterances_dataframe(self, selector, exclude_meta)
 
     def get_utterance_ids(self, selector=lambda utt: True) -> List[str]:
         """
 
         :return: a List of the ids of Utterances made by the speaker
         """
         return list([utt.id for utt in self.iter_utterances(selector)])
 
-    def get_conversation(self, cid: str): # -> Conversation:
+    def get_conversation(self, cid: str):  # -> Conversation:
         """
         Get the Conversation with the specified Conversation id
 
         :param cid: The id of the Conversation
         :return: A Conversation object
         """
         return self.conversations[cid]
 
-    def iter_conversations(self, selector=lambda convo: True): # -> Generator[Conversation, None, None]:
+    def iter_conversations(
+        self, selector=lambda convo: True
+    ):  # -> Generator[Conversation, None, None]:
         """
 
         :return: An iterator of the Conversations that the speaker has participated in
         """
         for v in self.conversations.values():
             if selector(v):
                 yield v
@@ -161,8 +158,13 @@
 
     def __eq__(self, other):
         if not isinstance(other, Speaker):
             return False
         try:
             return self.id == other.id
         except AttributeError:
-            return self.__dict__['_name'] == other.__dict__['_name']
+            return self.__dict__["_name"] == other.__dict__["_name"]
+
+    def __str__(self):
+        return "Speaker(id: {}, vectors: {}, meta: {})".format(
+            repr(self.id), self.vectors, self.meta
+        )
```

### Comparing `convokit-2.5.3/convokit/model/utterance.py` & `convokit-3.0.0/convokit/model/utterance.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 from typing import Dict, Optional
-from convokit.util import deprecation, warn
+
+from convokit.util import warn
 from .corpusComponent import CorpusComponent
 from .speaker import Speaker
 
 
 class Utterance(CorpusComponent):
     """Represents a single utterance in the dataset.
 
@@ -21,49 +22,101 @@
     :ivar reply_to: id of the utterance this was a reply to.
     :ivar timestamp: timestamp of the utterance.
     :ivar text: text of the utterance.
     :ivar meta: A dictionary-like view object providing read-write access to
         utterance-level metadata.
     """
 
-    def __init__(self, owner=None, id: Optional[str] = None, speaker: Optional[Speaker] = None,
-                 user: Optional[Speaker] = None, conversation_id: Optional[str] = None,
-                 root: Optional[str] = None, reply_to: Optional[str] = None,
-                 timestamp: Optional[int] = None, text: str = '',
-                 meta: Optional[Dict] = None):
-        super().__init__(obj_type="utterance", owner=owner, id=id, meta=meta)
-        speaker_ = speaker if speaker is not None else user
-        self.speaker = speaker_
-        if self.speaker is None:
+    def __init__(
+        self,
+        owner=None,
+        id: Optional[str] = None,
+        speaker: Optional[Speaker] = None,
+        conversation_id: Optional[str] = None,
+        reply_to: Optional[str] = None,
+        timestamp: Optional[int] = None,
+        text: str = "",
+        meta: Optional[Dict] = None,
+    ):
+        # check arguments that have alternate naming due to backwards compatibility
+        if speaker is None:
             raise ValueError("No Speaker found: Utterance must be initialized with a Speaker.")
-        self.user = speaker # for backwards compatbility
-        self.conversation_id = conversation_id if conversation_id is not None else root
-        if self.conversation_id is not None and not isinstance(self.conversation_id, str):
-            warn("Utterance conversation_id must be a string: conversation_id of utterance with ID: {} "
-                 "has been casted to a string.".format(self.id))
-            self.conversation_id = str(self.conversation_id)
-        self._root = self.conversation_id
-        self.reply_to = reply_to
-        self.timestamp = timestamp # int(timestamp) if timestamp is not None else timestamp
+
+        if conversation_id is not None and not isinstance(conversation_id, str):
+            warn(
+                "Utterance conversation_id must be a string: conversation_id of utterance with ID: {} "
+                "has been casted to a string.".format(id)
+            )
+            conversation_id = str(conversation_id)
         if not isinstance(text, str):
-            warn("Utterance text must be a string: text of utterance with ID: {} "
-                 "has been casted to a string.".format(self.id))
-            text = '' if text is None else str(text)
-        self.text = text
-
-    def _get_root(self):
-        deprecation("utterance.root", "utterance.conversation_id")
-        return self.conversation_id
-
-    def _set_root(self, value: str):
-        deprecation("utterance.root", "utterance.conversation_id")
-        self.conversation_id = value
-        # self._update_uid()
+            warn(
+                "Utterance text must be a string: text of utterance with ID: {} "
+                "has been casted to a string.".format(id)
+            )
+            text = "" if text is None else str(text)
+
+        props = {
+            "speaker_id": speaker.id,
+            "conversation_id": conversation_id,
+            "reply_to": reply_to,
+            "timestamp": timestamp,
+            "text": text,
+        }
+        super().__init__(obj_type="utterance", owner=owner, id=id, initial_data=props, meta=meta)
+        self.speaker_ = speaker
+
+    ############################################################################
+    ## directly-accessible class properties (roughly equivalent to keys in the
+    ## JSON, plus aliases for compatibility)
+    ############################################################################
+
+    def _get_speaker(self):
+        return self.speaker_
+
+    def _set_speaker(self, val):
+        self.speaker_ = val
+        self.set_data("speaker_id", self.speaker.id)
+
+    speaker = property(_get_speaker, _set_speaker)
+
+    def _get_conversation_id(self):
+        return self.get_data("conversation_id")
+
+    def _set_conversation_id(self, val):
+        self.set_data("conversation_id", val)
+
+    conversation_id = property(_get_conversation_id, _set_conversation_id)
+
+    def _get_reply_to(self):
+        return self.get_data("reply_to")
 
-    root = property(_get_root, _set_root)
+    def _set_reply_to(self, val):
+        self.set_data("reply_to", val)
+
+    reply_to = property(_get_reply_to, _set_reply_to)
+
+    def _get_timestamp(self):
+        return self.get_data("timestamp")
+
+    def _set_timestamp(self, val):
+        self.set_data("timestamp", val)
+
+    timestamp = property(_get_timestamp, _set_timestamp)
+
+    def _get_text(self):
+        return self.get_data("text")
+
+    def _set_text(self, val):
+        self.set_data("text", val)
+
+    text = property(_get_text, _set_text)
+
+    ############################################################################
+    ## end properties
+    ############################################################################
 
     def get_conversation(self):
         """
         Get the Conversation (identified by Utterance.conversation_id) this Utterance belongs to
 
         :return: a Conversation object
         """
@@ -74,31 +127,55 @@
         Get the Speaker that made this Utterance.
 
         :return: a Speaker object
         """
 
         return self.speaker
 
+    def to_dict(self):
+        return {
+            "id": self.id,
+            "conversation_id": self.conversation_id,
+            "reply_to": self.reply_to,
+            "speaker": self.speaker,
+            "timestamp": self.timestamp,
+            "text": self.text,
+            "vectors": self.vectors,
+            "meta": self.meta if type(self.meta) == dict else self.meta.to_dict(),
+        }
+
     def __hash__(self):
         return super().__hash__()
 
     def __eq__(self, other):
         if not isinstance(other, Utterance):
             return False
         try:
-            return self.id == other.id and self.conversation_id == other.conversation_id and self.reply_to == other.reply_to and \
-                   self.speaker == other.speaker and self.timestamp == other.timestamp and self.text == other.text
-        except AttributeError: # for backwards compatibility with wikiconv
+            return (
+                self.id == other.id
+                and (
+                    self.conversation_id is None
+                    or other.conversation_id is None
+                    or self.conversation_id == other.conversation_id
+                )
+                and self.reply_to == other.reply_to
+                and self.speaker == other.speaker
+                and self.timestamp == other.timestamp
+                and self.text == other.text
+            )
+        except AttributeError:  # for backwards compatibility with wikiconv
             return self.__dict__ == other.__dict__
 
     def __str__(self):
-        return "Utterance(id: {}, conversation_id: {}, reply-to: {}, " \
-               "speaker: {}, timestamp: {}, text: {}, vectors: {}, meta: {})".format(repr(self.id),
-                                                                                    self.conversation_id,
-                                                                                    self.reply_to,
-                                                                                    self.speaker,
-                                                                                    self.timestamp,
-                                                                                    repr(self.text),
-                                                                                    self.vectors,
-                                                                                    self.meta)
-
-
+        return (
+            "Utterance(id: {}, conversation_id: {}, reply-to: {}, "
+            "speaker: {}, timestamp: {}, text: {}, vectors: {}, meta: {})".format(
+                repr(self.id),
+                self.conversation_id,
+                self.reply_to,
+                self.speaker,
+                self.timestamp,
+                repr(self.text),
+                self.vectors,
+                self.meta,
+            )
+        )
```

### Comparing `convokit-2.5.3/convokit/model/utteranceNode.py` & `convokit-3.0.0/convokit/model/utteranceNode.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,20 +6,21 @@
 class UtteranceNode:
     """
     Wrapper class around Utterances to facilitiate tree traversal operations
 
     :ivar utt: the Utterance that this Node corresponds to
     :ivar children: a List of Utterance nodes that correspond to Utterances that respond to this node's Utterance
     """
+
     def __init__(self, utt: Utterance):
         self.utt = utt
         self.children = []
 
-    def set_children(self, children: List['UtteranceNode']):
-        self.children = sorted(children, key=lambda w: w.utt.timestamp) # earliest to latest utt
+    def set_children(self, children: List["UtteranceNode"]):
+        self.children = sorted(children, key=lambda w: w.utt.timestamp)  # earliest to latest utt
 
     def pre_order(self):
         """
         Pre-order traversal
         """
         if len(self.children) == 0:
             return [self]
```

### Comparing `convokit-2.5.3/convokit/paired_prediction/pairedPrediction.py` & `convokit-3.0.0/convokit/paired_prediction/pairedPrediction.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,109 +1,139 @@
-from sklearn.pipeline import Pipeline
-from sklearn.preprocessing import StandardScaler
+from typing import List, Callable
+
 from sklearn.linear_model import LogisticRegression
 from sklearn.model_selection import cross_val_score, KFold
-from typing import List, Callable
+from sklearn.pipeline import Pipeline
+from sklearn.preprocessing import StandardScaler
+
 from convokit import Transformer, CorpusComponent, Corpus
-from .util import *
 from convokit.classifier.util import get_coefs_helper
-from convokit.util import deprecation
+from .util import *
+
 
 class PairedPrediction(Transformer):
     """
     At a high level, Paired Prediction is a quasi-experimental method that controls for certain priors,
     see Cheng et al. 2014 for an illustrated example of PairedPrediction in research.
     (https://cs.stanford.edu/people/jure/pubs/disqus-icwsm14.pdf)
 
-    See Pairer's documentation for more information about pairing.
+    See :doc:`Pairer's documentation <pairer>` for more information about pairing.
 
     :param pred_feats: list of metadata attributes (i.e. predictive features) to be used in prediction.
         Features can either be values or a dictionary of key-value pairs.
     :param clf: optional classifier to be used in the paired prediction
     :param pair_id_attribute_name: metadata attribute name to use in annotating object with pair id, default: "pair_id"
     :param label_attribute_name: metadata attribute name to use in annotating object with predicted label, default: "label"
     :param pair_orientation_attribute_name: metadata attribute name to use in annotating object with pair orientation,
         default: "pair_orientation"
 
     """
-    def __init__(self, obj_type: str,
-                 pred_feats: List[str],
-                 clf=None,
-                 pair_id_attribute_name: str = "pair_id",
-                 pair_id_feat_name=None,
-                 label_attribute_name: str = "pair_obj_label",
-                 label_feat_name=None,
-                 pair_orientation_attribute_name: str = "pair_orientation",
-                 pair_orientation_feat_name=None):
 
+    def __init__(
+        self,
+        obj_type: str,
+        pred_feats: List[str],
+        clf=None,
+        pair_id_attribute_name: str = "pair_id",
+        label_attribute_name: str = "pair_obj_label",
+        pair_orientation_attribute_name: str = "pair_orientation",
+    ):
         assert obj_type in ["speaker", "utterance", "conversation"]
         self.obj_type = obj_type
-        self.clf = Pipeline([("standardScaler", StandardScaler(with_mean=False)),
-                             ("logreg", LogisticRegression(solver='liblinear'))]) if clf is None else clf
+        self.clf = (
+            Pipeline(
+                [
+                    ("standardScaler", StandardScaler(with_mean=False)),
+                    ("logreg", LogisticRegression(solver="liblinear")),
+                ]
+            )
+            if clf is None
+            else clf
+        )
         self.pred_feats = pred_feats
-        self.pair_id_attribute_name = pair_id_attribute_name if pair_id_feat_name is None else pair_id_feat_name
-        self.label_attribute_name = label_attribute_name if label_feat_name is None else label_feat_name
-        self.pair_orientation_attribute_name = pair_orientation_attribute_name if \
-            pair_orientation_feat_name is None else pair_orientation_feat_name
-
-        for deprecated_set in [(pair_id_feat_name, 'pair_id_feat_name', 'pair_id_attribute_name'),
-                                (label_feat_name, 'label_feat_name', 'label_attribute_name'),
-                                (pair_orientation_feat_name, 'pair_orientation_feat_name',
-                                 'pair_orientation_attribute_name')]:
-            if deprecated_set[0] is not None:
-                deprecation(f"PairedPrediction's {deprecated_set[1]} parameter", f'{deprecated_set[2]}')
-
-    def fit(self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True):
+        self.pair_id_attribute_name = pair_id_attribute_name
+        self.label_attribute_name = label_attribute_name
+        self.pair_orientation_attribute_name = pair_orientation_attribute_name
+
+    def fit(
+        self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda x: True
+    ):
         """
         Fit the internal classifier on the paired object features, with an optional selector selecting for which corpus objects to include in the analysis
 
         :param corpus: target Corpus
         :param selector: a (lambda) function that takes a Corpus object and returns a bool: True if the object is to be included in the paired prediction. By default, includes all objects.
         :return: fitted PairedPrediction Transformer
         """
         # Check if Pairer.transform() needs to be run first
         self._check_for_pair_information(corpus)
-        pair_id_to_objs = generate_pair_id_to_objs(corpus, self.obj_type, selector, self.pair_orientation_attribute_name,
-                                                   self.label_attribute_name, self.pair_id_attribute_name)
-
-        X, y = generate_paired_X_y(self.pred_feats, self.pair_orientation_attribute_name, pair_id_to_objs)
+        pair_id_to_objs = generate_pair_id_to_objs(
+            corpus,
+            self.obj_type,
+            selector,
+            self.pair_orientation_attribute_name,
+            self.label_attribute_name,
+            self.pair_id_attribute_name,
+        )
+
+        X, y = generate_paired_X_y(
+            self.pred_feats, self.pair_orientation_attribute_name, pair_id_to_objs
+        )
         self.clf.fit(X, y)
         return self
 
     def transform(self, corpus: Corpus) -> Corpus:
         """
         PairedPrediction does not add any annotations to the Corpus.
         """
         return corpus
 
     def _check_for_pair_information(self, corpus):
         # Check if transform() needs to be run first
         sample_obj = next(corpus.iter_objs(self.obj_type))
         meta_keys = set(sample_obj.meta)
-        required_keys = {self.pair_orientation_attribute_name, self.pair_id_attribute_name, self.label_attribute_name}
+        required_keys = {
+            self.pair_orientation_attribute_name,
+            self.pair_id_attribute_name,
+            self.label_attribute_name,
+        }
         required_keys -= meta_keys
         if len(required_keys) > 0:
-            raise ValueError("Some metadata attributes required for paired prediction are missing: {}. "
-                             "You may need to run Pairer.transform() first.".format(required_keys))
-
-    def summarize(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda x: True,
-                  cv=KFold(n_splits=5, shuffle=True)):
+            raise ValueError(
+                "Some metadata attributes required for paired prediction are missing: {}. "
+                "You may need to run Pairer.transform() first.".format(required_keys)
+            )
+
+    def summarize(
+        self,
+        corpus: Corpus,
+        selector: Callable[[CorpusComponent], bool] = lambda x: True,
+        cv=KFold(n_splits=5, shuffle=True),
+    ):
         """
         Run PairedPrediction on the corpus with cross-validation and returns the mean cross-validation score.
 
         :param corpus: target Corpus (must be annotated with pair information using PairedPrediction.transform())
         :param selector: a (lambda) function that takes a Corpus object and returns a bool: True if the object is to be included in summary. By default, includes all objects.
         :param cv: optional CV model: default is KFold(n_splits=5, shuffle=True)
         :return: cross-validation accuracy score
         """
-        pair_id_to_objs = generate_pair_id_to_objs(corpus, self.obj_type, selector, self.pair_orientation_attribute_name,
-                                                   self.label_attribute_name, self.pair_id_attribute_name)
-
-        X, y = generate_paired_X_y(self.pred_feats, self.pair_orientation_attribute_name, pair_id_to_objs)
-        return np.mean(cross_val_score(self.clf, X, y, cv=cv, error_score='raise'))
+        pair_id_to_objs = generate_pair_id_to_objs(
+            corpus,
+            self.obj_type,
+            selector,
+            self.pair_orientation_attribute_name,
+            self.label_attribute_name,
+            self.pair_id_attribute_name,
+        )
+
+        X, y = generate_paired_X_y(
+            self.pred_feats, self.pair_orientation_attribute_name, pair_id_to_objs
+        )
+        return np.mean(cross_val_score(self.clf, X, y, cv=cv, error_score="raise"))
 
     def get_coefs(self, feature_names: List[str], coef_func=None):
         """
         Get dataframe of classifier coefficients.
 
         :param feature_names: list of feature names to get coefficients for
         :param coef_func: function for accessing the list of coefficients from the classifier model; by default, assumes it is a pipeline with a logistic regression component
```

### Comparing `convokit-2.5.3/convokit/paired_prediction/util.py` & `convokit-3.0.0/convokit/paired_prediction/util.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,54 +1,58 @@
 from random import shuffle
 from pandas import DataFrame
 import numpy as np
 from scipy.sparse import csr_matrix, vstack, issparse
 from convokit.classifier.util import extract_feats_from_obj
 
 
-def generate_vectors_paired_X_y(corpus, vector_name, pair_orientation_attribute_name, pair_id_to_objs):
+def generate_vectors_paired_X_y(
+    corpus, vector_name, pair_orientation_attribute_name, pair_id_to_objs
+):
     """
     Generate the X, y matrix for paired prediction and annotate the objects with the pair orientation.
 
     :param corpus:
     :param vector_name:
     :param pair_orientation_attribute_name:
     :param pair_id_to_objs:
     :return:
     """
     pos_orientation_pair_ids = []
     neg_orientation_pair_ids = []
 
     for pair_id, (pos_obj, neg_obj) in pair_id_to_objs.items():
-        if pos_obj.meta[pair_orientation_attribute_name] == 'pos':
+        if pos_obj.meta[pair_orientation_attribute_name] == "pos":
             pos_orientation_pair_ids.append(pair_id)
         else:
             neg_orientation_pair_ids.append(pair_id)
 
-    pos_orientation_pos_objs, pos_orientation_neg_objs = \
-        zip(*[pair_id_to_objs[pair_id] for pair_id in pos_orientation_pair_ids])
-
-    neg_orientation_pos_objs, neg_orientation_neg_objs = \
-        zip(*[pair_id_to_objs[pair_id] for pair_id in neg_orientation_pair_ids])
+    pos_orientation_pos_objs, pos_orientation_neg_objs = zip(
+        *[pair_id_to_objs[pair_id] for pair_id in pos_orientation_pair_ids]
+    )
+
+    neg_orientation_pos_objs, neg_orientation_neg_objs = zip(
+        *[pair_id_to_objs[pair_id] for pair_id in neg_orientation_pair_ids]
+    )
 
     pos_pos_ids = [obj.id for obj in pos_orientation_pos_objs]
     pos_neg_ids = [obj.id for obj in pos_orientation_neg_objs]
 
     neg_pos_ids = [obj.id for obj in neg_orientation_pos_objs]
     neg_neg_ids = [obj.id for obj in neg_orientation_neg_objs]
 
     pos_pos_vectors = corpus.get_vectors(vector_name, pos_pos_ids)
     pos_neg_vectors = corpus.get_vectors(vector_name, pos_neg_ids)
 
     neg_pos_vectors = corpus.get_vectors(vector_name, neg_pos_ids)
     neg_neg_vectors = corpus.get_vectors(vector_name, neg_neg_ids)
 
-    y = np.array([1]*len(pos_orientation_pair_ids) + [0] * len(neg_orientation_pair_ids))
+    y = np.array([1] * len(pos_orientation_pair_ids) + [0] * len(neg_orientation_pair_ids))
 
-    if issparse(pos_pos_vectors): # for csr_matrix
+    if issparse(pos_pos_vectors):  # for csr_matrix
         X = vstack([pos_pos_vectors - pos_neg_vectors, neg_neg_vectors - neg_pos_vectors])
     else:
         X = np.vstack([pos_pos_vectors - pos_neg_vectors, neg_neg_vectors - neg_pos_vectors])
 
     indices = np.arange(X.shape[0])
     shuffle(indices)
     return X[indices], y[indices]
@@ -62,23 +66,23 @@
     :return: X, y matrix representing the predictive features and labels respectively
     """
     pos_obj_dict = dict()
     neg_obj_dict = dict()
     for pair_id, (pos_obj, neg_obj) in pair_id_to_objs.items():
         pos_obj_dict[pair_id] = extract_feats_from_obj(pos_obj, pred_feats)
         neg_obj_dict[pair_id] = extract_feats_from_obj(neg_obj, pred_feats)
-    pos_obj_df = DataFrame.from_dict(pos_obj_dict, orient='index')
-    neg_obj_df = DataFrame.from_dict(neg_obj_dict, orient='index')
+    pos_obj_df = DataFrame.from_dict(pos_obj_dict, orient="index")
+    neg_obj_df = DataFrame.from_dict(neg_obj_dict, orient="index")
 
     X, y = [], []
     pair_ids = list(pair_id_to_objs)
     shuffle(pair_ids)
     for pair_id in pair_ids:
-        pos_feats = np.array(pos_obj_df.loc[pair_id]).astype('float64')
-        neg_feats = np.array(neg_obj_df.loc[pair_id]).astype('float64')
+        pos_feats = np.array(pos_obj_df.loc[pair_id]).astype("float64")
+        neg_feats = np.array(neg_obj_df.loc[pair_id]).astype("float64")
         orientation = pair_id_to_objs[pair_id][0].meta[pair_orientation_attribute_name]
 
         assert orientation in ["pos", "neg"]
 
         if orientation == "pos":
             y.append(1)
             diff = pos_feats - neg_feats
@@ -87,22 +91,31 @@
             diff = neg_feats - pos_feats
 
         X.append(diff)
 
     return csr_matrix(np.array(X)), np.array(y)
 
 
-def generate_pair_id_to_objs(corpus, obj_type, selector, pair_orientation_attribute_name,
-                             label_attribute_name, pair_id_attribute_name):
-    pair_id_to_obj = {'pos': dict(), 'neg': dict()}
+def generate_pair_id_to_objs(
+    corpus,
+    obj_type,
+    selector,
+    pair_orientation_attribute_name,
+    label_attribute_name,
+    pair_id_attribute_name,
+):
+    pair_id_to_obj = {"pos": dict(), "neg": dict()}
     for obj in corpus.iter_objs(obj_type, selector):
-        if obj.meta[pair_orientation_attribute_name] is None: continue
+        if obj.meta[pair_orientation_attribute_name] is None:
+            continue
         pair_id_to_obj[obj.meta[label_attribute_name]][obj.meta[pair_id_attribute_name]] = obj
 
-    valid_pair_ids = set(pair_id_to_obj['pos'].keys()).intersection(set(pair_id_to_obj['neg'].keys()))
+    valid_pair_ids = set(pair_id_to_obj["pos"].keys()).intersection(
+        set(pair_id_to_obj["neg"].keys())
+    )
 
     # print(set(pair_id_to_obj['pos'].keys()))
     print("Found {} valid pairs.".format(len(valid_pair_ids)))
     pair_id_to_objs = dict()
     for pair_id in valid_pair_ids:
-        pair_id_to_objs[pair_id] = (pair_id_to_obj['pos'][pair_id], pair_id_to_obj['neg'][pair_id])
+        pair_id_to_objs[pair_id] = (pair_id_to_obj["pos"][pair_id], pair_id_to_obj["neg"][pair_id])
     return pair_id_to_objs
```

### Comparing `convokit-2.5.3/convokit/phrasing_motifs/censorNouns.py` & `convokit-3.0.0/convokit/phrasing_motifs/censorNouns.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,60 +1,74 @@
 from convokit.text_processing import TextProcessor
 
-NP_LABELS = set(['nsubj', 'nsubjpass', 'dobj', 'iobj', 'pobj', 'attr'])
+NP_LABELS = set(["nsubj", "nsubjpass", "dobj", "iobj", "pobj", "attr"])
 
 
 class CensorNouns(TextProcessor):
-	"""
-		Transformer that, given a parse (formatted as the output of a TextParser transformer) returns a parse where nouns and pronouns are replaced with "NN~". A rough heuristic for removing "content-related" tokens. This transformer also collapses constructions with Wh-determiners like What time [is it] into What [is it].
+    """
+    Transformer that, given a parse (formatted as the output of a TextParser transformer) returns a parse where nouns and pronouns are replaced with "NN~". A rough heuristic for removing "content-related" tokens. This transformer also collapses constructions with Wh-determiners like What time [is it] into What [is it].
+
+    :param output_field: name of attribute to output to.
+    :param input_field: name of field to use as input. defaults to 'parsed', which stores dependency parses as returned by the TextParser transformer; otherwise expects similarly-formatted input.
+    :param input_filter: a boolean function of signature `input_filter(utterance, aux_input)`. parses will only be computed for utterances where `input_filter` returns `True`. By default, will always return `True`, meaning that arcs will be computed for all utterances.
+    :param verbosity: frequency of status messages.
+    """
+
+    def __init__(self, output_field, input_field="parsed", input_filter=None, verbosity=0):
+        TextProcessor.__init__(
+            self,
+            censor_nouns,
+            output_field=output_field,
+            input_field=input_field,
+            input_filter=input_filter,
+            verbosity=verbosity,
+        )
 
-		:param output_field: name of attribute to output to.
-		:param input_field: name of field to use as input. defaults to 'parsed', which stores dependency parses as returned by the TextParser transformer; otherwise expects similarly-formatted input.
-		:param input_filter: a boolean function of signature `input_filter(utterance, aux_input)`. parses will only be computed for utterances where `input_filter` returns `True`. By default, will always return `True`, meaning that arcs will be computed for all utterances.
-		:param verbosity: frequency of status messages.
-	"""
-
-	def __init__(self, output_field, input_field='parsed', input_filter=None, verbosity=0):
-		TextProcessor.__init__(self, censor_nouns, 
-			output_field=output_field, input_field=input_field,
-			input_filter=input_filter, verbosity=verbosity)
 
 def _is_noun_ish(tok):
-	return (tok['dep'] in NP_LABELS) or \
-		(tok['tag'].startswith('NN') or tok['tag'].startswith('PRP')) \
-			or (tok['tag'].endswith('DET')  or tok['tag'].endswith('DT'))
+    return (
+        (tok["dep"] in NP_LABELS)
+        or (tok["tag"].startswith("NN") or tok["tag"].startswith("PRP"))
+        or (tok["tag"].endswith("DET") or tok["tag"].endswith("DT"))
+    )
+
 
 def _get_w_det(tok, sent):
+    if tok["tag"].startswith("W"):
+        return tok["tok"]
+    if len(tok["dn"]) == 0:
+        return False
+    first_tok = sent["toks"][tok["dn"][0]]
+    if first_tok["tag"].startswith("W"):
+        return first_tok["tok"]
+    return False
 
-	if tok['tag'].startswith('W'): return tok['tok']
-	if len(tok['dn']) == 0: return False
-	first_tok = sent['toks'][tok['dn'][0]]
-	if first_tok['tag'].startswith('W'): return first_tok['tok']
-	return False
 
 def _convert_noun(tok, sent):
-	if _is_noun_ish(tok):
-		has_w = _get_w_det(tok, sent)
-		if has_w:
-			return has_w.lower()
-		else:
-			return 'NN~'
-	return tok['tok'].lower()
+    if _is_noun_ish(tok):
+        has_w = _get_w_det(tok, sent)
+        if has_w:
+            return has_w.lower()
+        else:
+            return "NN~"
+    return tok["tok"].lower()
+
 
 def censor_nouns(text_entry):
-	"""
-		Stand-alone function that removes nouns from parsed text.
+    """
+    Stand-alone function that removes nouns from parsed text.
 
-		:param text_entry: parsed text
-		:return: parse with nouns censored out.
-	"""
-
-	sents = []
-	for raw_sent in text_entry:
-		sent = {'rt': raw_sent['rt'], 'toks': []}
-		for raw_tok in raw_sent['toks']:
-			tok = {k: raw_tok[k] for k in ['dep','dn','tag']}
-			if 'up' in raw_tok: tok['up'] = raw_tok['up']
-			tok['tok'] = _convert_noun(raw_tok, raw_sent)
-			sent['toks'].append(tok)
-		sents.append(sent)
-	return sents
+    :param text_entry: parsed text
+    :return: parse with nouns censored out.
+    """
+
+    sents = []
+    for raw_sent in text_entry:
+        sent = {"rt": raw_sent["rt"], "toks": []}
+        for raw_tok in raw_sent["toks"]:
+            tok = {k: raw_tok[k] for k in ["dep", "dn", "tag"]}
+            if "up" in raw_tok:
+                tok["up"] = raw_tok["up"]
+            tok["tok"] = _convert_noun(raw_tok, raw_sent)
+            sent["toks"].append(tok)
+        sents.append(sent)
+    return sents
```

### Comparing `convokit-2.5.3/convokit/phrasing_motifs/phrasingMotifs.py` & `convokit-3.0.0/convokit/phrasing_motifs/phrasingMotifs.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,50 +1,56 @@
-from convokit.text_processing import TextProcessor
 import itertools
-from collections import defaultdict
 import json
 import os
+from collections import defaultdict
+
+from convokit.text_processing import TextProcessor
 
 
 class PhrasingMotifs(TextProcessor):
     """
-        A model that extracts a set of "phrasings" from a Corpus in the fit step, and that identifies which phrasings in this set are present in an utterance in the transform step. Phrasings intuitively correspond to frequently-occurring structures in the dependency trees of utterances, and are operationalized as frequently-occurring sets of dependency-parse arcs (though any other token-like input could work). 
+    A model that extracts a set of "phrasings" from a Corpus in the fit step, and that identifies which phrasings in this set are present in an utterance in the transform step. Phrasings intuitively correspond to frequently-occurring structures in the dependency trees of utterances, and are operationalized as frequently-occurring sets of dependency-parse arcs (though any other token-like input could work).
 
-        The model expects as input utterances with a field consisting of either a string with space-separated tokens or arcs, or a list of such strings. 
+    The model expects as input utterances with a field consisting of either a string with space-separated tokens or arcs, or a list of such strings.
 
-        As output in the transform step it produces:
-            * a list, one per sentence, of space-separated phrasings contained in each sentence, where each phrasing is represented as a string where components (e.g., arcs) are separated by double underscores '__'. 
-            * a list of sink phrasings in each sentence -- the most finely-specified phrasing encapsulated by the sentence. (e.g., "do you agree..." is more finely-specified than "...agree...")
-
-        Internally the model contains the following elements:
-            * itemset_counts: a dictionary of phrasings to frequencies in the training data
-            * downlinks: the graph structure representing the relationship between phrasings. used to later determine which phrasings are contained in a sentence in the transform step.
-            * itemset_to_ids: maps phrasings to their de-duplicated forms.
-            * min_support: the minimum frequency of a subset that is to be considered a phrasing
-
-        :param output_field: name of attribute to write phrasings to in transform step. sink phrasings will be written to field <output_field>__sink.
-        :param fit_field: name of attribute to use as input in fit. 
-        :param min_support: the minimum frequency of phrasings to return
-        :param fit_filter:  a boolean function of signature `fit_filter(utterance)`. during the fit step phrasings will only be computed over utterances where `fit_filter` returns `True`. By default, will always return `True`, meaning that all utterances will be used.
-        :param transform_field: name of attribute to use as input in transform; defaults to the same field used in fit.
-        :param transform_filter: a boolean function of signature `transform_filter(utterance)`. during the transform step phrasings will only be computed over utterances where `transform_filter` returns `True`. defaults to filter used in fit step.
-        :param deduplication_threshold: merges phrasings into a single phrasing if phrasings co-occur above this frequency (i.e., pr(phrasing 1 | phrasing 2) and vice versa)
-        :param max_naive_itemset_size: maximum size of subsets to compute. above this size, a variant of the a-priori algorithm will be used in lieu of enumerating all possible subsets.
-        :param max_itemset_size: maximum size of subsets to consider as phrasings. setting lower will run faster but miss more complex phrasings.
-        :param verbosity: frequency of status messages.
+    As output in the transform step it produces:
+        * a list, one per sentence, of space-separated phrasings contained in each sentence, where each phrasing is represented as a string where components (e.g., arcs) are separated by double underscores '__'.
+        * a list of sink phrasings in each sentence -- the most finely-specified phrasing encapsulated by the sentence. (e.g., "do you agree..." is more finely-specified than "...agree...")
+
+    Internally the model contains the following elements:
+        * itemset_counts: a dictionary of phrasings to frequencies in the training data
+        * downlinks: the graph structure representing the relationship between phrasings. used to later determine which phrasings are contained in a sentence in the transform step.
+        * itemset_to_ids: maps phrasings to their de-duplicated forms.
+        * min_support: the minimum frequency of a subset that is to be considered a phrasing
+
+    :param output_field: name of attribute to write phrasings to in transform step. sink phrasings will be written to field <output_field>__sink.
+    :param fit_field: name of attribute to use as input in fit.
+    :param min_support: the minimum frequency of phrasings to return
+    :param fit_filter:  a boolean function of signature `fit_filter(utterance)`. during the fit step phrasings will only be computed over utterances where `fit_filter` returns `True`. By default, will always return `True`, meaning that all utterances will be used.
+    :param transform_field: name of attribute to use as input in transform; defaults to the same field used in fit.
+    :param transform_filter: a boolean function of signature `transform_filter(utterance)`. during the transform step phrasings will only be computed over utterances where `transform_filter` returns `True`. defaults to filter used in fit step.
+    :param deduplication_threshold: merges phrasings into a single phrasing if phrasings co-occur above this frequency (i.e., pr(phrasing 1 | phrasing 2) and vice versa)
+    :param max_naive_itemset_size: maximum size of subsets to compute. above this size, a variant of the a-priori algorithm will be used in lieu of enumerating all possible subsets.
+    :param max_itemset_size: maximum size of subsets to consider as phrasings. setting lower will run faster but miss more complex phrasings.
+    :param verbosity: frequency of status messages.
     """
 
-    def __init__(self, output_field, fit_field, 
-                 min_support, 
-                 fit_filter=None, 
-                 transform_field=None,
-                 transform_filter=None,
-                 deduplication_threshold=.9,
-                 max_naive_itemset_size=5, max_itemset_size=10,
-                 verbosity=0):
+    def __init__(
+        self,
+        output_field,
+        fit_field,
+        min_support,
+        fit_filter=None,
+        transform_field=None,
+        transform_filter=None,
+        deduplication_threshold=0.9,
+        max_naive_itemset_size=5,
+        max_itemset_size=10,
+        verbosity=0,
+    ):
         self.min_support = min_support
         self.deduplication_threshold = deduplication_threshold
         self.max_naive_itemset_size = max_naive_itemset_size
         self.max_itemset_size = max_itemset_size
 
         self.fit_field = fit_field
         if fit_filter is None:
@@ -52,362 +58,461 @@
         else:
             self.fit_filter = fit_filter
         if transform_field is None:
             transform_field = fit_field
         if transform_filter is None:
             transform_filter = fit_filter
 
-        self.phrasing_motif_info = {'itemset_counts': {},
-            'downlinks': {}, 'itemset_to_ids': {}, 'min_support': {}}
-        TextProcessor.__init__(self, self._get_phrasing_motifs_wrapper, output_field=[output_field, output_field + '__sink'], input_field=transform_field, input_filter=transform_filter, aux_input=self.phrasing_motif_info,
-                              verbosity=verbosity)
-    
+        self.phrasing_motif_info = {
+            "itemset_counts": {},
+            "downlinks": {},
+            "itemset_to_ids": {},
+            "min_support": {},
+        }
+        TextProcessor.__init__(
+            self,
+            self._get_phrasing_motifs_wrapper,
+            output_field=[output_field, output_field + "__sink"],
+            input_field=transform_field,
+            input_filter=transform_filter,
+            aux_input=self.phrasing_motif_info,
+            verbosity=verbosity,
+        )
+
     def fit(self, corpus, y=None):
         """
-            Fits a PhrasingMotifs model for a corpus -- that is, extracts all phrasings from the corpus.
+        Fits a PhrasingMotifs model for a corpus -- that is, extracts all phrasings from the corpus.
 
-            :param corpus: Corpus
-            :return: None
+        :param corpus: Corpus
+        :return: None
         """
 
         arcset_dict = self._get_sent_arcset_dict(corpus)
-        self.phrasing_motif_info = extract_phrasing_motifs(arcset_dict, self.min_support, self.deduplication_threshold,
-                       self.max_naive_itemset_size, self.max_itemset_size, self.verbosity)
-    
+        self.phrasing_motif_info = extract_phrasing_motifs(
+            arcset_dict,
+            self.min_support,
+            self.deduplication_threshold,
+            self.max_naive_itemset_size,
+            self.max_itemset_size,
+            self.verbosity,
+        )
+
     def _get_phrasing_motifs_wrapper(self, arcs_per_sent, aux_input):
         return get_phrasing_motifs(arcs_per_sent, self.phrasing_motif_info)
 
     def _get_sent_arcset_dict(self, corpus):
         sent_dict = {}
         for utterance in corpus.iter_utterances():
             if self.fit_filter(utterance):
-                for idx, sent in enumerate(utterance.get_info(self.input_field)):
-
-                    sent_dict['%s__%d' % (utterance.id, idx)] = sent.split()
+                for idx, sent in enumerate(utterance.retrieve_meta(self.input_field)):
+                    sent_dict["%s__%d" % (utterance.id, idx)] = sent.split()
         return sent_dict
-    
+
     def load_model(self, model_dir):
         """
-            Loads a saved PhrasingMotifs model from disk.
+        Loads a saved PhrasingMotifs model from disk.
 
-            :param model_dir: directory to read model from.
-            :return: None
+        :param model_dir: directory to read model from.
+        :return: None
         """
 
         if self.verbosity > 0:
-            print('reading itemset counts')
-        with open(os.path.join(model_dir, 'itemset_counts.json')) as f:
-            self.phrasing_motif_info['itemset_counts'] = {tuple(k.split('__')): v for k, v in json.load(f).items()}
-        
+            print("reading itemset counts")
+        with open(os.path.join(model_dir, "itemset_counts.json")) as f:
+            self.phrasing_motif_info["itemset_counts"] = {
+                tuple(k.split("__")): v for k, v in json.load(f).items()
+            }
+
         if self.verbosity > 0:
-            print('reading downlinks')
-        with open(os.path.join(model_dir, 'downlinks.json')) as f:
-            self.phrasing_motif_info['downlinks'] = {tuple(k.split('__')): 
-                  set([tuple(x) for x in v]) for k, v in json.load(f).items()}
+            print("reading downlinks")
+        with open(os.path.join(model_dir, "downlinks.json")) as f:
+            self.phrasing_motif_info["downlinks"] = {
+                tuple(k.split("__")): set([tuple(x) for x in v]) for k, v in json.load(f).items()
+            }
         if self.verbosity > 0:
-            print('reading itemset to ids')
-        with open(os.path.join(model_dir, 'itemset_to_ids.json')) as f:
-            self.phrasing_motif_info['itemset_to_ids'] = {tuple(k.split('__')): tuple(v.split('__')) for k, v in json.load(f).items()}       
+            print("reading itemset to ids")
+        with open(os.path.join(model_dir, "itemset_to_ids.json")) as f:
+            self.phrasing_motif_info["itemset_to_ids"] = {
+                tuple(k.split("__")): tuple(v.split("__")) for k, v in json.load(f).items()
+            }
         if self.verbosity > 0:
-            print('reading meta information')
-        with open(os.path.join(model_dir, 'meta.json')) as f:
-            self.phrasing_motif_info['min_support'] = json.load(f)['min_support']
+            print("reading meta information")
+        with open(os.path.join(model_dir, "meta.json")) as f:
+            self.phrasing_motif_info["min_support"] = json.load(f)["min_support"]
 
     def get_model(self):
-        '''
+        """
         Returns the PhrasingMotifs model. See class docstring for description of fields.
 
         :return: PhrasingMotifs model
-        '''
+        """
         return self.phrasing_motif_info
-    
+
     def dump_model(self, model_dir):
         """
-            Writes the model to disk. 
+        Writes the model to disk.
 
-            Will output one json file per model component.
+        Will output one json file per model component.
 
-            :param model_dir: directory to write to.
-            :return: None
+        :param model_dir: directory to write to.
+        :return: None
         """
 
         if self.verbosity > 0:
-            print('writing itemset counts')
+            print("writing itemset counts")
         if not os.path.exists(model_dir):
             os.mkdir(model_dir)
 
-        with open(os.path.join(model_dir, 'itemset_counts.json'), 'w') as f:
-            json.dump({'__'.join(k):v for k, v in self.phrasing_motif_info['itemset_counts'].items()}, f)
+        with open(os.path.join(model_dir, "itemset_counts.json"), "w") as f:
+            json.dump(
+                {"__".join(k): v for k, v in self.phrasing_motif_info["itemset_counts"].items()}, f
+            )
 
         if self.verbosity > 0:
-            print('writing downlinks')
-        with open(os.path.join(model_dir, 'downlinks.json'), 'w') as f:
-            json.dump({'__'.join(k):sorted(v) 
-                       for k, v in self.phrasing_motif_info['downlinks'].items()}, f)
+            print("writing downlinks")
+        with open(os.path.join(model_dir, "downlinks.json"), "w") as f:
+            json.dump(
+                {"__".join(k): sorted(v) for k, v in self.phrasing_motif_info["downlinks"].items()},
+                f,
+            )
         if self.verbosity > 0:
-            print('writing itemset to ids')
-        with open(os.path.join(model_dir, 'itemset_to_ids.json'), 'w') as f:
-            json.dump({'__'.join(k):'__'.join(v) 
-                       for k, v in self.phrasing_motif_info['itemset_to_ids'].items()}, f)
-        
+            print("writing itemset to ids")
+        with open(os.path.join(model_dir, "itemset_to_ids.json"), "w") as f:
+            json.dump(
+                {
+                    "__".join(k): "__".join(v)
+                    for k, v in self.phrasing_motif_info["itemset_to_ids"].items()
+                },
+                f,
+            )
+
         if self.verbosity > 0:
-            print('writing meta information')
-        with open(os.path.join(model_dir, 'meta.json'), 'w') as f:
-            json.dump({'min_support': self.phrasing_motif_info['min_support']}, f)
-    
+            print("writing meta information")
+        with open(os.path.join(model_dir, "meta.json"), "w") as f:
+            json.dump({"min_support": self.phrasing_motif_info["min_support"]}, f)
+
     def print_top_phrasings(self, k):
         """
-            prints the k most frequent phrasings.
+        prints the k most frequent phrasings.
 
-            :param k: number of phrasings to print
-            :return: None
+        :param k: number of phrasings to print
+        :return: None
         """
 
-        sorted_phrasings = sorted(self.phrasing_motif_info['itemset_counts'].items(),
-                                 key=lambda x: (-x[1], len(x[0]), x[0]))[:k]
+        sorted_phrasings = sorted(
+            self.phrasing_motif_info["itemset_counts"].items(),
+            key=lambda x: (-x[1], len(x[0]), x[0]),
+        )[:k]
         for phrasing, count in sorted_phrasings:
-            print(phrasing,count)
+            print(phrasing, count)
 
 
 def _print_output(i, verbosity):
     return (verbosity > 0) and (i > 0) and (i % verbosity == 0)
 
 
 # fit utilities
 def _get_sorted_combinations(itemset, k):
     combos = set()
     for set_ in itertools.combinations(itemset, k):
         combos.add(tuple(sorted(set_)))
     return combos
 
+
 def _get_mini_powerset(itemset, k):
     powerset = set()
-    for k in range(1, min(k+1, len(itemset) + 1)):
+    for k in range(1, min(k + 1, len(itemset) + 1)):
         powerset.update(_get_sorted_combinations(itemset, k))
     return powerset
 
-def _count_frequent_itemsets(set_dict, min_support, 
-                        max_naive_itemset_size=5, max_itemset_size=100, verbosity=0):
-    
+
+def _count_frequent_itemsets(
+    set_dict, min_support, max_naive_itemset_size=5, max_itemset_size=100, verbosity=0
+):
     if verbosity > 0:
-        print('counting frequent itemsets for %d sets' % len(set_dict))
+        print("counting frequent itemsets for %d sets" % len(set_dict))
     itemset_counts = defaultdict(lambda: defaultdict(int))
     key_to_itemsets = defaultdict(lambda: defaultdict(set))
-    
+
     if verbosity > 0:
-        print('\tfirst pass: counting itemsets up to and including %d items large' % max_naive_itemset_size)
+        print(
+            "\tfirst pass: counting itemsets up to and including %d items large"
+            % max_naive_itemset_size
+        )
     for idx, (key, set_) in enumerate(sorted(set_dict.items())):
         if _print_output(idx, verbosity):
-            print('\tfirst pass: %03d/%03d sets processed' % (idx, len(set_dict)))
+            print("\tfirst pass: %03d/%03d sets processed" % (idx, len(set_dict)))
         for itemset in _get_mini_powerset(set_, max_naive_itemset_size):
             itemset_counts[len(itemset)][itemset] += 1
             key_to_itemsets[key][len(itemset)].add(itemset)
-    
+
     for key, count_dicts in sorted(key_to_itemsets.items()):
         for i in range(1, max_naive_itemset_size + 1):
-            count_dicts[i] = [itemset for itemset in count_dicts[i]
-                             if itemset_counts[i][itemset] >= min_support]
+            count_dicts[i] = [
+                itemset for itemset in count_dicts[i] if itemset_counts[i][itemset] >= min_support
+            ]
     if max_naive_itemset_size >= max_itemset_size:
         return itemset_counts
-    
+
     if verbosity > 0:
-        print('\tsecond pass: counting itemsets more than %d items large' % max_naive_itemset_size)
-    remaining_sets = [key for key, count_dicts in sorted(key_to_itemsets.items()) 
-                          if len(count_dicts[max_naive_itemset_size]) > 0]
+        print("\tsecond pass: counting itemsets more than %d items large" % max_naive_itemset_size)
+    remaining_sets = [
+        key
+        for key, count_dicts in sorted(key_to_itemsets.items())
+        if len(count_dicts[max_naive_itemset_size]) > 0
+    ]
     itemset_size = max_naive_itemset_size + 1
     while (len(remaining_sets) > 0) and (itemset_size <= max_itemset_size):
         if verbosity > 0:
-            print('\tsecond pass: checking %d sets for itemsets of length %d' 
-                  % (len(remaining_sets), itemset_size))
+            print(
+                "\tsecond pass: checking %d sets for itemsets of length %d"
+                % (len(remaining_sets), itemset_size)
+            )
         for idx, key in enumerate(remaining_sets):
             if _print_output(idx, verbosity):
-                print('\tsecond pass: checked %03d/%03d sets for itemsets of length %d'
-                     % (idx, len(remaining_sets), itemset_size))
+                print(
+                    "\tsecond pass: checked %03d/%03d sets for itemsets of length %d"
+                    % (idx, len(remaining_sets), itemset_size)
+                )
             set_ = set_dict[key]
-            if len(set_) < itemset_size:  continue
-            
+            if len(set_) < itemset_size:
+                continue
+
             new_itemsets = set()
             for entry in set_:
                 if itemset_counts[1].get((entry,), 0) >= min_support:
                     for itemset in key_to_itemsets[key][itemset_size - 1]:
                         if entry not in itemset:
                             new_itemset = tuple(sorted(set(itemset + (entry,))))
                             new_itemsets.add(new_itemset)
             for new_itemset in new_itemsets:
                 itemset_counts[itemset_size][new_itemset] += 1
                 key_to_itemsets[key][itemset_size].add(new_itemset)
         for key, count_dicts in sorted(key_to_itemsets.items()):
-            count_dicts[itemset_size] = [itemset for itemset in count_dicts[itemset_size]
-                                        if itemset_counts[itemset_size][itemset] >= min_support]
-        remaining_sets = [key for key, count_dicts in sorted(key_to_itemsets.items())
-                         if len(count_dicts[itemset_size]) > 0]
+            count_dicts[itemset_size] = [
+                itemset
+                for itemset in count_dicts[itemset_size]
+                if itemset_counts[itemset_size][itemset] >= min_support
+            ]
+        remaining_sets = [
+            key
+            for key, count_dicts in sorted(key_to_itemsets.items())
+            if len(count_dicts[itemset_size]) > 0
+        ]
         itemset_size += 1
-    
+
     unrolled_itemset_counts = {}
     for itemset_size, count_dict in sorted(itemset_counts.items()):
         for k, v in sorted(count_dict.items()):
-            if v >= min_support: unrolled_itemset_counts[k] = v
-    unrolled_itemset_counts[('*',)] = len(set_dict)
-    
+            if v >= min_support:
+                unrolled_itemset_counts[k] = v
+    unrolled_itemset_counts[("*",)] = len(set_dict)
+
     unrolled_key_to_itemsets = {}
     for key, count_dicts in sorted(key_to_itemsets.items()):
         curr_unrolled = set()
         for _, count_dict in sorted(count_dicts.items()):
             curr_unrolled.update((k for k in count_dict if k in unrolled_itemset_counts))
         unrolled_key_to_itemsets[key] = sorted(curr_unrolled)
     return unrolled_itemset_counts, unrolled_key_to_itemsets
 
+
 def _make_itemset_tree(itemset_counts, verbosity=0):
-    
     if verbosity > 0:
-        print('making itemset tree for %d itemsets' % len(itemset_counts))
-    
+        print("making itemset tree for %d itemsets" % len(itemset_counts))
+
     edges = []
     uplinks = {}
     downlinks = defaultdict(set)
-    
+
     for itemset, count in sorted(itemset_counts.items()):
         parents = []
         itemset_size = len(itemset)
         if itemset_size == 1:
             item = itemset[0]
             # note this is the only part that is sort of dep-parse specific.
-            if item.endswith('*'):
-                parents.append(('*',))
-            elif '_' in item:
-                parents.append((item.split('_')[0] + '_*',))
-            elif '>' in item:
-                parents.append((item.split('>')[0] + '>*',))
+            if item.endswith("*"):
+                parents.append(("*",))
+            elif "_" in item:
+                parents.append((item.split("_")[0] + "_*",))
+            elif ">" in item:
+                parents.append((item.split(">")[0] + ">*",))
         else:
             for idx in range(itemset_size):
-                parents.append(itemset[:idx] + itemset[idx+1:])
+                parents.append(itemset[:idx] + itemset[idx + 1 :])
         for parent in parents:
             parent_count = itemset_counts[parent]
             pr_child = count / itemset_counts[parent]
-            edges.append({'child': itemset, 'parent': parent})
+            edges.append({"child": itemset, "parent": parent})
             uplinks[itemset] = parent
             downlinks[parent].add(itemset)
     return uplinks, downlinks
 
+
 def _deduplicate_itemsets(itemset_counts, itemset_collections, threshold, verbosity=20000):
     if verbosity > 0:
-        print('deduplicating itemsets')
+        print("deduplicating itemsets")
     cooccurrence_counts = defaultdict(lambda: defaultdict(int))
     for idx, (key, itemsets) in enumerate(sorted(itemset_collections.items())):
         if _print_output(idx, verbosity):
-            print('\tcounting itemset cooccurrences for %03d/%03d collections' 
-                  % (idx, len(itemset_collections)))
+            print(
+                "\tcounting itemset cooccurrences for %03d/%03d collections"
+                % (idx, len(itemset_collections))
+            )
         itemset_list = list(itemsets)
         for i in range(len(itemset_list)):
-            for j in range(i+1, len(itemset_list)):
+            for j in range(i + 1, len(itemset_list)):
                 cooccurrence_counts[itemset_list[i]][itemset_list[j]] += 1
                 cooccurrence_counts[itemset_list[j]][itemset_list[i]] += 1
     if verbosity > 0:
-        print('\tfinding supersets')
+        print("\tfinding supersets")
     superset_idx = 0
     supersets = defaultdict(set)
     itemset_to_superset = {}
     for idx, (itemset, count) in enumerate(sorted(itemset_counts.items())):
         if _print_output(idx, verbosity):
-            print('\tgetting supersets for %03d/%03d itemsets' % (idx, len(itemset_counts)))
-        if itemset in itemset_to_superset: continue
+            print("\tgetting supersets for %03d/%03d itemsets" % (idx, len(itemset_counts)))
+        if itemset in itemset_to_superset:
+            continue
         itemset_to_superset[itemset] = superset_idx
         supersets[superset_idx].add(itemset)
-        stack = [itemset2 for itemset2, count2 in sorted(cooccurrence_counts.get(itemset, {}).items())
-                if (count2/count >= threshold) and (count2/itemset_counts[itemset2] >= threshold)]
+        stack = [
+            itemset2
+            for itemset2, count2 in sorted(cooccurrence_counts.get(itemset, {}).items())
+            if (count2 / count >= threshold) and (count2 / itemset_counts[itemset2] >= threshold)
+        ]
         curr_stack = set(stack)
         while len(stack) > 0:
             neighbor = stack.pop()
             itemset_to_superset[neighbor] = superset_idx
             supersets[superset_idx].add(neighbor)
             neighbor_count = itemset_counts[neighbor]
-            to_push = [itemset2 for itemset2, count2 in sorted(cooccurrence_counts.get(neighbor, {}).items())
-                 if (count2/neighbor_count >= threshold) and (count2/itemset_counts[itemset2] >= threshold)
-                 and (itemset2 not in itemset_to_superset) and (itemset2 not in curr_stack)]
+            to_push = [
+                itemset2
+                for itemset2, count2 in sorted(cooccurrence_counts.get(neighbor, {}).items())
+                if (count2 / neighbor_count >= threshold)
+                and (count2 / itemset_counts[itemset2] >= threshold)
+                and (itemset2 not in itemset_to_superset)
+                and (itemset2 not in curr_stack)
+            ]
             curr_stack.update(to_push)
             stack += to_push
         superset_idx += 1
     superset_ids = {}
-    
+
     for idx, superset in sorted(supersets.items()):
-        superset_ids[idx] = sorted(superset, key=lambda x: (itemset_counts[x], len(x)), reverse=True)[0]
+        superset_ids[idx] = sorted(
+            superset, key=lambda x: (itemset_counts[x], len(x)), reverse=True
+        )[0]
     itemset_to_ids = {k: superset_ids[v] for k, v in sorted(itemset_to_superset.items())}
     supersets_by_id = {superset_ids[k]: list(v) for k, v in sorted(supersets.items())}
     return itemset_to_ids, supersets_by_id
 
-def extract_phrasing_motifs(set_dict, min_support, deduplication_threshold=.9, 
-                           max_naive_itemset_size=5, max_itemset_size=10, verbosity=0):
 
+def extract_phrasing_motifs(
+    set_dict,
+    min_support,
+    deduplication_threshold=0.9,
+    max_naive_itemset_size=5,
+    max_itemset_size=10,
+    verbosity=0,
+):
     """
-        standalone function to extract phrasings -- i.e., frequently-occurring collections of dependency-parse arcs (or other token-like objects).
+    standalone function to extract phrasings -- i.e., frequently-occurring collections of dependency-parse arcs (or other token-like objects).
 
-        :param set_dict: dictionary mapping an ID (e.g., an utterance-sentence ID) to the collection of arcs in the corresponding object.
-        :param min_support: minimum frequency of phrasings to return
-        :param deduplication_threshold: merges phrasings into a single phrasing if phrasings co-occur above this frequency 
-        :param max_naive_itemset_size: maximum size of subsets to compute. 
-        :param max_itemset_size: maximum size of subsets to consider as phrasings. 
-        :param verbosity: frequency of status messages.
+    :param set_dict: dictionary mapping an ID (e.g., an utterance-sentence ID) to the collection of arcs in the corresponding object.
+    :param min_support: minimum frequency of phrasings to return
+    :param deduplication_threshold: merges phrasings into a single phrasing if phrasings co-occur above this frequency
+    :param max_naive_itemset_size: maximum size of subsets to compute.
+    :param max_itemset_size: maximum size of subsets to consider as phrasings.
+    :param verbosity: frequency of status messages.
 
-        :return: phrasing motifs model, as a dict containing each component.
+    :return: phrasing motifs model, as a dict containing each component.
 
     """
 
     # counts frequently co-occurring subsets
-    itemset_counts, itemset_collections = _count_frequent_itemsets(set_dict, min_support,
-                             max_naive_itemset_size, max_itemset_size, verbosity)
+    itemset_counts, itemset_collections = _count_frequent_itemsets(
+        set_dict, min_support, max_naive_itemset_size, max_itemset_size, verbosity
+    )
     # induces a graph that relates subsets to each other
     uplinks, downlinks = _make_itemset_tree(itemset_counts, verbosity)
     # deduplicates frequently co-occurring subsets
-    itemset_to_ids, supersets_by_id = _deduplicate_itemsets(itemset_counts, itemset_collections, 
-                                                          deduplication_threshold, verbosity)
-    return {'itemset_counts': itemset_counts, 'downlinks': downlinks,
-           'itemset_to_ids': itemset_to_ids,  'min_support': min_support}
+    itemset_to_ids, supersets_by_id = _deduplicate_itemsets(
+        itemset_counts, itemset_collections, deduplication_threshold, verbosity
+    )
+    return {
+        "itemset_counts": itemset_counts,
+        "downlinks": downlinks,
+        "itemset_to_ids": itemset_to_ids,
+        "min_support": min_support,
+    }
+
 
 # transform utilities
 
+
 def _contains_candidate(container, candidate):
     return set(candidate).issubset(container)
 
+
 def _get_itemset_collection(items, downlinks, itemset_counts, itemset_to_ids):
     items = sorted(set(items))
     fit_itemsets = {}
     itemset_stack = [(x,) for x in items if (x,) in itemset_counts]
-    if len(itemset_stack) == 0: return {('*',): 0}
+    if len(itemset_stack) == 0:
+        return {("*",): 0}
     i = 0
     while (len(itemset_stack) > 0) and (i < 1000):
         i += 1
         next_itemset = itemset_stack.pop()
         itemset_count = itemset_counts.get(next_itemset, None)
         if itemset_count:
             children = sorted(downlinks.get(next_itemset, []))
-            valid_children = [child for child in children if _contains_candidate(items, child) 
-                             and (child in itemset_counts)]
+            valid_children = [
+                child
+                for child in children
+                if _contains_candidate(items, child) and (child in itemset_counts)
+            ]
             if len(valid_children) == 0:
                 fit_itemsets[next_itemset] = 0
             else:
-                fit_itemsets[next_itemset] = max(itemset_counts.get(child, 0)
-                                                for child in valid_children)
+                fit_itemsets[next_itemset] = max(
+                    itemset_counts.get(child, 0) for child in valid_children
+                )
             itemset_stack += valid_children
     fit_supersets = defaultdict(list)
     for k, v in sorted(fit_itemsets.items()):
         fit_supersets[itemset_to_ids[k]].append(v)
     return {k: min(v) for k, v in sorted(fit_supersets.items())}
 
+
 def get_phrasing_motifs(arcs_per_sent, phrasing_motif_info):
     """
-        standalone function that returns phrasings and sink phrasings given an utterance (consisting of a list of space-separated arcs per each sentence) and a phrasing motif model. 
+    standalone function that returns phrasings and sink phrasings given an utterance (consisting of a list of space-separated arcs per each sentence) and a phrasing motif model.
 
-        :param arcs_per_sent: input arcs per sentence
-        :param phrasing_motif_info: phrasing motif model
-        :return: phrasings and sink phrasings
+    :param arcs_per_sent: input arcs per sentence
+    :param phrasing_motif_info: phrasing motif model
+    :return: phrasings and sink phrasings
     """
 
     phrasings = []
     sink_phrasings = []
     for sent in arcs_per_sent:
-        result = _get_itemset_collection(sent.split(), phrasing_motif_info['downlinks'], phrasing_motif_info['itemset_counts'],
-                                       phrasing_motif_info['itemset_to_ids'])
+        result = _get_itemset_collection(
+            sent.split(),
+            phrasing_motif_info["downlinks"],
+            phrasing_motif_info["itemset_counts"],
+            phrasing_motif_info["itemset_to_ids"],
+        )
         # phrasings.append({'__'.join(k): v  for k, v in result.items() if k != ('*',)})
-        phrasings.append(' '.join(sorted('__'.join(k) for k,v in result.items() if k != ('*',))))
-        sink_phrasings.append(' '.join(sorted('__'.join(k) for k,v in result.items() if (k != ('*',))
-            and (v < phrasing_motif_info['min_support']))))
-    return phrasings, sink_phrasings
+        phrasings.append(" ".join(sorted("__".join(k) for k, v in result.items() if k != ("*",))))
+        sink_phrasings.append(
+            " ".join(
+                sorted(
+                    "__".join(k)
+                    for k, v in result.items()
+                    if (k != ("*",)) and (v < phrasing_motif_info["min_support"])
+                )
+            )
+        )
+    return phrasings, sink_phrasings
```

### Comparing `convokit-2.5.3/convokit/phrasing_motifs/questionSentences.py` & `convokit-3.0.0/convokit/phrasing_motifs/questionSentences.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,44 +1,53 @@
 from convokit.text_processing import TextProcessor
 
+
 class QuestionSentences(TextProcessor):
     """
-        Transformer that, given a list of sentences, returns a list containing only sentences which are questions (determined, as a rough heuristic, by whether they end in question marks). Returns an empty list if there are no questions. 
+    Transformer that, given a list of sentences, returns a list containing only sentences which are questions (determined, as a rough heuristic, by whether they end in question marks). Returns an empty list if there are no questions.
 
-        :param output_field: name of attribute to output to.
-        :param input_field: name of field to use as input. expects a list where each sentence corresponds to a sentence in filter_field.
-        :param use_caps: whether to only use sentences which start in capital letters. defaults to True. 
-        :param filter_field: name of field to check for question marks in, defaults to the output of the TextParser transformer. the entries of input_field and filter_field should exactly correspond.
-        :param input_filter: a boolean function of signature `input_filter(utterance, aux_input)`. parses will only be computed for utterances where `input_filter` returns `True`. By default, will always return `True`, meaning that arcs will be computed for all utterances.
-        :param verbosity: frequency of status messages.
+    :param output_field: name of attribute to output to.
+    :param input_field: name of field to use as input. expects a list where each sentence corresponds to a sentence in filter_field.
+    :param use_caps: whether to only use sentences which start in capital letters. defaults to True.
+    :param filter_field: name of field to check for question marks in, defaults to the output of the TextParser transformer. the entries of input_field and filter_field should exactly correspond.
+    :param input_filter: a boolean function of signature `input_filter(utterance, aux_input)`. parses will only be computed for utterances where `input_filter` returns `True`. By default, will always return `True`, meaning that arcs will be computed for all utterances.
+    :param verbosity: frequency of status messages.
     """
 
-    def __init__(self, output_field, input_field, use_caps=True, filter_field='parsed',
+    def __init__(
+        self,
+        output_field,
+        input_field,
+        use_caps=True,
+        filter_field="parsed",
         input_filter=None,
-        verbosity=0):
-
-
-        aux_input = {'input_field': input_field,
-        'filter_field': filter_field, 'use_caps': use_caps}
-
-
-        TextProcessor.__init__(self, self._get_question_sentences, output_field=output_field, input_field=[input_field, filter_field], input_filter=input_filter, aux_input=aux_input, verbosity=verbosity)
-    
+        verbosity=0,
+    ):
+        aux_input = {"input_field": input_field, "filter_field": filter_field, "use_caps": use_caps}
+
+        TextProcessor.__init__(
+            self,
+            self._get_question_sentences,
+            output_field=output_field,
+            input_field=[input_field, filter_field],
+            input_filter=input_filter,
+            aux_input=aux_input,
+            verbosity=verbosity,
+        )
 
     def _get_question_sentences(self, text_entry, aux_input):
-
-        text = text_entry[aux_input['input_field']]
-        parse = text_entry[aux_input['filter_field']]
+        text = text_entry[aux_input["input_field"]]
+        parse = text_entry[aux_input["filter_field"]]
         sents = []
         for input_sent, filter_sent in zip(text, parse):
             if isinstance(filter_sent, dict):
-                if filter_sent['toks'][-1]['tok'] != '?': 
+                if filter_sent["toks"][-1]["tok"] != "?":
                     continue
-                if aux_input['use_caps'] and not filter_sent['toks'][0]['tok'][0].isupper(): 
+                if aux_input["use_caps"] and not filter_sent["toks"][0]["tok"][0].isupper():
                     continue
             else:
-                if '?' not in filter_sent: 
+                if "?" not in filter_sent:
                     continue
-                if aux_input['use_caps'] and not filter_sent[0].isupper():
+                if aux_input["use_caps"] and not filter_sent[0].isupper():
                     continue
             sents.append(input_sent)
         return sents
```

### Comparing `convokit-2.5.3/convokit/politenessStrategies/politenessStrategies.py` & `convokit-3.0.0/convokit/politenessStrategies/politenessStrategies.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,165 +1,195 @@
 from typing import Callable, Optional
-from convokit.model import Utterance
-from convokit.text_processing.textParser import process_text
-from convokit.transformer import Transformer
-from convokit.model import Corpus, Utterance, Speaker
-
-from convokit.politeness_collections.politeness_api.features.politeness_strategies import get_politeness_strategy_features
-from convokit.politeness_collections.politeness_local.strategy_extractor import get_local_politeness_strategy_features
-from convokit.politeness_collections.politeness_cscw_zh.strategy_extractor import get_chinese_politeness_strategy_features
 
-import re
-import spacy
-from spacy.tokens import Doc
-import pandas as pd
 import matplotlib.pyplot as plt
 import numpy as np
+import pandas as pd
+from spacy.tokens import Doc
+
+from convokit.model import Corpus, Utterance, Speaker
+from convokit.politeness_collections.politeness_api.features.politeness_strategies import (
+    get_politeness_strategy_features,
+)
+from convokit.politeness_collections.politeness_cscw_zh.strategy_extractor import (
+    get_chinese_politeness_strategy_features,
+)
+from convokit.politeness_collections.politeness_local.strategy_extractor import (
+    get_local_politeness_strategy_features,
+)
+from convokit.text_processing.textParser import process_text
+from convokit.transformer import Transformer
+
 
 class PolitenessStrategies(Transformer):
     """
     Encapsulates extraction of politeness strategies from utterances in a
     Corpus.
-    
+
     :param parse_attribute_name: metadata attribute name to read parses from. Default is 'parsed'.
-    :param strategy_attribute_name: metadata attribute name to store politeness strategies features under during the `transform()` step.  Default is 'politeness_strategies'. 
+    :param strategy_attribute_name: metadata attribute name to store politeness strategies features under during the `transform()` step.  Default is 'politeness_strategies'.
     :param marker_attribute_name: metadata attribute name to store politeness markers under during the `transform()` step. Default is 'politeness_markers'.
     :param strategy_collection: collection of politeness strategies to extract. Options include:
         "politeness_api": English politeness strategies proposed in A computational approach to politeness with application to social factors (https://www.cs.cornell.edu/~cristian/Politeness.html)
         "politeness_local": English politeness strategies realized through local markers as used in Facilitating the Communication of Politeness through Fine-Grained Paraphrasing (https://www.cs.cornell.edu/~cristian/Politeness_Paraphrasing.html)
         "politeness_cscw_zh":  Chinese politeness strategies adapted from `Studying Politeness across Cultures using English Twitter and Mandarin Weibo (https://dl.acm.org/doi/abs/10.1145/3415190)
-        Default is "politeness_api". 
+        Default is "politeness_api".
     :param verbose: whether and how often to print status messages while computing features.
     """
 
-    def __init__(self, parse_attribute_name:str='parsed',strategy_attribute_name:str="politeness_strategies", marker_attribute_name:str="politeness_markers", strategy_collection:str="politeness_api", verbose:int=0):
-        
+    def __init__(
+        self,
+        parse_attribute_name: str = "parsed",
+        strategy_attribute_name: str = "politeness_strategies",
+        marker_attribute_name: str = "politeness_markers",
+        strategy_collection: str = "politeness_api",
+        verbose: int = 0,
+    ):
         self.parse_attribute_name = parse_attribute_name
         self.strategy_attribute_name = strategy_attribute_name
         self.marker_attribute_name = marker_attribute_name
         self.strategy_collection = strategy_collection
         self.verbose = verbose
-        
-        self._extractor_lookup = {"politeness_api": get_politeness_strategy_features, \
-                                  "politeness_local": get_local_politeness_strategy_features, \
-                                  "politeness_cscw_zh": get_chinese_politeness_strategy_features}
 
-    def transform(self, corpus: Corpus, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True,
-                  markers: bool = False):
+        self._extractor_lookup = {
+            "politeness_api": get_politeness_strategy_features,
+            "politeness_local": get_local_politeness_strategy_features,
+            "politeness_cscw_zh": get_chinese_politeness_strategy_features,
+        }
+
+    def transform(
+        self,
+        corpus: Corpus,
+        selector: Optional[Callable[[Utterance], bool]] = lambda utt: True,
+        markers: bool = False,
+    ):
         """
         Extract politeness strategies from each utterances in the corpus and annotate
         the utterances with the extracted strategies. Requires that the corpus has previously
         been transformed by a Parser, such that each utterance has dependency parse info in
         its metadata table.
 
         :param corpus: the corpus to compute features for.
         :param selector: a (lambda) function that takes an Utterance and returns a bool indicating whether the utterance should be included in this annotation step.
         :param markers: whether or not to add politeness occurrence markers
         """
-    
-        total_utts = len(corpus.utterances)
-        
+
+        total_utts = len(list(corpus.iter_utterances()))
+
         for idx, utt in enumerate(corpus.iter_utterances()):
-            
             if self.verbose > 0 and idx > 0 and idx % self.verbose == 0:
-                print('%03d/%03d utterances processed' % (idx, total_utts))
-            
-            if selector(utt):    
+                print("%03d/%03d utterances processed" % (idx, total_utts))
+
+            if selector(utt):
                 parsed = utt.retrieve_meta(self.parse_attribute_name)
                 for i, sent in enumerate(parsed):
                     for p in sent["toks"]:
                         # p["tok"] = re.sub("[^a-z,.:;]", "", p["tok"].lower())
-                        p["tok"] = p['tok'].lower()
-                
+                        p["tok"] = p["tok"].lower()
+
                 parses = [x["toks"] for x in parsed]
-            
-                utt.meta[self.strategy_attribute_name], marks = self._extractor_lookup[self.strategy_collection](parses)
+
+                utt.meta[self.strategy_attribute_name], marks = self._extractor_lookup[
+                    self.strategy_collection
+                ](parses)
 
                 if markers:
                     utt.meta[self.marker_attribute_name] = marks
             else:
                 utt.meta[self.strategy_attribute_name] = None
                 utt.meta[self.marker_attribute_name] = None
-            
+
         return corpus
-    
-    
-    def transform_utterance(self, utt: Utterance, spacy_nlp: Callable[[str], Doc] = None, markers: bool = False):
+
+    def transform_utterance(
+        self, utt: Utterance, spacy_nlp: Callable[[str], Doc] = None, markers: bool = False
+    ):
         """
         Extract politeness strategies for raw string inputs (or individual utterances)
-        
-        :param utt: the utterance to be annotated with politeness strategies. 
+
+        :param utt: the utterance to be annotated with politeness strategies.
         :spacy_nlp: if provided, will use this SpaCy object to do parsing; otherwise will initialize an object via `load('en')`.
         :return: the utterance with politeness annotations.
         """
-        
+
         if isinstance(utt, str):
-            utt = Utterance(text=utt, speaker=Speaker(id='speaker'))
-        
+            utt = Utterance(text=utt, speaker=Speaker(id="speaker"))
+
         if self.parse_attribute_name not in utt.meta:
-            
             if spacy_nlp is None:
-                raise ValueError('spacy object required')
-            
+                raise ValueError("spacy object required")
+
             parses = process_text(utt.text, spacy_nlp=spacy_nlp)
             utt.add_meta(self.parse_attribute_name, parses)
-        
+
         parsed = utt.retrieve_meta(self.parse_attribute_name)
         for i, sent in enumerate(parsed):
             for p in sent["toks"]:
-                p["tok"] = p['tok'].lower()
+                p["tok"] = p["tok"].lower()
         parses = [x["toks"] for x in parsed]
-        
-        utt.meta[self.strategy_attribute_name], marks = self._extractor_lookup[self.strategy_collection](parses)
+
+        utt.meta[self.strategy_attribute_name], marks = self._extractor_lookup[
+            self.strategy_collection
+        ](parses)
 
         if markers:
             utt.meta[self.marker_attribute_name] = marks
-        
+
         return utt
-    
-    
-    def _get_feat_df(self, corpus: Corpus, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True):
+
+    def _get_feat_df(
+        self, corpus: Corpus, selector: Optional[Callable[[Utterance], bool]] = lambda utt: True
+    ):
         """
         Construct binary feature dataframe. Used in summarize()
 
         :param corpus: the target Corpus
         :param selector: (lambda) function specifying whether the utterance should be included
         """
 
         utts = list(corpus.iter_utterances(selector))
 
         if self.strategy_attribute_name not in utts[0].meta:
-            print("Could not find politeness strategies metadata. Running transform() on corpus first...", end="")
+            print(
+                "Could not find politeness strategies metadata. Running transform() on corpus first...",
+                end="",
+            )
             self.transform(corpus)
             print("Done.")
 
-        df_feat = pd.DataFrame.from_dict({utt.id: utt.meta['politeness_strategies'] for utt in utts}, orient='index')
+        df_feat = pd.DataFrame.from_dict(
+            {utt.id: utt.meta["politeness_strategies"] for utt in utts}, orient="index"
+        )
 
         return df_feat
-    
-    
-    def summarize(self, corpus: Corpus, selector: Callable[[Utterance], bool] = lambda utt: True, plot: bool = False, y_lim = None):
+
+    def summarize(
+        self,
+        corpus: Corpus,
+        selector: Callable[[Utterance], bool] = lambda utt: True,
+        plot: bool = False,
+        y_lim=None,
+    ):
         """
-        Calculates strategy prevalence and plot graph if plot == True, with an optional selector that specifies which utterances to include in the analysis. 
+        Calculates strategy prevalence and plot graph if plot == True, with an optional selector that specifies which utterances to include in the analysis.
 
         :param corpus: the target Corpus
         :param selector: a function (typically, a lambda function) that takes an Utterance and returns True or False (i.e. include / exclude).
         By default, the selector includes all Utterances in the Corpus.
         :param plot: whether or not to output graph.
         :return: a pandas DataFrame of scores with graph optionally outputted
         """
-        
+
         df_feat = self._get_feat_df(corpus, selector)
         proportions = df_feat.sum(axis=0) / len(df_feat)
         num_strategies = len(proportions)
 
         if plot:
             plt.figure(dpi=200, figsize=(9, 6))
             plt.bar(proportions.index, proportions.values)
-            plt.xticks(np.arange(.4, num_strategies+.4), rotation=45, ha="right")
+            plt.xticks(np.arange(0.4, num_strategies + 0.4), rotation=45, ha="right")
             plt.ylabel("% utterance using strategy", size=20)
             plt.yticks(size=15)
 
             if y_lim != None:
                 plt.ylim(0, y_lim)
             plt.show()
```

### Comparing `convokit-2.5.3/convokit/politeness_collections/marker_utils.py` & `convokit-3.0.0/convokit/politeness_collections/marker_utils.py`

 * *Files 15% similar despite different names*

```diff
@@ -4,19 +4,19 @@
 from typing import Dict, List, Callable, Pattern, Optional
 
 STOP_TOK = "*"
 
 
 def load_ngram_markers(ngram_path: str) -> Dict[str, Dict]:
     """
-        Load ngram markers from file
+    Load ngram markers from file
     """
 
     # load markers
-    with open(ngram_path, 'r') as f:
+    with open(ngram_path, "r") as f:
         data = json.load(f)
 
     # organize markers into a trie
     trie = defaultdict(dict)
     for strategy, ngrams in data.items():
         for ngram in ngrams:
             words = ngram.split()
@@ -26,100 +26,105 @@
                 curr = curr.setdefault(word, {})
             # end with strategy name
             curr[STOP_TOK] = strategy
 
     return trie
 
 
-def extract_ngram_markers_given_start(words: List[str], \
-                                      sent_idx: int, i: int, \
-                                      ngrams: Dict[str, Dict]) -> Dict[str, List]:
+def extract_ngram_markers_given_start(
+    words: List[str], sent_idx: int, i: int, ngrams: Dict[str, Dict]
+) -> Dict[str, List]:
     """
-        Extract strategies based on ngram markers, starting from the given position
+    Extract strategies based on ngram markers, starting from the given position
     """
     strategies = defaultdict(list)
     curr, j = ngrams, i
 
     while j < len(words):
         word = words[j]
         if word not in curr:
             break
         curr = curr[word]
         if STOP_TOK in curr:
-            extracted = [(words[k], sent_idx, k) for k in range(i, j+1)]
+            extracted = [(words[k], sent_idx, k) for k in range(i, j + 1)]
             strategies[curr[STOP_TOK]].append(extracted)
         j += 1
 
     return strategies
 
 
-def extract_ngram_markers(words: List[str], sent_idx: int, \
-                          ngrams: Dict[str, Dict], offset: int = 0) -> Dict[str, List]:
+def extract_ngram_markers(
+    words: List[str], sent_idx: int, ngrams: Dict[str, Dict], offset: int = 0
+) -> Dict[str, List]:
     """
-        Extract strategies uses (with marker positions) from the parse of a sentence
+    Extract strategies uses (with marker positions) from the parse of a sentence
     """
-    strategies = defaultdict(list)    
+    strategies = defaultdict(list)
     for i in range(offset, len(words)):
         extracted = extract_ngram_markers_given_start(words, sent_idx, i, ngrams)
         for k, v in extracted.items():
             strategies[k].extend(v)
 
     return strategies
 
 
-def extract_starter_markers(words: List[str], sent_idx: int, 
-                            ngrams: Dict[str, Dict]) -> Dict[str, List]:
+def extract_starter_markers(
+    words: List[str], sent_idx: int, ngrams: Dict[str, Dict]
+) -> Dict[str, List]:
     """
-        Extract markers for sentence-starting strategies
+    Extract markers for sentence-starting strategies
     """
     return extract_ngram_markers_given_start(words, sent_idx, 0, ngrams)
 
 
-def extract_regex_strategies(pattern: Pattern, tokens: List[str],
-                          sent_idx: int, offset: int = 0):
-
+def extract_regex_strategies(pattern: Pattern, tokens: List[str], sent_idx: int, offset: int = 0):
     """
-        Extract markers for a given strategy based on regex patterns
+    Extract markers for a given strategy based on regex patterns
     """
-    
+
     # find matches
     sent = " ".join(tokens[offset:])
     matches = [match.span() for match in re.finditer(pattern, sent)]
 
     extracted = []
     for match_start, match_end in matches:
         # idx of starting token of the matched span
-        tok_start = len(sent[0: match_start].split())
+        tok_start = len(sent[0:match_start].split())
         # idx of ending token
-        tok_end = len(sent[0: match_end].split())
-        extracted_toks = [(tokens[i+offset], sent_idx, i+offset) for i in range(tok_start, tok_end)]
+        tok_end = len(sent[0:match_end].split())
+        extracted_toks = [
+            (tokens[i + offset], sent_idx, i + offset) for i in range(tok_start, tok_end)
+        ]
         extracted.append(extracted_toks)
 
     return extracted
 
 
-def extract_markers_from_sent(sent_parsed: List[Dict], sent_idx: int,
-                              ngrams: Optional[Dict[str, Dict]] = None,
-                              starters: Optional[Dict[str, Dict]] = None,
-                              non_starters: Optional[Dict[str, Dict]] = None,
-                              marker_fns: Optional[List[Callable[..., Dict[str, List]]]] = None,
-                              names: Optional[List[str]] = None) -> Dict[str, List]:
-    '''
+def extract_markers_from_sent(
+    sent_parsed: List[Dict],
+    sent_idx: int,
+    ngrams: Optional[Dict[str, Dict]] = None,
+    starters: Optional[Dict[str, Dict]] = None,
+    non_starters: Optional[Dict[str, Dict]] = None,
+    marker_fns: Optional[List[Callable[..., Dict[str, List]]]] = None,
+    names: Optional[List[str]] = None,
+) -> Dict[str, List]:
+    """
     Extracting markers from a parsed sentence
 
     :param sent_parsed: parsed sentence
     :param sent_idx: idx of the current sentence in the utterance
     :param ngrams: ngram markers
     :param starters: starter markers
-    :param non_starters: 
+    :param non_starters:
     :param marker_fns: list of functions to extract strategies not covered by lexicons
-    '''
+    """
 
     sent_summary = defaultdict(list)
-    words = [x['tok'].lower() for x in sent_parsed]
+    words = [x["tok"].lower() for x in sent_parsed]
 
     # ngrams markers
     if ngrams:
         ngram_markers = extract_ngram_markers(words, sent_idx, ngrams)
         for k, ngrams in ngram_markers.items():
             sent_summary[k].extend(ngrams)
 
@@ -127,21 +132,21 @@
     if starters:
         starter_markers = extract_starter_markers(words, sent_idx, starters)
         for k, starters in starter_markers.items():
             sent_summary[k].extend(starters)
 
     # non-starter strategies
     if non_starters:
-        non_starters = extract_ngram_markers(words, sent_idx, non_starters, offset = 1)
+        non_starters = extract_ngram_markers(words, sent_idx, non_starters, offset=1)
         for k, starters in non_starters.items():
             sent_summary[k].extend(starters)
-    
-    # update results for strategies that have other special conditions 
+
+    # update results for strategies that have other special conditions
     if marker_fns:
         if not names:
             names = [fn.__name__ for fn in marker_fns]
         for name, fn in zip(names, marker_fns):
             extracted = fn(sent_parsed, sent_idx)
             for markers in extracted:
                 sent_summary[name].extend(markers)
 
-    return sent_summary
+    return sent_summary
```

### Comparing `convokit-2.5.3/convokit/politeness_collections/politeness_api/features/politeness_strategies.py` & `convokit-3.0.0/convokit/politeness_collections/politeness_api/features/politeness_strategies.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,97 +1,205 @@
 import pkg_resources
 import os
 
 #####
 # Word lists
 
 hedges = [
-    "think", "thought", "thinking", "almost",
-    "apparent", "apparently", "appear", "appeared", "appears", "approximately", "around",
-    "assume", "assumed", "certain amount", "certain extent", "certain level", "claim",
-    "claimed", "doubt", "doubtful", "essentially", "estimate",
-    "estimated", "feel", "felt", "frequently", "from our perspective", "generally", "guess",
-    "in general", "in most cases", "in most instances", "in our view", "indicate", "indicated",
-    "largely", "likely", "mainly", "may", "maybe", "might", "mostly", "often", "on the whole",
-    "ought", "perhaps", "plausible", "plausibly", "possible", "possibly", "postulate",
-    "postulated", "presumable", "probable", "probably", "relatively", "roughly", "seems",
-    "should", "sometimes", "somewhat", "suggest", "suggested", "suppose", "suspect", "tend to",
-    "tends to", "typical", "typically", "uncertain", "uncertainly", "unclear", "unclearly",
-    "unlikely", "usually", "broadly", "tended to", "presumably", "suggests",
-    "from this perspective", "from my perspective", "in my view", "in this view", "in our opinion",
-    "in my opinion", "to my knowledge", "fairly", "quite", "rather", "argue", "argues", "argued",
-    "claims", "feels", "indicates", "supposed", "supposes", "suspects", "postulates"
+    "think",
+    "thought",
+    "thinking",
+    "almost",
+    "apparent",
+    "apparently",
+    "appear",
+    "appeared",
+    "appears",
+    "approximately",
+    "around",
+    "assume",
+    "assumed",
+    "certain amount",
+    "certain extent",
+    "certain level",
+    "claim",
+    "claimed",
+    "doubt",
+    "doubtful",
+    "essentially",
+    "estimate",
+    "estimated",
+    "feel",
+    "felt",
+    "frequently",
+    "from our perspective",
+    "generally",
+    "guess",
+    "in general",
+    "in most cases",
+    "in most instances",
+    "in our view",
+    "indicate",
+    "indicated",
+    "largely",
+    "likely",
+    "mainly",
+    "may",
+    "maybe",
+    "might",
+    "mostly",
+    "often",
+    "on the whole",
+    "ought",
+    "perhaps",
+    "plausible",
+    "plausibly",
+    "possible",
+    "possibly",
+    "postulate",
+    "postulated",
+    "presumable",
+    "probable",
+    "probably",
+    "relatively",
+    "roughly",
+    "seems",
+    "should",
+    "sometimes",
+    "somewhat",
+    "suggest",
+    "suggested",
+    "suppose",
+    "suspect",
+    "tend to",
+    "tends to",
+    "typical",
+    "typically",
+    "uncertain",
+    "uncertainly",
+    "unclear",
+    "unclearly",
+    "unlikely",
+    "usually",
+    "broadly",
+    "tended to",
+    "presumably",
+    "suggests",
+    "from this perspective",
+    "from my perspective",
+    "in my view",
+    "in this view",
+    "in our opinion",
+    "in my opinion",
+    "to my knowledge",
+    "fairly",
+    "quite",
+    "rather",
+    "argue",
+    "argues",
+    "argued",
+    "claims",
+    "feels",
+    "indicates",
+    "supposed",
+    "supposes",
+    "suspects",
+    "postulates",
 ]
 
 # Positive and negative words from Liu
-pos_filename = pkg_resources.resource_filename("convokit",
-    os.path.join("data", "liu-positive-words.txt"))
-neg_filename = pkg_resources.resource_filename("convokit",
-    os.path.join("data", "liu-negative-words.txt"))
+pos_filename = pkg_resources.resource_filename(
+    "convokit", os.path.join("data", "liu-positive-words.txt")
+)
+neg_filename = pkg_resources.resource_filename(
+    "convokit", os.path.join("data", "liu-negative-words.txt")
+)
 
 
 positive_words = set(map(lambda x: x.strip(), open(pos_filename).read().splitlines()))
-negative_words = set(map(lambda x: x.strip(), open(neg_filename, encoding="ISO-8859-1").read().splitlines()))
+negative_words = set(
+    map(lambda x: x.strip(), open(neg_filename, encoding="ISO-8859-1").read().splitlines())
+)
 
 #####
 # Lambda Functions
 
-please = lambda p: check_word([{"tok":"_"}] + p[1:], ["please"])
+please = lambda p: check_word([{"tok": "_"}] + p[1:], ["please"])
 please.__name__ = "Please"
 
 please_start = lambda p: check_word_at(p, 0, tok=["please"])
 please_start.__name__ = "Please start"
 
 has_hedge = lambda p: check_word(p, tok=hedges)
 has_hedge.__name__ = "HASHEDGE"
 
 btw = lambda p: check_word_at(p, 2, up_tok=["by"], tok=["way"], dep=["pobj"])
 btw.__name__ = "Indirect (btw)"
 
 hashedges = lambda p: check_word(p, dep=["nsubj"], up_tok=hedges)
 hashedges.__name__ = "Hedges"
 
-factuality = lambda p: combine_results([check_word(p, up_tok=["in"], tok=["fact"], dep=["pobj"]),
-                                        check_word(p, tok=["the"], up_tok=["point", "reality", "truth"], dep=["det"], precede=["point", "reality", "truth"]),
-                                        check_word(p, tok=["really","actually","honestly","surely"])])
+factuality = lambda p: combine_results(
+    [
+        check_word(p, up_tok=["in"], tok=["fact"], dep=["pobj"]),
+        check_word(
+            p,
+            tok=["the"],
+            up_tok=["point", "reality", "truth"],
+            dep=["det"],
+            precede=["point", "reality", "truth"],
+        ),
+        check_word(p, tok=["really", "actually", "honestly", "surely"]),
+    ]
+)
 factuality.__name__ = "Factuality"
 
-deference = lambda p: check_word_at(p, 0, tok=["great","good","nice","good","interesting","cool","excellent","awesome"])
+deference = lambda p: check_word_at(
+    p, 0, tok=["great", "good", "nice", "good", "interesting", "cool", "excellent", "awesome"]
+)
 deference.__name__ = "Deference"
 
-gratitude = lambda p: combine_results([check_word(p, tok=["thank","thanks"]), check_word(p, tok=["i"], up_tok=["appreciate"])])
+gratitude = lambda p: combine_results(
+    [check_word(p, tok=["thank", "thanks"]), check_word(p, tok=["i"], up_tok=["appreciate"])]
+)
 gratitude.__name__ = "Gratitude"
 
-apologize = lambda p: combine_results([check_word(p, tok=["sorry","woops","oops"]),
-                                       check_word(p, tok=["i"], up_tok=["apologize"], dep=["nsubj"]),
-                                       check_word(p, tok=["me"], up_tok=["forgive", "excuse"], dep=["dobj"])])
+apologize = lambda p: combine_results(
+    [
+        check_word(p, tok=["sorry", "woops", "oops"]),
+        check_word(p, tok=["i"], up_tok=["apologize"], dep=["nsubj"]),
+        check_word(p, tok=["me"], up_tok=["forgive", "excuse"], dep=["dobj"]),
+    ]
+)
 apologize.__name__ = "Apologizing"
 
 groupidentity = lambda p: check_word(p, tok=["we", "our", "us", "ourselves"])
 groupidentity.__name__ = "1st person pl."
 
-firstperson = lambda p: check_word([{"tok":"_"}] + p[1:], tok= ["i", "my", "mine", "myself"])
+firstperson = lambda p: check_word([{"tok": "_"}] + p[1:], tok=["i", "my", "mine", "myself"])
 firstperson.__name__ = "1st person"
 
-firstperson_start = lambda p: check_word_at(p, 0, tok=["i","my","mine","myself"])
+firstperson_start = lambda p: check_word_at(p, 0, tok=["i", "my", "mine", "myself"])
 firstperson_start.__name__ = "1st person start"
 
-secondperson = lambda p: check_word([{"tok":"_"}] + p[1:], tok= ["you","your","yours","yourself"])
+secondperson = lambda p: check_word(
+    [{"tok": "_"}] + p[1:], tok=["you", "your", "yours", "yourself"]
+)
 secondperson.__name__ = "2nd person"
 
-secondperson_start = lambda p: check_word_at(p, 0, tok=["you","your","yours","yourself"])
+secondperson_start = lambda p: check_word_at(p, 0, tok=["you", "your", "yours", "yourself"])
 secondperson_start.__name__ = "2nd person start"
 
-hello = lambda p: check_word_at(p, 0, tok=["hi","hello","hey"])
+hello = lambda p: check_word_at(p, 0, tok=["hi", "hello", "hey"])
 hello.__name__ = "Indirect (greeting)"
 
-why = lambda p: check_word(p[:2], tok=["what","why","who","how"])
+why = lambda p: check_word(p[:2], tok=["what", "why", "who", "how"])
 why.__name__ = "Direct question"
 
-conj = lambda p: check_word_at(p, 0, tok=["so","then","and","but","or"])
+conj = lambda p: check_word_at(p, 0, tok=["so", "then", "and", "but", "or"])
 conj.__name__ = "Direct start"
 
 has_positive = lambda p: check_word(p, tok=positive_words)
 has_positive.__name__ = "HASPOSITIVE"
 
 has_negative = lambda p: check_word(p, tok=negative_words)
 has_negative.__name__ = "HASNEGATIVE"
@@ -102,27 +210,30 @@
 indicative = lambda p: check_word(p, tok=["can", "will"], precede=["you"])
 indicative.__name__ = "INDICATIVE"
 
 
 #####
 # Helper functions and variables
 
+
 def combine_results(lst):
     """
     combines list of results
     ex: [[1, ["hey", 0]], [0,[]], [1, ["you", 1]]] -> [1, [["hey", 0],["you", 1]]]
     """
-    a = 0; b = []
+    a = 0
+    b = []
     for x in lst:
         a = max(a, x[0])
         if x[1] != []:
             b += x[1]
     return a, b
 
-def check_word_at(p, ind, tok = None, dep = None, up_tok = None, up_dep = None, precede = None):
+
+def check_word_at(p, ind, tok=None, dep=None, up_tok=None, up_dep=None, precede=None):
     """
     Returns an indicator and a marker
     If parameters match word at index:
         returns 1, [tok at ind, ind]
     Else:
         returns 0, []
     """
@@ -132,19 +243,20 @@
         return 0, []
     if dep != None and p[ind]["dep"] not in dep:
         return 0, []
     if up_tok != None and ("up" not in p[ind] or p[p[ind]["up"]]["tok"].lower() not in up_tok):
         return 0, []
     if up_dep != None and p[p[ind]["up"]]["dep"] not in up_dep:
         return 0, []
-    if precede != None and (len(p) <= ind + 1 or p[ind+1]["tok"] not in precede):
+    if precede != None and (len(p) <= ind + 1 or p[ind + 1]["tok"] not in precede):
         return 0, []
     return 1, [[(p[ind]["tok"], ind)]]
-    
-def check_word(p, tok = None, dep = None, up_tok = None, up_dep = None, precede = None):
+
+
+def check_word(p, tok=None, dep=None, up_tok=None, up_dep=None, precede=None):
     """
     Returns an indicator and a marker
     If parameters match any word in the sentence:
         returns 1, markers for each occurance
     Else:
         returns 0, []
     """
@@ -157,43 +269,63 @@
         if up_tok != None and ("up" not in x or p[x["up"]]["tok"].lower() not in up_tok):
             continue
         if up_dep != None and p[x["up"]]["dep"] not in up_dep:
             continue
         if precede != None and (len(p) <= ind + 1 or p[ind + 1]["tok"] not in precede):
             continue
         if up_tok != None:
-            toks += [[(x["tok"], ind), (p[x["up"]]["tok"].lower() , x["up"])]]
+            toks += [[(x["tok"], ind), (p[x["up"]]["tok"].lower(), x["up"])]]
         else:
-             toks += [[(x["tok"], ind)]]
+            toks += [[(x["tok"], ind)]]
     if toks != []:
         return 1, toks
     else:
         return 0, []
 
 
 # Feature function list
-F = [please, please_start, has_hedge, btw, hashedges, factuality, deference, gratitude, apologize, groupidentity,
-     firstperson, firstperson_start, secondperson, secondperson_start, hello, why, conj, has_positive, has_negative,
-     subjunctive, indicative]
+F = [
+    please,
+    please_start,
+    has_hedge,
+    btw,
+    hashedges,
+    factuality,
+    deference,
+    gratitude,
+    apologize,
+    groupidentity,
+    firstperson,
+    firstperson_start,
+    secondperson,
+    secondperson_start,
+    hello,
+    why,
+    conj,
+    has_positive,
+    has_negative,
+    subjunctive,
+    indicative,
+]
 
-fnc2feature_name = lambda f, keys: [key + "_==%s==" % f.__name__.replace(" ","_") for key in keys]
+fnc2feature_name = lambda f, keys: [key + "_==%s==" % f.__name__.replace(" ", "_") for key in keys]
 
 
 def get_politeness_strategy_features(parses):
     """
     :param utt- the utterance to be processed
     :type utterance- Object with attributes including text and meta
-    
+
         utt.meta is a dictionary with the following form:
         {
             parsed: [
                 { 'rt': 5
                   'toks': [{'dep': 'intj', 'dn': [], 'tag': 'UH', 'tok': 'hello', 'up': 2}, #sent 1, word 1
                           ... {sent 1 word 2} ,{sent 1 word 3}...]
-                    
+
                 },
                 { 'rt': 12
                 'toks': [{'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'i', 'up': 1}, # sent 2, word 1
                          {'dep': 'ROOT', 'dn': [0, 2, 3], 'tag': 'VBP', 'tok': 'need'},
                          ...]
                 }
             ]
@@ -204,29 +336,29 @@
             feature_name: 1 or 0
         }
     marker dictionary:
         {
             marker_name: list of [token, sentence index, word index]
         }
     """
-    
-    #build dictionary
+
+    # build dictionary
     features = {}
     markers = {}
     for fnc in F:
-        f = fnc2feature_name(fnc, ["feature_politeness", "politeness_markers"]) 
+        f = fnc2feature_name(fnc, ["feature_politeness", "politeness_markers"])
         features[f[0]] = 0
         markers[f[1]] = []
-        
+
     # runs lambda functions
     for sent_ind, sentence in enumerate(parses):
         for fnc in F:
             feature, marker = fnc(sentence)
             f = fnc2feature_name(fnc, ["feature_politeness", "politeness_markers"])
             features[f[0]] = max(features[f[0]], feature)
-            
+
             # adds sent_ind to marker information
             if len(marker) > 0:
                 for occ in marker:
                     markers[f[1]] += [[(mark[0], sent_ind, mark[1]) for mark in occ]]
 
-    return features, markers
+    return features, markers
```

### Comparing `convokit-2.5.3/convokit/politeness_collections/politeness_api/features/vectorizer.py` & `convokit-3.0.0/convokit/politeness_collections/politeness_api/features/vectorizer.py`

 * *Files 8% similar despite different names*

```diff
@@ -20,23 +20,26 @@
 
 def get_unigrams_and_bigrams(document):
     """
     Grabs unigrams and bigrams from document
     sentences. NLTK does the work.
     """
     # Get unigram list per sentence:
-    unigram_lists = [[y for y in t] for t in map(lambda x: nltk.word_tokenize(x), document['sentences'])]
+    unigram_lists = [
+        [y for y in t] for t in map(lambda x: nltk.word_tokenize(x), document["sentences"])
+    ]
     # Generate bigrams from all sentences:
-    bigrams = [tuple([y for y in t]) for l in map(lambda x: nltk.bigrams(x), unigram_lists) for t in l ]
+    bigrams = [
+        tuple([y for y in t]) for l in map(lambda x: nltk.bigrams(x), unigram_lists) for t in l
+    ]
     # Chain unigram lists
     unigrams = [x for l in unigram_lists for x in l]
     return unigrams, bigrams
 
 
-
 class PolitenessFeatureVectorizer:
 
     """
     Returns document features based on-
         - unigrams and bigrams
         - politeness strategies
             (inspired by B&L, modeled using dependency parses)
@@ -50,15 +53,14 @@
         Load pickled lists of unigram and bigram features
         These lists can be generated using the training set
         and PolitenessFeatureVectorizer.generate_bow_features
         """
         self.unigrams = pickle.load(open(self.UNIGRAMS_FILENAME, "rb"))
         self.bigrams = pickle.load(open(self.BIGRAMS_FILENAME, "rb"))
 
-
     def features(self, document):
         """
         document must be a dict of the following format--
             {
                 'text': "text str",
             }
         """
@@ -68,53 +70,58 @@
         # Add politeness strategy features:
         feature_dict.update(get_politeness_strategy_features(document))
         return feature_dict
 
     def _get_term_features(self, document):
         # One binary feature per ngram in
         # in self.unigrams and self.bigrams
-        unigrams, bigrams = document['unigrams'], document['bigrams'] 
+        unigrams, bigrams = document["unigrams"], document["bigrams"]
         # Add unigrams to document for later use
         unigrams, bigrams = set(unigrams), set(bigrams)
         f = {}
-        f.update(dict(map(lambda x: ("UNIGRAM_" + str(x), 1 if x in unigrams else 0), self.unigrams)))
+        f.update(
+            dict(map(lambda x: ("UNIGRAM_" + str(x), 1 if x in unigrams else 0), self.unigrams))
+        )
         f.update(dict(map(lambda x: ("BIGRAM_" + str(x), 1 if x in bigrams else 0), self.bigrams)))
-        return f 
+        return f
 
     @staticmethod
-    def preprocess(documents): 
-        nlp = spacy.load('en_core_web_sm')
+    def preprocess(documents):
+        nlp = spacy.load("en_core_web_sm")
 
         for document in documents:
-            document['sentences'] = nltk.sent_tokenize(document['text'])
-            document['parses'] = []
-             
-            for s in document['sentences']: 
+            document["sentences"] = nltk.sent_tokenize(document["text"])
+            document["parses"] = []
+
+            for s in document["sentences"]:
                 # Spacy inclues punctuation in dependency parsing, which would lead to errors in feature extraction
                 bak = s
                 s = ""
                 for x in bak:
                     if x in string.punctuation:
-                       s += " "
+                        s += " "
                     else:
-                       s += x
-                s = ' '.join(s.split())
-                doc = nlp(s)#unicode(s, "utf-8"))
+                        s += x
+                s = " ".join(s.split())
+                doc = nlp(s)  # unicode(s, "utf-8"))
                 cur = []
-                for sent in doc.sents: 
+                for sent in doc.sents:
                     pos = sent.start
                     for tok in sent:
-                        ele = "%s(%s-%d, %s-%d)"%(tok.dep_, tok.head.text, tok.head.i + 1 - pos, tok.text, tok.i + 1 - pos)
+                        ele = "%s(%s-%d, %s-%d)" % (
+                            tok.dep_,
+                            tok.head.text,
+                            tok.head.i + 1 - pos,
+                            tok.text,
+                            tok.i + 1 - pos,
+                        )
                         cur.append(ele)
-                    document['parses'].append(cur)
-            document['unigrams'], document['bigrams'] = get_unigrams_and_bigrams(document)
-        return documents 
-
-      
-
+                    document["parses"].append(cur)
+            document["unigrams"], document["bigrams"] = get_unigrams_and_bigrams(document)
+        return documents
 
     @staticmethod
     def generate_bow_features(documents, min_unigram_count=20, min_bigram_count=20):
         """
         Given a list of documents, compute and store list of unigrams and bigrams
         with a frequency > min_unigram_count and min_bigram_count, respectively.
         This method must be called prior to the first vectorizer instantiation.
@@ -125,39 +132,43 @@
             {
                 'text': 'text'
             }
         """
         unigram_counts, bigram_counts = defaultdict(int), defaultdict(int)
         # Count unigrams and bigrams:
         for d in documents:
-            unigrams = set(d['unigrams'])
-            bigrams  = set(d['bigrams'])
+            unigrams = set(d["unigrams"])
+            bigrams = set(d["bigrams"])
             # Count
             for w in unigrams:
                 unigram_counts[w] += 1
             for w in bigrams:
                 bigram_counts[w] += 1
         # Keep only ngrams that pass frequency threshold:
-        unigram_features = list(filter(lambda x: unigram_counts[x] > min_unigram_count, unigram_counts.keys()))
-        bigram_features = list(filter(lambda x: bigram_counts[x] > min_bigram_count, bigram_counts.keys()))
+        unigram_features = list(
+            filter(lambda x: unigram_counts[x] > min_unigram_count, unigram_counts.keys())
+        )
+        bigram_features = list(
+            filter(lambda x: bigram_counts[x] > min_bigram_count, bigram_counts.keys())
+        )
         # Save results:
-        pickle.dump(unigram_features, open(PolitenessFeatureVectorizer.UNIGRAMS_FILENAME, 'wb'))
-        pickle.dump(bigram_features, open(PolitenessFeatureVectorizer.BIGRAMS_FILENAME, 'wb'))
+        pickle.dump(unigram_features, open(PolitenessFeatureVectorizer.UNIGRAMS_FILENAME, "wb"))
+        pickle.dump(bigram_features, open(PolitenessFeatureVectorizer.BIGRAMS_FILENAME, "wb"))
+
 
 def alphas(s):
     bak = s
     s = ""
     for x in bak:
         if x.isalpha():
-           s += x
+            s += x
     return s
 
 
 if __name__ == "__main__":
-
     """
     Extract features from test documents
     """
 
     from test_documents import TEST_DOCUMENTS
 
     vectorizer = PolitenessFeatureVectorizer()
@@ -165,13 +176,17 @@
     documents = PolitenessFeatureVectorizer.preprocess(documents)
 
     for doc in documents:
         f = vectorizer.features(doc)
 
         # Print summary of features that are present
         print("\n====================")
-        print("Text: ", doc['text'])
-        print("\tUnigrams, Bigrams: %d" % len(filter(lambda x: f[x] > 0 and ("UNIGRAM_" in x or "BIGRAM_" in x), f.iterkeys())))
-        print("\tPoliteness Strategies: \n\t\t%s" % "\n\t\t".join(filter(lambda x: f[x] > 0 and "feature_politeness_" in x, f.iterkeys())))
+        print("Text: ", doc["text"])
+        print(
+            "\tUnigrams, Bigrams: %d"
+            % len(filter(lambda x: f[x] > 0 and ("UNIGRAM_" in x or "BIGRAM_" in x), f.iterkeys()))
+        )
+        print(
+            "\tPoliteness Strategies: \n\t\t%s"
+            % "\n\t\t".join(filter(lambda x: f[x] > 0 and "feature_politeness_" in x, f.iterkeys()))
+        )
         print("\n")
-        
-
```

### Comparing `convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/lexicons/ngram_markers.json` & `convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/lexicons/ngram_markers.json`

 * *Files identical despite different names*

### Comparing `convokit-2.5.3/convokit/politeness_collections/politeness_cscw_zh/strategy_extractor.py` & `convokit-3.0.0/convokit/politeness_collections/politeness_cscw_zh/strategy_extractor.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,82 +1,115 @@
 import json
 import os
 import re
-from itertools import chain 
+from itertools import chain
 import pkg_resources
 from collections import defaultdict
 from typing import Dict, List, Tuple
 
-from convokit.politeness_collections.marker_utils import load_ngram_markers, extract_regex_strategies, extract_markers_from_sent
+from convokit.politeness_collections.marker_utils import (
+    load_ngram_markers,
+    extract_regex_strategies,
+    extract_markers_from_sent,
+)
 
 LEXICON_DIR = "politeness_collections/politeness_cscw_zh/lexicons"
 
-ngram_path = pkg_resources.resource_filename("convokit",
-    os.path.join(LEXICON_DIR, "ngram_markers.json"))
+ngram_path = pkg_resources.resource_filename(
+    "convokit", os.path.join(LEXICON_DIR, "ngram_markers.json")
+)
+
+starter_path = pkg_resources.resource_filename(
+    "convokit", os.path.join(LEXICON_DIR, "starter_markers.json")
+)
+
+non_starter_path = pkg_resources.resource_filename(
+    "convokit", os.path.join(LEXICON_DIR, "non_starter_markers.json")
+)
+
+
+PLEASE_PATTERN = re.compile(r"([烦劳还]?\s?请)|([烦劳]您)")
+START_QN_PATTERN = re.compile(r"^\W*([为凭]什么\s?|几\s?|哪\s?|多少\s?|怎\s?|谁\s?|咋\s?)")
+CAN_YOU_PATTERN = re.compile(r"[你您]\s?[是可想觉要].+?[吗呢呀？]")
+COULD_YOU_PATTERN = re.compile(r"[你您]\s?(?P<A>[可想觉要])\s?不\s?(?P=A)")
 
-starter_path = pkg_resources.resource_filename("convokit",
-    os.path.join(LEXICON_DIR, "starter_markers.json"))
-
-non_starter_path = pkg_resources.resource_filename("convokit",
-    os.path.join(LEXICON_DIR, "non_starter_markers.json"))
-
-
-PLEASE_PATTERN = re.compile(r'([烦劳还]?\s?请)|([烦劳]您)')
-START_QN_PATTERN = re.compile(r'^\W*([为凭]什么\s?|几\s?|哪\s?|多少\s?|怎\s?|谁\s?|咋\s?)')
-CAN_YOU_PATTERN = re.compile(r'[你您]\s?[是可想觉要].+?[吗呢呀？]')
-COULD_YOU_PATTERN = re.compile(r'[你您]\s?(?P<A>[可想觉要])\s?不\s?(?P=A)')
 
 # strategy functions (regex)
 def please(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    tokens = [x['tok'] for x in sent_parsed]
+    tokens = [x["tok"] for x in sent_parsed]
     return extract_regex_strategies(PLEASE_PATTERN, tokens, sent_idx, offset=1)
 
+
 def start_question(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    tokens = [x['tok'] for x in sent_parsed]
+    tokens = [x["tok"] for x in sent_parsed]
     return extract_regex_strategies(START_QN_PATTERN, tokens, sent_idx)
 
+
 def can_you(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    tokens = [x['tok'] for x in sent_parsed]
+    tokens = [x["tok"] for x in sent_parsed]
     return extract_regex_strategies(CAN_YOU_PATTERN, tokens, sent_idx)
 
+
 def could_you(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    tokens = [x['tok'] for x in sent_parsed]
+    tokens = [x["tok"] for x in sent_parsed]
     return extract_regex_strategies(COULD_YOU_PATTERN, tokens, sent_idx)
-    
+
 
 # full list of strategies
-STRATEGIES = ['apologetic','best_wishes','can_you', 'could_you',
-              'emergency','factuality',
-              'first_person_plural','first_person_singular',
-              'gratitude','greeting','hedge','honorifics',
-              'indirect_btw','ingroup_iden','praise','promise','please', 
-              'start_i','start_please','start_question','start_so','start_you',
-              'taboo','together','you_direct','you_honorific']
+STRATEGIES = [
+    "apologetic",
+    "best_wishes",
+    "can_you",
+    "could_you",
+    "emergency",
+    "factuality",
+    "first_person_plural",
+    "first_person_singular",
+    "gratitude",
+    "greeting",
+    "hedge",
+    "honorifics",
+    "indirect_btw",
+    "ingroup_iden",
+    "praise",
+    "promise",
+    "please",
+    "start_i",
+    "start_please",
+    "start_question",
+    "start_so",
+    "start_you",
+    "taboo",
+    "together",
+    "you_direct",
+    "you_honorific",
+]
 
 
-# different types of markers 
+# different types of markers
 NGRAMS = load_ngram_markers(ngram_path)
 STARTERS = load_ngram_markers(starter_path)
 NON_STARTERS = load_ngram_markers(non_starter_path)
 MARKER_FNS = [please, start_question, can_you, could_you]
 
 
-def get_chinese_politeness_strategy_features(parses: List[List]) -> Tuple[Dict[str, int], Dict[str, List[Tuple]]]:
-    
+def get_chinese_politeness_strategy_features(
+    parses: List[List],
+) -> Tuple[Dict[str, int], Dict[str, List[Tuple]]]:
     """
-        Extract strategies given a parsed utterance 
+    Extract strategies given a parsed utterance
     """
-    
-    markers = {k:[] for k in STRATEGIES}
-    
+
+    markers = {k: [] for k in STRATEGIES}
+
     for sent_idx, sent_parsed in enumerate(parses):
-        sent_markers = extract_markers_from_sent(sent_parsed, sent_idx, \
-                                                 NGRAMS, STARTERS, NON_STARTERS, \
-                                                 MARKER_FNS)
+        sent_markers = extract_markers_from_sent(
+            sent_parsed, sent_idx, NGRAMS, STARTERS, NON_STARTERS, MARKER_FNS
+        )
         # update markers
-        for k,v in sent_markers.items():
+        for k, v in sent_markers.items():
             markers[k].extend(v)
-    
-    # binary features 
+
+    # binary features
     features = {k: int(len(marker_list) > 0) for k, marker_list in markers.items()}
-    
-    return features, markers
+
+    return features, markers
```

### Comparing `convokit-2.5.3/convokit/politeness_collections/politeness_local/lexicons/ngram_markers.json` & `convokit-3.0.0/convokit/politeness_collections/politeness_local/lexicons/ngram_markers.json`

 * *Files identical despite different names*

### Comparing `convokit-2.5.3/convokit/politeness_collections/politeness_local/strategy_extractor.py` & `convokit-3.0.0/convokit/politeness_collections/politeness_local/strategy_extractor.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,116 +1,150 @@
 import json
 import os
 import re
-from itertools import chain 
+from itertools import chain
 import pkg_resources
 from collections import defaultdict
 from typing import Dict, List, Tuple, Set, Optional
 
-from convokit.politeness_collections.marker_utils import load_ngram_markers, extract_ngram_markers, extract_markers_from_sent
+from convokit.politeness_collections.marker_utils import (
+    load_ngram_markers,
+    extract_ngram_markers,
+    extract_markers_from_sent,
+)
 
 LEXICON_DIR = "politeness_collections/politeness_local/lexicons"
 
-ngram_path = pkg_resources.resource_filename("convokit",
-    os.path.join(LEXICON_DIR, "ngram_markers.json"))
-
-starter_path = pkg_resources.resource_filename("convokit",
-    os.path.join(LEXICON_DIR, "starter_markers.json"))
-
-non_starter_path = pkg_resources.resource_filename("convokit",
-    os.path.join(LEXICON_DIR, "non_starter_markers.json"))
-
-# strategy functions 
-
-def extract_dep_parse_markers(sent_parsed: List[Dict], sent_idx: int, \
-                              child: str, parents: Optional[Set]=None, \
-                              relation: Optional[str]=None):
-    
+ngram_path = pkg_resources.resource_filename(
+    "convokit", os.path.join(LEXICON_DIR, "ngram_markers.json")
+)
+
+starter_path = pkg_resources.resource_filename(
+    "convokit", os.path.join(LEXICON_DIR, "starter_markers.json")
+)
+
+non_starter_path = pkg_resources.resource_filename(
+    "convokit", os.path.join(LEXICON_DIR, "non_starter_markers.json")
+)
+
+# strategy functions
+
+
+def extract_dep_parse_markers(
+    sent_parsed: List[Dict],
+    sent_idx: int,
+    child: str,
+    parents: Optional[Set] = None,
+    relation: Optional[str] = None,
+):
     matched = []
-    
-    for i, tok in enumerate(sent_parsed):            
-        
-        # tok matches
-        if tok['tok'].lower() == child:
-             
-            # check relation (if applicable)  
-            if not relation or tok['dep'] == relation:
 
-                # check parent (if applicable) 
+    for i, tok in enumerate(sent_parsed):
+        # tok matches
+        if tok["tok"].lower() == child:
+            # check relation (if applicable)
+            if not relation or tok["dep"] == relation:
+                # check parent (if applicable)
                 if not parents:
-                    matched.append((tok['tok'], sent_idx, i))
-                
-                elif tok['dep'] != 'ROOT' and sent_parsed[tok['up']]['tok'] in parents:            
+                    matched.append((tok["tok"], sent_idx, i))
+
+                elif tok["dep"] != "ROOT" and sent_parsed[tok["up"]]["tok"] in parents:
                     # keep both child and parent
-                    matched.extend([(tok['tok'], sent_idx, i), \
-                                    (sent_parsed[tok['up']]['tok'], sent_idx, tok['up'])])
-                
-    return matched 
+                    matched.extend(
+                        [
+                            (tok["tok"], sent_idx, i),
+                            (sent_parsed[tok["up"]]["tok"], sent_idx, tok["up"]),
+                        ]
+                    )
+
+    return matched
 
 
 def actually(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    
-    # two types of matches 
-    cond1 = extract_dep_parse_markers(sent_parsed, sent_idx, "the", \
-                                      parents={'point', 'reality', 'truth'}, relation="det")
-    cond2 = extract_dep_parse_markers(sent_parsed, sent_idx, "fact", \
-                                      parents={'in'}, relation="pobj")
-    
-    return cond1 + cond2  
+    # two types of matches
+    cond1 = extract_dep_parse_markers(
+        sent_parsed, sent_idx, "the", parents={"point", "reality", "truth"}, relation="det"
+    )
+    cond2 = extract_dep_parse_markers(
+        sent_parsed, sent_idx, "fact", parents={"in"}, relation="pobj"
+    )
+
+    return cond1 + cond2
+
 
 def adv_just(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
     return extract_dep_parse_markers(sent_parsed, sent_idx, "just", relation="advmod")
 
 
 def apology(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    cond1 =  extract_dep_parse_markers(sent_parsed, sent_idx, "me", \
-                                       parents={'forgive', 'excuse'}, relation='dobj')
-    cond2 = extract_dep_parse_markers(sent_parsed, sent_idx,'i', \
-                                      parents={'apologize'}, relation="nsubj")
-    return cond1 + cond2 
+    cond1 = extract_dep_parse_markers(
+        sent_parsed, sent_idx, "me", parents={"forgive", "excuse"}, relation="dobj"
+    )
+    cond2 = extract_dep_parse_markers(
+        sent_parsed, sent_idx, "i", parents={"apologize"}, relation="nsubj"
+    )
+    return cond1 + cond2
 
 
 def gratitude(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    
-    return extract_dep_parse_markers(sent_parsed, sent_idx, "i", parents={'appreciate'}) + \
-           extract_dep_parse_markers(sent_parsed, sent_idx, "we", parents={'appreciate'})
-    
-    
-def swearing(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
-    return extract_dep_parse_markers(sent_parsed, sent_idx, "the", \
-                                     parents=['fuck', 'hell', 'heck'], relation="det")
+    return extract_dep_parse_markers(
+        sent_parsed, sent_idx, "i", parents={"appreciate"}
+    ) + extract_dep_parse_markers(sent_parsed, sent_idx, "we", parents={"appreciate"})
 
 
-# all strategies being considered 
-STRATEGIES = ['Actually','Adverb.Just','Affirmation','Apology', 
-              'By.The.Way','Conj.Start','Filler','For.Me','For.You',
-              'Gratitude','Greeting','Hedges','Indicative',
-              'Please','Please.Start','Reassurance',
-              'Subjunctive','Swearing']
+def swearing(sent_parsed: List[Dict], sent_idx: int) -> Dict[str, List]:
+    return extract_dep_parse_markers(
+        sent_parsed, sent_idx, "the", parents=["fuck", "hell", "heck"], relation="det"
+    )
+
+
+# all strategies being considered
+STRATEGIES = [
+    "Actually",
+    "Adverb.Just",
+    "Affirmation",
+    "Apology",
+    "By.The.Way",
+    "Conj.Start",
+    "Filler",
+    "For.Me",
+    "For.You",
+    "Gratitude",
+    "Greeting",
+    "Hedges",
+    "Indicative",
+    "Please",
+    "Please.Start",
+    "Reassurance",
+    "Subjunctive",
+    "Swearing",
+]
 
-# different types of markers 
+# different types of markers
 NGRAMS = load_ngram_markers(ngram_path)
 STARTERS = load_ngram_markers(starter_path)
 NON_STARTERS = load_ngram_markers(non_starter_path)
-MARKER_FNS = [actually, adv_just, apology, gratitude, swearing] 
+MARKER_FNS = [actually, adv_just, apology, gratitude, swearing]
 NAMES = ["Actually", "Adverb.Just", "Apology", "Gratitude", "Swearing"]
 
-def get_local_politeness_strategy_features(parses: List[List]) -> Tuple[Dict[str, int], Dict[str, List[Tuple]]]:
-    
+
+def get_local_politeness_strategy_features(
+    parses: List[List],
+) -> Tuple[Dict[str, int], Dict[str, List[Tuple]]]:
     """
-        Extract strategies given a parsed utterance 
+    Extract strategies given a parsed utterance
     """
-    
-    markers = {k:[] for k in STRATEGIES}
-    
+
+    markers = {k: [] for k in STRATEGIES}
+
     for sent_idx, sent_parsed in enumerate(parses):
-        sent_markers = extract_markers_from_sent(sent_parsed, sent_idx, \
-                                                 NGRAMS, STARTERS, NON_STARTERS, \
-                                                 MARKER_FNS, NAMES)
+        sent_markers = extract_markers_from_sent(
+            sent_parsed, sent_idx, NGRAMS, STARTERS, NON_STARTERS, MARKER_FNS, NAMES
+        )
         # update markers
-        for k,v in sent_markers.items():
+        for k, v in sent_markers.items():
             markers[k].extend(v)
-    
-    # binary features 
+
+    # binary features
     features = {k: int(len(marker_list) > 0) for k, marker_list in markers.items()}
-    
-    return features, markers
+
+    return features, markers
```

### Comparing `convokit-2.5.3/convokit/prompt_types/promptTypes.py` & `convokit-3.0.0/convokit/prompt_types/promptTypes.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 from sklearn.preprocessing import normalize
 from sklearn.decomposition import TruncatedSVD
 from sklearn.cluster import KMeans
 import joblib
 
 from convokit.transformer import Transformer
 
+
 class PromptTypes(Transformer):
     """
     Model that infers a vector representation of utterances in terms of the responses that similar utterances tend to
     prompt, as well as types of rhetorical intentions encapsulated by utterances in a corpus, in terms of their
     anticipated responses (operationalized as k-means clusters of vectors).
 
     Under the surface, the model takes as input pairs of prompts and responses during the fit step. In this stage the
@@ -67,47 +68,65 @@
     :param max_dist: the maximum distance between a vector representation of an utterance and the cluster centroid; a
         cluster whose distance to all centroids is above this cutoff will get assigned to a null type, denoted by -1.
         Defaults to 0.9.
     :param random_state: the random seed to use.
     :param verbosity: frequency of status messages.
     """
 
-    def __init__(self, prompt_field, reference_field, output_field, n_types=8,
-                prompt_transform_field=None, reference_transform_field=None,
-                prompt__tfidf_min_df=100, prompt__tfidf_max_df=.1,
-                reference__tfidf_min_df=100, reference__tfidf_max_df=.1,
-                snip_first_dim=True,
-                svd__n_components=25, max_dist=.9,
-                random_state=None, verbosity=0):
-
+    def __init__(
+        self,
+        prompt_field,
+        reference_field,
+        output_field,
+        n_types=8,
+        prompt_transform_field=None,
+        reference_transform_field=None,
+        prompt__tfidf_min_df=100,
+        prompt__tfidf_max_df=0.1,
+        reference__tfidf_min_df=100,
+        reference__tfidf_max_df=0.1,
+        snip_first_dim=True,
+        svd__n_components=25,
+        max_dist=0.9,
+        random_state=None,
+        verbosity=0,
+    ):
         self.prompt_embedding_model = {}
         self.type_models = {}
         self.train_results = {}
         self.train_types = {}
 
         self.prompt_field = prompt_field
         self.reference_field = reference_field
 
-        self.prompt_transform_field = prompt_transform_field if prompt_transform_field is not None else self.prompt_field
-        self.reference_transform_field = reference_transform_field if reference_transform_field is not None else self.reference_field
+        self.prompt_transform_field = (
+            prompt_transform_field if prompt_transform_field is not None else self.prompt_field
+        )
+        self.reference_transform_field = (
+            reference_transform_field
+            if reference_transform_field is not None
+            else self.reference_field
+        )
 
         self.output_field = output_field
 
         self.prompt__tfidf_min_df = prompt__tfidf_min_df
         self.prompt__tfidf_max_df = prompt__tfidf_max_df
         self.reference__tfidf_min_df = reference__tfidf_min_df
         self.reference__tfidf_max_df = reference__tfidf_max_df
         self.snip_first_dim = snip_first_dim
         self.svd__n_components = svd__n_components
         self.default_n_types = n_types
         self.random_state = random_state
         self.max_dist = max_dist
         self.verbosity = verbosity
 
-    def fit(self, corpus, y=None, prompt_selector=lambda utt: True, reference_selector=lambda utt: True):
+    def fit(
+        self, corpus, y=None, prompt_selector=lambda utt: True, reference_selector=lambda utt: True
+    ):
         """
         Fits a PromptTypes model for a corpus -- that is, learns latent representations of prompt and response terms, as well as prompt types.
 
         :param corpus: Corpus
         :param prompt_selector: a boolean function of signature `filter(utterance)` that determines which
         utterances will be considered as prompts in the fit step. defaults to using all utterances which have a response.
         :param reference_selector: a boolean function of signature `filter(utterance)` that determines which utterances
@@ -115,98 +134,159 @@
             prompt.
 
         :return: None
         """
         self.prompt_selector = prompt_selector
         self.reference_selector = reference_selector
 
-        _, prompt_input, _, reference_input = self._get_pair_input(corpus, self.prompt_field, self.reference_field,
-                                    self.prompt_selector, self.reference_selector)
-        self.prompt_embedding_model = fit_prompt_embedding_model(prompt_input, reference_input,
-                                self.snip_first_dim, self.prompt__tfidf_min_df, self.prompt__tfidf_max_df,
-                                self.reference__tfidf_min_df, self.reference__tfidf_max_df,
-                                self.svd__n_components, self.random_state, self.verbosity)
-        self.train_results['prompt_ids'], self.train_results['prompt_vects'],\
-            self.train_results['reference_ids'], self.train_results['reference_vects'] = self._get_embeddings(corpus, prompt_selector, reference_selector)
+        _, prompt_input, _, reference_input = self._get_pair_input(
+            corpus,
+            self.prompt_field,
+            self.reference_field,
+            self.prompt_selector,
+            self.reference_selector,
+        )
+        self.prompt_embedding_model = fit_prompt_embedding_model(
+            prompt_input,
+            reference_input,
+            self.snip_first_dim,
+            self.prompt__tfidf_min_df,
+            self.prompt__tfidf_max_df,
+            self.reference__tfidf_min_df,
+            self.reference__tfidf_max_df,
+            self.svd__n_components,
+            self.random_state,
+            self.verbosity,
+        )
+        (
+            self.train_results["prompt_ids"],
+            self.train_results["prompt_vects"],
+            self.train_results["reference_ids"],
+            self.train_results["reference_vects"],
+        ) = self._get_embeddings(corpus, prompt_selector, reference_selector)
         self.refit_types(self.default_n_types, self.random_state)
 
-
-    def transform(self, corpus, use_fit_selectors=True, prompt_selector=lambda utt: True, reference_selector=lambda utt: True):
+    def transform(
+        self,
+        corpus,
+        use_fit_selectors=True,
+        prompt_selector=lambda utt: True,
+        reference_selector=lambda utt: True,
+    ):
         """
         Computes vector representations and prompt type assignments for utterances in a corpus.
 
         :param corpus: Corpus
         :param use_fit_selectors: defaults to True, will use the same filters as the fit step to determine which utterances will be considered as prompts and responses in the transform step.
         :param prompt_selector: filter that determines which utterances will be considered as prompts in the
             transform step. defaults to prompt_selector, the same as is used in fit.
         :param reference_selector: filter that determines which utterances will be considered as responses in the
             transform step. defaults to reference_selector, the same as is used in fit.
         :return: the corpus, with per-utterance representations and type assignments.
         """
         if use_fit_selectors:
             prompt_selector = self.prompt_selector
             reference_selector = self.reference_selector
-        prompt_ids, prompt_vects, reference_ids, reference_vects = self._get_embeddings(corpus, prompt_selector, reference_selector)
-
-        corpus.set_vector_matrix(self.output_field + '__prompt_repr', matrix=prompt_vects, ids=prompt_ids)
-        corpus.set_vector_matrix(self.output_field + '__reference_repr', matrix=reference_vects, ids=reference_ids)
-
-        prompt_df, reference_df = self._get_type_assignments(prompt_ids, prompt_vects, reference_ids, reference_vects)
-        prompt_dists, prompt_assigns = prompt_df[prompt_df.columns[:-1]].values, prompt_df['type_id'].values
+        prompt_ids, prompt_vects, reference_ids, reference_vects = self._get_embeddings(
+            corpus, prompt_selector, reference_selector
+        )
+
+        corpus.set_vector_matrix(
+            self.output_field + "__prompt_repr", matrix=prompt_vects, ids=prompt_ids
+        )
+        corpus.set_vector_matrix(
+            self.output_field + "__reference_repr", matrix=reference_vects, ids=reference_ids
+        )
+
+        prompt_df, reference_df = self._get_type_assignments(
+            prompt_ids, prompt_vects, reference_ids, reference_vects
+        )
+        prompt_dists, prompt_assigns = (
+            prompt_df[prompt_df.columns[:-1]].values,
+            prompt_df["type_id"].values,
+        )
         prompt_min_dists = prompt_dists.min(axis=1)
-        reference_dists, reference_assigns = reference_df[reference_df.columns[:-1]].values, reference_df['type_id'].values
+        reference_dists, reference_assigns = (
+            reference_df[reference_df.columns[:-1]].values,
+            reference_df["type_id"].values,
+        )
         reference_min_dists = reference_dists.min(axis=1)
 
-        corpus.set_vector_matrix(self.output_field + '__prompt_dists.%s' % self.default_n_types, ids=prompt_df.index, matrix=prompt_dists,
-            columns=['type_%d_dist' % x for x in range(prompt_dists.shape[1])])
-        corpus.set_vector_matrix(self.output_field + '__reference_dists.%s' % self.default_n_types,
-                                ids=reference_df.index, matrix=reference_dists,
-            columns=['type_%d_dist' % x for x in range(prompt_dists.shape[1])])
+        corpus.set_vector_matrix(
+            self.output_field + "__prompt_dists__%s" % self.default_n_types,
+            ids=prompt_df.index,
+            matrix=prompt_dists,
+            columns=["type_%d_dist" % x for x in range(prompt_dists.shape[1])],
+        )
+        corpus.set_vector_matrix(
+            self.output_field + "__reference_dists__%s" % self.default_n_types,
+            ids=reference_df.index,
+            matrix=reference_dists,
+            columns=["type_%d_dist" % x for x in range(prompt_dists.shape[1])],
+        )
         for id, assign, dist in zip(prompt_df.index, prompt_assigns, prompt_min_dists):
-            corpus.get_utterance(id).add_meta(self.output_field + '__prompt_type.%s' % self.default_n_types, assign)
-            corpus.get_utterance(id).add_meta(self.output_field + '__prompt_type_dist.%s' % self.default_n_types, float(dist))
+            corpus.get_utterance(id).add_meta(
+                self.output_field + "__prompt_type__%s" % self.default_n_types, assign
+            )
+            corpus.get_utterance(id).add_meta(
+                self.output_field + "__prompt_type_dist__%s" % self.default_n_types, float(dist)
+            )
         for id, assign, dist in zip(reference_df.index, reference_assigns, reference_min_dists):
-            corpus.get_utterance(id).add_meta(self.output_field + '__reference_type.%s' % self.default_n_types, assign)
-            corpus.get_utterance(id).add_meta(self.output_field + '__reference_type_dist.%s' % self.default_n_types, float(dist))
+            corpus.get_utterance(id).add_meta(
+                self.output_field + "__reference_type__%s" % self.default_n_types, assign
+            )
+            corpus.get_utterance(id).add_meta(
+                self.output_field + "__reference_type_dist__%s" % self.default_n_types, float(dist)
+            )
         return corpus
 
     def transform_utterance(self, utterance):
         """
         Computes vector representations and prompt type assignments for a single utterance.
 
         :param utterance: the utterance.
         :return: the utterance, annotated with representations and type assignments.
         """
 
         # if self.prompt_transform_filter(utterance):
-        utterance = self._transform_utterance_side(utterance, 'prompt')
+        utterance = self._transform_utterance_side(utterance, "prompt")
         # if self.reference_transform_filter(utterance):
-        utterance = self._transform_utterance_side(utterance, 'reference')
+        utterance = self._transform_utterance_side(utterance, "reference")
         return utterance
 
-
     def _transform_utterance_side(self, utterance, side):
-        if side == 'prompt':
+        if side == "prompt":
             input_field = self.prompt_transform_field
-        elif side == 'reference':
+        elif side == "reference":
             input_field = self.reference_transform_field
         utt_id = utterance.id
         utt_input = utterance.retrieve_meta(input_field)
         if isinstance(utt_input, list):
-            utt_input = '\n'.join(utt_input)
-        utt_ids, utt_vects = transform_embeddings(self.prompt_embedding_model, [utt_id], [utt_input], side=side)
-        assign_df = assign_prompt_types(self.type_models[self.default_n_types], utt_ids, utt_vects, self.max_dist)
+            utt_input = "\n".join(utt_input)
+        utt_ids, utt_vects = transform_embeddings(
+            self.prompt_embedding_model, [utt_id], [utt_input], side=side
+        )
+        assign_df = assign_prompt_types(
+            self.type_models[self.default_n_types], utt_ids, utt_vects, self.max_dist
+        )
         vals = assign_df.values[0]
         dists = vals[:-1]
         min_dist = min(dists)
         assign = vals[-1]
-        utterance.add_meta(self.output_field + '__%s_type.%s' % (side, self.default_n_types), assign)
-        utterance.add_meta(self.output_field + '__%s_type_dist.%s' % (side, self.default_n_types), float(min_dist))
-        utterance.add_meta(self.output_field + '__%s_dists.%s' % (side, self.default_n_types), [float(x) for x in dists])
-        utterance.add_meta(self.output_field + '__%s_repr' % side, [float(x) for x in utt_vects[0]])
+        utterance.add_meta(
+            self.output_field + "__%s_type__%s" % (side, self.default_n_types), assign
+        )
+        utterance.add_meta(
+            self.output_field + "__%s_type_dist__%s" % (side, self.default_n_types), float(min_dist)
+        )
+        utterance.add_meta(
+            self.output_field + "__%s_dists__%s" % (side, self.default_n_types),
+            [float(x) for x in dists],
+        )
+        utterance.add_meta(self.output_field + "__%s_repr" % side, [float(x) for x in utt_vects[0]])
         return utterance
 
     def refit_types(self, n_types, random_state=None, name=None):
         """
         Using the latent representations of prompt terms learned during the initial `fit` call, infers `n_types` prompt types. permits retraining the clustering model that determines the number of types, on top of the initial model. calling this *and* updating the `default_n_types` field of the model will result in future `transform` calls assigning utterances to one of `n_types` prompt types.
 
         :param n_types: number of types to learn
@@ -217,155 +297,172 @@
 
         if name is None:
             key = n_types
         else:
             key = name
         if random_state is None:
             random_state = self.random_state
-        self.type_models[key] = fit_prompt_type_model(self.prompt_embedding_model, n_types, random_state, self.max_dist, self.verbosity)
+        self.type_models[key] = fit_prompt_type_model(
+            self.prompt_embedding_model, n_types, random_state, self.max_dist, self.verbosity
+        )
         prompt_df, reference_df = self._get_type_assignments(type_key=key)
-        self.train_types[key] = {'prompt_df': prompt_df, 'reference_df': reference_df}
-
+        self.train_types[key] = {"prompt_df": prompt_df, "reference_df": reference_df}
 
     def _get_embeddings(self, corpus, prompt_selector, reference_selector):
-        prompt_ids, prompt_inputs = self._get_input(corpus, self.prompt_transform_field,
-                                                    prompt_selector)
-        reference_ids, reference_inputs = self._get_input(corpus, self.reference_transform_field, reference_selector)
-        prompt_ids, prompt_vects = transform_embeddings(self.prompt_embedding_model,
-                                                        prompt_ids, prompt_inputs,
-                                                        side='prompt')
-        reference_ids, reference_vects = transform_embeddings(self.prompt_embedding_model,
-                                                        reference_ids, reference_inputs,
-                                                        side='reference')
+        prompt_ids, prompt_inputs = self._get_input(
+            corpus, self.prompt_transform_field, prompt_selector
+        )
+        reference_ids, reference_inputs = self._get_input(
+            corpus, self.reference_transform_field, reference_selector
+        )
+        prompt_ids, prompt_vects = transform_embeddings(
+            self.prompt_embedding_model, prompt_ids, prompt_inputs, side="prompt"
+        )
+        reference_ids, reference_vects = transform_embeddings(
+            self.prompt_embedding_model, reference_ids, reference_inputs, side="reference"
+        )
         return prompt_ids, prompt_vects, reference_ids, reference_vects
 
-
-    def _get_type_assignments(self, prompt_ids=None, prompt_vects=None,
-                             reference_ids=None, reference_vects=None, type_key=None):
+    def _get_type_assignments(
+        self,
+        prompt_ids=None,
+        prompt_vects=None,
+        reference_ids=None,
+        reference_vects=None,
+        type_key=None,
+    ):
         if prompt_ids is None:
-            prompt_ids, prompt_vects, reference_ids, reference_vects = [self.train_results[k] for k in
-                                        ['prompt_ids', 'prompt_vects', 'reference_ids', 'reference_vects']]
+            prompt_ids, prompt_vects, reference_ids, reference_vects = [
+                self.train_results[k]
+                for k in ["prompt_ids", "prompt_vects", "reference_ids", "reference_vects"]
+            ]
         if type_key is None:
             type_key = self.default_n_types
-        prompt_df = assign_prompt_types(self.type_models[type_key], prompt_ids, prompt_vects, self.max_dist)
-        reference_df = assign_prompt_types(self.type_models[type_key], reference_ids, reference_vects, self.max_dist)
+        prompt_df = assign_prompt_types(
+            self.type_models[type_key], prompt_ids, prompt_vects, self.max_dist
+        )
+        reference_df = assign_prompt_types(
+            self.type_models[type_key], reference_ids, reference_vects, self.max_dist
+        )
         return prompt_df, reference_df
 
-
     def display_type(self, type_id, corpus=None, type_key=None, k=10):
         """
         For a particular prompt type, displays the representative prompt and response terms. can also display representative prompt and response utterances.
 
         :param type_id: ID of the prompt type to display.
         :param corpus: pass in the training corpus to also display representative utterances.
         :param type_key: the name of the prompt type clustering model to use. defaults to `n_types` that the model was initialized with, but if `refit_types` is called with different number of types, can be modified to display this updated model as well.
         :param k: the number of sample terms (or utteranceS) to display.
         :return: None
         """
 
         if type_key is None:
             type_key = self.default_n_types
-        prompt_df = self.type_models[type_key]['prompt_df']
-        reference_df = self.type_models[type_key]['reference_df']
+        prompt_df = self.type_models[type_key]["prompt_df"]
+        reference_df = self.type_models[type_key]["reference_df"]
 
         top_prompt = prompt_df[prompt_df.type_id == type_id].sort_values(type_id).head(k)
         top_ref = reference_df[reference_df.type_id == type_id].sort_values(type_id).head(k)
-        print('top prompt:')
+        print("top prompt:")
         print(top_prompt)
-        print('top response:')
+        print("top response:")
         print(top_ref)
 
         if corpus is not None:
-            prompt_df = self.train_types[type_key]['prompt_df']
-            reference_df = self.train_types[type_key]['reference_df']
+            prompt_df = self.train_types[type_key]["prompt_df"]
+            reference_df = self.train_types[type_key]["reference_df"]
             top_prompt = prompt_df[prompt_df.type_id == type_id].sort_values(type_id).head(k).index
-            top_ref = reference_df[reference_df.type_id == type_id].sort_values(type_id).head(k).index
-            print('top prompts:')
+            top_ref = (
+                reference_df[reference_df.type_id == type_id].sort_values(type_id).head(k).index
+            )
+            print("top prompts:")
             for utt in top_prompt:
                 print(utt, corpus.get_utterance(utt).text)
                 print(corpus.get_utterance(utt).retrieve_meta(self.prompt_transform_field))
                 print()
-            print('top responses:')
+            print("top responses:")
             for utt in top_ref:
                 print(utt, corpus.get_utterance(utt).text)
                 print(corpus.get_utterance(utt).retrieve_meta(self.reference_transform_field))
                 print()
 
     def summarize(self, corpus, type_ids=None, type_key=None, k=10):
-        '''
+        """
         Displays representative prompt and response terms and utterances for each type learned. A wrapper for `display_type`.
 
         :param corpus: corpus to display utterances for (must have `transform()` called on it)
         :param type_ids: ID of the prompt type to display. if None, will display all types.
         :param type_key: the name of the prompt type clustering model to use. defaults to `n_types` that the model was initialized with, but if `refit_types` is called with different number of types, can be modified to display this updated model as well.
         :param k: the number of sample terms (or utteranceS) to display.
         :return: None
-        '''
+        """
         if type_key is None:
             type_key = self.default_n_types
 
-        n_types = self.type_models[type_key]['km_model'].n_clusters
+        n_types = self.type_models[type_key]["km_model"].n_clusters
         if type_ids is None:
             type_ids = list(range(n_types))
         if not isinstance(type_ids, list):
             type_ids = [type_ids]
         for type_id in type_ids:
-            print('TYPE', type_id)
+            print("TYPE", type_id)
             self.display_type(type_id, corpus, type_key, k)
-            print('====')
+            print("====")
 
-    def dump_model(self, model_dir, type_keys='default', dump_train_corpus=True):
+    def dump_model(self, model_dir, type_keys="default", dump_train_corpus=True):
         """
         Dumps the model to disk.
 
         :param model_dir: directory to write model to
         :param type_keys: if 'default', will only write the type clustering model corresponding to the `n_types` the model was initialized with. if 'all', will write all clustering models that have been trained via calls to `refit_types`. can also take a list of clustering models.
         :param dump_train_corpus: whether to also write the representations and type assignments of the training corpus. defaults to True.
         :return: None
         """
 
         if self.verbosity > 0:
-            print('dumping embedding model')
+            print("dumping embedding model")
         if not os.path.exists(model_dir):
             try:
                 os.mkdir(model_dir)
             except:
                 pass
-        for k in ['prompt_tfidf_model', 'reference_tfidf_model', 'svd_model']:
-            joblib.dump(self.prompt_embedding_model[k],
-                       os.path.join(model_dir, k + '.joblib'))
+        for k in ["prompt_tfidf_model", "reference_tfidf_model", "svd_model"]:
+            joblib.dump(self.prompt_embedding_model[k], os.path.join(model_dir, k + ".joblib"))
 
-        for k in ['U_prompt', 'U_reference']:
+        for k in ["U_prompt", "U_reference"]:
             np.save(os.path.join(model_dir, k), self.prompt_embedding_model[k])
 
         if dump_train_corpus:
             if self.verbosity > 0:
-                print('dumping training embeddings')
-            for k in ['prompt_ids', 'prompt_vects', 'reference_ids', 'reference_vects']:
-                np.save(os.path.join(model_dir, 'train_' + k), self.train_results[k])
+                print("dumping training embeddings")
+            for k in ["prompt_ids", "prompt_vects", "reference_ids", "reference_vects"]:
+                np.save(os.path.join(model_dir, "train_" + k), self.train_results[k])
 
-        if type_keys == 'default':
+        if type_keys == "default":
             to_dump = [self.default_n_types]
-        elif type_keys == 'all':
+        elif type_keys == "all":
             to_dump = self.type_models.keys()
         else:
             to_dump = type_keys
         for key in to_dump:
             if self.verbosity > 0:
-                print('dumping type model', key)
+                print("dumping type model", key)
             type_model = self.type_models[key]
-            joblib.dump(type_model['km_model'], os.path.join(model_dir, 'km_model.%s.joblib' % key))
-            for k in ['prompt_df', 'reference_df']:
-                type_model[k].to_csv(os.path.join(model_dir, '%s.%s.tsv' % (k, key)), sep='\t')
+            joblib.dump(type_model["km_model"], os.path.join(model_dir, "km_model.%s.joblib" % key))
+            for k in ["prompt_df", "reference_df"]:
+                type_model[k].to_csv(os.path.join(model_dir, "%s.%s.tsv" % (k, key)), sep="\t")
             if dump_train_corpus:
                 train_types = self.train_types[key]
-                for k in ['prompt_df', 'reference_df']:
-                    train_types[k].to_csv(os.path.join(model_dir, 'train_%s.%s.tsv' % (k, key)), sep='\t')
+                for k in ["prompt_df", "reference_df"]:
+                    train_types[k].to_csv(
+                        os.path.join(model_dir, "train_%s.%s.tsv" % (k, key)), sep="\t"
+                    )
 
-    def get_model(self, type_keys='default'):
+    def get_model(self, type_keys="default"):
         """
         Returns the model as a dictionary containing:
             * embedding_model: stores information pertaining to the vector representations.
                 * prompt_tfidf_model: sklearn tf-idf model that converts prompt input to term-document matrix
                 * reference_tfidf_model: tf-idf model that converts response input to term-document matrix
                 * svd_model: sklearn TruncatedSVD model that produces a low-dimensional representation of responses and prompts
                 * U_prompt: vector representations of prompt terms
@@ -373,238 +470,274 @@
             * type_models: a dictionary mapping each type clustering model to:
                 * km_model: a sklearn KMeans model of the learned types
                 * prompt_df: distances to cluster centroids, and type assignments, of prompt terms
                 * reference_df: distances to cluster centroids, and type assignments, of reference terms
         :param type_keys: if 'default', will return the type clustering model corresponding to the `n_types` the model was initialized with. if 'all', returns all clustering models that have been trained via calls to `refit_types`. can also take a list of clustering models.
         :return: the prompt types model
         """
-        if type_keys == 'default':
+        if type_keys == "default":
             to_get = [self.default_n_types]
-        elif type_keys == 'all':
+        elif type_keys == "all":
             to_get = self.type_models.keys()
         else:
             to_get = type_keys
-        to_return = {'embedding_model': self.prompt_embedding_model, 
-                'type_models': {k: self.type_models[k] for k in to_get}}
+        to_return = {
+            "embedding_model": self.prompt_embedding_model,
+            "type_models": {k: self.type_models[k] for k in to_get},
+        }
         return to_return
 
-    def load_model(self, model_dir, type_keys='default', load_train_corpus=True):
+    def load_model(self, model_dir, type_keys="default", load_train_corpus=True):
         """
         Loads the model from disk.
 
         :param model_dir: directory to read model to
         :param type_keys: if 'default', will only read the type clustering model corresponding to the `n_types` the model was initialized with. if 'all', will read all clustering models that are available in directory. can also take a list of clustering models.
         :param load_train_corpus: whether to also read the representations and type assignments of the training corpus. defaults to True.
         :return: None
         """
         if self.verbosity > 0:
-            print('loading embedding model')
-        for k in ['prompt_tfidf_model', 'reference_tfidf_model', 'svd_model']:
-            self.prompt_embedding_model[k] = joblib.load(os.path.join(model_dir, k + '.joblib'))
-        for k in ['U_prompt', 'U_reference']:
-            self.prompt_embedding_model[k] = np.load(os.path.join(model_dir, k + '.npy'))
+            print("loading embedding model")
+        for k in ["prompt_tfidf_model", "reference_tfidf_model", "svd_model"]:
+            self.prompt_embedding_model[k] = joblib.load(os.path.join(model_dir, k + ".joblib"))
+        for k in ["U_prompt", "U_reference"]:
+            self.prompt_embedding_model[k] = np.load(os.path.join(model_dir, k + ".npy"))
 
         if load_train_corpus:
             if self.verbosity > 0:
-                print('loading training embeddings')
-            for k in ['prompt_ids', 'prompt_vects', 'reference_ids', 'reference_vects']:
-                self.train_results[k] = np.load(os.path.join(model_dir, 'train_' + k + '.npy'))
+                print("loading training embeddings")
+            for k in ["prompt_ids", "prompt_vects", "reference_ids", "reference_vects"]:
+                self.train_results[k] = np.load(os.path.join(model_dir, "train_" + k + ".npy"))
 
-        if type_keys == 'default':
+        if type_keys == "default":
             to_load = [self.default_n_types]
-        elif type_keys == 'all':
-            to_load = [x.replace('km_model.','').replace('.joblib','')
-                      for x in os.listdir(model_dir) if x.startswith('km_model')]
+        elif type_keys == "all":
+            to_load = [
+                x.replace("km_model.", "").replace(".joblib", "")
+                for x in os.listdir(model_dir)
+                if x.startswith("km_model")
+            ]
         else:
             to_load = type_keys
         for key in to_load:
             try:
                 key = int(key)
-            except: pass
+            except:
+                pass
             if self.verbosity > 0:
-                print('loading type model', key)
-            self.type_models[key] = {} # this should be an int-ish
-            self.type_models[key]['km_model'] = joblib.load(
-                os.path.join(model_dir, 'km_model.%s.joblib' % key))
-
-            for k in ['prompt_df', 'reference_df']:
-                self.type_models[key][k] =\
-                    pd.read_csv(os.path.join(model_dir, '%s.%s.tsv' % (k, key)), sep='\t', index_col=0)
-                self.type_models[key][k].columns = [int(x) for x in self.type_models[key][k].columns[:-1]]\
-                    + ['type_id']
+                print("loading type model", key)
+            self.type_models[key] = {}  # this should be an int-ish
+            self.type_models[key]["km_model"] = joblib.load(
+                os.path.join(model_dir, "km_model.%s.joblib" % key)
+            )
+
+            for k in ["prompt_df", "reference_df"]:
+                self.type_models[key][k] = pd.read_csv(
+                    os.path.join(model_dir, "%s.%s.tsv" % (k, key)), sep="\t", index_col=0
+                )
+                self.type_models[key][k].columns = [
+                    int(x) for x in self.type_models[key][k].columns[:-1]
+                ] + ["type_id"]
             if load_train_corpus:
                 self.train_types[key] = {}
-                for k in ['prompt_df', 'reference_df']:
+                for k in ["prompt_df", "reference_df"]:
                     self.train_types[key][k] = pd.read_csv(
-                        os.path.join(model_dir, 'train_%s.%s.tsv' % (k, key)), sep='\t', index_col=0
+                        os.path.join(model_dir, "train_%s.%s.tsv" % (k, key)), sep="\t", index_col=0
                     )
-                    self.train_types[key][k].columns = \
-                        [int(x) for x in self.train_types[key][k].columns[:-1]] + ['type_id']
+                    self.train_types[key][k].columns = [
+                        int(x) for x in self.train_types[key][k].columns[:-1]
+                    ] + ["type_id"]
 
     def _get_input(self, corpus, field, filter_fn, check_nonempty=True):
         ids = []
         inputs = []
         for utterance in corpus.iter_utterances():
             input = utterance.retrieve_meta(field)
             if isinstance(input, list):
-                input = '\n'.join(input)
-            if filter_fn(utterance)\
-                and ((not check_nonempty) or (len(input) > 0)):
+                input = "\n".join(input)
+            if filter_fn(utterance) and ((not check_nonempty) or (len(input) > 0)):
                 ids.append(utterance.id)
                 inputs.append(input)
         return ids, inputs
 
-    def _get_pair_input(self, corpus, prompt_field, reference_field,
-              prompt_selector, reference_selector,
-              check_nonempty=True):
+    def _get_pair_input(
+        self,
+        corpus,
+        prompt_field,
+        reference_field,
+        prompt_selector,
+        reference_selector,
+        check_nonempty=True,
+    ):
         prompt_ids = []
         prompt_utts = []
         reference_ids = []
         reference_utts = []
         for reference_utt in corpus.iter_utterances():
             if reference_utt.reply_to is None:
                 continue
             prompt_utt_id = reference_utt.reply_to
             try:
                 prompt_utt = corpus.get_utterance(prompt_utt_id)
             except:
                 continue
-            if prompt_selector(prompt_utt) \
-                and reference_selector(reference_utt):
-
+            if prompt_selector(prompt_utt) and reference_selector(reference_utt):
                 prompt_input = prompt_utt.retrieve_meta(prompt_field)
                 reference_input = reference_utt.retrieve_meta(reference_field)
 
                 if (prompt_input is None) or (reference_input is None):
                     continue
 
                 if isinstance(prompt_input, list):
-                     prompt_input = '\n'.join(prompt_input)
+                    prompt_input = "\n".join(prompt_input)
                 if isinstance(reference_input, list):
-                     reference_input = '\n'.join(reference_input)
+                    reference_input = "\n".join(reference_input)
 
                 if (not check_nonempty) or ((len(prompt_input) > 0) and (len(reference_input) > 0)):
                     prompt_ids.append(prompt_utt.id)
                     prompt_utts.append(prompt_input)
                     reference_ids.append(reference_utt.id)
                     reference_utts.append(reference_input)
         return prompt_ids, prompt_utts, reference_ids, reference_utts
 
 
-
-def fit_prompt_embedding_model(prompt_input, reference_input, snip_first_dim=True,
-            prompt__tfidf_min_df=100, prompt__tfidf_max_df=.1,
-            reference__tfidf_min_df=100, reference__tfidf_max_df=.1,
-            svd__n_components=25, random_state=None, verbosity=0):
+def fit_prompt_embedding_model(
+    prompt_input,
+    reference_input,
+    snip_first_dim=True,
+    prompt__tfidf_min_df=100,
+    prompt__tfidf_max_df=0.1,
+    reference__tfidf_min_df=100,
+    reference__tfidf_max_df=0.1,
+    svd__n_components=25,
+    random_state=None,
+    verbosity=0,
+):
     """
     Standalone function that fits an embedding model given paired prompt and response inputs. See docstring of the `PromptTypes` class for details.
 
     :param prompt_input: list of prompts (represented as space-separated strings of terms)
     :param reference_input: list of responses (represented as space-separated strings of terms). note that each entry of reference_input should be a response to the corresponding entry in prompt_input.
     :return: prompt embedding model
     """
 
     if verbosity > 0:
-        print('fitting %d input pairs' % len(prompt_input))
-        print('fitting reference tfidf model')
+        print("fitting %d input pairs" % len(prompt_input))
+        print("fitting reference tfidf model")
     reference_tfidf_model = TfidfVectorizer(
         min_df=reference__tfidf_min_df,
         max_df=reference__tfidf_max_df,
         binary=True,
-        token_pattern=r'(?u)(\S+)'
+        token_pattern=r"(?u)(\S+)",
     )
     reference_vect = reference_tfidf_model.fit_transform(reference_input)
 
     if verbosity > 0:
-        print('fitting prompt tfidf model')
+        print("fitting prompt tfidf model")
     prompt_tfidf_model = TfidfVectorizer(
         min_df=prompt__tfidf_min_df,
         max_df=prompt__tfidf_max_df,
         binary=True,
-        token_pattern=r'(?u)(\S+)'
+        token_pattern=r"(?u)(\S+)",
     )
     prompt_vect = prompt_tfidf_model.fit_transform(prompt_input)
 
     if verbosity > 0:
-        print('fitting svd model')
-    svd_model = TruncatedSVD(n_components=svd__n_components, random_state=random_state, algorithm='arpack')
-   
+        print("fitting svd model")
+    svd_model = TruncatedSVD(
+        n_components=svd__n_components, random_state=random_state, algorithm="arpack"
+    )
+
     U_reference = svd_model.fit_transform(normalize(reference_vect.T))
     s = svd_model.singular_values_
     U_reference /= s
     U_prompt = (svd_model.components_ * normalize(prompt_vect, axis=0) / s[:, np.newaxis]).T
 
     if snip_first_dim:
         U_prompt = U_prompt[:, 1:]
         U_reference = U_reference[:, 1:]
     U_prompt_norm = normalize(U_prompt)
     U_reference_norm = normalize(U_reference)
 
-    return {'prompt_tfidf_model': prompt_tfidf_model, 'reference_tfidf_model': reference_tfidf_model,
-           'svd_model': svd_model, 'U_prompt': U_prompt_norm, 'U_reference': U_reference_norm}
+    return {
+        "prompt_tfidf_model": prompt_tfidf_model,
+        "reference_tfidf_model": reference_tfidf_model,
+        "svd_model": svd_model,
+        "U_prompt": U_prompt_norm,
+        "U_reference": U_reference_norm,
+    }
 
-def transform_embeddings(model, ids, input, side='prompt', filter_empty=True):
+
+def transform_embeddings(model, ids, input, side="prompt", filter_empty=True):
     """
     Standalone function that returns vector representations of input text given a trained PromptTypes prompt_embedding_model. See docstring of `PromptTypes` class for details.
 
     :param model: prompt embedding model
     :param ids: ids of input text
     :param input: a list where each entry has corresponding id in the ids argument, and is a string of terms corresponding to an utterance.
     :param side: whether to return prompt or response embeddings ("prompt" and "reference" respectively); defaults to "prompt"
     :param filter_empty: if `True`, will not return embeddings for prompts with no terms.
     :return: input IDs `ids`, and corresponding vector representations of input `vect`
     """
 
-    tfidf_vects = normalize(model['%s_tfidf_model' % side].transform(input), norm='l1')
+    tfidf_vects = normalize(model["%s_tfidf_model" % side].transform(input), norm="l1")
     mask = np.array(tfidf_vects.sum(axis=1)).flatten() > 0
-    vects = normalize(tfidf_vects * model['U_%s' % side])
+    vects = normalize(tfidf_vects * model["U_%s" % side])
     if filter_empty:
         ids = np.array(ids)[mask]
         vects = vects[mask]
     return ids, vects
 
+
 def fit_prompt_type_model(model, n_types, random_state=None, max_dist=0.9, verbosity=0):
     """
     Standalone function that fits a prompt type model given paired prompt and response inputs. See docstring of the `PromptTypes` class for details.
 
     :param model: prompt embedding model (from `fit_prompt_embedding_model()`)
     :param n_types: number of prompt types to infer
     :return: prompt type model
     """
 
     if verbosity > 0:
-        print('fitting %d prompt types' % n_types)
+        print("fitting %d prompt types" % n_types)
     km = KMeans(n_clusters=n_types, random_state=random_state)
-    km.fit(model['U_prompt'])
-    prompt_dists = km.transform(model['U_prompt'])
-    prompt_clusters = km.predict(model['U_prompt'])
+    km.fit(model["U_prompt"])
+    prompt_dists = km.transform(model["U_prompt"])
+    prompt_clusters = km.predict(model["U_prompt"])
     prompt_clusters[prompt_dists.min(axis=1) >= max_dist] = -1
-    reference_dists = km.transform(model['U_reference'])
-    reference_clusters = km.predict(model['U_reference'])
+    reference_dists = km.transform(model["U_reference"])
+    reference_clusters = km.predict(model["U_reference"])
     reference_clusters[reference_dists.min(axis=1) >= max_dist] = -1
 
-    prompt_df = pd.DataFrame(index=model['prompt_tfidf_model'].get_feature_names(),
-                          data=np.hstack([prompt_dists, prompt_clusters[:,np.newaxis]]),
-                          columns=list(range(n_types)) + ['type_id'])
-    reference_df = pd.DataFrame(index=model['reference_tfidf_model'].get_feature_names(),
-                          data=np.hstack([reference_dists, reference_clusters[:,np.newaxis]]),
-                          columns=list(range(n_types)) + ['type_id'])
-    return {'km_model': km,
-           'prompt_df': prompt_df, 'reference_df': reference_df}
+    prompt_df = pd.DataFrame(
+        index=model["prompt_tfidf_model"].get_feature_names(),
+        data=np.hstack([prompt_dists, prompt_clusters[:, np.newaxis]]),
+        columns=list(range(n_types)) + ["type_id"],
+    )
+    reference_df = pd.DataFrame(
+        index=model["reference_tfidf_model"].get_feature_names(),
+        data=np.hstack([reference_dists, reference_clusters[:, np.newaxis]]),
+        columns=list(range(n_types)) + ["type_id"],
+    )
+    return {"km_model": km, "prompt_df": prompt_df, "reference_df": reference_df}
+
 
 def assign_prompt_types(model, ids, vects, max_dist=0.9):
     """
     Standalone function that returns type assignments of input vectors given a trained PromptTypes type model. See docstring of `PromptTypes` class for details.
 
     :param model: prompt type model
     :param ids: ids of input vectors
     :param vects: input vectors
     :return: a dataframe storing cluster centroid distances and the assigned type.
     """
 
-    dists = model['km_model'].transform(vects)
-    clusters = model['km_model'].predict(vects)
+    dists = model["km_model"].transform(vects)
+    clusters = model["km_model"].predict(vects)
     dist_mask = dists.min(axis=1) >= max_dist
-    clusters[ dist_mask] = -1
-    df = pd.DataFrame(index=ids, data=np.hstack([dists,clusters[:,np.newaxis]]),
-                     columns=list(range(dists.shape[1])) + ['type_id'])
+    clusters[dist_mask] = -1
+    df = pd.DataFrame(
+        index=ids,
+        data=np.hstack([dists, clusters[:, np.newaxis]]),
+        columns=list(range(dists.shape[1])) + ["type_id"],
+    )
     return df
```

### Comparing `convokit-2.5.3/convokit/ranker/ranker.py` & `convokit-3.0.0/convokit/ranker/ranker.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,54 +1,57 @@
 from typing import List, Callable, Union
+
 import pandas as pd
 
 from convokit import Corpus, Transformer, CorpusComponent
-from convokit.util import deprecation
 
 
 class Ranker(Transformer):
     """
     Ranker sorts the objects in the Corpus by a given scoring function and annotates the objects with their rankings.
 
     :param obj_type: type of Corpus object to rank: 'conversation', 'speaker', or 'utterance'
     :param score_func: function for computing the score of a given object
     :param score_attribute_name: metadata attribute name to use in annotation for score value, default: "score"
     :param rank_attribute_name: metadata attribute name to use in annotation for the rank value, default: "rank"
     """
-    def __init__(self, obj_type: str,
-                 score_func: Callable[[CorpusComponent], Union[int, float]],
-                 score_attribute_name: str = "score",
-                 score_feat_name=None,
-                 rank_attribute_name: str = "rank",
-                 rank_feat_name=None):
+
+    def __init__(
+        self,
+        obj_type: str,
+        score_func: Callable[[CorpusComponent], Union[int, float]],
+        score_attribute_name: str = "score",
+        rank_attribute_name: str = "rank",
+    ):
         self.obj_type = obj_type
         self.score_func = score_func
-        self.score_attribute_name = score_attribute_name if score_feat_name is None else score_feat_name
-        self.rank_attribute_name = rank_attribute_name if rank_feat_name is None else rank_feat_name
-
-        if score_feat_name is not None:
-            deprecation("Ranker's score_feat_name parameter", 'score_attribute_name')
+        self.score_attribute_name = score_attribute_name
+        self.rank_attribute_name = rank_attribute_name
 
-        if rank_feat_name is not None:
-            deprecation("Ranker's rank_feat_name parameter", 'rank_attribute_name')
-
-    def transform(self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda obj: True) -> Corpus:
+    def transform(
+        self, corpus: Corpus, y=None, selector: Callable[[CorpusComponent], bool] = lambda obj: True
+    ) -> Corpus:
         """
         Annotate corpus objects with scores and rankings.
 
         :param corpus: target corpus
         :param selector: (lambda) function taking in a Corpus object and returning True / False; selects for Corpus objects to annotate.
         :return: annotated corpus
         """
-        obj_iters = {"conversation": corpus.iter_conversations,
-                     "speaker": corpus.iter_speakers,
-                     "utterance": corpus.iter_utterances}
+        obj_iters = {
+            "conversation": corpus.iter_conversations,
+            "speaker": corpus.iter_speakers,
+            "utterance": corpus.iter_utterances,
+        }
         obj_scores = [(obj.id, self.score_func(obj)) for obj in obj_iters[self.obj_type](selector)]
-        df = pd.DataFrame(obj_scores, columns=["id", self.score_attribute_name]) \
-            .set_index('id').sort_values(self.score_attribute_name, ascending=False)
+        df = (
+            pd.DataFrame(obj_scores, columns=["id", self.score_attribute_name])
+            .set_index("id")
+            .sort_values(self.score_attribute_name, ascending=False)
+        )
         df[self.rank_attribute_name] = [idx + 1 for idx, _ in enumerate(df.index)]
 
         for obj in corpus.iter_objs(obj_type=self.obj_type):
             if obj.id in df.index:
                 obj.add_meta(self.score_attribute_name, df.loc[obj.id][self.score_attribute_name])
                 obj.add_meta(self.rank_attribute_name, df.loc[obj.id][self.rank_attribute_name])
             else:
@@ -60,46 +63,70 @@
         """
         Annotate list of Corpus objects with scores and rankings.
 
         :param objs: target list of Corpus objects
         :return: list of annotated COrpus objects
         """
         obj_scores = [(obj.id, self.score_func(obj)) for obj in objs]
-        df = pd.DataFrame(obj_scores, columns=["id", self.score_attribute_name]) \
-            .set_index('id').sort_values(self.score_attribute_name, ascending=False)
+        df = (
+            pd.DataFrame(obj_scores, columns=["id", self.score_attribute_name])
+            .set_index("id")
+            .sort_values(self.score_attribute_name, ascending=False)
+        )
         df[self.rank_attribute_name] = [idx + 1 for idx, _ in enumerate(df.index)]
         for obj in objs:
             obj.add_meta(self.score_attribute_name, df.loc[obj.id][self.score_attribute_name])
             obj.add_meta(self.rank_attribute_name, df.loc[obj.id][self.rank_attribute_name])
         return objs
 
-    def summarize(self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda obj: True):
+    def summarize(
+        self, corpus: Corpus, selector: Callable[[CorpusComponent], bool] = lambda obj: True
+    ):
         """
         Generate a dataframe indexed by object id, containing score + rank, and sorted by rank (in ascending order) of the objects in an annotated corpus, with an optional selector selecting which objects to be included in the dataframe
 
         :param corpus: annotated target corpus
         :param selector: a (lambda) function that takes a Corpus object and returns True or False (i.e. include / exclude). By default, the selector includes all objects of the specified type in the Corpus.
         :return: a pandas DataFrame
         """
-        obj_iters = {"conversation": corpus.iter_conversations,
-                     "speaker": corpus.iter_speakers,
-                     "utterance": corpus.iter_utterances}
-        obj_scores_ranks = [(obj.id, obj.meta[self.score_attribute_name], obj.meta[self.rank_attribute_name])
-                      for obj in obj_iters[self.obj_type](selector)]
-
-        df = pd.DataFrame(obj_scores_ranks, columns=["id", self.score_attribute_name, self.rank_attribute_name])\
-                        .set_index('id').sort_values(self.rank_attribute_name, ascending=True)
+        obj_iters = {
+            "conversation": corpus.iter_conversations,
+            "speaker": corpus.iter_speakers,
+            "utterance": corpus.iter_utterances,
+        }
+        obj_scores_ranks = [
+            (obj.id, obj.meta[self.score_attribute_name], obj.meta[self.rank_attribute_name])
+            for obj in obj_iters[self.obj_type](selector)
+        ]
+
+        df = (
+            pd.DataFrame(
+                obj_scores_ranks,
+                columns=["id", self.score_attribute_name, self.rank_attribute_name],
+            )
+            .set_index("id")
+            .sort_values(self.rank_attribute_name, ascending=True)
+        )
 
         return df
 
     def summarize_objs(self, objs: List[CorpusComponent]):
         """
         Generate a dataframe indexed by object id, containing score + rank, and sorted by rank (in ascending order) of the objects in an annotated corpus, or a list of corpus objects
 
         :param objs: list of annotated corpus objects
         :return: a pandas DataFrame
         """
-        obj_scores_ranks = [(obj.id, obj.meta[self.score_attribute_name], obj.meta[self.rank_attribute_name]) for obj in objs]
-        df = pd.DataFrame(obj_scores_ranks, columns=["id", self.score_attribute_name, self.rank_attribute_name]) \
-            .set_index('id').sort_values(self.rank_attribute_name, ascending=True)
+        obj_scores_ranks = [
+            (obj.id, obj.meta[self.score_attribute_name], obj.meta[self.rank_attribute_name])
+            for obj in objs
+        ]
+        df = (
+            pd.DataFrame(
+                obj_scores_ranks,
+                columns=["id", self.score_attribute_name, self.rank_attribute_name],
+            )
+            .set_index("id")
+            .sort_values(self.rank_attribute_name, ascending=True)
+        )
 
-        return df
+        return df
```

### Comparing `convokit-2.5.3/convokit/speakerConvoDiversity/speakerConvoDiversity.py` & `convokit-3.0.0/convokit/speakerConvoDiversity/speakerConvoDiversity2.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,267 +1,333 @@
-import numpy as np 
+import numpy as np
+import pandas as pd
 from convokit.transformer import Transformer
 from convokit.speaker_convo_helpers.speaker_convo_attrs import SpeakerConvoAttrs
 from itertools import chain
 from collections import Counter
 from convokit.speaker_convo_helpers.speaker_convo_lifestage import SpeakerConvoLifestage
+from convokit import Utterance
+from convokit.surprise import Surprise
+from sklearn.feature_extraction.text import CountVectorizer
+from tqdm import tqdm
+from typing import List
+
 
 def _join_all_tokens(parses):
-	joined = []
-	for parse in parses:
-		for sent in parse:
-			joined += [tok['tok'].lower() for tok in sent['toks']]
-	return joined
+    joined = []
+    for parse in parses:
+        for sent in parse:
+            joined += [tok["tok"].lower() for tok in sent["toks"]]
+    return joined
+
 
 def _nan_mean(arr):
-	arr = [x for x in arr if not np.isnan(x)]
-	if len(arr) > 0:
-		return np.mean(arr)
-	else:
-		return np.nan
+    arr = [x for x in arr if not np.isnan(x)]
+    if len(arr) > 0:
+        return np.mean(arr)
+    else:
+        return np.nan
+
 
 def _perplexity(test_text, train_text):
-	N_train, N_test = len(train_text), len(test_text)
-	if min(N_train, N_test) == 0: return np.nan
-	train_counts = Counter(train_text)
-	return sum(
-			-np.log(train_counts.get(tok, 1)/N_train) for tok in test_text
-		)/N_test
-
-def compute_divergences(cmp_tokens, ref_token_list, 
-			aux_input={'cmp_sample_size': 200, 'ref_sample_size': 1000,
-				'n_iters': 50}):
-	'''
-	computes the linguistic divergence between a text `cmp_tokens` and a set of reference texts `ref_token_list`. in particular, implements a sampling-based unigram perplexity score (where the sampling is done to ensure that we do not incur length-based effects)
-
-	this function takes in several parameters, through the `aux_input` argument:
-		* cmp_sample_size: the number of tokens to sample from the analyzed text `cmp_tokens`. the function returns `np.nan` if `cmp_tokens` doesn't have that many tokens.
-		* ref_sample_size: the nubmer of tokens to sample from each reference text. typically setting this to be longer than `cmp_tokens` makes sense, especially in the (typical) use case where language models are trained on longer texts. if none of the texts in `ref_token_list` pass this length threshold then the fucntion returns `np.nan`.
-		* n_iters: the number of times to compute divergence.
-
-	:param cmp_tokens: the text to compute divergence of (relative to texts in `ref_token_list`). is a list of tokens.
-	:param ref_token_list: the texts on which to train reference language models against which `cmp_tokens` is compared. each entry in the list is a list of tokens.
-	:param aux_input: additional parameters (see above)
-	:return: if texts are of sufficient length, returns a perplexity score, else returns `np.nan`
-	'''
-	if len(cmp_tokens) < aux_input['cmp_sample_size']:
-		return np.nan
-	ref_token_list = [toks for toks in ref_token_list if len(toks) >= aux_input['ref_sample_size']]
-	if len(ref_token_list) == 0: return np.nan
-	cmp_samples = np.random.choice(cmp_tokens, (aux_input['n_iters'], aux_input['cmp_sample_size']))
-	sample_idxes = np.random.randint(0, len(ref_token_list), size=(aux_input['n_iters']))
-	ref_samples = [np.random.choice(ref_token_list[idx], aux_input['ref_sample_size']) for idx 
-				  in sample_idxes]
-	return _nan_mean([_perplexity(cmp_sample, ref_sample) for cmp_sample, ref_sample 
-					 in zip(cmp_samples, ref_samples)])
+    N_train, N_test = len(train_text), len(test_text)
+    if min(N_train, N_test) == 0:
+        return np.nan
+    train_counts = Counter(train_text)
+    return sum(-np.log(train_counts.get(tok, 1) / N_train) for tok in test_text) / N_test
 
 
 class SpeakerConvoDiversity(Transformer):
-	'''
-	implements methodology to compute the linguistic divergence between a speaker's activity in each conversation in a corpus (i.e., the language of their utterances) and a reference language model trained over a different set of conversations/speakers.  See `SpeakerConvoDiversityWrapper` for more specific implementation which compares language used by individuals within fixed lifestages, and see the implementation of this wrapper for examples of calls to this transformer.
+    """
+    Implements methodology to compute the linguistic divergence between a speaker's activity in each conversation in a corpus (i.e., the language of their utterances) and a reference language model trained over a different set of conversations/speakers.  See `SpeakerConvoDiversityWrapper` for more specific implementation which compares language used by individuals within fixed lifestages, and see the implementation of this wrapper for examples of calls to this transformer.
 
-	The transformer assumes that a corpus has already been tokenized (via a call to `TextParser`).
+    The transformer assumes that a corpus has already been tokenized (via a call to `TextParser`).
 
-	In general, this is appropriate for cases when the reference language model you wish to compare against varies across different speaker/conversations; in contrast, if you wish to compare many conversations to a _single_ language model (e.g., one trained on past conversations) then this will be inefficient.
+    In general, this is appropriate for cases when the reference language model you wish to compare against varies across different speaker/conversations; in contrast, if you wish to compare many conversations to a _single_ language model (e.g., one trained on past conversations) then this will be inefficient.
 
-	This will produce attributes per speaker-conversation (i.e., the behavior of a speaker in a conversation); hence it takes as parameters functions which will subset the data at a speaker-conversation level. these functions operate on a table which has as columns:
-		* `speaker`: speaker ID
-		* `convo_id`: conversation ID
-		* `convo_idx`: n where this conversation is the nth that the speaker participated in
-		* `tokens`: all utterances the speaker contributed to the conversation, concatenated together as a single list of words
-		* any other speaker-conversation, speaker, or conversation-level metadata required to filter input and select reference language models per speaker-conversation (passed in via the `speaker_convo_cols`, `speaker_cols` and `convo_cols` parameters)
-	The table is the output of calling  `Corpus.get_full_attribute_table`; see documentation of that function for further reference.
-
-	The transformer supports two broad types of comparisons:
-		* if `groupby=[]`, then each text will be compared against a single reference text (specified by `select_fn`)
-		* if `groupby=[key]` then each text will be compared against a set of reference texts, where each reference text represents a different chunk of the data, aggregated by `key` (e.g., each text could be compared against the utterances contributed by different speakers, such that in each iteration of a divergence computation, the text is compared against just the utterances of a single speaker.)
-
-	:param cmp_select_fn: the subset of speaker-conversation entries to compute divergences for. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parametsr required; returns a boolean mask over the dataframe.
-	:param ref_select_fn: the subset of speaker-conversation entries to compute reference language models over. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
-	:param select_fn: function of the form fn(df,row, aux) where df is a data frame indexed by speaker-conversation, row is a row of a dataframe indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
-	:param divergence_fn: function to compute divergence between a speaker-conversation and reference texts. By default, the transformer will compute unigram perplexity scores, as implemented by the `compute_divergences` function. However, you can also specify your own divergence function (e.g., some sort of bigram divergence) using the same function signature.
-	:param speaker_convo_cols: additional speaker-convo attributes used as input to the selector functions
-	:param speaker_cols: additional speaker-level attributes
-	:param convo_cols: additional conversation-level attributes
-	:param groupby: whether to aggregate the reference texts according to the specified keys (leave empty to avoid aggregation).
-	:param aux_input: a dictionary of auxiliary input to the selector functions and the divergence computation
-	:param recompute_tokens: whether to reprocess tokens by aggregating all tokens across different utterances made by a speaker in a conversation. by default, will cache existing output.
-	:param verbosity: frequency of status messages.
-	'''
-
-	def __init__(self, output_field,
-			cmp_select_fn=lambda df, aux: np.ones(len(df)).astype(bool), 
-		  ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool), 
-		  select_fn=lambda df, row, aux: np.ones(len(df)).astype(bool),
-		  divergence_fn=compute_divergences,
-		  speaker_convo_cols=[], speaker_cols=[], convo_cols=[],
-		 groupby=[], aux_input={}, recompute_tokens=False, verbosity=0):
-
-		self.output_field = output_field
-		self.cmp_select_fn = cmp_select_fn
-		self.ref_select_fn = ref_select_fn
-		self.select_fn = select_fn
-		self.divergence_fn = divergence_fn
-		self.speaker_convo_cols = speaker_convo_cols
-		self.speaker_cols = speaker_cols
-		self.convo_cols = convo_cols
-		self.groupby = groupby
-		self.aux_input = aux_input
-		self.verbosity = verbosity
-
-		self.agg_tokens = SpeakerConvoAttrs('tokens',
-								 agg_fn=_join_all_tokens,
-								 recompute=recompute_tokens)
-
-
-	def transform(self, corpus):
-		if self.verbosity > 0:
-			print('joining tokens across conversation utterances')
-		corpus = self.agg_tokens.transform(corpus)
-		
-		speaker_convo_cols = list(set(self.speaker_convo_cols + ['tokens']))
-
-		input_table = corpus.get_full_attribute_table(
-				list(set(self.speaker_convo_cols + ['tokens'])),
-				self.speaker_cols, self.convo_cols
-			)
-		results = compute_speaker_convo_divergence(input_table, self.cmp_select_fn, self.ref_select_fn, self.select_fn, self.divergence_fn, self.groupby, self.aux_input, self.verbosity)
-		for entry in results:
-			corpus.set_speaker_convo_info(entry['speaker'],
-                                          entry['convo_id'], self.output_field, entry['divergence'])
-		return corpus
-
-
-
-
-def compute_speaker_convo_divergence(input_table, cmp_select_fn=lambda df, aux: np.ones(len(df)).astype(bool), 
-								  ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool), 
-								  select_fn=lambda df, row, aux: np.ones(len(df)).astype(bool),
-								  divergence_fn=compute_divergences,
-								 groupby=[], aux_input={}, verbosity=0):
-	'''
-		given a table of speaker-conversation entries, computes linguistic divergences between each speaker-conversation entry and reference text. See `SpeakerConvoDiversity` for further explanation of arguments.
-
-		The function operates on a table which has as columns:
-			* `speaker`: speaker ID
-			* `convo_id`: conversation ID
-			* `convo_idx`: n where this conversation is the nth that the speaker participated in
-			* `tokens`: all utterances the speaker contributed to the conversation, concatenated together as a single list of words
-			* any other speaker-conversation, speaker, or conversation-level metadata required to filter input and select reference language models per speaker-conversation.
-		
-		:param cmp_select_fn: the subset of speaker-conversation entries to compute divergences for. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parametsr required; returns a boolean mask over the dataframe.
-		:param ref_select_fn: the subset of speaker-conversation entries to compute reference language models over. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
-		:param select_fn: function of the form fn(df,row, aux) where df is a data frame indexed by speaker-conversation, row is a row of a dataframe indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
-		:param divergence_fn: function to compute divergence between a speaker-conversation and reference texts. By default, the transformer will compute unigram perplexity scores, as implemented by the `compute_divergences` function. However, you can also specify your own divergence function (e.g., some sort of bigram divergence) using the same function signature.
-		:param groupby: whether to aggregate the reference texts according to the specified keys (leave empty to avoid aggregation). 
-		:param aux_input: a dictionary of auxiliary input to the selector functions and the divergence computation
-		:param verbosity: frequency of status messages.
-	'''
-
-	cmp_subset = input_table[cmp_select_fn(input_table, aux_input)]
-	ref_subset = input_table[ref_select_fn(input_table, aux_input)]
-	entries = []
-	for idx, (_, row) in enumerate(cmp_subset.iterrows()):
-		if (verbosity > 0) and (idx % verbosity == 0) and (idx > 0):
-			print(idx, '/', len(cmp_subset))
-		
-		cmp_tokens = np.array(row.tokens)
-		
-		curr_ref_subset = ref_subset[select_fn(ref_subset, row, aux_input)]
-		
-		if len(groupby) == 0:
-			ref_tokens = [np.array(list(chain(*curr_ref_subset.tokens.values)))]
-		else:
-			curr_ref_subset = curr_ref_subset.groupby(groupby).tokens\
-				.agg(lambda x: list(chain(*x))).reset_index()
-			curr_ref_subset['tokens'] = curr_ref_subset.tokens.map(np.array)
-			ref_tokens = curr_ref_subset.tokens.values
-		
-		divergence = divergence_fn(cmp_tokens, ref_tokens, aux_input)
-		if not np.isnan(divergence):
-			entries.append({'speaker': row.speaker, 'convo_id': row.convo_id, 'divergence': divergence})
-	return entries
+    This will produce attributes per speaker-conversation (i.e., the behavior of a speaker in a conversation); hence it takes as parameters functions which will subset the data at a speaker-conversation level. these functions operate on a table which has as columns:
+      * `speaker`: speaker ID
+      * `convo_id`: conversation ID
+      * `convo_idx`: n where this conversation is the nth that the speaker participated in
+      * `tokens`: all utterances the speaker contributed to the conversation, concatenated together as a single list of words
+      * any other speaker-conversation, speaker, or conversation-level metadata required to filter input and select reference language models per speaker-conversation (passed in via the `speaker_convo_cols`, `speaker_cols` and `convo_cols` parameters)
+    The table is the output of calling  `Corpus.get_full_attribute_table`; see documentation of that function for further reference.
+
+    The transformer supports two broad types of comparisons:
+      * if `groupby=[]`, then each text will be compared against a single reference text (specified by `select_fn`)
+      * if `groupby=[key]` then each text will be compared against a set of reference texts, where each reference text represents a different chunk of the data, aggregated by `key` (e.g., each text could be compared against the utterances contributed by different speakers, such that in each iteration of a divergence computation, the text is compared against just the utterances of a single speaker.)
+
+    :param cmp_select_fn: the subset of speaker-conversation entries to compute divergences for. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parametsr required; returns a boolean mask over the dataframe.
+    :param ref_select_fn: the subset of speaker-conversation entries to compute reference language models over. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
+    :param select_fn: function of the form fn(df, row, aux) where df is a data frame indexed by speaker-conversation, row is a row of a dataframe indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
+    :param divergence_fn: function to compute divergence between a speaker-conversation and reference texts. By default, the transformer will compute unigram perplexity scores, as implemented by the `compute_divergences` function. However, you can also specify your own divergence function (e.g., some sort of bigram divergence) using the same function signature.
+    :param speaker_convo_cols: additional speaker-convo attributes used as input to the selector functions
+    :param speaker_cols: additional speaker-level attributes
+    :param convo_cols: additional conversation-level attributes
+    :param model_key_cols: list of attributes that is a subset of the attributes retrieved using `Corpus.get_full_attribute_table`. these attributes specify which speaker-convo entries correspond to the same reference text. `select_fn` should return the same boolean mask over the dataframe for speaker-convo entries which have the same values for all these attributes.
+    :param groupby: whether to aggregate the reference texts according to the specified keys (leave empty to avoid aggregation).
+    :param aux_input: a dictionary of auxiliary input to the selector functions and the divergence computation
+    :param recompute_tokens: whether to reprocess tokens by aggregating all tokens across different utterances made by a speaker in a conversation. by default, will cache existing output.
+    :param verbosity: frequency of status messages.
+    """
+
+    def __init__(
+        self,
+        output_field,
+        cmp_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+        ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+        select_fn=lambda df, row, aux: np.ones(len(df)).astype(bool),
+        speaker_convo_cols=[],
+        speaker_cols=[],
+        convo_cols=[],
+        model_key_cols=["speaker", "convo_id"],
+        groupby=[],
+        aux_input={},
+        recompute_tokens=False,
+        verbosity=0,
+    ):
+        self.output_field = output_field
+        self.surprise_attr_name = f"surprise_{output_field}"
+        self.cmp_select_fn = cmp_select_fn
+        self.ref_select_fn = ref_select_fn
+        self.select_fn = select_fn
+        self.speaker_convo_cols = speaker_convo_cols
+        self.speaker_cols = speaker_cols
+        self.convo_cols = convo_cols
+        self.model_key_cols = model_key_cols
+        self.groupby = groupby
+        self.aux_input = aux_input
+        self.verbosity = verbosity
+
+        self.agg_tokens = SpeakerConvoAttrs(
+            "tokens", agg_fn=_join_all_tokens, recompute=recompute_tokens
+        )
+
+        self.model_key_map = {}
+
+    def transform(self, corpus):
+        if self.verbosity > 0:
+            print("joining tokens across conversation utterances")
+        corpus = self.agg_tokens.transform(corpus)
+
+        speaker_convo_cols = list(set(self.speaker_convo_cols + ["tokens"]))
+
+        input_table = corpus.get_full_attribute_table(
+            list(set(self.speaker_convo_cols + ["tokens"])), self.speaker_cols, self.convo_cols
+        )
+
+        surprise_transformer = self._init_surprise(
+            lambda utt: self._get_model_key(utt, self.model_key_cols, input_table)
+        )
+        surprise_transformer.fit(
+            corpus, text_func=lambda utt: self._get_text_func(utt, input_table)
+        )
+        surprise_transformer.transform(
+            corpus,
+            "speaker",
+            target_text_func=lambda utt: self._get_utt_row(utt, input_table).tokens,
+        )
+        self._set_output(corpus, input_table)
+        return corpus
+
+    def _get_utt_row(self, utt: Utterance, df: pd.DataFrame):
+        """
+        Returns the row in `df` corresponding to `utt` using the speaker and conversation id of `utt`.
+        """
+        return df.loc[f"{utt.speaker.id}__{utt.conversation_id}"]
+
+    def _get_model_key(self, utt: Utterance, model_key_cols: List[str], df: pd.DataFrame):
+        """
+        Returns the model key used by `Surprise` that corresponds to `utt` and `model_key_cols`.
+        Finds the row in `df` corresponding to `utt` and creates a model key using the values for the attributes in `model_key_cols` in that row.
+        """
+        utt_row = self._get_utt_row(utt, df)
+        key = ".".join([str(utt_row[col]) for col in model_key_cols])
+        self.model_key_map[key] = (utt_row["speaker"], utt_row["convo_id"])
+        return key
+
+    def _init_surprise(self, model_key_selector):
+        """
+        Initializes an instance of the `Surprise` transformer with paramters corresponding to this instance of `SpeakerConvoDiversity`.
+        """
+        target_sample_size = (
+            self.aux_input["cmp_sample_size"] if "cmp_sample_size" in self.aux_input else 200
+        )
+        context_sample_size = (
+            self.aux_input["ref_sample_size"] if "ref_sample_size" in self.aux_input else 1000
+        )
+        n_samples = self.aux_input["n_iters"] if "n_iters" in self.aux_input else 50
+        return Surprise(
+            model_key_selector,
+            tokenizer=lambda x: x,
+            surprise_attr_name=self.surprise_attr_name,
+            target_sample_size=target_sample_size,
+            context_sample_size=context_sample_size,
+            n_samples=n_samples,
+            smooth=False,
+        )
+
+    def _get_text_func(self, utt: Utterance, df: pd.DataFrame):
+        """
+        Returns the reference text that should be to calculate speaker convo diversity for the speaker-convo group that `utt` belongs to.
+        """
+        utt_row = self._get_utt_row(utt, df)
+        ref_subset = df[self.ref_select_fn(df, self.aux_input)]
+        ref_subset = ref_subset[self.select_fn(ref_subset, utt_row, self.aux_input)]
+        if not self.groupby:
+            return [np.array(list(chain(*ref_subset.tokens.values)))]
+        ref_subset = (
+            ref_subset.groupby(self.groupby).tokens.agg(lambda x: list(chain(*x))).reset_index()
+        )
+        ref_subset["tokens"] = ref_subset.tokens.map(np.array)
+        return ref_subset.tokens.values
+
+    def _get_row(self, df, fields, vals):
+        """
+        Retrieves the row of `df` where each attribute `fields[i]` has the value `vals[i]`.
+        Assumes that there is exactly one row in `df` with fields equal to vals.
+        """
+        str_df = df.astype("str")
+        mask = np.ones(df.shape[0], dtype=bool)
+        for field, val in zip(fields, vals):
+            mask &= str_df[field] == val
+        return df[mask].iloc[0]
+
+    def _set_output(self, corpus, df):
+        """
+        Adds `self.output_field` to speaker convo info using scores returned by `Surprise` transformer.
+        """
+        entries = []
+        for speaker in tqdm(corpus.iter_speakers(), desc="set output"):
+            if self.surprise_attr_name in speaker.meta:
+                scores = speaker.meta[self.surprise_attr_name]
+                for key, score in scores.items():
+                    if np.isnan(score):
+                        continue
+                    speaker, convo_id = self.model_key_map[key]
+                    corpus.set_speaker_convo_info(speaker, convo_id, self.output_field, score)
 
 
 class SpeakerConvoDiversityWrapper(Transformer):
 
-	'''
-	Implements methodology for calculating linguistic diversity per life-stage. A wrapper around `SpeakerConvoDiversity`.
+    """
+    Implements methodology for calculating linguistic diversity per life-stage. A wrapper around `SpeakerConvoDiversity`.
 
-	Outputs the following (speaker, conversation) attributes:
-		* `div__self` (within-diversity)
-		* `div__other` (across-diversity)
-		* `div__adj` (relative diversity)
-
-	Note that `np.nan` is returned for (speaker, conversation) pairs with not enough text.
-
-	:param output_field: prefix of attributes to output, defaults to 'div'
-	:param lifestage_size: number of conversations per lifestage
-	:param max_exp: highest experience level (i.e., # convos taken) to compute diversity scores for.
-	:param sample_size: number of words to sample per convo
-	:param min_n_utterances: minimum number of utterances a speaker contributes per convo for that (speaker, convo) to get scored
-	:param n_iters: number of samples to take for perplexity scoring
-	:param cohort_delta: timespan between when speakers start for them to be counted as part of the same cohort. defaults to 2 months
-	:param verbosity: amount of output to print
-	'''
-	
-	def __init__(self, output_field='div', lifestage_size=20, max_exp=120,
-				sample_size=200, min_n_utterances=1, n_iters=50, cohort_delta=60*60*24*30*2, verbosity=100):
-		aux_input = {'n_iters': n_iters, 'cmp_sample_size': sample_size, 
-						  'ref_sample_size': (lifestage_size//2) * sample_size,
-						 'max_exp': max_exp, 'min_n_utterances': min_n_utterances,
-						 'cohort_delta': cohort_delta, 'lifestage_size': lifestage_size}
-		self.lifestage_transform = SpeakerConvoLifestage(lifestage_size)
-		self.output_field = output_field
-
-		# SpeakerConvoDiversity transformer to compute within-diversity
-		self.self_div = SpeakerConvoDiversity(output_field + '__self',
-			cmp_select_fn=lambda df, aux: (df.convo_idx < aux['max_exp']) & (df.n_convos__speaker >= aux['max_exp'])\
-				& (df.tokens.map(len) >= aux['cmp_sample_size']) & (df.n_utterances >= aux['min_n_utterances']),
-			ref_select_fn = lambda df, aux: np.ones(len(df)).astype(bool),
-			select_fn = lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)\
-				& (df.speaker == row.speaker) & (df.lifestage == row.lifestage),
-			speaker_convo_cols=['n_utterances','lifestage'], speaker_cols=['n_convos'],
-			divergence_fn=compute_divergences, groupby=[], aux_input=aux_input, verbosity=verbosity
-		 )
-
-		# SpeakerConvoDiversity transformer to compute across-diversity
-		self.other_div = SpeakerConvoDiversity(output_field + '__other',
-			cmp_select_fn=lambda df, aux: (df.convo_idx < aux['max_exp']) & (df.n_convos__speaker >= aux['max_exp'])\
-				& (df.tokens.map(len) >= aux['cmp_sample_size']) & (df.n_utterances >= aux['min_n_utterances']),
-			ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
-			select_fn = lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)\
-				& (df.speaker != row.speaker) & (df.lifestage == row.lifestage)\
-				& (df.n_convos__speaker >= (row.lifestage + 1) * aux['lifestage_size'])\
-				& (df.start_time__speaker.between(row.start_time__speaker - aux['cohort_delta'],
-											  row.start_time__speaker + aux['cohort_delta'])),
-			divergence_fn=compute_divergences,
-			speaker_convo_cols=['n_utterances', 'lifestage'], speaker_cols=['n_convos', 'start_time'],
-			groupby=['speaker', 'lifestage'], aux_input=aux_input, verbosity=verbosity
-		 )
-		self.verbosity = verbosity
-		
-	def transform(self, corpus):
-		if self.verbosity > 0:
-			print('getting lifestages')
-		corpus = self.lifestage_transform.transform(corpus)
-		if self.verbosity > 0:
-			print('getting within diversity')
-		corpus = self.self_div.transform(corpus)
-		if self.verbosity > 0:
-			print('getting across diversity')
-		corpus = self.other_div.transform(corpus)
-		if self.verbosity > 0:
-			print('getting relative diversity')
-		div_table = corpus.get_full_attribute_table([self.output_field + '__self', 
-													 self.output_field + '__other'])
-		div_table = div_table[div_table[self.output_field + '__self'].notnull() | div_table[self.output_field + '__other'].notnull()]
-		div_table[self.output_field + '__adj'] = div_table[self.output_field + '__other'] \
-			- div_table[self.output_field + '__self']
-		for idx, (_, row) in enumerate(div_table.iterrows()):
-			if (idx > 0) and (self.verbosity > 0) and (idx % self.verbosity == 0):
-				print(idx, '/', len(div_table))
-			if not np.isnan(row[self.output_field + '__adj']):
-				corpus.set_speaker_convo_info(row.speaker, row.convo_id, self.output_field + '__adj',
-                                              row[self.output_field + '__adj'])
-		return corpus
-		
+    Outputs the following (speaker, conversation) attributes:
+      * `div__self` (within-diversity)
+      * `div__other` (across-diversity)
+      * `div__adj` (relative diversity)
+
+    Note that `np.nan` is returned for (speaker, conversation) pairs with not enough text.
+
+    :param output_field: prefix of attributes to output, defaults to 'div'
+    :param lifestage_size: number of conversations per lifestage
+    :param max_exp: highest experience level (i.e., # convos taken) to compute diversity scores for.
+    :param sample_size: number of words to sample per convo
+    :param min_n_utterances: minimum number of utterances a speaker contributes per convo for that (speaker, convo) to get scored
+    :param n_iters: number of samples to take for perplexity scoring
+    :param cohort_delta: timespan between when speakers start for them to be counted as part of the same cohort. defaults to 2 months
+    :param verbosity: amount of output to print
+    """
+
+    def __init__(
+        self,
+        output_field="div",
+        lifestage_size=20,
+        max_exp=120,
+        sample_size=200,
+        min_n_utterances=1,
+        n_iters=50,
+        cohort_delta=60 * 60 * 24 * 30 * 2,
+        verbosity=100,
+    ):
+        aux_input = {
+            "n_iters": n_iters,
+            "cmp_sample_size": sample_size,
+            "ref_sample_size": (lifestage_size // 2) * sample_size,
+            "max_exp": max_exp,
+            "min_n_utterances": min_n_utterances,
+            "cohort_delta": cohort_delta,
+            "lifestage_size": lifestage_size,
+        }
+        self.lifestage_transform = SpeakerConvoLifestage(lifestage_size)
+        self.output_field = output_field
+
+        # SpeakerConvoDiversity transformer to compute within-diversity
+        self.self_div = SpeakerConvoDiversity(
+            output_field + "__self",
+            cmp_select_fn=lambda df, aux: (df.convo_idx < aux["max_exp"])
+            & (df.n_convos__speaker >= aux["max_exp"])
+            & (df.tokens.map(len) >= aux["cmp_sample_size"])
+            & (df.n_utterances >= aux["min_n_utterances"]),
+            ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+            select_fn=lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)
+            & (df.speaker == row.speaker)
+            & (df.lifestage == row.lifestage),
+            speaker_convo_cols=["n_utterances", "lifestage"],
+            speaker_cols=["n_convos"],
+            model_key_cols=["convo_idx", "speaker", "lifestage"],
+            groupby=[],
+            aux_input=aux_input,
+            verbosity=verbosity,
+        )
+
+        # SpeakerConvoDiversity transformer to compute across-diversity
+        self.other_div = SpeakerConvoDiversity(
+            output_field + "__other",
+            cmp_select_fn=lambda df, aux: (df.convo_idx < aux["max_exp"])
+            & (df.n_convos__speaker >= aux["max_exp"])
+            & (df.tokens.map(len) >= aux["cmp_sample_size"])
+            & (df.n_utterances >= aux["min_n_utterances"]),
+            ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+            select_fn=lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)
+            & (df.speaker != row.speaker)
+            & (df.lifestage == row.lifestage)
+            & (df.n_convos__speaker >= (row.lifestage + 1) * aux["lifestage_size"])
+            & (
+                df.start_time__speaker.between(
+                    row.start_time__speaker - aux["cohort_delta"],
+                    row.start_time__speaker + aux["cohort_delta"],
+                )
+            ),
+            speaker_convo_cols=["n_utterances", "lifestage"],
+            speaker_cols=["n_convos", "start_time"],
+            model_key_cols=["convo_idx", "speaker", "lifestage"],
+            groupby=["speaker", "lifestage"],
+            aux_input=aux_input,
+            verbosity=verbosity,
+        )
+        self.verbosity = verbosity
+
+    def transform(self, corpus):
+        if self.verbosity > 0:
+            print("getting lifestages")
+        corpus = self.lifestage_transform.transform(corpus)
+        if self.verbosity > 0:
+            print("getting within diversity")
+        corpus = self.self_div.transform(corpus)
+        if self.verbosity > 0:
+            print("getting across diversity")
+        corpus = self.other_div.transform(corpus)
+        if self.verbosity > 0:
+            print("getting relative diversity")
+        div_table = corpus.get_full_attribute_table(
+            [self.output_field + "__self", self.output_field + "__other"]
+        )
+        div_table = div_table[
+            div_table[self.output_field + "__self"].notnull()
+            | div_table[self.output_field + "__other"].notnull()
+        ]
+        div_table[self.output_field + "__adj"] = (
+            div_table[self.output_field + "__other"] - div_table[self.output_field + "__self"]
+        )
+        for idx, (_, row) in enumerate(div_table.iterrows()):
+            if (idx > 0) and (self.verbosity > 0) and (idx % self.verbosity == 0):
+                print(idx, "/", len(div_table))
+            if not np.isnan(row[self.output_field + "__adj"]):
+                corpus.set_speaker_convo_info(
+                    row.speaker,
+                    row.convo_id,
+                    self.output_field + "__adj",
+                    row[self.output_field + "__adj"],
+                )
+        return corpus
```

### Comparing `convokit-2.5.3/convokit/speakerConvoDiversity/speakerConvoDiversity2.py` & `convokit-3.0.0/convokit/speakerConvoDiversity/speakerConvoDiversity.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,272 +1,340 @@
 import numpy as np
-import pandas as pd
 from convokit.transformer import Transformer
 from convokit.speaker_convo_helpers.speaker_convo_attrs import SpeakerConvoAttrs
 from itertools import chain
 from collections import Counter
 from convokit.speaker_convo_helpers.speaker_convo_lifestage import SpeakerConvoLifestage
-from convokit import Utterance
-from convokit.surprise import Surprise
-from sklearn.feature_extraction.text import CountVectorizer
-from tqdm import tqdm
-from typing import List
 
 
 def _join_all_tokens(parses):
-  joined = []
-  for parse in parses:
-    for sent in parse:
-      joined += [tok['tok'].lower() for tok in sent['toks']]
-  return joined
+    joined = []
+    for parse in parses:
+        for sent in parse:
+            joined += [tok["tok"].lower() for tok in sent["toks"]]
+    return joined
 
 
 def _nan_mean(arr):
-  arr = [x for x in arr if not np.isnan(x)]
-  if len(arr) > 0:
-    return np.mean(arr)
-  else:
-    return np.nan
+    arr = [x for x in arr if not np.isnan(x)]
+    if len(arr) > 0:
+        return np.mean(arr)
+    else:
+        return np.nan
 
 
 def _perplexity(test_text, train_text):
-  N_train, N_test = len(train_text), len(test_text)
-  if min(N_train, N_test) == 0: return np.nan
-  train_counts = Counter(train_text)
-  return sum(
-      -np.log(train_counts.get(tok, 1)/N_train) for tok in test_text
-    )/N_test
+    N_train, N_test = len(train_text), len(test_text)
+    if min(N_train, N_test) == 0:
+        return np.nan
+    train_counts = Counter(train_text)
+    return sum(-np.log(train_counts.get(tok, 1) / N_train) for tok in test_text) / N_test
+
+
+def compute_divergences(
+    cmp_tokens,
+    ref_token_list,
+    aux_input={"cmp_sample_size": 200, "ref_sample_size": 1000, "n_iters": 50},
+):
+    """
+    computes the linguistic divergence between a text `cmp_tokens` and a set of reference texts `ref_token_list`. in particular, implements a sampling-based unigram perplexity score (where the sampling is done to ensure that we do not incur length-based effects)
+
+    this function takes in several parameters, through the `aux_input` argument:
+            * cmp_sample_size: the number of tokens to sample from the analyzed text `cmp_tokens`. the function returns `np.nan` if `cmp_tokens` doesn't have that many tokens.
+            * ref_sample_size: the nubmer of tokens to sample from each reference text. typically setting this to be longer than `cmp_tokens` makes sense, especially in the (typical) use case where language models are trained on longer texts. if none of the texts in `ref_token_list` pass this length threshold then the fucntion returns `np.nan`.
+            * n_iters: the number of times to compute divergence.
+
+    :param cmp_tokens: the text to compute divergence of (relative to texts in `ref_token_list`). is a list of tokens.
+    :param ref_token_list: the texts on which to train reference language models against which `cmp_tokens` is compared. each entry in the list is a list of tokens.
+    :param aux_input: additional parameters (see above)
+    :return: if texts are of sufficient length, returns a perplexity score, else returns `np.nan`
+    """
+    if len(cmp_tokens) < aux_input["cmp_sample_size"]:
+        return np.nan
+    ref_token_list = [toks for toks in ref_token_list if len(toks) >= aux_input["ref_sample_size"]]
+    if len(ref_token_list) == 0:
+        return np.nan
+    cmp_samples = np.random.choice(cmp_tokens, (aux_input["n_iters"], aux_input["cmp_sample_size"]))
+    sample_idxes = np.random.randint(0, len(ref_token_list), size=(aux_input["n_iters"]))
+    ref_samples = [
+        np.random.choice(ref_token_list[idx], aux_input["ref_sample_size"]) for idx in sample_idxes
+    ]
+    return _nan_mean(
+        [
+            _perplexity(cmp_sample, ref_sample)
+            for cmp_sample, ref_sample in zip(cmp_samples, ref_samples)
+        ]
+    )
 
 
 class SpeakerConvoDiversity(Transformer):
-  '''
-  Implements methodology to compute the linguistic divergence between a speaker's activity in each conversation in a corpus (i.e., the language of their utterances) and a reference language model trained over a different set of conversations/speakers.  See `SpeakerConvoDiversityWrapper` for more specific implementation which compares language used by individuals within fixed lifestages, and see the implementation of this wrapper for examples of calls to this transformer.
-
-  The transformer assumes that a corpus has already been tokenized (via a call to `TextParser`).
-
-  In general, this is appropriate for cases when the reference language model you wish to compare against varies across different speaker/conversations; in contrast, if you wish to compare many conversations to a _single_ language model (e.g., one trained on past conversations) then this will be inefficient.
-
-  This will produce attributes per speaker-conversation (i.e., the behavior of a speaker in a conversation); hence it takes as parameters functions which will subset the data at a speaker-conversation level. these functions operate on a table which has as columns:
-    * `speaker`: speaker ID
-    * `convo_id`: conversation ID
-    * `convo_idx`: n where this conversation is the nth that the speaker participated in
-    * `tokens`: all utterances the speaker contributed to the conversation, concatenated together as a single list of words
-    * any other speaker-conversation, speaker, or conversation-level metadata required to filter input and select reference language models per speaker-conversation (passed in via the `speaker_convo_cols`, `speaker_cols` and `convo_cols` parameters)
-  The table is the output of calling  `Corpus.get_full_attribute_table`; see documentation of that function for further reference.
-
-  The transformer supports two broad types of comparisons:
-    * if `groupby=[]`, then each text will be compared against a single reference text (specified by `select_fn`)
-    * if `groupby=[key]` then each text will be compared against a set of reference texts, where each reference text represents a different chunk of the data, aggregated by `key` (e.g., each text could be compared against the utterances contributed by different speakers, such that in each iteration of a divergence computation, the text is compared against just the utterances of a single speaker.)
-
-  :param cmp_select_fn: the subset of speaker-conversation entries to compute divergences for. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parametsr required; returns a boolean mask over the dataframe.
-  :param ref_select_fn: the subset of speaker-conversation entries to compute reference language models over. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
-  :param select_fn: function of the form fn(df, row, aux) where df is a data frame indexed by speaker-conversation, row is a row of a dataframe indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
-  :param divergence_fn: function to compute divergence between a speaker-conversation and reference texts. By default, the transformer will compute unigram perplexity scores, as implemented by the `compute_divergences` function. However, you can also specify your own divergence function (e.g., some sort of bigram divergence) using the same function signature.
-  :param speaker_convo_cols: additional speaker-convo attributes used as input to the selector functions
-  :param speaker_cols: additional speaker-level attributes
-  :param convo_cols: additional conversation-level attributes
-  :param model_key_cols: list of attributes that is a subset of the attributes retrieved using `Corpus.get_full_attribute_table`. these attributes specify which speaker-convo entries correspond to the same reference text. `select_fn` should return the same boolean mask over the dataframe for speaker-convo entries which have the same values for all these attributes.
-  :param groupby: whether to aggregate the reference texts according to the specified keys (leave empty to avoid aggregation).
-  :param aux_input: a dictionary of auxiliary input to the selector functions and the divergence computation
-  :param recompute_tokens: whether to reprocess tokens by aggregating all tokens across different utterances made by a speaker in a conversation. by default, will cache existing output.
-  :param verbosity: frequency of status messages.
-  '''
-
-  def __init__(self, output_field,
-      cmp_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
-      ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
-      select_fn=lambda df, row, aux: np.ones(len(df)).astype(bool),
-      speaker_convo_cols=[], speaker_cols=[], convo_cols=[], model_key_cols=['speaker', 'convo_id'],
-     groupby=[], aux_input={}, recompute_tokens=False, verbosity=0):
-
-    self.output_field = output_field
-    self.surprise_attr_name = f"surprise_{output_field}"
-    self.cmp_select_fn = cmp_select_fn
-    self.ref_select_fn = ref_select_fn
-    self.select_fn = select_fn
-    self.speaker_convo_cols = speaker_convo_cols
-    self.speaker_cols = speaker_cols
-    self.convo_cols = convo_cols
-    self.model_key_cols = model_key_cols
-    self.groupby = groupby
-    self.aux_input = aux_input
-    self.verbosity = verbosity
-
-    self.agg_tokens = SpeakerConvoAttrs('tokens',
-                 agg_fn=_join_all_tokens,
-                 recompute=recompute_tokens)
-    
-    self.model_key_map = {}
-
-
-  def transform(self, corpus):
-    if self.verbosity > 0:
-      print('joining tokens across conversation utterances')
-    corpus = self.agg_tokens.transform(corpus)
-    
-    speaker_convo_cols = list(set(self.speaker_convo_cols + ['tokens']))
-
-    input_table = corpus.get_full_attribute_table(
-        list(set(self.speaker_convo_cols + ['tokens'])),
-        self.speaker_cols, self.convo_cols
-      )
-
-    surprise_transformer = self._init_surprise(lambda utt: self._get_model_key(utt, self.model_key_cols, input_table))
-    surprise_transformer.fit(corpus, text_func=lambda utt: self._get_text_func(utt, input_table))
-    surprise_transformer.transform(corpus, 'speaker', target_text_func=lambda utt: self._get_utt_row(utt, input_table).tokens)
-    self._set_output(corpus, input_table)
-    return corpus
-
-
-  def _get_utt_row(self, utt: Utterance, df: pd.DataFrame):
-    """
-    Returns the row in `df` corresponding to `utt` using the speaker and conversation id of `utt`.
-    """
-    return df.loc[f'{utt.speaker.id}__{utt.conversation_id}']
-
-
-  def _get_model_key(self, utt: Utterance, model_key_cols: List[str], df: pd.DataFrame):
-    """
-    Returns the model key used by `Surprise` that corresponds to `utt` and `model_key_cols`. 
-    Finds the row in `df` corresponding to `utt` and creates a model key using the values for the attributes in `model_key_cols` in that row.
     """
-    utt_row = self._get_utt_row(utt, df)
-    key = '.'.join([str(utt_row[col]) for col in model_key_cols])
-    self.model_key_map[key] = (utt_row['speaker'], utt_row['convo_id'])
-    return key
-  
-
-  def _init_surprise(self, model_key_selector):
-    """
-    Initializes an instance of the `Surprise` transformer with paramters corresponding to this instance of `SpeakerConvoDiversity`.
-    """
-    target_sample_size = self.aux_input['cmp_sample_size'] if 'cmp_sample_size' in self.aux_input else 200
-    context_sample_size = self.aux_input['ref_sample_size']  if 'ref_sample_size' in self.aux_input else 1000
-    n_samples = self.aux_input['n_iters'] if 'n_iters' in self.aux_input else 50
-    return Surprise(model_key_selector, tokenizer=lambda x: x, surprise_attr_name=self.surprise_attr_name, target_sample_size=target_sample_size, context_sample_size=context_sample_size, n_samples=n_samples, smooth=False)
+    implements methodology to compute the linguistic divergence between a speaker's activity in each conversation in a corpus (i.e., the language of their utterances) and a reference language model trained over a different set of conversations/speakers.  See `SpeakerConvoDiversityWrapper` for more specific implementation which compares language used by individuals within fixed lifestages, and see the implementation of this wrapper for examples of calls to this transformer.
 
+    The transformer assumes that a corpus has already been tokenized (via a call to `TextParser`).
 
-  def _get_text_func(self, utt: Utterance, df: pd.DataFrame):
-    """
-    Returns the reference text that should be to calculate speaker convo diversity for the speaker-convo group that `utt` belongs to. 
-    """
-    utt_row = self._get_utt_row(utt, df)
-    ref_subset = df[self.ref_select_fn(df, self.aux_input)]
-    ref_subset = ref_subset[self.select_fn(ref_subset, utt_row, self.aux_input)]
-    if not self.groupby:
-      return [np.array(list(chain(*ref_subset.tokens.values)))]
-    ref_subset = ref_subset.groupby(self.groupby).tokens.agg(lambda x: list(chain(*x))).reset_index()
-    ref_subset['tokens'] = ref_subset.tokens.map(np.array)
-    return ref_subset.tokens.values
+    In general, this is appropriate for cases when the reference language model you wish to compare against varies across different speaker/conversations; in contrast, if you wish to compare many conversations to a _single_ language model (e.g., one trained on past conversations) then this will be inefficient.
 
-  
-  def _get_row(self, df, fields, vals):
+    This will produce attributes per speaker-conversation (i.e., the behavior of a speaker in a conversation); hence it takes as parameters functions which will subset the data at a speaker-conversation level. these functions operate on a table which has as columns:
+            * `speaker`: speaker ID
+            * `convo_id`: conversation ID
+            * `convo_idx`: n where this conversation is the nth that the speaker participated in
+            * `tokens`: all utterances the speaker contributed to the conversation, concatenated together as a single list of words
+            * any other speaker-conversation, speaker, or conversation-level metadata required to filter input and select reference language models per speaker-conversation (passed in via the `speaker_convo_cols`, `speaker_cols` and `convo_cols` parameters)
+    The table is the output of calling  `Corpus.get_full_attribute_table`; see documentation of that function for further reference.
+
+    The transformer supports two broad types of comparisons:
+            * if `groupby=[]`, then each text will be compared against a single reference text (specified by `select_fn`)
+            * if `groupby=[key]` then each text will be compared against a set of reference texts, where each reference text represents a different chunk of the data, aggregated by `key` (e.g., each text could be compared against the utterances contributed by different speakers, such that in each iteration of a divergence computation, the text is compared against just the utterances of a single speaker.)
+
+    :param cmp_select_fn: the subset of speaker-conversation entries to compute divergences for. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parametsr required; returns a boolean mask over the dataframe.
+    :param ref_select_fn: the subset of speaker-conversation entries to compute reference language models over. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
+    :param select_fn: function of the form fn(df,row, aux) where df is a data frame indexed by speaker-conversation, row is a row of a dataframe indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
+    :param divergence_fn: function to compute divergence between a speaker-conversation and reference texts. By default, the transformer will compute unigram perplexity scores, as implemented by the `compute_divergences` function. However, you can also specify your own divergence function (e.g., some sort of bigram divergence) using the same function signature.
+    :param speaker_convo_cols: additional speaker-convo attributes used as input to the selector functions
+    :param speaker_cols: additional speaker-level attributes
+    :param convo_cols: additional conversation-level attributes
+    :param groupby: whether to aggregate the reference texts according to the specified keys (leave empty to avoid aggregation).
+    :param aux_input: a dictionary of auxiliary input to the selector functions and the divergence computation
+    :param recompute_tokens: whether to reprocess tokens by aggregating all tokens across different utterances made by a speaker in a conversation. by default, will cache existing output.
+    :param verbosity: frequency of status messages.
+    """
+
+    def __init__(
+        self,
+        output_field,
+        cmp_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+        ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+        select_fn=lambda df, row, aux: np.ones(len(df)).astype(bool),
+        divergence_fn=compute_divergences,
+        speaker_convo_cols=[],
+        speaker_cols=[],
+        convo_cols=[],
+        groupby=[],
+        aux_input={},
+        recompute_tokens=False,
+        verbosity=0,
+    ):
+        self.output_field = output_field
+        self.cmp_select_fn = cmp_select_fn
+        self.ref_select_fn = ref_select_fn
+        self.select_fn = select_fn
+        self.divergence_fn = divergence_fn
+        self.speaker_convo_cols = speaker_convo_cols
+        self.speaker_cols = speaker_cols
+        self.convo_cols = convo_cols
+        self.groupby = groupby
+        self.aux_input = aux_input
+        self.verbosity = verbosity
+
+        self.agg_tokens = SpeakerConvoAttrs(
+            "tokens", agg_fn=_join_all_tokens, recompute=recompute_tokens
+        )
+
+    def transform(self, corpus):
+        if self.verbosity > 0:
+            print("joining tokens across conversation utterances")
+        corpus = self.agg_tokens.transform(corpus)
+
+        speaker_convo_cols = list(set(self.speaker_convo_cols + ["tokens"]))
+
+        input_table = corpus.get_full_attribute_table(
+            list(set(self.speaker_convo_cols + ["tokens"])), self.speaker_cols, self.convo_cols
+        )
+        results = compute_speaker_convo_divergence(
+            input_table,
+            self.cmp_select_fn,
+            self.ref_select_fn,
+            self.select_fn,
+            self.divergence_fn,
+            self.groupby,
+            self.aux_input,
+            self.verbosity,
+        )
+        for entry in results:
+            corpus.set_speaker_convo_info(
+                entry["speaker"], entry["convo_id"], self.output_field, entry["divergence"]
+            )
+        return corpus
+
+
+def compute_speaker_convo_divergence(
+    input_table,
+    cmp_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+    ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+    select_fn=lambda df, row, aux: np.ones(len(df)).astype(bool),
+    divergence_fn=compute_divergences,
+    groupby=[],
+    aux_input={},
+    verbosity=0,
+):
+    """
+    given a table of speaker-conversation entries, computes linguistic divergences between each speaker-conversation entry and reference text. See `SpeakerConvoDiversity` for further explanation of arguments.
+
+    The function operates on a table which has as columns:
+            * `speaker`: speaker ID
+            * `convo_id`: conversation ID
+            * `convo_idx`: n where this conversation is the nth that the speaker participated in
+            * `tokens`: all utterances the speaker contributed to the conversation, concatenated together as a single list of words
+            * any other speaker-conversation, speaker, or conversation-level metadata required to filter input and select reference language models per speaker-conversation.
+
+    :param cmp_select_fn: the subset of speaker-conversation entries to compute divergences for. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parametsr required; returns a boolean mask over the dataframe.
+    :param ref_select_fn: the subset of speaker-conversation entries to compute reference language models over. function of the form fn(df, aux) where df is a data frame indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
+    :param select_fn: function of the form fn(df,row, aux) where df is a data frame indexed by speaker-conversation, row is a row of a dataframe indexed by speaker-conversation, and aux is any auxiliary parameters required; returns a boolean mask over the dataframe.
+    :param divergence_fn: function to compute divergence between a speaker-conversation and reference texts. By default, the transformer will compute unigram perplexity scores, as implemented by the `compute_divergences` function. However, you can also specify your own divergence function (e.g., some sort of bigram divergence) using the same function signature.
+    :param groupby: whether to aggregate the reference texts according to the specified keys (leave empty to avoid aggregation).
+    :param aux_input: a dictionary of auxiliary input to the selector functions and the divergence computation
+    :param verbosity: frequency of status messages.
     """
-    Retrieves the row of `df` where each attribute `fields[i]` has the value `vals[i]`.
-    Assumes that there is exactly one row in `df` with fields equal to vals.
-    """
-    str_df = df.astype('str')
-    mask = np.ones(df.shape[0], dtype=bool)
-    for field, val in zip(fields, vals):
-      mask &= (str_df[field] == val)
-    return df[mask].iloc[0]
-
 
-  def _set_output(self, corpus, df):
-    """
-    Adds `self.output_field` to speaker convo info using scores returned by `Surprise` transformer.
-    """
+    cmp_subset = input_table[cmp_select_fn(input_table, aux_input)]
+    ref_subset = input_table[ref_select_fn(input_table, aux_input)]
     entries = []
-    for speaker in tqdm(corpus.iter_speakers(), desc='set output'):
-      if self.surprise_attr_name in speaker.meta:
-        scores = speaker.meta[self.surprise_attr_name]
-        for key, score in scores.items():
-          if np.isnan(score):
-            continue
-          speaker, convo_id = self.model_key_map[key]
-          corpus.set_speaker_convo_info(speaker, convo_id, self.output_field, score)
+    for idx, (_, row) in enumerate(cmp_subset.iterrows()):
+        if (verbosity > 0) and (idx % verbosity == 0) and (idx > 0):
+            print(idx, "/", len(cmp_subset))
+
+        cmp_tokens = np.array(row.tokens)
+
+        curr_ref_subset = ref_subset[select_fn(ref_subset, row, aux_input)]
+
+        if len(groupby) == 0:
+            ref_tokens = [np.array(list(chain(*curr_ref_subset.tokens.values)))]
+        else:
+            curr_ref_subset = (
+                curr_ref_subset.groupby(groupby).tokens.agg(lambda x: list(chain(*x))).reset_index()
+            )
+            curr_ref_subset["tokens"] = curr_ref_subset.tokens.map(np.array)
+            ref_tokens = curr_ref_subset.tokens.values
+
+        divergence = divergence_fn(cmp_tokens, ref_tokens, aux_input)
+        if not np.isnan(divergence):
+            entries.append(
+                {"speaker": row.speaker, "convo_id": row.convo_id, "divergence": divergence}
+            )
+    return entries
 
 
 class SpeakerConvoDiversityWrapper(Transformer):
 
-  '''
-  Implements methodology for calculating linguistic diversity per life-stage. A wrapper around `SpeakerConvoDiversity`.
+    """
+    Implements methodology for calculating linguistic diversity per life-stage. A wrapper around `SpeakerConvoDiversity`.
 
-  Outputs the following (speaker, conversation) attributes:
-    * `div__self` (within-diversity)
-    * `div__other` (across-diversity)
-    * `div__adj` (relative diversity)
-
-  Note that `np.nan` is returned for (speaker, conversation) pairs with not enough text.
-
-  :param output_field: prefix of attributes to output, defaults to 'div'
-  :param lifestage_size: number of conversations per lifestage
-  :param max_exp: highest experience level (i.e., # convos taken) to compute diversity scores for.
-  :param sample_size: number of words to sample per convo
-  :param min_n_utterances: minimum number of utterances a speaker contributes per convo for that (speaker, convo) to get scored
-  :param n_iters: number of samples to take for perplexity scoring
-  :param cohort_delta: timespan between when speakers start for them to be counted as part of the same cohort. defaults to 2 months
-  :param verbosity: amount of output to print
-  '''
-  
-  def __init__(self, output_field='div', lifestage_size=20, max_exp=120,
-        sample_size=200, min_n_utterances=1, n_iters=50, cohort_delta=60*60*24*30*2, verbosity=100):
-    aux_input = {'n_iters': n_iters, 'cmp_sample_size': sample_size, 
-              'ref_sample_size': (lifestage_size//2) * sample_size,
-             'max_exp': max_exp, 'min_n_utterances': min_n_utterances,
-             'cohort_delta': cohort_delta, 'lifestage_size': lifestage_size}
-    self.lifestage_transform = SpeakerConvoLifestage(lifestage_size)
-    self.output_field = output_field
-
-    # SpeakerConvoDiversity transformer to compute within-diversity
-    self.self_div = SpeakerConvoDiversity(output_field + '__self',
-      cmp_select_fn=lambda df, aux: (df.convo_idx < aux['max_exp']) & (df.n_convos__speaker >= aux['max_exp'])\
-        & (df.tokens.map(len) >= aux['cmp_sample_size']) & (df.n_utterances >= aux['min_n_utterances']),
-      ref_select_fn = lambda df, aux: np.ones(len(df)).astype(bool),
-      select_fn = lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)\
-        & (df.speaker == row.speaker) & (df.lifestage == row.lifestage),
-      speaker_convo_cols=['n_utterances','lifestage'], speaker_cols=['n_convos'],
-      model_key_cols=['convo_idx', 'speaker', 'lifestage'],
-      groupby=[], aux_input=aux_input, verbosity=verbosity
-     )
-
-    # SpeakerConvoDiversity transformer to compute across-diversity
-    self.other_div = SpeakerConvoDiversity(output_field + '__other',
-      cmp_select_fn=lambda df, aux: (df.convo_idx < aux['max_exp']) & (df.n_convos__speaker >= aux['max_exp'])\
-        & (df.tokens.map(len) >= aux['cmp_sample_size']) & (df.n_utterances >= aux['min_n_utterances']),
-      ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
-      select_fn = lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)\
-        & (df.speaker != row.speaker) & (df.lifestage == row.lifestage)\
-        & (df.n_convos__speaker >= (row.lifestage + 1) * aux['lifestage_size'])\
-        & (df.start_time__speaker.between(row.start_time__speaker - aux['cohort_delta'],
-                        row.start_time__speaker + aux['cohort_delta'])),
-      speaker_convo_cols=['n_utterances', 'lifestage'], speaker_cols=['n_convos', 'start_time'],
-      model_key_cols=['convo_idx', 'speaker', 'lifestage'],
-      groupby=['speaker', 'lifestage'], aux_input=aux_input, verbosity=verbosity
-     )
-    self.verbosity = verbosity
-    
-  def transform(self, corpus):
-    if self.verbosity > 0:
-      print('getting lifestages')
-    corpus = self.lifestage_transform.transform(corpus)
-    if self.verbosity > 0:
-      print('getting within diversity')
-    corpus = self.self_div.transform(corpus)
-    if self.verbosity > 0:
-      print('getting across diversity')
-    corpus = self.other_div.transform(corpus)
-    if self.verbosity > 0:
-      print('getting relative diversity')
-    div_table = corpus.get_full_attribute_table([self.output_field + '__self', 
-                           self.output_field + '__other'])
-    div_table = div_table[div_table[self.output_field + '__self'].notnull() | div_table[self.output_field + '__other'].notnull()]
-    div_table[self.output_field + '__adj'] = div_table[self.output_field + '__other'] \
-      - div_table[self.output_field + '__self']
-    for idx, (_, row) in enumerate(div_table.iterrows()):
-      if (idx > 0) and (self.verbosity > 0) and (idx % self.verbosity == 0):
-        print(idx, '/', len(div_table))
-      if not np.isnan(row[self.output_field + '__adj']):
-        corpus.set_speaker_convo_info(row.speaker, row.convo_id, self.output_field + '__adj',
-                                              row[self.output_field + '__adj'])
-    return corpus
-    
+    Outputs the following (speaker, conversation) attributes:
+            * `div__self` (within-diversity)
+            * `div__other` (across-diversity)
+            * `div__adj` (relative diversity)
+
+    Note that `np.nan` is returned for (speaker, conversation) pairs with not enough text.
+
+    :param output_field: prefix of attributes to output, defaults to 'div'
+    :param lifestage_size: number of conversations per lifestage
+    :param max_exp: highest experience level (i.e., # convos taken) to compute diversity scores for.
+    :param sample_size: number of words to sample per convo
+    :param min_n_utterances: minimum number of utterances a speaker contributes per convo for that (speaker, convo) to get scored
+    :param n_iters: number of samples to take for perplexity scoring
+    :param cohort_delta: timespan between when speakers start for them to be counted as part of the same cohort. defaults to 2 months
+    :param verbosity: amount of output to print
+    """
+
+    def __init__(
+        self,
+        output_field="div",
+        lifestage_size=20,
+        max_exp=120,
+        sample_size=200,
+        min_n_utterances=1,
+        n_iters=50,
+        cohort_delta=60 * 60 * 24 * 30 * 2,
+        verbosity=100,
+    ):
+        aux_input = {
+            "n_iters": n_iters,
+            "cmp_sample_size": sample_size,
+            "ref_sample_size": (lifestage_size // 2) * sample_size,
+            "max_exp": max_exp,
+            "min_n_utterances": min_n_utterances,
+            "cohort_delta": cohort_delta,
+            "lifestage_size": lifestage_size,
+        }
+        self.lifestage_transform = SpeakerConvoLifestage(lifestage_size)
+        self.output_field = output_field
+
+        # SpeakerConvoDiversity transformer to compute within-diversity
+        self.self_div = SpeakerConvoDiversity(
+            output_field + "__self",
+            cmp_select_fn=lambda df, aux: (df.convo_idx < aux["max_exp"])
+            & (df.n_convos__speaker >= aux["max_exp"])
+            & (df.tokens.map(len) >= aux["cmp_sample_size"])
+            & (df.n_utterances >= aux["min_n_utterances"]),
+            ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+            select_fn=lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)
+            & (df.speaker == row.speaker)
+            & (df.lifestage == row.lifestage),
+            speaker_convo_cols=["n_utterances", "lifestage"],
+            speaker_cols=["n_convos"],
+            divergence_fn=compute_divergences,
+            groupby=[],
+            aux_input=aux_input,
+            verbosity=verbosity,
+        )
+
+        # SpeakerConvoDiversity transformer to compute across-diversity
+        self.other_div = SpeakerConvoDiversity(
+            output_field + "__other",
+            cmp_select_fn=lambda df, aux: (df.convo_idx < aux["max_exp"])
+            & (df.n_convos__speaker >= aux["max_exp"])
+            & (df.tokens.map(len) >= aux["cmp_sample_size"])
+            & (df.n_utterances >= aux["min_n_utterances"]),
+            ref_select_fn=lambda df, aux: np.ones(len(df)).astype(bool),
+            select_fn=lambda df, row, aux: (df.convo_idx % 2 != row.convo_idx % 2)
+            & (df.speaker != row.speaker)
+            & (df.lifestage == row.lifestage)
+            & (df.n_convos__speaker >= (row.lifestage + 1) * aux["lifestage_size"])
+            & (
+                df.start_time__speaker.between(
+                    row.start_time__speaker - aux["cohort_delta"],
+                    row.start_time__speaker + aux["cohort_delta"],
+                )
+            ),
+            divergence_fn=compute_divergences,
+            speaker_convo_cols=["n_utterances", "lifestage"],
+            speaker_cols=["n_convos", "start_time"],
+            groupby=["speaker", "lifestage"],
+            aux_input=aux_input,
+            verbosity=verbosity,
+        )
+        self.verbosity = verbosity
+
+    def transform(self, corpus):
+        if self.verbosity > 0:
+            print("getting lifestages")
+        corpus = self.lifestage_transform.transform(corpus)
+        if self.verbosity > 0:
+            print("getting within diversity")
+        corpus = self.self_div.transform(corpus)
+        if self.verbosity > 0:
+            print("getting across diversity")
+        corpus = self.other_div.transform(corpus)
+        if self.verbosity > 0:
+            print("getting relative diversity")
+        div_table = corpus.get_full_attribute_table(
+            [self.output_field + "__self", self.output_field + "__other"]
+        )
+        div_table = div_table[
+            div_table[self.output_field + "__self"].notnull()
+            | div_table[self.output_field + "__other"].notnull()
+        ]
+        div_table[self.output_field + "__adj"] = (
+            div_table[self.output_field + "__other"] - div_table[self.output_field + "__self"]
+        )
+        for idx, (_, row) in enumerate(div_table.iterrows()):
+            if (idx > 0) and (self.verbosity > 0) and (idx % self.verbosity == 0):
+                print(idx, "/", len(div_table))
+            if not np.isnan(row[self.output_field + "__adj"]):
+                corpus.set_speaker_convo_info(
+                    row.speaker,
+                    row.convo_id,
+                    self.output_field + "__adj",
+                    row[self.output_field + "__adj"],
+                )
+        return corpus
```

### Comparing `convokit-2.5.3/convokit/speaker_convo_helpers/speaker_convo_attrs.py` & `convokit-3.0.0/convokit/speaker_convo_helpers/speaker_convo_attrs.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,43 +1,51 @@
 from convokit.transformer import Transformer
 from convokit.model import Corpus
 
+
 class SpeakerConvoAttrs(Transformer):
 
-    '''
-        Transformer that aggregates statistics per (speaker, convo). e.g., average wordcount of all utterances that speaker contributed per convo. Assumes that `corpus.organize_speaker_convo_history` has already been called.
+    """
+    Transformer that aggregates statistics per (speaker, convo). e.g., average wordcount of all utterances that speaker contributed per convo. Assumes that `corpus.organize_speaker_convo_history` has already been called.
+
+    :param attr_name: name of attribute to aggregate over. note that this attribute must already exist as an annotation to utterances in the corpus.
+    :param output_field: name of the aggregated attribute to output. defaults to `attr_name`.
+    :param agg_fn: function to aggregate utterance-level attribute with. defaults to returning a list.
+    :param recompute: if `False`, will not recompute the aggregate if `output_field` already exists for a speaker convo entry.
+    """
 
-        :param attr_name: name of attribute to aggregate over. note that this attribute must already exist as an annotation to utterances in the corpus.
-        :param output_field: name of the aggregated attribute to output. defaults to `attr_name`.
-        :param agg_fn: function to aggregate utterance-level attribute with. defaults to returning a list.
-        :param recompute: if `False`, will not recompute the aggregate if `output_field` already exists for a speaker convo entry.
-    '''
-    
     def __init__(self, attr_name, output_field=None, agg_fn=None, recompute=False):
         self.attr_name = attr_name
         if output_field is None:
             self.output_field = attr_name
         else:
             self.output_field = output_field
         if agg_fn is None:
             self.agg_fn = list
         else:
             self.agg_fn = agg_fn
         self.recompute = recompute
-    
+
     def transform(self, corpus: Corpus):
-        '''
+        """
         creates and populates speaker, convo aggregates.
 
         :param corpus: the Corpus to transform.
         :type corpus: Corpus
-        '''
+        """
 
         for speaker in corpus.iter_speakers():
-            if 'conversations' not in speaker.meta: continue
+            if "conversations" not in speaker.meta:
+                continue
 
-            for convo_id, convo in speaker.meta['conversations'].items():
-                if self.recompute or (corpus.get_speaker_convo_info(speaker.id, convo_id, self.output_field) is None):
-                    utterance_attrs = [corpus.get_utterance(utt_id).meta[self.attr_name] 
-                                       for utt_id in convo['utterance_ids']]
-                    corpus.set_speaker_convo_info(speaker.id, convo_id, self.output_field, self.agg_fn(utterance_attrs))
+            for convo_id, convo in speaker.meta["conversations"].items():
+                if self.recompute or (
+                    corpus.get_speaker_convo_info(speaker.id, convo_id, self.output_field) is None
+                ):
+                    utterance_attrs = [
+                        corpus.get_utterance(utt_id).meta[self.attr_name]
+                        for utt_id in convo["utterance_ids"]
+                    ]
+                    corpus.set_speaker_convo_info(
+                        speaker.id, convo_id, self.output_field, self.agg_fn(utterance_attrs)
+                    )
         return corpus
```

### Comparing `convokit-2.5.3/convokit/speaker_convo_helpers/speaker_convo_lifestage.py` & `convokit-3.0.0/convokit/speaker_convo_helpers/speaker_convo_lifestage.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,25 +1,30 @@
 from convokit.transformer import Transformer
 
+
 class SpeakerConvoLifestage(Transformer):
-    
-    '''
-		Transformer that, for each speaker in a conversation, computes the lifestage of the speaker in that conversation. For instance, if lifestages are 20 conversations long, then the first 20 conversations a speaker participates in will be in lifestage 0, and the second 20 will be in lifestage 1.
 
-		Assumes that `corpus.organize_speaker_convo_history` has already been called.
+    """
+    Transformer that, for each speaker in a conversation, computes the lifestage of the speaker in that conversation. For instance, if lifestages are 20 conversations long, then the first 20 conversations a speaker participates in will be in lifestage 0, and the second 20 will be in lifestage 1.
+
+    Assumes that `corpus.organize_speaker_convo_history` has already been called.
 
-		:param lifestage_size: size of the lifestage 
-		:param output_field: name of speaker conversation attribute to output, defaults to "lifestage"
-    '''
+    :param lifestage_size: size of the lifestage
+    :param output_field: name of speaker conversation attribute to output, defaults to "lifestage"
+    """
 
-    def __init__(self, lifestage_size, output_field='lifestage'):
+    def __init__(self, lifestage_size, output_field="lifestage"):
         self.output_field = output_field
         self.lifestage_size = lifestage_size
-        
+
     def transform(self, corpus):
         for speaker in corpus.iter_speakers():
-            if 'conversations' not in speaker.meta:
+            if "conversations" not in speaker.meta:
                 continue
-            for convo_id, convo in speaker.meta['conversations'].items():
-                corpus.set_speaker_convo_info(speaker.id, convo_id, self.output_field,
-                                              int(convo['idx']//self.lifestage_size))
+            for convo_id, convo in speaker.meta["conversations"].items():
+                corpus.set_speaker_convo_info(
+                    speaker.id,
+                    convo_id,
+                    self.output_field,
+                    int(convo["idx"] // self.lifestage_size),
+                )
         return corpus
```

### Comparing `convokit-2.5.3/convokit/surprise/surprise.py` & `convokit-3.0.0/convokit/surprise/surprise.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,239 +4,269 @@
 from convokit.model import Corpus, CorpusComponent, Utterance
 from itertools import chain
 from nltk.tokenize import word_tokenize
 from sklearn.feature_extraction.text import CountVectorizer
 from tqdm import tqdm
 from typing import Callable, List, Tuple, Union
 
+
 def _cross_entropy(target: List[str], context: List[str], smooth=True):
-  """
-  Calculates H(P,Q) = -sum_{x\in X}(P(x) * log(Q(x)))
-  
-  :param target: list of tokens that make up the target text (P)
-  :param context: list of tokens that make up the context (Q)
-  :param smooth: whether to use add 1 smoothing for OOV tokens
-  
-  :return: cross entropy
-  """
-  N_target, N_context = len(target), len(context)
-  if min(N_target, N_context) == 0: return np.nan
-  context_counts = Counter(context)
-  V = len(context_counts) + 1 if smooth else 0
-  k = 1 if smooth else 0
-  val = 0 if smooth else 1
-  return sum(
-    -np.log((context_counts.get(tok, val) + k)/(N_context + V)) for tok in target
-  )/N_target
+    """
+    Calculates H(P,Q) = -sum_{x\in X}(P(x) * log(Q(x)))
+
+    :param target: list of tokens that make up the target text (P)
+    :param context: list of tokens that make up the context (Q)
+    :param smooth: whether to use add 1 smoothing for OOV tokens
+
+    :return: cross entropy
+    """
+    N_target, N_context = len(target), len(context)
+    if min(N_target, N_context) == 0:
+        return np.nan
+    context_counts = Counter(context)
+    V = len(context_counts) + 1 if smooth else 0
+    k = 1 if smooth else 0
+    val = 0 if smooth else 1
+    return (
+        sum(-np.log((context_counts.get(tok, val) + k) / (N_context + V)) for tok in target)
+        / N_target
+    )
+
 
 def sample(tokens: List[Union[np.ndarray, List[str]]], sample_size: int, n_samples=50, p=None):
-  """
-  Generates random samples from a list of lists of tokens.
+    """
+    Generates random samples from a list of lists of tokens.
 
-  :param toks: a list of lists of tokens to sample from.
-  :param sample_size: the number of tokens to include in each sample.
-  :param n_samples: the number of samples to take.
-
-  :return: numpy array where each row is a sample of tokens
-  """
-  if not sample_size:
-    assert len(tokens) == 1
-    return np.tile(tokens[0], (n_samples,1))
-  tokens_list = np.array([toks for toks in tokens if len(toks) >= sample_size])
-  if tokens_list.shape[0] == 0: return None
-  rng = np.random.default_rng()
-  sample_idxes = rng.integers(0, tokens_list.shape[0], size=(n_samples))
-  return np.array([rng.choice(tokens_list[i], sample_size) for i in sample_idxes])
+    :param toks: a list of lists of tokens to sample from.
+    :param sample_size: the number of tokens to include in each sample.
+    :param n_samples: the number of samples to take.
+
+    :return: numpy array where each row is a sample of tokens
+    """
+    if not sample_size:
+        assert len(tokens) == 1
+        return np.tile(tokens[0], (n_samples, 1))
+    tokens_list = np.array([toks for toks in tokens if len(toks) >= sample_size])
+    if tokens_list.shape[0] == 0:
+        return None
+    rng = np.random.default_rng()
+    sample_idxes = rng.integers(0, tokens_list.shape[0], size=(n_samples))
+    return np.array([rng.choice(tokens_list[i], sample_size) for i in sample_idxes])
 
 
 class Surprise(Transformer):
-  """
-  Computes how surprising a target (an utterance or group of utterances) is based on some context. 
-  The measure for surprise used is cross entropy. Uses fixed size samples from target and context text 
-  to mitigate effects of length on cross entropy.
-
-  :param model_key_selector: function that defines how utterances should be mapped to models. 
-      Takes in an utterance and returns the key to use for mapping the utterance to a corresponding model.
-  :param tokenize: optional function that takes in a string and returns a list of tokens in that string. 
-      default: nltk's word_tokenize
-  :param surprise_attr_name: the name for the metadata attribute to add to objects.
-      default: surprise
-  :param target_sample_size: number of tokens to sample from each target (test text). If `None`, then the entire target will be used.
-  :param context_sample_size: number of tokens to sample from each context (training text). If `None`, then the entire context will be used.
-  :param n_samples: number of samples to take for each target-context pair.
-  :param sampling_fn: function for generating samples of tokens.
-  :param smooth: whether to use laplace smoothing when calculating surprise.
-  """
-  def __init__(self, model_key_selector: Callable[[Utterance], str],
-      tokenizer: Callable[[str], List[str]]=word_tokenize,
-      surprise_attr_name="surprise",
-      target_sample_size=100, context_sample_size=100, n_samples=50, 
-      sampling_fn: Callable[[np.ndarray, int], np.ndarray]=sample, 
-      smooth: bool=True):
-    self.model_key_selector = model_key_selector
-    self.tokenizer = tokenizer
-    self.surprise_attr_name = surprise_attr_name
-    self.target_sample_size = target_sample_size
-    self.context_sample_size = context_sample_size
-    self.n_samples = n_samples
-    self.sampling_fn = sampling_fn
-    self.smooth = smooth
-  
-  def fit(self, corpus: Corpus,
-      text_func: Callable[[Utterance], List[str]]=None,
-      selector: Callable[[Utterance], bool]=lambda utt: True):
-    """
-    Fits a model for each group of utterances in a corpus. The group that an 
-    utterance belongs to is determined by the `model_key_selector` parameter in 
-    the transformer's constructor.
-
-    :param corpus: corpus to create models from.
-    :param text_func: optional function to define how the text a model is trained 
-        on should be selected. Takes an utterance as input and returns a list of 
-        strings to train the model corresponding to that utterance on. The model 
-        corresponding to the utterance is determined by `self.model_key_selector`. 
-        For every utterance corresponding to the same model key, this function 
-        should return the same result.
-        If `text_func` is `None`, a model will be trained on the text from all 
-        the utterances that belong to its group.
-    :param selector: determines which utterances in the corpus to train models for.
-    """
-    self.model_groups = defaultdict(list)
-    for utt in tqdm(corpus.iter_utterances(selector=selector), desc='fit1'):
-      key = self.model_key_selector(utt)
-      if text_func:
-        if key not in self.model_groups:
-          self.model_groups[key] = text_func(utt)
-      else:
-        self.model_groups[key].append(utt.text)
-    for key in tqdm(self.model_groups, desc='fit2'):
-      if not text_func:
-        self.model_groups[key] = [' '.join(self.model_groups[key])]
-      self.model_groups[key] = list(map(lambda x: self.tokenizer(x), self.model_groups[key]))
-    return self
-
-  def transform(self, corpus: Corpus,
-      obj_type: str,
-      group_and_models: Callable[[Utterance], Tuple[str, List[str]]]=None,
-      group_model_attr_key: Callable[[str, str], str]=None,
-      selector: Callable[[CorpusComponent], bool]=lambda _: True,
-      target_text_func: Callable[[Utterance], List[str]]=None):
-    """
-    Annotates `obj_type` components in a corpus with surprise scores. Should be 
-    called after fit().
-
-    :param corpus: corpus to compute surprise for.
-    :param obj_type: the type of corpus components to annotate. Should be either 
-        'utterance', 'speaker', 'conversation', or 'corpus'. 
-    :param group_and_models: optional function that defines how an utterance should 
-        be grouped to form a target text and what models (contexts) the group should 
-        be compared to when calculating surprise. Takes in an utterance and returns 
-        a tuple containing the name of the group the utterance belongs to and a 
-        list of models to calculate how surprising that group is against. Objects 
-        will be annotated with a metadata field `self.surprise_attr_name` that is 
-        maps a key corresponding to the `groupname` and `modelkey` to the surprise 
-        score for utterances in the group when compared to the model. The key used 
-        is defined by the `group_model_attr_key` parameter.
-        If `group_and_models` is `None`, `self.model_key_selector` will be used 
-        to select the group that an utterance belongs to. The surprise score will 
-        be calculated for each group of utterances compared to the model in 
-        `self.models` corresponding to the group.
-    :param group_model_attr_key: optional function to define what key should be used 
-        for a given `groupname` and `modelkey`. 
-        If `group_model_attr_key` is `None`, the default key used will be 
-        "GROUP_groupname_MODEL_modelkey" unless `groupname` and `modelkey` are equal 
-        in which case just "modelkey" will be used as the key.
-    :param selector: function to select objects to annotate. if function returns true, object will be annotated.
-    :param target_text_func: optional function to define what the target text corresponding to an utterance should be. 
-        takes in an utterance and returns a list of string tokens
-    """
-    if obj_type == 'corpus':
-      utt_groups = defaultdict(list)
-      group_models = defaultdict(set)
-      for utt in corpus.iter_utterances():
-        if group_and_models:
-          group_name, models = group_and_models(utt)
-        else:
-          group_name = self.model_key_selector(utt)
-          models = {group_name}
-        if target_text_func:
-          if group_name not in utt_groups:
-            utt_groups[group_name] = [target_text_func(utt)]
-        else:
-          utt_groups[group_name].append(self.tokenizer(utt.text))
-        group_models[group_name].update(models)
-      surprise_scores = {}
-      for group_name in tqdm(utt_groups, desc='transform'):
-        for model_key in group_models[group_name]:
-          context = self.model_groups[model_key]
-          target = list(chain(*utt_groups[group_name]))
-          surprise_scores[Surprise._format_attr_key(group_name, model_key, group_model_attr_key)] = self._compute_surprise(target, context)
-      corpus.add_meta(self.surprise_attr_name, surprise_scores)
-    elif obj_type == 'utterance':
-      for utt in tqdm(corpus.iter_utterances(selector=selector), desc='transform'):
-        if group_and_models:
-          group_name, models = group_and_models(utt)
-          surprise_scores = {}
-          for model_key in models:
-            context = self.model_groups[model_key]
-            target = target_text_func(utt) if target_text_func else self.tokenizer(utt.text)
-            surprise_scores[Surprise._format_attr_key(group_name, model_key, group_model_attr_key)] = self._compute_surprise(target, context)
-          utt.add_meta(self.surprise_attr_name, surprise_scores)
+    """
+    Computes how surprising a target (an utterance or group of utterances) is based on some context.
+    The measure for surprise used is cross entropy. Uses fixed size samples from target and context text
+    to mitigate effects of length on cross entropy.
+
+    :param model_key_selector: function that defines how utterances should be mapped to models.
+        Takes in an utterance and returns the key to use for mapping the utterance to a corresponding model.
+    :param tokenize: optional function that takes in a string and returns a list of tokens in that string.
+        default: nltk's word_tokenize
+    :param surprise_attr_name: the name for the metadata attribute to add to objects.
+        default: surprise
+    :param target_sample_size: number of tokens to sample from each target (test text). If `None`, then the entire target will be used.
+    :param context_sample_size: number of tokens to sample from each context (training text). If `None`, then the entire context will be used.
+    :param n_samples: number of samples to take for each target-context pair.
+    :param sampling_fn: function for generating samples of tokens.
+    :param smooth: whether to use laplace smoothing when calculating surprise.
+    """
+
+    def __init__(
+        self,
+        model_key_selector: Callable[[Utterance], str],
+        tokenizer: Callable[[str], List[str]] = word_tokenize,
+        surprise_attr_name="surprise",
+        target_sample_size=100,
+        context_sample_size=100,
+        n_samples=50,
+        sampling_fn: Callable[[np.ndarray, int], np.ndarray] = sample,
+        smooth: bool = True,
+    ):
+        self.model_key_selector = model_key_selector
+        self.tokenizer = tokenizer
+        self.surprise_attr_name = surprise_attr_name
+        self.target_sample_size = target_sample_size
+        self.context_sample_size = context_sample_size
+        self.n_samples = n_samples
+        self.sampling_fn = sampling_fn
+        self.smooth = smooth
+
+    def fit(
+        self,
+        corpus: Corpus,
+        text_func: Callable[[Utterance], List[str]] = None,
+        selector: Callable[[Utterance], bool] = lambda utt: True,
+    ):
+        """
+        Fits a model for each group of utterances in a corpus. The group that an
+        utterance belongs to is determined by the `model_key_selector` parameter in
+        the transformer's constructor.
+
+        :param corpus: corpus to create models from.
+        :param text_func: optional function to define how the text a model is trained
+            on should be selected. Takes an utterance as input and returns a list of
+            strings to train the model corresponding to that utterance on. The model
+            corresponding to the utterance is determined by `self.model_key_selector`.
+            For every utterance corresponding to the same model key, this function
+            should return the same result.
+            If `text_func` is `None`, a model will be trained on the text from all
+            the utterances that belong to its group.
+        :param selector: determines which utterances in the corpus to train models for.
+        """
+        self.model_groups = defaultdict(list)
+        for utt in tqdm(corpus.iter_utterances(selector=selector), desc="fit1"):
+            key = self.model_key_selector(utt)
+            if text_func:
+                if key not in self.model_groups:
+                    self.model_groups[key] = text_func(utt)
+            else:
+                self.model_groups[key].append(utt.text)
+        for key in tqdm(self.model_groups, desc="fit2"):
+            if not text_func:
+                self.model_groups[key] = [" ".join(self.model_groups[key])]
+            self.model_groups[key] = list(map(lambda x: self.tokenizer(x), self.model_groups[key]))
+        return self
+
+    def transform(
+        self,
+        corpus: Corpus,
+        obj_type: str,
+        group_and_models: Callable[[Utterance], Tuple[str, List[str]]] = None,
+        group_model_attr_key: Callable[[str, str], str] = None,
+        selector: Callable[[CorpusComponent], bool] = lambda _: True,
+        target_text_func: Callable[[Utterance], List[str]] = None,
+    ):
+        """
+        Annotates `obj_type` components in a corpus with surprise scores. Should be
+        called after fit().
+
+        :param corpus: corpus to compute surprise for.
+        :param obj_type: the type of corpus components to annotate. Should be either
+            'utterance', 'speaker', 'conversation', or 'corpus'.
+        :param group_and_models: optional function that defines how an utterance should
+            be grouped to form a target text and what models (contexts) the group should
+            be compared to when calculating surprise. Takes in an utterance and returns
+            a tuple containing the name of the group the utterance belongs to and a
+            list of models to calculate how surprising that group is against. Objects
+            will be annotated with a metadata field `self.surprise_attr_name` that is
+            maps a key corresponding to the `groupname` and `modelkey` to the surprise
+            score for utterances in the group when compared to the model. The key used
+            is defined by the `group_model_attr_key` parameter.
+            If `group_and_models` is `None`, `self.model_key_selector` will be used
+            to select the group that an utterance belongs to. The surprise score will
+            be calculated for each group of utterances compared to the model in
+            `self.models` corresponding to the group.
+        :param group_model_attr_key: optional function to define what key should be used
+            for a given `groupname` and `modelkey`.
+            If `group_model_attr_key` is `None`, the default key used will be
+            "GROUP_groupname_MODEL_modelkey" unless `groupname` and `modelkey` are equal
+            in which case just "modelkey" will be used as the key.
+        :param selector: function to select objects to annotate. if function returns true, object will be annotated.
+        :param target_text_func: optional function to define what the target text corresponding to an utterance should be.
+            takes in an utterance and returns a list of string tokens
+        """
+        if obj_type == "corpus":
+            utt_groups = defaultdict(list)
+            group_models = defaultdict(set)
+            for utt in corpus.iter_utterances():
+                if group_and_models:
+                    group_name, models = group_and_models(utt)
+                else:
+                    group_name = self.model_key_selector(utt)
+                    models = {group_name}
+                if target_text_func:
+                    if group_name not in utt_groups:
+                        utt_groups[group_name] = [target_text_func(utt)]
+                else:
+                    utt_groups[group_name].append(self.tokenizer(utt.text))
+                group_models[group_name].update(models)
+            surprise_scores = {}
+            for group_name in tqdm(utt_groups, desc="transform"):
+                for model_key in group_models[group_name]:
+                    context = self.model_groups[model_key]
+                    target = list(chain(*utt_groups[group_name]))
+                    surprise_scores[
+                        Surprise._format_attr_key(group_name, model_key, group_model_attr_key)
+                    ] = self._compute_surprise(target, context)
+            corpus.add_meta(self.surprise_attr_name, surprise_scores)
+        elif obj_type == "utterance":
+            for utt in tqdm(corpus.iter_utterances(selector=selector), desc="transform"):
+                if group_and_models:
+                    group_name, models = group_and_models(utt)
+                    surprise_scores = {}
+                    for model_key in models:
+                        context = self.model_groups[model_key]
+                        target = (
+                            target_text_func(utt) if target_text_func else self.tokenizer(utt.text)
+                        )
+                        surprise_scores[
+                            Surprise._format_attr_key(group_name, model_key, group_model_attr_key)
+                        ] = self._compute_surprise(target, context)
+                    utt.add_meta(self.surprise_attr_name, surprise_scores)
+                else:
+                    group_name = self.model_key_selector(utt)
+                    context = self.model_groups[group_name]
+                    target = target_text_func(utt) if target_text_func else self.tokenizer(utt.text)
+                    utt.add_meta(self.surprise_attr_name, self._compute_surprise(target, context))
         else:
-          group_name = self.model_key_selector(utt)
-          context = self.model_groups[group_name]
-          target = target_text_func(utt) if target_text_func else self.tokenizer(utt.text)
-          utt.add_meta(self.surprise_attr_name, self._compute_surprise(target, context))
-    else:
-      for obj in tqdm(corpus.iter_objs(obj_type, selector=selector), desc='transform'):
-        utt_groups = defaultdict(list)
-        group_models = defaultdict(set)
-        for utt in obj.iter_utterances():
-          if group_and_models:
-            group_name, models = group_and_models(utt)
-          else:
-            group_name = self.model_key_selector(utt)
-            models = {group_name}
-          if target_text_func:
-            if group_name not in utt_groups:
-              utt_groups[group_name] = [target_text_func(utt)]
-          else:
-            utt_groups[group_name].append(self.tokenizer(utt.text))
-          group_models[group_name].update(models)
-        surprise_scores = {}
-        for group_name in utt_groups:
-          for model_key in group_models[group_name]:
-            assert (model_key in self.model_groups), 'invalid model key'
-            if not self.model_groups[model_key]: continue
-            context = self.model_groups[model_key]
-            target = list(chain(*utt_groups[group_name]))
-            surprise_scores[Surprise._format_attr_key(group_name, model_key, group_model_attr_key)] = self._compute_surprise(target, context)
-        obj.add_meta(self.surprise_attr_name, surprise_scores)
-    return corpus
-
-  def _compute_surprise(self, target: List[str], context: List[List[str]]):
-    """
-    Computes how surprising a target text is based on a context. Surprise scores are calculated using cross entropy. 
-    To mitigate length based effects on cross entropy, several random sample of fixed sizes are taken from the traget and context. 
-    Returns the average of the cross entropies for all pairs of samples.
-    
-    :param target: a list of tokens in the target
-    :param context: a list of lists of tokens in each group of the context
-    
-    :return: surprise score
-    """
-    target_tokens = np.array(target)
-    context_tokens = [np.array(text) for text in context]
-    target_samples = self.sampling_fn([target_tokens], self.target_sample_size, self.n_samples)
-    context_samples = self.sampling_fn(context_tokens, self.context_sample_size, self.n_samples)
-    if target_samples is None or context_samples is None:
-      return np.nan
-    return np.nanmean([_cross_entropy(target_sample, context_sample, self.smooth) for target_sample, context_sample in zip(target_samples, context_samples)])
-
-  @staticmethod
-  def _format_attr_key(group_name, model_key, format_fn=None):
-    if format_fn:
-      return format_fn(group_name, model_key)
-    if group_name == model_key:
-        return model_key
-    return f'GROUP_{group_name}__MODEL_{model_key}'
-    
+            for obj in tqdm(corpus.iter_objs(obj_type, selector=selector), desc="transform"):
+                utt_groups = defaultdict(list)
+                group_models = defaultdict(set)
+                for utt in obj.iter_utterances():
+                    if group_and_models:
+                        group_name, models = group_and_models(utt)
+                    else:
+                        group_name = self.model_key_selector(utt)
+                        models = {group_name}
+                    if target_text_func:
+                        if group_name not in utt_groups:
+                            utt_groups[group_name] = [target_text_func(utt)]
+                    else:
+                        utt_groups[group_name].append(self.tokenizer(utt.text))
+                    group_models[group_name].update(models)
+                surprise_scores = {}
+                for group_name in utt_groups:
+                    for model_key in group_models[group_name]:
+                        assert model_key in self.model_groups, "invalid model key"
+                        if not self.model_groups[model_key]:
+                            continue
+                        context = self.model_groups[model_key]
+                        target = list(chain(*utt_groups[group_name]))
+                        surprise_scores[
+                            Surprise._format_attr_key(group_name, model_key, group_model_attr_key)
+                        ] = self._compute_surprise(target, context)
+                obj.add_meta(self.surprise_attr_name, surprise_scores)
+        return corpus
+
+    def _compute_surprise(self, target: List[str], context: List[List[str]]):
+        """
+        Computes how surprising a target text is based on a context. Surprise scores are calculated using cross entropy.
+        To mitigate length based effects on cross entropy, several random sample of fixed sizes are taken from the traget and context.
+        Returns the average of the cross entropies for all pairs of samples.
+
+        :param target: a list of tokens in the target
+        :param context: a list of lists of tokens in each group of the context
+
+        :return: surprise score
+        """
+        target_tokens = np.array(target)
+        context_tokens = [np.array(text) for text in context]
+        target_samples = self.sampling_fn([target_tokens], self.target_sample_size, self.n_samples)
+        context_samples = self.sampling_fn(context_tokens, self.context_sample_size, self.n_samples)
+        if target_samples is None or context_samples is None:
+            return np.nan
+        return np.nanmean(
+            [
+                _cross_entropy(target_sample, context_sample, self.smooth)
+                for target_sample, context_sample in zip(target_samples, context_samples)
+            ]
+        )
+
+    @staticmethod
+    def _format_attr_key(group_name, model_key, format_fn=None):
+        if format_fn:
+            return format_fn(group_name, model_key)
+        if group_name == model_key:
+            return model_key
+        return f"GROUP_{group_name}__MODEL_{model_key}"
```

### Comparing `convokit-2.5.3/convokit/text_processing/textCleaner.py` & `convokit-3.0.0/convokit/text_processing/textCleaner.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,33 +1,34 @@
 from convokit.model import Corpus
 from .textProcessor import TextProcessor
 from typing import Callable, Optional
 from cleantext import clean
 
 
-clean_str = lambda s: clean(s,
-                            fix_unicode=True,               # fix various unicode errors
-                            to_ascii=True,                  # transliterate to closest ASCII representation
-                            lower=True,                     # lowercase text
-                            no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them
-                            no_urls=True,                  # replace all URLs with a special token
-                            no_emails=True,                # replace all email addresses with a special token
-                            no_phone_numbers=True,         # replace all phone numbers with a special token
-                            no_numbers=True,               # replace all numbers with a special token
-                            no_digits=False,                # replace all digits with a special token
-                            no_currency_symbols=True,      # replace all currency symbols with a special token
-                            no_punct=False,                 # fully remove punctuation
-                            replace_with_url="<URL>",
-                            replace_with_email="<EMAIL>",
-                            replace_with_phone_number="<PHONE>",
-                            replace_with_number="<NUMBER>",
-                            replace_with_digit="0",
-                            replace_with_currency_symbol="<CUR>",
-                            lang="en"
-                            )
+clean_str = lambda s: clean(
+    s,
+    fix_unicode=True,  # fix various unicode errors
+    to_ascii=True,  # transliterate to closest ASCII representation
+    lower=True,  # lowercase text
+    no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them
+    no_urls=True,  # replace all URLs with a special token
+    no_emails=True,  # replace all email addresses with a special token
+    no_phone_numbers=True,  # replace all phone numbers with a special token
+    no_numbers=True,  # replace all numbers with a special token
+    no_digits=False,  # replace all digits with a special token
+    no_currency_symbols=True,  # replace all currency symbols with a special token
+    no_punct=False,  # fully remove punctuation
+    replace_with_url="<URL>",
+    replace_with_email="<EMAIL>",
+    replace_with_phone_number="<PHONE>",
+    replace_with_number="<NUMBER>",
+    replace_with_digit="0",
+    replace_with_currency_symbol="<CUR>",
+    lang="en",
+)
 
 
 class TextCleaner(TextProcessor):
     """
     Transformer that cleans the text of utterances in an input Corpus. By default, the text cleaner assumes the
     text is in English. It fixes unicode errors, transliterates text to the closest ASCII representation,
     lowercases text, removes line breaks, and replaces URLs, emails, phone numbers, numbers, currency symbols with
@@ -44,37 +45,48 @@
         By default, will always return `True`, meaning that all utterances will be cleaned.
     :param verbosity: frequency of status messages
     :param replace_text: whether to replace the text being cleaned with the cleaned version. True by default.
         If False, the cleaned text is stored under attribute 'cleaned'.
     :param save_original: if replacing text, whether to save the original version of the text. If True, saves it
         under the 'original' attribute.
     """
-    def __init__(self, text_cleaner: Optional[Callable[[str], str]]=None,
-                 input_field=None, input_filter=lambda utt, aux: True,
-                 verbosity: int = 100, replace_text: bool = True, save_original: bool = True):
 
+    def __init__(
+        self,
+        text_cleaner: Optional[Callable[[str], str]] = None,
+        input_field=None,
+        input_filter=lambda utt, aux: True,
+        verbosity: int = 100,
+        replace_text: bool = True,
+        save_original: bool = True,
+    ):
         if replace_text:
             if save_original:
-                output_field = 'original'
+                output_field = "original"
             else:
-                output_field = 'cleaned_temp'
+                output_field = "cleaned_temp"
         else:
-            output_field = 'cleaned'
+            output_field = "cleaned"
         self.replace_text = replace_text
         self.save_original = save_original
         proc_fn = text_cleaner if text_cleaner is not None else clean_str
-        super().__init__(proc_fn=proc_fn, input_field=input_field, input_filter=input_filter,
-                         verbosity=verbosity, output_field=output_field)
+        super().__init__(
+            proc_fn=proc_fn,
+            input_field=input_field,
+            input_filter=input_filter,
+            verbosity=verbosity,
+            output_field=output_field,
+        )
 
     def transform(self, corpus: Corpus) -> Corpus:
         super().transform(corpus)
         if self.replace_text:
             selector = lambda utt_: self.input_filter(utt_, None)
             for utt in corpus.iter_utterances(selector):
                 cleaned_text = utt.retrieve_meta(self.output_field)
                 if self.save_original:
                     utt.add_meta(self.output_field, utt.text)
                 utt.text = cleaned_text
 
             if not self.save_original:
-                corpus.delete_metadata('utterance', self.output_field)
-        return corpus
+                corpus.delete_metadata("utterance", self.output_field)
+        return corpus
```

### Comparing `convokit-2.5.3/convokit/text_processing/textProcessor.py` & `convokit-3.0.0/convokit/text_processing/textProcessor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,34 @@
-from convokit.transformer import Transformer
-from convokit.model import Corpus, Utterance, Speaker
 from inspect import signature
 
+from convokit.model import Corpus, Utterance, Speaker
+from convokit.transformer import Transformer
+
+
 class TextProcessor(Transformer):
     """
     A base class for Transformers that perform per-utterance computations, i.e., computing  utterance-by-utterance features or representations.
 
     :param proc_fn: function to compute per utterance. Supports one of two function signatures: `proc_fn(input)` and `proc_fn(input, auxiliary_info)`.
     :param input_field: If set to a string, the attribute of the utterance that `proc_fn` will take as input. If set to `None`, will default to reading `utt.text`. If set to a list of attributes, `proc_fn` will expect a dict of {attribute name: attribute value}.
     :param output_field: If set to a string, the name of the attribute that the output of `proc_fn` will be written to. If set to a list, `proc_fn` will return a tuple where each entry in the tuple corresponds to a field in the list.
     :param aux_input: any auxiliary input that `proc_fn` needs (e.g., a pre-loaded model); passed in as a dict.
     :param input_filter: a boolean function of signature `input_filter(utterance, aux_input)`. attributes will only be computed for utterances where `input_filter` returns `True`. By default, will always return `True`, meaning that attributes will be computed for all utterances.
     :param verbosity: frequency at which to print status messages when computing attributes.
     """
-    
-    def __init__(self, proc_fn, output_field, input_field=None, aux_input=None, input_filter=None, verbosity=0):
-        
+
+    def __init__(
+        self,
+        proc_fn,
+        output_field,
+        input_field=None,
+        aux_input=None,
+        input_filter=None,
+        verbosity=0,
+    ):
         self.proc_fn = proc_fn
         self.aux_input = aux_input if aux_input is not None else {}
         # self.input_filter = input_filter if input_filter is not None else lambda utt, aux: True
         # temporary fix to deal with aux_input argument to input_filter
         if input_filter:
             if len(signature(input_filter).parameters) == 1:
                 self.input_filter = lambda utt, aux: input_filter(utt)
@@ -27,33 +36,33 @@
                 self.input_filter = input_filter
         else:
             self.input_filter = lambda utt, aux: True
         self.input_field = input_field
         self.output_field = output_field
         self.verbosity = verbosity
         self.multi_outputs = isinstance(output_field, list)
-    
+
     def _print_output(self, i):
         return (self.verbosity > 0) and (i > 0) and (i % self.verbosity == 0)
 
     def transform(self, corpus: Corpus) -> Corpus:
         """
-            Computes per-utterance attributes for each utterance in the Corpus, storing these values in the `output_field` of each utterance as specified in the constructor. For utterances which do not contain all of the `input_field` attributes as specified in the constructor, or for utterances which return `False` on `input_filter`, this call will not annotate the utterance. 
+        Computes per-utterance attributes for each utterance in the Corpus, storing these values in the `output_field` of each utterance as specified in the constructor. For utterances which do not contain all of the `input_field` attributes as specified in the constructor, or for utterances which return `False` on `input_filter`, this call will not annotate the utterance.
 
-            :param corpus: Corpus
-            :return: the corpus
+        :param corpus: Corpus
+        :return: the corpus
         """
 
-        total_utts = len(corpus.utterances)
+        total_utts = len(list(corpus.iter_utterances()))
 
         for idx, utterance in enumerate(corpus.iter_utterances()):
-            
             if self._print_output(idx):
-                print('%03d/%03d utterances processed' % (idx, total_utts))
-            if not self.input_filter(utterance, self.aux_input): continue
+                print("%03d/%03d utterances processed" % (idx, total_utts))
+            if not self.input_filter(utterance, self.aux_input):
+                continue
             if self.input_field is None:
                 text_entry = utterance.text
             elif isinstance(self.input_field, str):
                 text_entry = utterance.retrieve_meta(self.input_field)
 
             elif isinstance(self.input_field, list):
                 text_entry = {field: utterance.retrieve_meta(field) for field in self.input_field}
@@ -66,17 +75,18 @@
             else:
                 result = self.proc_fn(text_entry, self.aux_input)
             if self.multi_outputs:
                 for res, out in zip(result, self.output_field):
                     utterance.add_meta(out, res)
             else:
                 utterance.add_meta(self.output_field, result)
-        if self.verbosity > 0: print('%03d/%03d utterances processed' % (total_utts, total_utts))
+        if self.verbosity > 0:
+            print("%03d/%03d utterances processed" % (total_utts, total_utts))
         return corpus
-    
+
     def transform_utterance(self, utt, override_input_filter=False):
         """
         Computes per-utterance attributes of an individual utterance or string. For utterances which do not contain all of the `input_field` attributes as specified in the constructor, or for utterances which return `False` on `input_filter`, this call will not annotate the utterance. For strings, will convert the string to an utterance and return the utterance, annotating it if `input_field` is not set to `None` at initialization.
 
         :param utt: utterance or a string
         :param override_input_filter: ignore `input_filter` and compute attribute for all utterances
         :return: the utterance
@@ -84,16 +94,16 @@
 
         if isinstance(utt, str):
             utt = Utterance(text=utt, speaker=Speaker(id="speaker"))
         if self.input_field is None:
             text_entry = utt.text
         else:
             if not override_input_filter:
-                if not self.input_filter(utt, self.aux_input): 
-                    return utt 
+                if not self.input_filter(utt, self.aux_input):
+                    return utt
             if isinstance(self.input_field, str):
                 text_entry = utt.retrieve_meta(self.input_field)
             elif isinstance(self.input_field, list):
                 text_entry = {field: utt.retrieve_meta(field) for field in self.input_field}
                 if sum(x is None for x in text_entry.values()) > 0:
                     return utt
         if text_entry is None:
@@ -104,8 +114,7 @@
             result = self.proc_fn(text_entry, self.aux_input)
         if self.multi_outputs:
             for res, out in zip(result, self.output_field):
                 utt.add_meta(out, res)
         else:
             utt.add_meta(self.output_field, result)
         return utt
-
```

### Comparing `convokit-2.5.3/convokit/transformer.py` & `convokit-3.0.0/convokit/transformer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 from abc import ABC, abstractmethod
 from .model import Corpus
 
+
 class Transformer(ABC):
     """
     Abstract base class for modules that take in a Corpus and modify the Corpus
     and/or extend it with additional information, imitating the scikit-learn
     Transformer API. Exposes ``fit()`` and ``transform()`` methods. ``fit()`` performs any
     necessary precomputation (or “training” in machine learning parlance) while
     ``transform()`` does the work of actually computing the modification and
-    applying it to the corpus. 
+    applying it to the corpus.
 
     All subclasses must implement ``transform()``;
     subclasses that require precomputation should also override ``fit()``, which by
     default does nothing. Additionally, the interface also exposes a
     ``fit_transform()`` method that does both steps on the same Corpus in one line.
     By default this is implemented to simply call ``fit()`` followed by ``transform()``,
     but designers of Transformer subclasses may also choose to overwrite the
@@ -21,27 +22,27 @@
     """
 
     def fit(self, corpus: Corpus, y=None, **kwargs):
         """Use the provided Corpus to perform any precomputations necessary to
         later perform the actual transformation step.
 
         :param corpus: the Corpus to use for fitting
-        
+
         :return: the fitted Transformer
         """
         return self
 
     @abstractmethod
     def transform(self, corpus: Corpus, **kwargs) -> Corpus:
         """Modify the provided corpus. This is an abstract method that must be
         implemented by any Transformer subclass
 
         :param corpus: the Corpus to transform
 
-        :return: modified version of the input Corpus. Note that unlike the 
+        :return: modified version of the input Corpus. Note that unlike the
             scikit-learn equivalent, ``transform()`` operates inplace on the Corpus
             (though for convenience and compatibility with scikit-learn, it also
             returns the modified Corpus).
         """
         pass
 
     def fit_transform(self, corpus: Corpus, y=None, **kwargs) -> Corpus:
@@ -51,8 +52,8 @@
 
         :return: same as transform
         """
         self.fit(corpus, y=y, **kwargs)
         return self.transform(corpus, **kwargs)
 
     def summarize(self, corpus: Corpus, **kwargs):
-        pass
+        pass
```

### Comparing `convokit-2.5.3/convokit/util.py` & `convokit-3.0.0/convokit/util.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,27 @@
-import urllib.request
-import shutil
+import json
 import os
+import shutil
+import urllib.request
+import uuid
+import warnings
 import zipfile
-import json
 from typing import Dict
+
 import requests
-import warnings
+
 
 # returns a path to the dataset file
-def download(name: str, verbose: bool = True, data_dir: str = None, use_newest_version: bool = True,
-             use_local: bool = False) -> str:
+def download(
+    name: str,
+    verbose: bool = True,
+    data_dir: str = None,
+    use_newest_version: bool = True,
+    use_local: bool = False,
+) -> str:
     """Use this to download (or use saved) convokit data by name.
 
     :param name: Which item to download. Currently supported:
 
         - "wiki-corpus": Wikipedia Talk Page Conversations Corpus
             A medium-size collection of conversations from Wikipedia editors' talk pages.
             (see http://www.cs.cornell.edu/~cristian/Echoes_of_power.html)
@@ -69,41 +77,43 @@
         (regardless of whether a newer version exists)
 
     :return: The path to the downloaded item.
     """
     if use_local:
         return download_local(name, data_dir)
 
-    dataset_config = requests.get('https://zissou.infosci.cornell.edu/convokit/datasets/download_config.json').json()
+    dataset_config = requests.get(
+        "https://raw.githubusercontent.com/CornellNLP/ConvoKit/master/download_config.json"
+    ).json()
 
-    cur_version = dataset_config['cur_version']
-    DatasetURLs = dataset_config['DatasetURLs']
+    cur_version = dataset_config["cur_version"]
+    DatasetURLs = dataset_config["DatasetURLs"]
 
     if name.startswith("subreddit"):
         subreddit_name = name.split("-", maxsplit=1)[1]
         # print(subreddit_name)
-        cur_version[name] = cur_version['subreddit']
+        cur_version[name] = cur_version["subreddit"]
         DatasetURLs[name] = get_subreddit_info(subreddit_name)
         # print(DatasetURLs[name])
     elif name.startswith("wikiconv"):
         wikiconv_year = name.split("-")[1]
-        cur_version[name] = cur_version['wikiconv']
+        cur_version[name] = cur_version["wikiconv"]
         DatasetURLs[name] = _get_wikiconv_year_info(wikiconv_year)
     elif name.startswith("supreme-"):
-        supreme_year = name.split('-')[1]
-        cur_version[name] = cur_version['supreme']
+        supreme_year = name.split("-")[1]
+        cur_version[name] = cur_version["supreme"]
         DatasetURLs[name] = _get_supreme_info(supreme_year)
     else:
         name = name.lower()
 
     custom_data_dir = data_dir
 
     data_dir = os.path.expanduser("~/.convokit/")
 
-        #pkg_resources.resource_filename("convokit", "")
+    # pkg_resources.resource_filename("convokit", "")
     if not os.path.exists(data_dir):
         os.mkdir(data_dir)
     if not os.path.exists(os.path.join(data_dir, "downloads")):
         os.mkdir(os.path.join(data_dir, "downloads"))
 
     dataset_path = os.path.join(data_dir, "downloads", name)
 
@@ -130,60 +140,66 @@
                 downloaded[dname, path] = version
                 downloaded_paths[dname] = path
                 if custom_data_dir is None and name == dname:
                     dataset_path = os.path.join(path, name)
 
         # print(list(downloaded.keys()))
         if (name, os.path.dirname(dataset_path)) in downloaded:
-            if use_newest_version and name in cur_version and \
-                downloaded[name, os.path.dirname(dataset_path)] < cur_version[name]:
-                    needs_download = True
+            if (
+                use_newest_version
+                and name in cur_version
+                and downloaded[name, os.path.dirname(dataset_path)] < cur_version[name]
+            ):
+                needs_download = True
         else:
             needs_download = True
 
     if needs_download:
-
         print("Downloading {} to {}".format(name, dataset_path))
-    #name not in downloaded or \
-    #    (use_newest_version and name in cur_version and
-    #        downloaded[name] < cur_version[name]):
+        # name not in downloaded or \
+        #    (use_newest_version and name in cur_version and
+        #        downloaded[name] < cur_version[name]):
         if name.endswith("-motifs"):
             for url in DatasetURLs[name]:
-                full_name = name + url[url.rfind('/'):]
+                full_name = name + url[url.rfind("/") :]
                 if full_name not in downloaded:
-                    motif_file_path = dataset_path + url[url.rfind('/'):]
+                    motif_file_path = dataset_path + url[url.rfind("/") :]
                     if not os.path.exists(os.path.dirname(motif_file_path)):
                         os.makedirs(os.path.dirname(motif_file_path))
                     _download_helper(motif_file_path, url, verbose, full_name, downloadeds_path)
         else:
             url = DatasetURLs[name]
             _download_helper(dataset_path, url, verbose, name, downloadeds_path)
     else:
-
         print("Dataset already exists at {}".format(dataset_path))
         dataset_path = os.path.join(downloaded_paths[name], name)
 
     return dataset_path
 
+
 def download_local(name: str, data_dir: str):
     """
     Get path to a previously-downloaded local version of the corpus (which may be an older version).
-    
+
     :param name: name of Corpus
     :return: string path to local Corpus
     """
     custom_data_dir = data_dir
     data_dir = os.path.expanduser("~/.convokit/")
 
-    #pkg_resources.resource_filename("convokit", "")
+    # pkg_resources.resource_filename("convokit", "")
     if not os.path.exists(data_dir):
-        raise FileNotFoundError("No convokit data directory found. No local corpus version available.")
+        raise FileNotFoundError(
+            "No convokit data directory found. No local corpus version available."
+        )
 
     if not os.path.exists(os.path.join(data_dir, "downloads")):
-        raise FileNotFoundError("Local convokit data directory found, but no downloads folder exists. No local corpus version available.")
+        raise FileNotFoundError(
+            "Local convokit data directory found, but no downloads folder exists. No local corpus version available."
+        )
 
     dataset_path = os.path.join(data_dir, "downloads", name)
 
     if custom_data_dir is not None:
         dataset_path = os.path.join(custom_data_dir, name)
 
     if not os.path.exists(os.path.dirname(dataset_path)):
@@ -212,58 +228,71 @@
             raise FileNotFoundError("Could not find corpus in local directory.")
 
         print("Dataset already exists at {}".format(dataset_path))
         dataset_path = os.path.join(downloaded_paths[name], name)
 
     return dataset_path
 
-def _download_helper(dataset_path: str, url: str, verbose: bool, name: str, downloadeds_path: str) -> None:
 
-    if url.lower().endswith(".corpus") or url.lower().endswith(".corpus.zip") or url.lower().endswith(".zip"):
+def _download_helper(
+    dataset_path: str, url: str, verbose: bool, name: str, downloadeds_path: str
+) -> None:
+    if (
+        url.lower().endswith(".corpus")
+        or url.lower().endswith(".corpus.zip")
+        or url.lower().endswith(".zip")
+    ):
         dataset_path += ".zip"
 
-    with urllib.request.urlopen(url) as response, \
-            open(dataset_path, "wb") as out_file:
+    with urllib.request.urlopen(url) as response, open(dataset_path, "wb") as out_file:
         if verbose:
             length = float(response.info()["Content-Length"])
-            length = str(round(length / 1e6, 1)) + "MB" \
-                if length > 1e6 else \
-                str(round(length / 1e3, 1)) + "KB"
-            print("Downloading", name, "from", url,
-                  "(" + length + ")...", end=" ", flush=True)
+            length = (
+                str(round(length / 1e6, 1)) + "MB"
+                if length > 1e6
+                else str(round(length / 1e3, 1)) + "KB"
+            )
+            print("Downloading", name, "from", url, "(" + length + ")...", end=" ", flush=True)
         shutil.copyfileobj(response, out_file)
 
     # post-process (extract) corpora
     if name.startswith("subreddit"):
         with zipfile.ZipFile(dataset_path, "r") as zipf:
             corpus_dir = os.path.join(os.path.dirname(dataset_path), name)
             if not os.path.exists(corpus_dir):
                 os.mkdir(corpus_dir)
             zipf.extractall(corpus_dir)
 
     elif url.lower().endswith(".corpus") or url.lower().endswith(".zip"):
-        #print(dataset_path)
+        # print(dataset_path)
         with zipfile.ZipFile(dataset_path, "r") as zipf:
             zipf.extractall(os.path.dirname(dataset_path))
 
     if verbose:
         print("Done")
     with open(downloadeds_path, "a") as f:
-        fn = os.path.join(os.path.dirname(dataset_path), name)#os.path.join(os.path.dirname(data), name)
-        f.write("{}$#${}$#${}\n".format(name, os.path.realpath(os.path.dirname(dataset_path) + "/"), corpus_version(fn)))
-        #f.write(name + "\n")
+        fn = os.path.join(
+            os.path.dirname(dataset_path), name
+        )  # os.path.join(os.path.dirname(data), name)
+        f.write(
+            "{}$#${}$#${}\n".format(
+                name, os.path.realpath(os.path.dirname(dataset_path) + "/"), corpus_version(fn)
+            )
+        )
+        # f.write(name + "\n")
+
 
 def corpus_version(filename: str) -> int:
     with open(os.path.join(filename, "index.json")) as f:
         d = json.load(f)
         return int(d["version"])
 
+
 # retrieve grouping and completes the download link for subreddit
 def get_subreddit_info(subreddit_name: str) -> str:
-
     # base directory of subreddit corpuses
     subreddit_base = "http://zissou.infosci.cornell.edu/convokit/datasets/subreddit-corpus/"
     data_dir = subreddit_base + "corpus-zipped/"
 
     groupings_url = subreddit_base + "subreddit-groupings.txt"
     groups_fetched = urllib.request.urlopen(groupings_url)
 
@@ -274,63 +303,74 @@
             # return os.path.join(data_dir, group, subreddit_name + ".corpus.zip")
             return data_dir + group + "/" + subreddit_name + ".corpus.zip"
 
     print("The subreddit requested is not available.")
 
     return ""
 
+
 def subreddit_in_grouping(subreddit: str, grouping_key: str) -> bool:
     """
     :param subreddit: subreddit name
     :param grouping_key: example: "askreddit~-~blackburn"
     :return: if string is within the grouping range
     """
     bounds = grouping_key.split("~-~")
     if len(bounds) == 1:
         print(subreddit, grouping_key)
     return bounds[0] <= subreddit <= bounds[1]
 
+
 def _get_wikiconv_year_info(year: str) -> str:
     """completes the download link for wikiconv"""
 
     # base directory of wikicon corpuses
     wikiconv_base = "http://zissou.infosci.cornell.edu/convokit/datasets/wikiconv-corpus/"
     data_dir = wikiconv_base + "corpus-zipped/"
 
     return data_dir + year + "/full.corpus.zip"
 
-def _get_supreme_info(year: str) -> str:
 
+def _get_supreme_info(year: str) -> str:
     supreme_base = "http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/"
-    return supreme_base + 'supreme-' + year + '.zip'
+    return supreme_base + "supreme-" + year + ".zip"
+
 
 def meta_index(corpus=None, filename: str = None) -> Dict:
-    keys = ["utterances-index", "conversations-index", "speakers-index",
-            "overall-index"]
+    keys = ["utterances-index", "conversations-index", "speakers-index", "overall-index"]
     if corpus is not None:
         return {k: v for k, v in corpus.meta_index.items() if k in keys}
     if filename is not None:
         with open(os.path.join(filename, "index.json")) as f:
             d = json.load(f)
             return d
 
+
 def warn(text: str):
     """
     Pre-pends a red-colored 'WARNING: ' to [text]. This is a printed warning and cannot be suppressed.
 
     :param text: Warning message
     :return: 'WARNING: [text]'
     """
-    print('\033[91m'+ "WARNING: " + '\033[0m' + text)
+    print("\033[91m" + "WARNING: " + "\033[0m" + text)
 
 
 def _deprecation_format(message, category, filename, lineno, file=None, line=None):
-    return '{}:{}: {}: {}\n'.format(filename, lineno, category.__name__, message)
+    return "{}:{}: {}: {}\n".format(filename, lineno, category.__name__, message)
 
 
 def deprecation(prev_name: str, new_name: str, stacklevel: int = 3):
     """
     Suppressable deprecation warning.
     """
     warnings.formatwarning = _deprecation_format
-    warnings.warn("{} is deprecated and will be removed in a future release. "
-                  "Use {} instead.".format(prev_name, new_name), category=FutureWarning, stacklevel=stacklevel)
+    warnings.warn(
+        "{} is deprecated and will be removed in a future release. "
+        "Use {} instead.".format(prev_name, new_name),
+        category=FutureWarning,
+        stacklevel=stacklevel,
+    )
+
+
+def create_safe_id():
+    return "_" + uuid.uuid4().hex
```

### Comparing `convokit-2.5.3/convokit.egg-info/PKG-INFO` & `convokit-3.0.0/convokit.egg-info/PKG-INFO`

 * *Files 26% similar despite different names*

```diff
@@ -1,15 +1,18 @@
 Metadata-Version: 2.1
 Name: convokit
-Version: 2.5.3
-Summary: Cornell Conversational Analysis Toolkit
-Home-page: https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit
+Version: 3.0.0
+Summary: ConvoKit
+Home-page: https://github.com/CornellNLP/ConvoKit
 Author: Jonathan P. Chang, Caleb Chiam, Liye Fu, Andrew Wang, Justine Zhang, Cristian Danescu-Niculescu-Mizil
 Author-email: cristian@cs.cornell.edu
 License: UNKNOWN
-Description: UNKNOWN
 Platform: UNKNOWN
 Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
 Provides-Extra: craft
+License-File: LICENSE.md
+
+UNKNOWN
+
```

### Comparing `convokit-2.5.3/convokit.egg-info/SOURCES.txt` & `convokit-3.0.0/convokit.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 LICENSE.md
 README.md
+pyproject.toml
 setup.py
 convokit/__init__.py
+convokit/convokitConfig.py
 convokit/convokitPipeline.py
 convokit/transformer.py
 convokit/util.py
 convokit.egg-info/PKG-INFO
 convokit.egg-info/SOURCES.txt
 convokit.egg-info/dependency_links.txt
 convokit.egg-info/requires.txt
@@ -39,24 +41,24 @@
 convokit/forecaster/CRAFT/__init__.py
 convokit/hyperconvo/__init__.py
 convokit/hyperconvo/communityEmbedder.py
 convokit/hyperconvo/hyperconvo.py
 convokit/hyperconvo/hypergraph.py
 convokit/hyperconvo/threadEmbedder.py
 convokit/model/__init__.py
+convokit/model/backendMapper.py
 convokit/model/conversation.py
 convokit/model/convoKitIndex.py
 convokit/model/convoKitMatrix.py
 convokit/model/convoKitMeta.py
 convokit/model/corpus.py
 convokit/model/corpusComponent.py
-convokit/model/corpusHelper.py
 convokit/model/corpusUtil.py
+convokit/model/corpus_helpers.py
 convokit/model/speaker.py
-convokit/model/user.py
 convokit/model/utterance.py
 convokit/model/utteranceNode.py
 convokit/paired_prediction/__init__.py
 convokit/paired_prediction/pairedPrediction.py
 convokit/paired_prediction/pairedVectorPrediction.py
 convokit/paired_prediction/pairer.py
 convokit/paired_prediction/util.py
```

### Comparing `convokit-2.5.3/setup.py` & `convokit-3.0.0/setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,60 +1,69 @@
 from setuptools import setup
 
 setup(
     name="convokit",
     author="Jonathan P. Chang, Caleb Chiam, Liye Fu, Andrew Wang, Justine Zhang, Cristian Danescu-Niculescu-Mizil",
     author_email="cristian@cs.cornell.edu",
-    url="https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit",
-    description="Cornell Conversational Analysis Toolkit",
-    version="2.5.3",
-    packages=["convokit",
-                "convokit.bag_of_words",
-                "convokit.classifier",
-                "convokit.coordination",
-                "convokit.fighting_words",
-                "convokit.forecaster",
-                "convokit.forecaster.CRAFT",
-                "convokit.hyperconvo",
-                "convokit.model",
-                "convokit.paired_prediction",
-                "convokit.phrasing_motifs",
-                "convokit.politeness_collections",
-                "convokit.politeness_collections.politeness_api",
-                "convokit.politeness_collections.politeness_api.features",
-                "convokit.politeness_collections.politeness_local",
-                "convokit.politeness_collections.politeness_cscw_zh",
-                "convokit.politenessStrategies",
-                "convokit.prompt_types",
-                "convokit.ranker",
-                "convokit.text_processing",
-                "convokit.speaker_convo_helpers",
-                "convokit.speakerConvoDiversity",
-                "convokit.expected_context_framework",
-                "convokit.surprise"
-              ],
-    package_data={"convokit": ["data/*.txt", 
-                               "politeness_collections/politeness_local/lexicons/*.json",  
-                               "politeness_collections/politeness_cscw_zh/lexicons/*.json"]},
+    url="https://github.com/CornellNLP/ConvoKit",
+    description="ConvoKit",
+    version="3.0.0",
+    packages=[
+        "convokit",
+        "convokit.bag_of_words",
+        "convokit.classifier",
+        "convokit.coordination",
+        "convokit.fighting_words",
+        "convokit.forecaster",
+        "convokit.forecaster.CRAFT",
+        "convokit.hyperconvo",
+        "convokit.model",
+        "convokit.paired_prediction",
+        "convokit.phrasing_motifs",
+        "convokit.politeness_collections",
+        "convokit.politeness_collections.politeness_api",
+        "convokit.politeness_collections.politeness_api.features",
+        "convokit.politeness_collections.politeness_local",
+        "convokit.politeness_collections.politeness_cscw_zh",
+        "convokit.politenessStrategies",
+        "convokit.prompt_types",
+        "convokit.ranker",
+        "convokit.text_processing",
+        "convokit.speaker_convo_helpers",
+        "convokit.speakerConvoDiversity",
+        "convokit.expected_context_framework",
+        "convokit.surprise",
+    ],
+    package_data={
+        "convokit": [
+            "data/*.txt",
+            "politeness_collections/politeness_local/lexicons/*.json",
+            "politeness_collections/politeness_cscw_zh/lexicons/*.json",
+        ]
+    },
     install_requires=[
         "matplotlib>=3.0.0",
         "pandas>=0.23.4",
         "msgpack-numpy>=0.4.3.2",
         "spacy>=2.3.5",
         "scipy>=1.1.0",
         "scikit-learn>=0.20.0",
         "nltk>=3.4",
         "dill>=0.2.9",
         "joblib>=0.13.2",
-        "clean-text>=0.1.1",
-        "unidecode>=1.1.1"
+        "clean-text>=0.6.0",
+        "unidecode>=1.1.1",
+        "tqdm>=4.64.0",
+        "pymongo>=4.0",
+        "pyyaml>=5.4.1",
+        "dnspython>=1.16.0",
     ],
     extras_require={
-        'craft': ["torch>=0.12"],
+        "craft": ["torch>=0.12"],
     },
     classifiers=[
         "Programming Language :: Python",
-        "Programming Language :: Python :: 3.6",
-        "Programming Language :: Python :: 3.7",
         "Programming Language :: Python :: 3.8",
-    ]
+        "Programming Language :: Python :: 3.9",
+        "Programming Language :: Python :: 3.10",
+    ],
 )
```

